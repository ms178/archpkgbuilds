--- glibc-2.25/math/Makefile~	2017-02-05 15:28:43.000000000 +0000
+++ glibc-2.25/math/Makefile	2017-07-29 13:52:56.181213874 +0000
@@ -21,6 +21,8 @@

 include ../Makeconfig

+CFLAGS-.o += -fno-stack-protector -fno-math-errno -falign-functions=32 -flto=auto
+
 # Installed header files.
 headers		:= math.h bits/mathcalls.h \
 		   fpu_control.h complex.h bits/cmathcalls.h fenv.h \
--- glibc-2.37/sysdeps/generic/adaptive_spin_count.h~	2023-02-01 03:27:45.000000000 +0000
+++ glibc-2.37/sysdeps/generic/adaptive_spin_count.h	2023-04-20 16:24:07.132939021 +0000
@@ -19,4 +19,4 @@
 /* The choice of 100 spins for the default spin count for an adaptive spin
    is a completely arbitrary choice that has not been evaluated thoroughly
    using modern hardware.  */
-#define DEFAULT_ADAPTIVE_COUNT 100
+#define DEFAULT_ADAPTIVE_COUNT 5000
--- glibc-2.24/malloc/malloc.c~	2016-11-13 22:53:14.000000000 +0000
+++ glibc-2.24/malloc/malloc.c	2016-11-13 23:01:29.750884186 +0000
@@ -858,7 +858,7 @@
 #define M_TRIM_THRESHOLD       -1

 #ifndef DEFAULT_TRIM_THRESHOLD
-#define DEFAULT_TRIM_THRESHOLD (128 * 1024)
+#define DEFAULT_TRIM_THRESHOLD (512 * 1024)
 #endif

 /*
@@ -891,7 +891,7 @@
 #define M_TOP_PAD              -2

 #ifndef DEFAULT_TOP_PAD
-#define DEFAULT_TOP_PAD        (0)
+#define DEFAULT_TOP_PAD        (256 * 1024)
 #endif

 /*
--- glibc-2.36/malloc/malloc.c~	2022-07-29 22:03:09.000000000 +0000
+++ glibc-2.36/malloc/malloc.c	2022-09-02 18:38:17.273948072 +0000
@@ -958,7 +958,7 @@
 */

 #ifndef DEFAULT_MMAP_THRESHOLD_MIN
-#define DEFAULT_MMAP_THRESHOLD_MIN (128 * 1024)
+#define DEFAULT_MMAP_THRESHOLD_MIN (512 * 1024)
 #endif

 #ifndef DEFAULT_MMAP_THRESHOLD_MAX
--- glibc-2.36/malloc/arena.c~	2022-07-29 22:03:09.000000000 +0000
+++ glibc-2.36/malloc/arena.c	2022-11-08 17:43:39.951807284 +0000
@@ -940,11 +940,11 @@
               int n = __get_nprocs_sched ();

               if (n >= 1)
-                narenas_limit = NARENAS_FROM_NCORES (n);
+                narenas_limit = NARENAS_FROM_NCORES (n + 32);
               else
                 /* We have no information about the system.  Assume two
                    cores.  */
-                narenas_limit = NARENAS_FROM_NCORES (2);
+                narenas_limit = NARENAS_FROM_NCORES (2 + 32);
             }
         }
     repeat:;
--- glibc-2.36/malloc/malloc.c~	2022-09-02 18:38:17.000000000 +0000
+++ glibc-2.36/malloc/malloc.c	2022-11-08 20:32:05.797225851 +0000
@@ -2710,6 +2710,9 @@
 #endif
 	size = ALIGN_UP (size, GLRO(dl_pagesize));

+     if (size < 512 * 1024)
+	 size = 512 * 1024;
+
       /*
          Don't try to call MORECORE if argument is so big as to appear
          negative. Note that since mmap takes size_t arg, it may succeed
From 9c308b6c4800e39bed92becde22c4a5365510b35 Mon Sep 17 00:00:00 2001
From: Ikey Doherty <michael.i.doherty@intel.com>
Date: Thu, 9 Apr 2015 16:24:28 +0100
Subject: [PATCH] locale: Use cache location

Signed-off-by: Ikey Doherty <michael.i.doherty@intel.com>
---
 locale/loadarchive.c         | 2 +-
 locale/programs/locale.c     | 2 +-
 locale/programs/locarchive.c | 2 +-
 3 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/locale/loadarchive.c b/locale/loadarchive.c
index 0ac11af..4767db2 100644
--- a/locale/loadarchive.c
+++ b/locale/loadarchive.c
@@ -42,7 +42,7 @@


 /* Name of the locale archive file.  */
-static const char archfname[] = COMPLOCALEDIR "/locale-archive";
+static const char archfname[] = "/var/cache/locale/locale-archive";

 /* Size of initial mapping window, optimal if large enough to
    cover the header plus the initial locale.  */
diff --git a/locale/programs/locale.c b/locale/programs/locale.c
index 6cb3d5e..6fd43c6 100644
--- a/locale/programs/locale.c
+++ b/locale/programs/locale.c
@@ -45,7 +45,7 @@
 #include "../locarchive.h"
 #include <programs/xmalloc.h>

-#define ARCHIVE_NAME COMPLOCALEDIR "/locale-archive"
+#define ARCHIVE_NAME "/var/cache/locale/locale-archive"

 /* If set print the name of the category.  */
 static int show_category_name;
diff --git a/locale/programs/locarchive.c b/locale/programs/locarchive.c
index fadc3bf..9752b88 100644
--- a/locale/programs/locarchive.c
+++ b/locale/programs/locarchive.c
@@ -57,7 +57,7 @@

 extern const char *output_prefix;

-#define ARCHIVE_NAME COMPLOCALEDIR "/locale-archive"
+#define ARCHIVE_NAME "/var/cache/locale/locale-archive"

 static const char *locnames[] =
   {
--
2.7.0

--- glibc-2.21/nscd/nscd_helper.c~	2015-02-06 01:40:18.000000000 -0500
+++ glibc-2.21/nscd/nscd_helper.c	2015-04-24 09:04:49.404527044 -0400
@@ -560,6 +560,7 @@
 __nscd_open_socket (const char *key, size_t keylen, request_type type,
 		    void *response, size_t responselen)
 {
+  return -1;
   /* This should never happen and it is something the nscd daemon
      enforces, too.  He it helps to limit the amount of stack
      used.  */

--- glibc-2.29/sysdeps/x86/atomic-machine.h~	2019-01-31 16:45:36.000000000 +0000
+++ glibc-2.29/sysdeps/x86/atomic-machine.h	2019-01-31 22:21:32.316611237 +0000
@@ -566,6 +566,6 @@
 #define atomic_read_barrier() __asm ("" ::: "memory")
 #define atomic_write_barrier() __asm ("" ::: "memory")

-#define atomic_spin_nop() __asm ("pause")
+#define atomic_spin_nop() __asm ("lfence")

 #endif /* atomic-machine.h */

From: Guobing Chen <guobing.chen@intel.com>
Date: Tue, 21 May 2019 15:53:18 +0800
Subject: [PATCH] Set vector-width and alignment to fix GCC AVX issue

GCC does not always provide optimized binary code when compile under
arch=haswell or arch=skylake-avx512. Some generated functions like
libm's sin/cos/sincos/sqrt are even performing worse under AVX2/AVX512
compiling options. This patch restrict the vector-width case-by-case for
some senstive libm functions, and also add alignment (align(64)) to make
related functions perform good.

With this patch, on AVX2/AVX512 platforms, sqrt with 11~13% better
performance, exp with 24~26% better performance, exp2 with 7~9% better
performance. And sincos can performs ~97% better on AVX512 platform.

Signed-off-by: Guobing Chen <guobing.chen@intel.com>
---
 math/w_sqrt_compat.c            | 1 +
 sysdeps/ieee754/dbl-64/e_exp.c  | 1 +
 sysdeps/ieee754/dbl-64/e_exp2.c | 1 +
 sysdeps/x86_64/fpu/Makefile     | 3 +++
 4 files changed, 6 insertions(+)

diff --git a/math/w_sqrt_compat.c b/math/w_sqrt_compat.c
index cc5ba4b7..d977ec4c 100644
--- a/math/w_sqrt_compat.c
+++ b/math/w_sqrt_compat.c
@@ -26,6 +26,7 @@
 #if LIBM_SVID_COMPAT
 /* wrapper sqrt */
 double
+__attribute__((aligned(64)))
 __sqrt (double x)
 {
   if (__builtin_expect (isless (x, 0.0), 0) && _LIB_VERSION != _IEEE_)
diff --git a/sysdeps/ieee754/dbl-64/e_exp.c b/sysdeps/ieee754/dbl-64/e_exp.c
index 853d6ca7..7290caab 100644
--- a/sysdeps/ieee754/dbl-64/e_exp.c
+++ b/sysdeps/ieee754/dbl-64/e_exp.c
@@ -94,6 +94,7 @@ top12 (double x)

 double
 SECTION
+__attribute__((aligned(64)))
 __exp (double x)
 {
   uint32_t abstop;
diff --git a/sysdeps/ieee754/dbl-64/e_exp2.c b/sysdeps/ieee754/dbl-64/e_exp2.c
index 22cade8b..fe20e84c 100644
--- a/sysdeps/ieee754/dbl-64/e_exp2.c
+++ b/sysdeps/ieee754/dbl-64/e_exp2.c
@@ -87,6 +87,7 @@ top12 (double x)
 }

 double
+__attribute__((aligned(64)))
 __exp2 (double x)
 {
   uint32_t abstop;
diff --git a/sysdeps/x86_64/fpu/Makefile b/sysdeps/x86_64/fpu/Makefile
index b5f95890..30c71c84 100644
--- a/sysdeps/x86_64/fpu/Makefile
+++ b/sysdeps/x86_64/fpu/Makefile
@@ -240,4 +240,7 @@ endif
 # Limit vector width to 128 bits to work around this issue.  It improves
 # performance of sin and cos by more than 40% on Skylake.
 CFLAGS-branred.c = -mprefer-vector-width=128
+CFLAGS-s_sincos.c = -mprefer-vector-width=256
+CFLAGS-e_exp.c = -mprefer-vector-width=128
+CFLAGS-e_exp2.c = -mprefer-vector-width=128
 endif
--
2.21.0

diff --git a/sysdeps/x86_64/fpu/Makefile b/sysdeps/x86_64/fpu/Makefile
index b82cd126..56e68f04 100644
--- a/sysdeps/x86_64/fpu/Makefile
+++ b/sysdeps/x86_64/fpu/Makefile
@@ -136,8 +136,8 @@ ifeq ($(subdir)$(config-cflags-mprefer-vector-width),mathyes)
 #
 # Limit vector width to 128 bits to work around this issue.  It improves
 # performance of sin and cos by more than 40% on Skylake.
-CFLAGS-branred.c = -mprefer-vector-width=128
-CFLAGS-s_sincos.c = -mprefer-vector-width=256
-CFLAGS-e_exp.c = -mprefer-vector-width=128
-CFLAGS-e_exp2.c = -mprefer-vector-width=128
+CFLAGS-branred.c = -mprefer-vector-width=256 -flto=auto
+CFLAGS-s_sincos.c = -mprefer-vector-width=256 -flto=auto
+CFLAGS-e_exp.c = -mprefer-vector-width=256
+CFLAGS-e_exp2.c = -mprefer-vector-width=256
 endif

This patch align memmove unaligned routines to 64 byte.  Default 16 byte
alignment may cause upto 15% random perf regression for less than vector
size memmove.
---
 sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S b/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
index 838f8f8bff..85c0efd9e3 100644
--- a/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
+++ b/sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
@@ -207,7 +207,7 @@ ENTRY (MEMMOVE_CHK_SYMBOL (__memmove_chk, unaligned))
 END (MEMMOVE_CHK_SYMBOL (__memmove_chk, unaligned))
 #endif

-ENTRY (MEMMOVE_SYMBOL (__memmove, unaligned))
+ENTRY_P2ALIGN (MEMMOVE_SYMBOL (__memmove, unaligned), 6)
 	movq	%rdi, %rax
 L(start):
 # ifdef __ILP32__
--
2.44.0

v3: Add tag_new_usable.

Improve performance of __libc_malloc by splitting it into 2 parts: first handle
the tcache fastpath, then do the rest in a separate tailcalled function.
This results in significant performance gains since __libc_malloc doesn't need
to setup a frame and we delay tcache initialization and setting of errno until
later.

On Neoverse V2, bench-malloc-simple improves by 6.7% overall (up to 8.5% for
ST case) and bench-malloc-thread improves by 20.3% for 1 thread and 14.4% for
32 threads.

Regress passed, OK for commit?

---

diff --git a/malloc/malloc.c b/malloc/malloc.c
index 7e4c1399385051b1989cbc0ac14266d2138695af..a0bc733482532ce34684d0357cb9076b03ac8a52 100644
--- a/malloc/malloc.c
+++ b/malloc/malloc.c
@@ -1325,6 +1325,9 @@ nextchunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 static __always_inline size_t
 checked_request2size (size_t req) __nonnull (1)
 {
+  _Static_assert (PTRDIFF_MAX <= SIZE_MAX / 2,
+                  "PTRDIFF_MAX is not more than half of SIZE_MAX");
+
   if (__glibc_unlikely (req > PTRDIFF_MAX))
     return 0;
 
@@ -3380,26 +3383,17 @@ tcache_thread_shutdown (void)
 #endif /* !USE_TCACHE  */
 
 #if IS_IN (libc)
-void *
-__libc_malloc (size_t bytes)
+
+static void * __attribute_noinline__
+__libc_malloc2 (size_t bytes)
 {
   mstate ar_ptr;
   void *victim;
 
-  _Static_assert (PTRDIFF_MAX <= SIZE_MAX / 2,
-                  "PTRDIFF_MAX is not more than half of SIZE_MAX");
-
   if (!__malloc_initialized)
     ptmalloc_init ();
-#if USE_TCACHE
-  bool err = tcache_try_malloc (bytes, &victim);
-
-  if (err)
-      return NULL;
 
-  if (victim)
-      return tag_new_usable (victim);
-#endif
+  MAYBE_INIT_TCACHE ();
 
   if (SINGLE_THREAD_P)
     {
@@ -3430,6 +3424,19 @@ __libc_malloc (size_t bytes)
           ar_ptr == arena_for_chunk (mem2chunk (victim)));
   return victim;
 }
+
+void *
+__libc_malloc (size_t bytes)
+{
+#if USE_TCACHE
+  size_t tc_idx = csize2tidx (checked_request2size (bytes));
+
+  if (tcache_available (tc_idx))
+    return tag_new_usable (tcache_get (tc_idx));
+#endif
+
+  return __libc_malloc2 (bytes);
+}
 libc_hidden_def (__libc_malloc)
 
 void
