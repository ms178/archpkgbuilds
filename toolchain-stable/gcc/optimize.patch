The following avoids collecting all loops exit blocks into bitmaps
and computing the union of those up the loop tree possibly repeatedly.
Instead we make sure to do this only once for each loop with a
definition possibly requiring a LC phi node plus make sure to
leverage recorded exits to avoid the intermediate bitmap allocation.

Bootstrapped and tested on x86_64-unknown-linux-gnu, pushed.

	* tree-ssa-loop-manip.cc (compute_live_loop_exits): Take
	the def loop exit block bitmap as argument instead of
	re-computing it here.
	(add_exit_phis_var): Adjust.
	(loop_name_cmp): New function.
	(add_exit_phis): Sort variables to insert LC PHI nodes
	after definition loop, for each definition loop compute
	the exit block bitmap once.
	(get_loops_exit): Remove.
	(rewrite_into_loop_closed_ssa_1): Do not pre-record
	all loop exit blocks into bitmaps.  Record loop exits
	if required.
---
 gcc/tree-ssa-loop-manip.cc | 95 ++++++++++++++++++++++----------------
 1 file changed, 56 insertions(+), 39 deletions(-)

diff --git a/gcc/tree-ssa-loop-manip.cc b/gcc/tree-ssa-loop-manip.cc
index 9f3b62652ea..0324ff60a0f 100644
--- a/gcc/tree-ssa-loop-manip.cc
+++ b/gcc/tree-ssa-loop-manip.cc
@@ -183,12 +183,14 @@ find_sibling_superloop (class loop *use_loop, class loop *def_loop)
 /* DEF_BB is a basic block containing a DEF that needs rewriting into
    loop-closed SSA form.  USE_BLOCKS is the set of basic blocks containing
    uses of DEF that "escape" from the loop containing DEF_BB (i.e. blocks in
-   USE_BLOCKS are dominated by DEF_BB but not in the loop father of DEF_B).
+   USE_BLOCKS are dominated by DEF_BB but not in the loop father of DEF_BB).
    ALL_EXITS[I] is the set of all basic blocks that exit loop I.
+   DEF_LOOP_EXITS is a bitmap of loop exit blocks that exit the loop
+   containing DEF_BB or its outer loops.

-   Compute the subset of LOOP_EXITS that exit the loop containing DEF_BB
-   or one of its loop fathers, in which DEF is live.  This set is returned
-   in the bitmap LIVE_EXITS.
+   Compute the subset of loop exit destinations that exit the loop
+   containing DEF_BB or one of its loop fathers, in which DEF is live.
+   This set is returned in the bitmap LIVE_EXITS.

    Instead of computing the complete livein set of the def, we use the loop
    nesting tree as a form of poor man's structure analysis.  This greatly
@@ -197,18 +199,17 @@ find_sibling_superloop (class loop *use_loop, class loop *def_loop)

 static void
 compute_live_loop_exits (bitmap live_exits, bitmap use_blocks,
-			 bitmap *loop_exits, basic_block def_bb)
+			 basic_block def_bb, bitmap def_loop_exits)
 {
   unsigned i;
   bitmap_iterator bi;
   class loop *def_loop = def_bb->loop_father;
   unsigned def_loop_depth = loop_depth (def_loop);
-  bitmap def_loop_exits;

   /* Normally the work list size is bounded by the number of basic
      blocks in the largest loop.  We don't know this number, but we
      can be fairly sure that it will be relatively small.  */
-  auto_vec<basic_block> worklist (MAX (8, n_basic_blocks_for_fn (cfun) / 128));
+  auto_vec<basic_block, 8> worklist (MAX (8, n_basic_blocks_for_fn (cfun) / 128));

   EXECUTE_IF_SET_IN_BITMAP (use_blocks, 0, i, bi)
     {
@@ -272,13 +273,7 @@ compute_live_loop_exits (bitmap live_exits, bitmap use_blocks,
 	}
     }

-  def_loop_exits = BITMAP_ALLOC (&loop_renamer_obstack);
-  for (class loop *loop = def_loop;
-       loop != current_loops->tree_root;
-       loop = loop_outer (loop))
-    bitmap_ior_into (def_loop_exits, loop_exits[loop->num]);
   bitmap_and_into (live_exits, def_loop_exits);
-  BITMAP_FREE (def_loop_exits);
 }

 /* Add a loop-closing PHI for VAR in basic block EXIT.  */
@@ -322,23 +317,33 @@ add_exit_phi (basic_block exit, tree var)
    Exits of the loops are stored in LOOP_EXITS.  */

 static void
-add_exit_phis_var (tree var, bitmap use_blocks, bitmap *loop_exits)
+add_exit_phis_var (tree var, bitmap use_blocks, bitmap def_loop_exits)
 {
   unsigned index;
   bitmap_iterator bi;
   basic_block def_bb = gimple_bb (SSA_NAME_DEF_STMT (var));
-  bitmap live_exits = BITMAP_ALLOC (&loop_renamer_obstack);

   gcc_checking_assert (! bitmap_bit_p (use_blocks, def_bb->index));

-  compute_live_loop_exits (live_exits, use_blocks, loop_exits, def_bb);
+  auto_bitmap live_exits (&loop_renamer_obstack);
+  compute_live_loop_exits (live_exits, use_blocks, def_bb, def_loop_exits);

   EXECUTE_IF_SET_IN_BITMAP (live_exits, 0, index, bi)
     {
       add_exit_phi (BASIC_BLOCK_FOR_FN (cfun, index), var);
     }
+}

-  BITMAP_FREE (live_exits);
+static int
+loop_name_cmp (const void *p1, const void *p2)
+{
+  auto l1 = (const std::pair<int, int> *)p1;
+  auto l2 = (const std::pair<int, int> *)p2;
+  if (l1->first < l2->first)
+    return -1;
+  else if (l1->first > l2->first)
+    return 1;
+  return 0;
 }

 /* Add exit phis for the names marked in NAMES_TO_RENAME.
@@ -346,31 +351,38 @@ add_exit_phis_var (tree var, bitmap use_blocks, bitmap *loop_exits)
    names are used are stored in USE_BLOCKS.  */

 static void
-add_exit_phis (bitmap names_to_rename, bitmap *use_blocks, bitmap *loop_exits)
+add_exit_phis (bitmap names_to_rename, bitmap *use_blocks)
 {
   unsigned i;
   bitmap_iterator bi;

+  /* Sort names_to_rename after definition loop so we can avoid re-computing
+     def_loop_exits.  */
+  auto_vec<std::pair<int, int> > names (bitmap_count_bits (names_to_rename));
   EXECUTE_IF_SET_IN_BITMAP (names_to_rename, 0, i, bi)
     {
-      add_exit_phis_var (ssa_name (i), use_blocks[i], loop_exits);
+      tree name = ssa_name (i);
+      loop_p def_loop = gimple_bb (SSA_NAME_DEF_STMT (name))->loop_father;
+      names.quick_push (std::make_pair (def_loop->num, i));
     }
-}
+  names.qsort (loop_name_cmp);

-/* Fill the array of bitmaps LOOP_EXITS with all loop exit edge targets.  */
-
-static void
-get_loops_exits (bitmap *loop_exits)
-{
-  unsigned j;
-  edge e;
-
-  for (auto loop : loops_list (cfun, 0))
+  auto_bitmap def_loop_exits (&loop_renamer_obstack);
+  loop_p last_def_loop = NULL;
+  for (auto p : names)
     {
-      auto_vec<edge> exit_edges = get_loop_exit_edges (loop);
-      loop_exits[loop->num] = BITMAP_ALLOC (&loop_renamer_obstack);
-      FOR_EACH_VEC_ELT (exit_edges, j, e)
-        bitmap_set_bit (loop_exits[loop->num], e->dest->index);
+      loop_p def_loop = get_loop (cfun, p.first);
+      if (def_loop != last_def_loop)
+	{
+	  bitmap_clear (def_loop_exits);
+	  last_def_loop = def_loop;
+	  for (class loop *loop = def_loop; loop != current_loops->tree_root;
+	       loop = loop_outer (loop))
+	    for (auto exit = loop->exits->next; exit->e; exit = exit->next)
+	      bitmap_set_bit (def_loop_exits, exit->e->dest->index);
+	}
+      add_exit_phis_var (ssa_name (p.second), use_blocks[p.second],
+			 def_loop_exits);
     }
 }

@@ -566,16 +578,21 @@ rewrite_into_loop_closed_ssa_1 (bitmap changed_bbs, unsigned update_flag,

   if (!bitmap_empty_p (names_to_rename))
     {
-      /* An array of bitmaps where LOOP_EXITS[I] is the set of basic blocks
-	 that are the destination of an edge exiting loop number I.  */
-      bitmap *loop_exits = XNEWVEC (bitmap, number_of_loops (cfun));
-      get_loops_exits (loop_exits);
+      bool release_recorded_exits_p = false;
+      if (!loops_state_satisfies_p (LOOPS_HAVE_RECORDED_EXITS))
+	{
+	  /* Doing one scan over the whole function is cheaper than
+	     traversing the loop tree and gathering BBs of each loop.  */
+	  record_loop_exits ();
+	  release_recorded_exits_p = true;
+	}

       /* Add the PHI nodes on exits of the loops for the names we need to
 	 rewrite.  */
-      add_exit_phis (names_to_rename, use_blocks, loop_exits);
+      add_exit_phis (names_to_rename, use_blocks);

-      free (loop_exits);
+      if (release_recorded_exits_p)
+	release_recorded_exits (cfun);

       /* Fix up all the names found to be used outside their original
 	 loops.  */
--
2.35.3

In many cases loops have only one exit or a variable is only live
across one of the exits.  In this case we know that all uses
outside of the loop will be dominated by the single LC PHI node
we insert.  If that holds for all variables requiring LC SSA PHIs
then we can simplify the update_ssa process, avoiding the
(iterated) dominance frontier computations.

Bootstrapped and tested on x86_64-unknown-linux-gnu, pushed.

	* tree-ssa-loop-manip.cc (add_exit_phis_var): Return the
	number of LC PHIs inserted.
	(add_exit_phis): Return whether any variable required
	multiple LC PHI nodes.
	(rewrite_into_loop_closed_ssa_1): Use TODO_update_ssa_no_phi
	when possible.
---
 gcc/tree-ssa-loop-manip.cc | 30 +++++++++++++++++++++---------
 1 file changed, 21 insertions(+), 9 deletions(-)

diff --git a/gcc/tree-ssa-loop-manip.cc b/gcc/tree-ssa-loop-manip.cc
index 0324ff60a0f..c531f1f12fd 100644
--- a/gcc/tree-ssa-loop-manip.cc
+++ b/gcc/tree-ssa-loop-manip.cc
@@ -314,9 +314,10 @@ add_exit_phi (basic_block exit, tree var)
 }

 /* Add exit phis for VAR that is used in LIVEIN.
-   Exits of the loops are stored in LOOP_EXITS.  */
+   Exits of the loops are stored in LOOP_EXITS.  Returns the number
+   of PHIs added for VAR.  */

-static void
+static unsigned
 add_exit_phis_var (tree var, bitmap use_blocks, bitmap def_loop_exits)
 {
   unsigned index;
@@ -328,10 +329,13 @@ add_exit_phis_var (tree var, bitmap use_blocks, bitmap def_loop_exits)
   auto_bitmap live_exits (&loop_renamer_obstack);
   compute_live_loop_exits (live_exits, use_blocks, def_bb, def_loop_exits);

+  unsigned cnt = 0;
   EXECUTE_IF_SET_IN_BITMAP (live_exits, 0, index, bi)
     {
       add_exit_phi (BASIC_BLOCK_FOR_FN (cfun, index), var);
+      cnt++;
     }
+  return cnt;
 }

 static int
@@ -348,13 +352,15 @@ loop_name_cmp (const void *p1, const void *p2)

 /* Add exit phis for the names marked in NAMES_TO_RENAME.
    Exits of the loops are stored in EXITS.  Sets of blocks where the ssa
-   names are used are stored in USE_BLOCKS.  */
+   names are used are stored in USE_BLOCKS.  Returns whether any name
+   required multiple LC PHI nodes.  */

-static void
+static bool
 add_exit_phis (bitmap names_to_rename, bitmap *use_blocks)
 {
   unsigned i;
   bitmap_iterator bi;
+  bool multiple_p = false;

   /* Sort names_to_rename after definition loop so we can avoid re-computing
      def_loop_exits.  */
@@ -381,9 +387,12 @@ add_exit_phis (bitmap names_to_rename, bitmap *use_blocks)
 	    for (auto exit = loop->exits->next; exit->e; exit = exit->next)
 	      bitmap_set_bit (def_loop_exits, exit->e->dest->index);
 	}
-      add_exit_phis_var (ssa_name (p.second), use_blocks[p.second],
-			 def_loop_exits);
+      if (add_exit_phis_var (ssa_name (p.second), use_blocks[p.second],
+			     def_loop_exits) > 1)
+	multiple_p = true;
     }
+
+  return multiple_p;
 }

 /* For USE in BB, if it is used outside of the loop it is defined in,
@@ -588,15 +597,18 @@ rewrite_into_loop_closed_ssa_1 (bitmap changed_bbs, unsigned update_flag,
 	}

       /* Add the PHI nodes on exits of the loops for the names we need to
-	 rewrite.  */
-      add_exit_phis (names_to_rename, use_blocks);
+	 rewrite.  When no variable required multiple LC PHI nodes to be
+	 inserted then we know that all uses outside of the loop are
+	 dominated by the single LC SSA definition and no further PHI
+	 node insertions are required.  */
+      bool need_phis_p = add_exit_phis (names_to_rename, use_blocks);

       if (release_recorded_exits_p)
 	release_recorded_exits (cfun);

       /* Fix up all the names found to be used outside their original
 	 loops.  */
-      update_ssa (TODO_update_ssa);
+      update_ssa (need_phis_p ? TODO_update_ssa : TODO_update_ssa_no_phi);
     }

   bitmap_obstack_release (&loop_renamer_obstack);
--
2.35.3

From fb268a37704b1598a84051c735514ff38adad038 Mon Sep 17 00:00:00 2001
From: Frederik Harwath <frederik@codesourcery.com>
Date: Wed, 18 May 2022 07:59:42 +0200
Subject: [PATCH] graphite: Extend SCoP detection dump output

Extend dump output to make understanding why Graphite rejects to
include a loop in a SCoP easier (for GCC developers).

gcc/ChangeLog:

	* graphite-scop-detection.cc (scop_detection::can_represent_loop):
	Output reason for failure to dump file.
	(scop_detection::harmful_loop_in_region): Likewise.
	(scop_detection::graphite_can_represent_expr): Likewise.
	(scop_detection::stmt_has_simple_data_refs_p): Likewise.
	(scop_detection::stmt_simple_for_scop_p): Likewise.
	(print_sese_loop_numbers): New function.
	(scop_detection::add_scop): Use from here.

gcc/testsuite/ChangeLog:

	* gcc.dg/graphite/scop-22a.c: New test.
---
 gcc/graphite-scop-detection.cc           | 184 ++++++++++++++++++++---
 gcc/testsuite/gcc.dg/graphite/scop-22a.c |  56 +++++++
 2 files changed, 219 insertions(+), 21 deletions(-)
 create mode 100644 gcc/testsuite/gcc.dg/graphite/scop-22a.c

diff --git a/gcc/graphite-scop-detection.cc b/gcc/graphite-scop-detection.cc
index 8c0ee9975579..9792d87ee0ae 100644
--- a/gcc/graphite-scop-detection.cc
+++ b/gcc/graphite-scop-detection.cc
@@ -69,12 +69,27 @@ public:
     fprintf (output.dump_file, "%d", i);
     return output;
   }
+
   friend debug_printer &
   operator<< (debug_printer &output, const char *s)
   {
     fprintf (output.dump_file, "%s", s);
     return output;
   }
+
+  friend debug_printer &
+  operator<< (debug_printer &output, gimple* stmt)
+  {
+    print_gimple_stmt (output.dump_file, stmt, 0, TDF_VOPS | TDF_MEMSYMS);
+    return output;
+  }
+
+  friend debug_printer &
+  operator<< (debug_printer &output, tree t)
+  {
+    print_generic_expr (output.dump_file, t, TDF_SLIM);
+    return output;
+  }
 } dp;

 #define DEBUG_PRINT(args) do \
@@ -506,6 +521,27 @@ scop_detection::merge_sese (sese_l first, sese_l second) const
   return combined;
 }

+/* Print the loop numbers of the loops contained in SESE to FILE. */
+
+static void
+print_sese_loop_numbers (FILE *file, sese_l sese)
+{
+  bool first_loop = true;
+  for (loop_p nest = sese.entry->dest->loop_father; nest; nest = nest->next)
+    {
+      if (!loop_in_sese_p (nest, sese))
+        break;
+
+      for (auto loop : loops_list (cfun, LI_INCLUDE_ROOT, nest))
+        {
+          gcc_assert (loop_in_sese_p (loop, sese));
+
+          fprintf (file, "%s%d", first_loop ? "" : ", ", loop->num);
+          first_loop = false;
+        }
+    }
+}
+
 /* Build scop outer->inner if possible.  */

 void
@@ -519,6 +555,10 @@ scop_detection::build_scop_depth (loop_p loop)
       if (! next
 	  || harmful_loop_in_region (next))
 	{
+	  if (next)
+	    DEBUG_PRINT (dp << "[scop-detection] Discarding SCoP on loops ";
+			 print_sese_loop_numbers (dump_file, next);
+			 dp << " because of harmful loops\n");
 	  if (s)
 	    add_scop (s);
 	  build_scop_depth (loop);
@@ -560,14 +600,63 @@ scop_detection::can_represent_loop (loop_p loop, sese_l scop)
       || !single_pred_p (loop->latch)
       || exit->src != single_pred (loop->latch)
       || !empty_block_p (loop->latch))
-    return false;
+    {
+      DEBUG_PRINT (dp << "[can_represent_loop-fail] Loop shape unsupported.\n");
+      return false;
+    }
+
+  bool edge_irreducible = (loop_preheader_edge (loop)->flags
+			   & EDGE_IRREDUCIBLE_LOOP);
+  if (edge_irreducible)
+    {
+      DEBUG_PRINT (dp << "[can_represent_loop-fail] "
+			 "Loop is not a natural loop.\n");
+      return false;
+    }
+
+  bool niter_is_unconditional = number_of_iterations_exit (loop,
+							   single_exit (loop),
+							   &niter_desc, false);
+
+  if (!niter_is_unconditional)
+    {
+      DEBUG_PRINT (dp << "[can_represent_loop-fail] "
+			 "Loop niter not unconditional.\n"
+			 "Condition: " << niter_desc.assumptions << "\n");
+      return false;
+    }
+
+  niter = number_of_latch_executions (loop);
+  if (!niter)
+    {
+      DEBUG_PRINT (dp << "[can_represent_loop-fail] Loop niter unknown.\n");
+      return false;
+    }
+  if (!niter_desc.control.no_overflow)
+    {
+      DEBUG_PRINT (dp << "[can_represent_loop-fail] Loop niter can overflow.\n");
+      return false;
+    }

-  return !(loop_preheader_edge (loop)->flags & EDGE_IRREDUCIBLE_LOOP)
-    && number_of_iterations_exit (loop, single_exit (loop), &niter_desc, false)
-    && niter_desc.control.no_overflow
-    && (niter = number_of_latch_executions (loop))
-    && !chrec_contains_undetermined (niter)
-    && graphite_can_represent_expr (scop, loop, niter);
+  bool undetermined_coefficients = chrec_contains_undetermined (niter);
+  if (undetermined_coefficients)
+    {
+      DEBUG_PRINT (dp << "[can_represent_loop-fail] "
+			 "Loop niter chrec contains undetermined "
+			 "coefficients.\n");
+      return false;
+    }
+
+  bool can_represent_expr = graphite_can_represent_expr (scop, loop, niter);
+  if (!can_represent_expr)
+    {
+      DEBUG_PRINT (dp << "[can_represent_loop-fail] "
+		      << "Loop niter expression cannot be represented: "
+		      << niter << "\n");
+      return false;
+    }
+
+  return true;
 }

 /* Return true when BEGIN is the preheader edge of a loop with a single exit
@@ -640,6 +729,13 @@ scop_detection::add_scop (sese_l s)

   scops.safe_push (s);
   DEBUG_PRINT (dp << "[scop-detection] Adding SCoP: "; print_sese (dump_file, s));
+
+  if (dump_file && dump_flags & TDF_DETAILS)
+    {
+      fprintf (dump_file, "Loops in SCoP: ");
+      print_sese_loop_numbers (dump_file, s);
+      fprintf (dump_file, "\n");
+    }
 }

 /* Return true when a statement in SCOP cannot be represented by Graphite.  */
@@ -665,7 +761,12 @@ scop_detection::harmful_loop_in_region (sese_l scop) const

       /* The basic block should not be part of an irreducible loop.  */
       if (bb->flags & BB_IRREDUCIBLE_LOOP)
-	return true;
+	{
+	  DEBUG_PRINT (dp << "[scop-detection-fail] Found bb in irreducible "
+			     "loop.\n");
+
+	  return true;
+	}

       /* Check for unstructured control flow: CFG not generated by structured
 	 if-then-else.  */
@@ -676,7 +777,11 @@ scop_detection::harmful_loop_in_region (sese_l scop) const
 	  FOR_EACH_EDGE (e, ei, bb->succs)
 	    if (!dominated_by_p (CDI_POST_DOMINATORS, bb, e->dest)
 		&& !dominated_by_p (CDI_DOMINATORS, e->dest, bb))
-	      return true;
+	      {
+		DEBUG_PRINT (dp << "[scop-detection-fail] Found unstructured "
+				   "control flow.\n");
+		return true;
+	      }
 	}

       /* Collect all loops in the current region.  */
@@ -688,7 +793,11 @@ scop_detection::harmful_loop_in_region (sese_l scop) const
       for (gimple_stmt_iterator gsi = gsi_start_bb (bb);
 	   !gsi_end_p (gsi); gsi_next (&gsi))
 	if (!stmt_simple_for_scop_p (scop, gsi_stmt (gsi), bb))
-	  return true;
+	  {
+	    DEBUG_PRINT (dp << "[scop-detection-fail] "
+			       "Found harmful statement.\n");
+	    return true;
+	  }

       for (basic_block dom = first_dom_son (CDI_DOMINATORS, bb);
 	   dom;
@@ -731,9 +840,10 @@ scop_detection::harmful_loop_in_region (sese_l scop) const
 	  && ! loop_nest_has_data_refs (loop))
 	{
 	  DEBUG_PRINT (dp << "[scop-detection-fail] loop_" << loop->num
-		       << "does not have any data reference.\n");
+		       << " does not have any data reference.\n");
 	  return true;
 	}
+      DEBUG_PRINT (dp << "[scop-detection] loop_" << loop->num << " is harmless.\n");
     }

   return false;
@@ -922,7 +1032,21 @@ scop_detection::graphite_can_represent_expr (sese_l scop, loop_p loop,
 					     tree expr)
 {
   tree scev = cached_scalar_evolution_in_region (scop, loop, expr);
-  return graphite_can_represent_scev (scop, scev);
+  bool can_represent = graphite_can_represent_scev (scop, scev);
+
+  if (!can_represent)
+    {
+      if (dump_file)
+	{
+	  fprintf (dump_file,
+		   "[graphite_can_represent_expr] Cannot represent scev \"");
+	  print_generic_expr (dump_file, scev, TDF_SLIM);
+	  fprintf (dump_file, "\" of expression ");
+	  print_generic_expr (dump_file, expr, TDF_SLIM);
+	  fprintf (dump_file, " in loop %d\n", loop->num);
+	}
+    }
+  return can_represent;
 }

 /* Return true if the data references of STMT can be represented by Graphite.
@@ -938,7 +1062,11 @@ scop_detection::stmt_has_simple_data_refs_p (sese_l scop, gimple *stmt)

   auto_vec<data_reference_p> drs;
   if (! graphite_find_data_references_in_stmt (nest, loop, stmt, &drs))
-    return false;
+    {
+      DEBUG_PRINT (dp << "[stmt_has_simple_data_refs_p] "
+			 "Unanalyzable statement.\n");
+      return false;
+    }

   int j;
   data_reference_p dr;
@@ -946,7 +1074,12 @@ scop_detection::stmt_has_simple_data_refs_p (sese_l scop, gimple *stmt)
     {
       for (unsigned i = 0; i < DR_NUM_DIMENSIONS (dr); ++i)
 	if (! graphite_can_represent_scev (scop, DR_ACCESS_FN (dr, i)))
-	  return false;
+	  {
+	    DEBUG_PRINT (dp << "[stmt_has_simple_data_refs_p] "
+			       "Cannot represent access function SCEV: "
+			    << DR_ACCESS_FN (dr, i) << "\n");
+	    return false;
+	  }
     }

   return true;
@@ -1027,14 +1160,23 @@ scop_detection::stmt_simple_for_scop_p (sese_l scop, gimple *stmt,
 	for (unsigned i = 0; i < 2; ++i)
 	  {
 	    tree op = gimple_op (stmt, i);
-	    if (!graphite_can_represent_expr (scop, loop, op)
-		/* We can only constrain on integer type.  */
-		|| ! INTEGRAL_TYPE_P (TREE_TYPE (op)))
+	    if (!graphite_can_represent_expr (scop, loop, op))
+	      {
+		DEBUG_PRINT (dump_printf_loc (MSG_MISSED_OPTIMIZATION, stmt,
+					      "[scop-detection-fail] "
+					      "Graphite cannot represent cond "
+					      "stmt operator expression.\n"));
+		DEBUG_PRINT (dp << op << "\n");
+		return false;
+	      }
+
+	    if (! INTEGRAL_TYPE_P (TREE_TYPE (op)))
 	      {
-		DEBUG_PRINT (dp << "[scop-detection-fail] "
-				<< "Graphite cannot represent stmt:\n";
-			     print_gimple_stmt (dump_file, stmt, 0,
-						TDF_VOPS | TDF_MEMSYMS));
+		DEBUG_PRINT (dump_printf_loc (MSG_MISSED_OPTIMIZATION, stmt,
+					      "[scop-detection-fail] "
+					      "Graphite cannot represent cond "
+					      "statement operator. "
+					      "Type must be integral.\n"));
 		return false;
 	      }
 	  }
diff --git a/gcc/testsuite/gcc.dg/graphite/scop-22a.c b/gcc/testsuite/gcc.dg/graphite/scop-22a.c
new file mode 100644
index 000000000000..00d4b5315aeb
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/graphite/scop-22a.c
@@ -0,0 +1,56 @@
+/* { dg-require-effective-target size32plus } */
+double u[1782225];
+
+void foo(int N, int *res)
+{
+  int i, j;
+  double a, b;
+  double sum = 0.0;
+
+  for (j = 3; j < N; j = j * j)
+    {
+      sum += a + b;
+    }
+
+  /* Next two loops form first SCoP */
+  for (i = 0; i < N; i++)
+    sum += u[i];
+
+  for (i = 0; i < N; i++)
+    {
+      a = u[i];
+      u[i] = i * i;
+      b = u[i];
+      sum += a + b;
+    }
+
+  for (j = 3; j < N; j = j * j)
+    {
+      sum += a + b;
+    }
+
+  for (j = 3; j < N; j = j * j)
+    {
+      sum += a + b;
+    }
+
+  /* Next two loop-nests form second SCoP */
+  for (i = 0; i < N; i++)
+    sum += u[i];
+
+  for (i = 0; i < N; i++)
+    for (j = 0; j < N; j++)
+      {
+	a = u[i];
+	u[i] = i * i;
+	b = u[j];
+	sum += a + b;
+      }
+
+  *res = sum + N;
+}
+
+/* { dg-final { scan-tree-dump-times "number of SCoPs: 2" 1 "graphite"} } */
+/* { dg-final { scan-tree-dump-times "Loops in SCoP" 2 "graphite"} } */
+/* { dg-final { scan-tree-dump "Loops in SCoP: 2, 3" "graphite"} } */
+/* { dg-final { scan-tree-dump "Loops in SCoP: 6, 7, 8" "graphite"} } */
--
2.36.0

graphite: Rename isl_id_for_ssa_name

The SSA names for which this function gets used are always SCoP
parameters and hence "isl_id_for_parameter" is a better name.  It also
explains the prefix "P_" for those names in the ISL representation.

gcc/ChangeLog:

	* graphite-sese-to-poly.cc (isl_id_for_ssa_name): Rename to ...
	(isl_id_for_parameter): ... this new function name.
	(build_scop_context): Adjust function use.

 gcc/graphite-sese-to-poly.cc | 21 +++++++++++----------
 1 file changed, 11 insertions(+), 10 deletions(-)

diff --git a/gcc/graphite-sese-to-poly.cc b/gcc/graphite-sese-to-poly.cc
index 5a6d779052c..ea67b267e1c 100644
--- a/gcc/graphite-sese-to-poly.cc
+++ b/gcc/graphite-sese-to-poly.cc
@@ -100,14 +100,15 @@ extract_affine_mul (scop_p s, tree e, __isl_take isl_space *space)
   return isl_pw_aff_mul (lhs, rhs);
 }

-/* Return an isl identifier from the name of the ssa_name E.  */
+/* Return an isl identifier for the parameter P.  */

 static isl_id *
-isl_id_for_ssa_name (scop_p s, tree e)
+isl_id_for_parameter (scop_p s, tree p)
 {
-  char name1[14];
-  snprintf (name1, sizeof (name1), "P_%d", SSA_NAME_VERSION (e));
-  return isl_id_alloc (s->isl_context, name1, e);
+  gcc_checking_assert (TREE_CODE (p) == SSA_NAME);
+  char name[14];
+  snprintf (name, sizeof (name), "P_%d", SSA_NAME_VERSION (p));
+  return isl_id_alloc (s->isl_context, name, p);
 }

 /* Return an isl identifier for the data reference DR.  Data references and
@@ -898,15 +899,15 @@ build_scop_context (scop_p scop)
   isl_space *space = isl_space_set_alloc (scop->isl_context, nbp, 0);

   unsigned i;
-  tree e;
-  FOR_EACH_VEC_ELT (region->params, i, e)
+  tree p;
+  FOR_EACH_VEC_ELT (region->params, i, p)
     space = isl_space_set_dim_id (space, isl_dim_param, i,
-                                  isl_id_for_ssa_name (scop, e));
+				  isl_id_for_parameter (scop, p));

   scop->param_context = isl_set_universe (space);

-  FOR_EACH_VEC_ELT (region->params, i, e)
-    add_param_constraints (scop, i, e);
+  FOR_EACH_VEC_ELT (region->params, i, p)
+    add_param_constraints (scop, i, p);
 }

 /* Return true when loop A is nested in loop B.  */

graphite: Fix minor mistakes in comments

gcc/ChangeLog:

	* graphite-sese-to-poly.cc (build_poly_sr_1): Fix a typo and
	a reference to a variable which does not exist.
	* graphite-isl-ast-to-gimple.cc (gsi_insert_earliest): Fix typo
	in comment.

 gcc/graphite-isl-ast-to-gimple.cc | 2 +-
 gcc/graphite-sese-to-poly.cc      | 4 ++--
 2 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/gcc/graphite-isl-ast-to-gimple.cc b/gcc/graphite-isl-ast-to-gimple.cc
index 45ed7704807..844b6d4e2b5 100644
--- a/gcc/graphite-isl-ast-to-gimple.cc
+++ b/gcc/graphite-isl-ast-to-gimple.cc
@@ -1014,7 +1014,7 @@ gsi_insert_earliest (gimple_seq seq)
   basic_block begin_bb = get_entry_bb (codegen_region);

   /* Inserting the gimple statements in a vector because gimple_seq behave
-     in strage ways when inserting the stmts from it into different basic
+     in strange ways when inserting the stmts from it into different basic
      blocks one at a time.  */
   auto_vec<gimple *, 3> stmts;
   for (gimple_stmt_iterator gsi = gsi_start (seq); !gsi_end_p (gsi);
diff --git a/gcc/graphite-sese-to-poly.cc b/gcc/graphite-sese-to-poly.cc
index ea67b267e1c..51ba3af204f 100644
--- a/gcc/graphite-sese-to-poly.cc
+++ b/gcc/graphite-sese-to-poly.cc
@@ -649,14 +649,14 @@ build_poly_sr_1 (poly_bb_p pbb, gimple *stmt, tree var, enum poly_dr_type kind,
 		 isl_map *acc, isl_set *subscript_sizes)
 {
   scop_p scop = PBB_SCOP (pbb);
-  /* Each scalar variables has a unique alias set number starting from
+  /* Each scalar variable has a unique alias set number starting from
      the maximum alias set assigned to a dr.  */
   int alias_set = scop->max_alias_set + SSA_NAME_VERSION (var);
   subscript_sizes = isl_set_fix_si (subscript_sizes, isl_dim_set, 0,
 				    alias_set);

   /* Add a constrain to the ACCESSES polyhedron for the alias set of
-     data reference DR.  */
+     the reference.  */
   isl_constraint *c
     = isl_equality_alloc (isl_local_space_from_space (isl_map_get_space (acc)));
   c = isl_constraint_set_constant_si (c, -alias_set);

The code to remove LC PHI nodes in clean_up_loop_closed_phi does not handle
virtual operands because may_propagate_copy generally returns false
for them.  The following copies the merge_blocks variant for
dealing with them.

This fixes a missed jump threading in gcc.dg/auto-init-uninit-4.c
which manifests in bogus uninit diagnostics.

Bootstrap and regtest pending on x86_64-unknown-linux-gnu.

	PR tree-optimization/106186
	* tree-ssa-propagate.cc (clean_up_loop_closed_phi):
	Properly handle virtual PHI nodes.
---
 gcc/tree-ssa-propagate.cc | 16 +++++++++++++++-
 1 file changed, 15 insertions(+), 1 deletion(-)

diff --git a/gcc/tree-ssa-propagate.cc b/gcc/tree-ssa-propagate.cc
index 163b24f0e69..9dc4bfd85bf 100644
--- a/gcc/tree-ssa-propagate.cc
+++ b/gcc/tree-ssa-propagate.cc
@@ -1272,7 +1272,21 @@ clean_up_loop_closed_phi (function *fun)
 	      rhs = gimple_phi_arg_def (phi, 0);
 	      lhs = gimple_phi_result (phi);

-	      if (rhs && may_propagate_copy (lhs, rhs))
+	      if (virtual_operand_p (rhs))
+		{
+		  imm_use_iterator iter;
+		  use_operand_p use_p;
+		  gimple *stmt;
+
+		  FOR_EACH_IMM_USE_STMT (stmt, iter, lhs)
+		    FOR_EACH_IMM_USE_ON_STMT (use_p, iter)
+		      SET_USE (use_p, rhs);
+
+		  if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (lhs))
+		    SSA_NAME_OCCURS_IN_ABNORMAL_PHI (rhs) = 1;
+		  remove_phi_node (&gsi, true);
+		}
+	      else if (may_propagate_copy (lhs, rhs))
 		{
 		  /* Dump details.  */
 		  if (dump_file && (dump_flags & TDF_DETAILS))
--
2.35.3

The following avoids copying and using blocks_to_update to
the interesting_blocks sbitmap when doing update_ssa as it is
unused besides the redundant query in the domwalk.

Bootstrapped and tested on x86_64-unknown-linux-gnu, pushed.

	* tree-into-ssa.cc (rewrite_update_dom_walker::before_dom_children):
	Do not look at interesting_blocks which is a copy of
	blocks_to_update.
	(update_ssa): Do not initialize it.
	(pass_build_ssa::execute): Set interesting_blocks to NULL
	after releasing it.
---
 gcc/tree-into-ssa.cc | 22 ++++++----------------
 1 file changed, 6 insertions(+), 16 deletions(-)

diff --git a/gcc/tree-into-ssa.cc b/gcc/tree-into-ssa.cc
index c4e40e8fb08..c90651c3a89 100644
--- a/gcc/tree-into-ssa.cc
+++ b/gcc/tree-into-ssa.cc
@@ -2214,15 +2214,11 @@ rewrite_update_dom_walker::before_dom_children (basic_block bb)
     }

   /* Step 2.  Rewrite every variable used in each statement in the block.  */
-  if (bitmap_bit_p (interesting_blocks, bb->index))
-    {
-      gcc_checking_assert (bitmap_bit_p (blocks_to_update, bb->index));
-      for (gimple_stmt_iterator gsi = gsi_start_bb (bb); !gsi_end_p (gsi); )
-	if (rewrite_update_stmt (gsi_stmt (gsi), gsi))
-	  gsi_remove (&gsi, true);
-	else
-	  gsi_next (&gsi);
-    }
+  for (gimple_stmt_iterator gsi = gsi_start_bb (bb); !gsi_end_p (gsi); )
+    if (rewrite_update_stmt (gsi_stmt (gsi), gsi))
+      gsi_remove (&gsi, true);
+    else
+      gsi_next (&gsi);

   /* Step 3.  Update PHI nodes.  */
   rewrite_update_phi_arguments (bb);
@@ -2460,6 +2456,7 @@ pass_build_ssa::execute (function *fun)
   free (dfs);

   sbitmap_free (interesting_blocks);
+  interesting_blocks = NULL;

   fini_ssa_renamer ();

@@ -3503,15 +3500,8 @@ update_ssa (unsigned update_flags)
     get_var_info (sym)->info.current_def = NULL_TREE;

   /* Now start the renaming process at START_BB.  */
-  interesting_blocks = sbitmap_alloc (last_basic_block_for_fn (cfun));
-  bitmap_clear (interesting_blocks);
-  EXECUTE_IF_SET_IN_BITMAP (blocks_to_update, 0, i, bi)
-    bitmap_set_bit (interesting_blocks, i);
-
   rewrite_blocks (start_bb, REWRITE_UPDATE);

-  sbitmap_free (interesting_blocks);
-
   /* Debugging dumps.  */
   if (dump_file)
     {
--
2.35.3

1. Add a predicate for constant vectors which can be converted to integer
constants suitable for constant integer stores.  For a 8-byte constant
vector, the converted 64-bit integer must be valid for store with 64-bit
immediate, which is a 64-bit integer sign-extended from a 32-bit integer.
2. Add a new pattern to allow 2-byte, 4-byte and 8-byte constant vector
stores, like

(set (mem:V2HI (reg:DI 84))
     (const_vector:V2HI [(const_int 0 [0]) (const_int 1 [0x1])]))

3. After reload, convert constant vector stores to constant integer
stores, like

(set (mem:SI (reg:DI 5 di [84]))
     (const_int 65536 [0x10000]))

For

void
foo (short * c)
{
  c[0] = 0;
  c[1] = 1;
}

it generates

	movl	$65536, (%rdi)

instead of

	movl	.LC0(%rip), %eax
	movl	%eax, (%rdi)

gcc/

	PR target/106022
	* config/i386/i386-protos.h (ix86_convert_const_vector_to_integer):
	New.
	* config/i386/i386.cc (ix86_convert_const_vector_to_integer):
	New.
	* config/i386/mmx.md (V_16_32_64): New.
	(*mov<mode>_imm): New patterns for stores with 16-bit, 32-bit
	and 64-bit constant vector.
	* config/i386/predicates.md (x86_64_const_vector_operand): New.

gcc/testsuite/

	PR target/106022
	* gcc.target/i386/pr106022-1.c: New test.
	* gcc.target/i386/pr106022-2.c: Likewise.
	* gcc.target/i386/pr106022-3.c: Likewise.
	* gcc.target/i386/pr106022-4.c: Likewise.
---
 gcc/config/i386/i386-protos.h              |  2 +
 gcc/config/i386/i386.cc                    | 47 ++++++++++++++++++++++
 gcc/config/i386/mmx.md                     | 37 +++++++++++++++++
 gcc/config/i386/predicates.md              | 11 +++++
 gcc/testsuite/gcc.target/i386/pr106022-1.c | 13 ++++++
 gcc/testsuite/gcc.target/i386/pr106022-2.c | 14 +++++++
 gcc/testsuite/gcc.target/i386/pr106022-3.c | 14 +++++++
 gcc/testsuite/gcc.target/i386/pr106022-4.c | 14 +++++++
 8 files changed, 152 insertions(+)
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106022-1.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106022-2.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106022-3.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106022-4.c

diff --git a/gcc/config/i386/i386-protos.h b/gcc/config/i386/i386-protos.h
index 3596ce81ecf..cf847751ac5 100644
--- a/gcc/config/i386/i386-protos.h
+++ b/gcc/config/i386/i386-protos.h
@@ -122,6 +122,8 @@ extern void ix86_expand_unary_operator (enum rtx_code, machine_mode,
 					rtx[]);
 extern rtx ix86_build_const_vector (machine_mode, bool, rtx);
 extern rtx ix86_build_signbit_mask (machine_mode, bool, bool);
+extern HOST_WIDE_INT ix86_convert_const_vector_to_integer (rtx,
+							   machine_mode);
 extern void ix86_split_convert_uns_si_sse (rtx[]);
 extern void ix86_expand_convert_uns_didf_sse (rtx, rtx);
 extern void ix86_expand_convert_uns_sixf_sse (rtx, rtx);
diff --git a/gcc/config/i386/i386.cc b/gcc/config/i386/i386.cc
index b15b4893bb9..0cfe9962f75 100644
--- a/gcc/config/i386/i386.cc
+++ b/gcc/config/i386/i386.cc
@@ -15723,6 +15723,53 @@ ix86_build_signbit_mask (machine_mode mode, bool vect, bool invert)
   return force_reg (vec_mode, v);
 }

+/* Return HOST_WIDE_INT for const vector OP in MODE.  */
+
+HOST_WIDE_INT
+ix86_convert_const_vector_to_integer (rtx op, machine_mode mode)
+{
+  if (GET_MODE_SIZE (mode) > UNITS_PER_WORD)
+    gcc_unreachable ();
+
+  int nunits = GET_MODE_NUNITS (mode);
+  wide_int val = wi::zero (GET_MODE_BITSIZE (mode));
+  machine_mode innermode = GET_MODE_INNER (mode);
+  unsigned int innermode_bits = GET_MODE_BITSIZE (innermode);
+
+  switch (mode)
+    {
+    case E_V2QImode:
+    case E_V4QImode:
+    case E_V2HImode:
+    case E_V8QImode:
+    case E_V4HImode:
+    case E_V2SImode:
+      for (int i = 0; i < nunits; ++i)
+	{
+	  int v = INTVAL (XVECEXP (op, 0, i));
+	  wide_int wv = wi::shwi (v, innermode_bits);
+	  val = wi::insert (val, wv, innermode_bits * i, innermode_bits);
+	}
+      break;
+    case E_V2HFmode:
+    case E_V4HFmode:
+    case E_V2SFmode:
+      for (int i = 0; i < nunits; ++i)
+	{
+	  rtx x = XVECEXP (op, 0, i);
+	  int v = real_to_target (NULL, CONST_DOUBLE_REAL_VALUE (x),
+				  REAL_MODE_FORMAT (innermode));
+	  wide_int wv = wi::shwi (v, innermode_bits);
+	  val = wi::insert (val, wv, innermode_bits * i, innermode_bits);
+	}
+      break;
+    default:
+      gcc_unreachable ();
+    }
+
+  return val.to_shwi ();
+}
+
 /* Return TRUE or FALSE depending on whether the first SET in INSN
    has source and destination with matching CC modes, and that the
    CC mode is at least as constrained as REQ_MODE.  */
diff --git a/gcc/config/i386/mmx.md b/gcc/config/i386/mmx.md
index ba53007a35e..3294c1e6274 100644
--- a/gcc/config/i386/mmx.md
+++ b/gcc/config/i386/mmx.md
@@ -69,6 +69,12 @@ (define_mode_iterator VI_16_32 [V4QI V2QI V2HI])
 ;; 4-byte and 2-byte QImode vector modes
 (define_mode_iterator VI1_16_32 [V4QI V2QI])

+;; All 2-byte, 4-byte and 8-byte vector modes with more than 1 element
+(define_mode_iterator V_16_32_64
+   [V2QI V4QI V2HI V2HF
+    (V8QI "TARGET_64BIT") (V4HI "TARGET_64BIT") (V4HF "TARGET_64BIT")
+    (V2SI "TARGET_64BIT") (V2SF "TARGET_64BIT")])
+
 ;; V2S* modes
 (define_mode_iterator V2FI [V2SF V2SI])

@@ -331,6 +337,37 @@ (define_insn "*mov<mode>_internal"
 	   ]
 	   (symbol_ref "true")))])

+;; 16-bit, 32-bit and 64-bit constant vector stores.  After reload,
+;; convert them to immediate integer stores.
+(define_insn_and_split "*mov<mode>_imm"
+  [(set (match_operand:V_16_32_64 0 "memory_operand" "=m")
+	(match_operand:V_16_32_64 1 "x86_64_const_vector_operand" "i"))]
+  ""
+  "#"
+  "&& reload_completed"
+  [(set (match_dup 0) (match_dup 1))]
+{
+  HOST_WIDE_INT val = ix86_convert_const_vector_to_integer (operands[1],
+							    <MODE>mode);
+  operands[1] = GEN_INT (val);
+  machine_mode mode;
+  switch (GET_MODE_SIZE (<MODE>mode))
+    {
+    case 2:
+      mode = HImode;
+      break;
+    case 4:
+      mode = SImode;
+      break;
+    case 8:
+      mode = DImode;
+      break;
+    default:
+      gcc_unreachable ();
+    }
+  operands[0] = lowpart_subreg (mode, operands[0], <MODE>mode);
+})
+
 ;; For TARGET_64BIT we always round up to 8 bytes.
 (define_insn "*push<mode>2_rex64"
   [(set (match_operand:V_32 0 "push_operand" "=X,X")
diff --git a/gcc/config/i386/predicates.md b/gcc/config/i386/predicates.md
index 128144f1050..c71c453cceb 100644
--- a/gcc/config/i386/predicates.md
+++ b/gcc/config/i386/predicates.md
@@ -1194,6 +1194,17 @@ (define_predicate "reg_or_const_vector_operand"
   (ior (match_operand 0 "register_operand")
        (match_code "const_vector")))

+;; Return true when OP is CONST_VECTOR which can be converted to a
+;; sign extended 32-bit integer.
+(define_predicate "x86_64_const_vector_operand"
+  (match_code "const_vector")
+{
+  if (GET_MODE_SIZE (mode) > UNITS_PER_WORD)
+    return false;
+  HOST_WIDE_INT val = ix86_convert_const_vector_to_integer (op, mode);
+  return trunc_int_for_mode (val, SImode) == val;
+})
+
 ;; Return true when OP is nonimmediate or standard SSE constant.
 (define_predicate "nonimmediate_or_sse_const_operand"
   (ior (match_operand 0 "nonimmediate_operand")
diff --git a/gcc/testsuite/gcc.target/i386/pr106022-1.c b/gcc/testsuite/gcc.target/i386/pr106022-1.c
new file mode 100644
index 00000000000..6643b4c30f1
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106022-1.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -march=x86-64" } */
+
+void
+foo (char *c)
+{
+  c[0] = 0;
+  c[1] = 1;
+  c[2] = 2;
+  c[3] = 3;
+}
+
+/* { dg-final { scan-assembler-times "movl\[ \\t\]+\\\$50462976," 1 } } */
diff --git a/gcc/testsuite/gcc.target/i386/pr106022-2.c b/gcc/testsuite/gcc.target/i386/pr106022-2.c
new file mode 100644
index 00000000000..0e79fb53297
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106022-2.c
@@ -0,0 +1,14 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -march=x86-64" } */
+
+void
+foo (int *c)
+{
+  c = __builtin_assume_aligned (c, 16);
+  c[0] = -1;
+  c[1] = -1;
+}
+
+/* { dg-final { scan-assembler-times "movq\[ \\t\]+\[^\n\]*%xmm" 2 { target { ia32 } } } } */
+/* { dg-final { scan-assembler-times "movq\[ \\t\]+\\\$-1," 1 { target { ! ia32 } } } } */
+/* { dg-final { scan-assembler-not "xmm" { target { ! ia32 } } } } */
diff --git a/gcc/testsuite/gcc.target/i386/pr106022-3.c b/gcc/testsuite/gcc.target/i386/pr106022-3.c
new file mode 100644
index 00000000000..8b0c2a8f6d8
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106022-3.c
@@ -0,0 +1,14 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -march=x86-64" } */
+
+void
+foo (int *c)
+{
+  c[0] = 0;
+  c[1] = 1;
+  c[2] = 2;
+  c[3] = 3;
+}
+
+/* { dg-final { scan-assembler-times "movdqa\[ \\t\]+\[^\n\]*%xmm" 1 } } */
+/* { dg-final { scan-assembler-times "movups\[ \\t\]+\[^\n\]*%xmm" 1 } } */
diff --git a/gcc/testsuite/gcc.target/i386/pr106022-4.c b/gcc/testsuite/gcc.target/i386/pr106022-4.c
new file mode 100644
index 00000000000..8ecda170af3
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106022-4.c
@@ -0,0 +1,14 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -march=x86-64" } */
+
+void
+foo (float *c)
+{
+  c[0] = 2.3;
+  c[1] = 0.0;
+}
+
+/* { dg-final { scan-assembler-times "movl\[ \\t\]+\\\$0x40133333" 1 { target { ia32 } } } } */
+/* { dg-final { scan-assembler-times "movl\[ \\t\]+\\\$0x00000000" 1 { target { ia32 } } } } */
+/* { dg-final { scan-assembler-times "movq\[ \\t\]+\\\$1075000115," 1 { target { ! ia32 } } } } */
+/* { dg-final { scan-assembler-not "xmm" } } */
--
2.36.1

From 842ab824d565d5ab823bb6da55ad7adb36f87bf3 Mon Sep 17 00:00:00 2001
From: Haochen Jiang <haochen.jiang@intel.com>
Date: Mon, 30 May 2022 17:12:31 +0800
Subject: [PATCH] i386: Extend cvtps2pd to memory

gcc/ChangeLog:

	PR target/43618
	* config/i386/sse.md (extendv2sfv2df2): New define_expand.
	(sse2_cvtps2pd_<mask_name>): Change constraint of operands[1].
	(*sse2_cvtps2pd_<mask_name>_1): Rename from extendvsdfv2df2.

gcc/testsuite/ChangeLog:

	PR target/43618
	* gcc.target/i386/pr43618-1.c: New test.
---
 gcc/config/i386/sse.md                    | 26 ++++++++++++++++++-----
 gcc/testsuite/gcc.target/i386/pr43618-1.c | 12 +++++++++++
 2 files changed, 33 insertions(+), 5 deletions(-)
 create mode 100644 gcc/testsuite/gcc.target/i386/pr43618-1.c

diff --git a/gcc/config/i386/sse.md b/gcc/config/i386/sse.md
index 8b2602bfa79..742bb6c222c 100644
--- a/gcc/config/i386/sse.md
+++ b/gcc/config/i386/sse.md
@@ -9175,11 +9175,27 @@
    (set_attr "prefix" "evex")
    (set_attr "mode" "<sseinsnmode>")])

+(define_expand "extendv2sfv2df2"
+  [(set (match_operand:V2DF 0 "register_operand")
+	(float_extend:V2DF
+	  (match_operand:V2SF 1 "nonimmediate_operand")))]
+  "TARGET_MMX_WITH_SSE"
+{
+  if (!MEM_P (operands[1]))
+    {
+      operands[1] = lowpart_subreg (V4SFmode,
+				    force_reg (V2SFmode, operands[1]),
+				    V2SFmode);
+      emit_insn (gen_sse2_cvtps2pd (operands[0], operands[1]));
+      DONE;
+    }
+})
+
 (define_insn "sse2_cvtps2pd<mask_name>"
   [(set (match_operand:V2DF 0 "register_operand" "=v")
 	(float_extend:V2DF
 	  (vec_select:V2SF
-	    (match_operand:V4SF 1 "vector_operand" "vm")
+	    (match_operand:V4SF 1 "register_operand" "v")
 	    (parallel [(const_int 0) (const_int 1)]))))]
   "TARGET_SSE2 && <mask_avx512vl_condition>"
   "%vcvtps2pd\t{%1, %0<mask_operand2>|%0<mask_operand2>, %q1}"
@@ -9191,12 +9207,12 @@
    (set_attr "prefix" "maybe_vex")
    (set_attr "mode" "V2DF")])

-(define_insn "extendv2sfv2df2"
+(define_insn "*sse2_cvtps2pd<mask_name>_1"
   [(set (match_operand:V2DF 0 "register_operand" "=v")
 	(float_extend:V2DF
-	  (match_operand:V2SF 1 "register_operand" "v")))]
-  "TARGET_MMX_WITH_SSE"
-  "%vcvtps2pd\t{%1, %0|%0, %1}"
+	  (match_operand:V2SF 1 "memory_operand" "m")))]
+  "TARGET_SSE2 && <mask_avx512vl_condition>"
+  "%vcvtps2pd\t{%1, %0<mask_operand2>|%0<mask_operand2>, %q1}"
   [(set_attr "type" "ssecvt")
    (set_attr "amdfam10_decode" "direct")
    (set_attr "athlon_decode" "double")
diff --git a/gcc/testsuite/gcc.target/i386/pr43618-1.c b/gcc/testsuite/gcc.target/i386/pr43618-1.c
new file mode 100644
index 00000000000..7d16f0e0cf9
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr43618-1.c
@@ -0,0 +1,12 @@
+/* { dg-do compile { target { ! ia32 } } } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler-not "movq" } } */
+/* { dg-final { scan-assembler "cvtps2pd" } } */
+
+void
+foo (float a[2], double b[2])
+{
+    int i;
+    for (i = 0; i < 2; i++)
+      b[i] = a[i];
+}
--
2.18.1

diff --git a/gcc/config/i386/sse.md b/gcc/config/i386/sse.md
index 3396ff748da..5b91c7be54e 100644
--- a/gcc/config/i386/sse.md
+++ b/gcc/config/i386/sse.md
@@ -9208,7 +9208,7 @@
    (set_attr "prefix" "maybe_vex")
    (set_attr "mode" "V2DF")])

-(define_insn "*sse2_cvtps2pd<mask_name>_1"
+(define_insn "sse2_cvtps2pd<mask_name>_1"
   [(set (match_operand:V2DF 0 "register_operand" "=v")
 	(float_extend:V2DF
 	  (match_operand:V2SF 1 "memory_operand" "m")))]
@@ -9270,7 +9270,15 @@
 	  (vec_select:V2SF
 	    (match_operand:V4SF 1 "vector_operand")
 	    (parallel [(const_int 0) (const_int 1)]))))]
-  "TARGET_SSE2")
+  "TARGET_SSE2"
+{
+  if (MEM_P (operands[1]))
+    {
+      operands[1] = adjust_address_nv (operands[1], V2SFmode, 0);
+      emit_insn (gen_sse2_cvtps2pd_1 (operands[0], operands[1]));
+      DONE;
+    }
+})

 (define_expand "vec_unpacks_lo_v8sf"
   [(set (match_operand:V4DF 0 "register_operand")
diff --git a/gcc/testsuite/g++.target/i386/pr106180-1.C b/gcc/testsuite/g++.target/i386/pr106180-1.C
new file mode 100644
index 00000000000..7f734536001
--- /dev/null
+++ b/gcc/testsuite/g++.target/i386/pr106180-1.C
@@ -0,0 +1,31 @@
+/* { dg-do compile } */
+/* { dg-options "-O3 -c -ffloat-store  -std=c++11" } */
+
+struct PointT
+{
+  double x, y;
+};
+using PointF = PointT;
+
+template <int _Nm> struct __array_traits { typedef PointT _Type[_Nm]; };
+template <int _Nm> struct array
+{
+  typename __array_traits<_Nm>::_Type _M_elems;
+};
+
+float SampleGrid_low, SampleGrid_high;
+using QuadrilateralF = array<4>;
+struct PerspectiveTransform
+{
+  PerspectiveTransform (QuadrilateralF, QuadrilateralF);
+};
+
+void SampleGrid()
+{
+  PerspectiveTransform
+  {
+    { PointF {SampleGrid_high, SampleGrid_low},
+      SampleGrid_low, SampleGrid_high },
+    {}
+  };
+}
--
2.18.2

The target optimize pragma path to initialize extra target specific
builtins missed handling of the pure_p flag which in turn causes
extra clobber side-effects of gather builtins leading to unexpected
issues downhill.

Bootstrap and regtest running on x86_64-unknown-linux-gnu, will push
as obvious if that succeeds.

	* config/i386/i386-builtins.cc (ix86_add_new_builtins): Properly
	set DECL_PURE_P.

	* g++.dg/pr106219.C: New testcase.
---
 gcc/config/i386/i386-builtins.cc |  2 ++
 gcc/testsuite/g++.dg/pr106219.C  | 31 +++++++++++++++++++++++++++++++
 2 files changed, 33 insertions(+)
 create mode 100644 gcc/testsuite/g++.dg/pr106219.C

diff --git a/gcc/config/i386/i386-builtins.cc b/gcc/config/i386/i386-builtins.cc
index 96743e6122d..fe7243c3837 100644
--- a/gcc/config/i386/i386-builtins.cc
+++ b/gcc/config/i386/i386-builtins.cc
@@ -385,6 +385,8 @@ ix86_add_new_builtins (HOST_WIDE_INT isa, HOST_WIDE_INT isa2)
 	  ix86_builtins[i] = decl;
 	  if (ix86_builtins_isa[i].const_p)
 	    TREE_READONLY (decl) = 1;
+	  if (ix86_builtins_isa[i].pure_p)
+	    DECL_PURE_P (decl) = 1;
 	}
     }

diff --git a/gcc/testsuite/g++.dg/pr106219.C b/gcc/testsuite/g++.dg/pr106219.C
new file mode 100644
index 00000000000..3cad1507d5f
--- /dev/null
+++ b/gcc/testsuite/g++.dg/pr106219.C
@@ -0,0 +1,31 @@
+// { dg-do compile }
+// { dg-options "-O3" }
+// { dg-additional-options "-march=bdver2" { target x86_64-*-* } }
+
+int max(int __b) {
+  if (0 < __b)
+    return __b;
+  return 0;
+}
+struct Plane {
+  Plane(int, int);
+  int *Row();
+};
+#ifdef __x86_64__
+#pragma GCC target "sse2,ssse3,avx,avx2"
+#endif
+float *ConvolveXSampleAndTranspose_rowp;
+int ConvolveXSampleAndTranspose_res, ConvolveXSampleAndTranspose_r;
+void ConvolveXSampleAndTranspose() {
+  Plane out(0, ConvolveXSampleAndTranspose_res);
+  for (int y;;) {
+    float sum;
+    for (int i = ConvolveXSampleAndTranspose_r; i; ++i)
+      sum += i;
+    for (; ConvolveXSampleAndTranspose_r; ++ConvolveXSampleAndTranspose_r)
+      sum +=
+          ConvolveXSampleAndTranspose_rowp[max(ConvolveXSampleAndTranspose_r)] *
+          ConvolveXSampleAndTranspose_r;
+    out.Row()[y] = sum;
+  }
+}
--
2.35.3

diff --git a/gcc/ipa-visibility.cc b/gcc/ipa-visibility.cc
index 8a27e7bcd..3ed2b7cf6 100644
--- a/gcc/ipa-visibility.cc
+++ b/gcc/ipa-visibility.cc
@@ -873,6 +873,25 @@ function_and_variable_visibility (bool whole_program)
 	}
     }

+  if (symtab->state >= IPA_SSA)
+    {
+      FOR_EACH_VARIABLE (vnode)
+	{
+	  tree decl = vnode->decl;
+
+	  /* Upgrade TLS access model based on optimized visibility status,
+	     unless it was specified explicitly or no references remain.  */
+	  if (DECL_THREAD_LOCAL_P (decl)
+	      && !lookup_attribute ("tls_model", DECL_ATTRIBUTES (decl))
+	      && vnode->ref_list.referring.length ())
+	    {
+	      enum tls_model new_model = decl_default_tls_model (decl);
+	      gcc_checking_assert (new_model >= decl_tls_model (decl));
+	      set_decl_tls_model (decl, new_model);
+	    }
+	}
+    }
+
   if (dump_file)
     {
       fprintf (dump_file, "\nMarking local functions:");
diff --git a/gcc/varasm.cc b/gcc/varasm.cc
index 4db8506b1..de149e82c 100644
--- a/gcc/varasm.cc
+++ b/gcc/varasm.cc
@@ -6679,6 +6679,36 @@ init_varasm_once (void)
 #endif
 }

+/* Determine whether SYMBOL is used in any optimized function.  */
+
+static bool
+have_optimized_refs (struct symtab_node *symbol)
+{
+  struct ipa_ref *ref;
+
+  for (int i = 0; symbol->iterate_referring (i, ref); i++)
+    {
+      cgraph_node *cnode = dyn_cast <cgraph_node *> (ref->referring);
+
+      if (cnode && opt_for_fn (cnode->decl, optimize))
+	return true;
+    }
+
+  return false;
+}
+
+/* Check if promoting general-dynamic TLS access model to local-dynamic is
+   desirable for DECL.  */
+
+static bool
+optimize_dyn_tls_for_decl_p (const_tree decl)
+{
+  if (optimize)
+    return true;
+  return symtab->state >= IPA && have_optimized_refs (symtab_node::get (decl));
+}
+
+
 enum tls_model
 decl_default_tls_model (const_tree decl)
 {
@@ -6696,7 +6726,7 @@ decl_default_tls_model (const_tree decl)

   /* Local dynamic is inefficient when we're not combining the
      parts of the address.  */
-  else if (optimize && is_local)
+  else if (is_local && optimize_dyn_tls_for_decl_p (decl))
     kind = TLS_MODEL_LOCAL_DYNAMIC;
   else
     kind = TLS_MODEL_GLOBAL_DYNAMIC;
diff --git a/gcc/testsuite/gcc.dg/tls/vis-attr-gd.c b/gcc/testsuite/gcc.dg/tls/vis-attr-gd.c
new file mode 100644
index 000000000..89a248a80
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/tls/vis-attr-gd.c
@@ -0,0 +1,12 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target fpic } */
+/* { dg-require-effective-target tls } */
+/* { dg-options "-O2 -fPIC -fdump-ipa-whole-program" } */
+
+// tls_model should be global-dynamic due to explicitly specified attribute
+__attribute__((tls_model("global-dynamic")))
+__thread int x;
+
+void reference() { x++; }
+
+/* { dg-final { scan-ipa-dump "Varpool flags: tls-global-dynamic" "whole-program" } } */
diff --git a/gcc/testsuite/gcc.dg/tls/vis-attr-hidden-gd.c b/gcc/testsuite/gcc.dg/tls/vis-attr-hidden-gd.c
new file mode 100644
index 000000000..e32565588
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/tls/vis-attr-hidden-gd.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target fpic } */
+/* { dg-require-effective-target tls } */
+/* { dg-options "-O2 -fPIC -fdump-ipa-whole-program" } */
+
+// tls_model should be global-dynamic due to explicitly specified attribute
+__attribute__((visibility("hidden")))
+__attribute__((tls_model("global-dynamic")))
+__thread int x;
+
+void reference() { x++; }
+
+/* { dg-final { scan-ipa-dump "Varpool flags: tls-global-dynamic" "whole-program" } } */
diff --git a/gcc/testsuite/gcc.dg/tls/vis-attr-hidden.c b/gcc/testsuite/gcc.dg/tls/vis-attr-hidden.c
new file mode 100644
index 000000000..0d43fc565
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/tls/vis-attr-hidden.c
@@ -0,0 +1,12 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target fpic } */
+/* { dg-require-effective-target tls } */
+/* { dg-options "-O2 -fPIC -fdump-ipa-whole-program" } */
+
+//tls_model should be local-dynamic due to visibility("hidden")
+__attribute__((visibility("hidden")))
+__thread int x;
+
+void reference() { x++; }
+
+/* { dg-final { scan-ipa-dump "Varpool flags: tls-local-dynamic" "whole-program" } } */
diff --git a/gcc/testsuite/gcc.dg/tls/vis-flag-hidden-gd.c b/gcc/testsuite/gcc.dg/tls/vis-flag-hidden-gd.c
new file mode 100644
index 000000000..cad41e0c8
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/tls/vis-flag-hidden-gd.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target fpic } */
+/* { dg-require-effective-target tls } */
+/* { dg-options "-O2 -fPIC -fdump-ipa-whole-program -fvisibility=hidden" } */
+
+
+// tls_model should be global-dynamic due to explicitly specified attribute
+__attribute__((tls_model("global-dynamic")))
+__thread int x;
+
+void reference() { x++; }
+
+/* { dg-final { scan-ipa-dump "Varpool flags: tls-global-dynamic" "whole-program" } } */
diff --git a/gcc/testsuite/gcc.dg/tls/vis-flag-hidden.c b/gcc/testsuite/gcc.dg/tls/vis-flag-hidden.c
new file mode 100644
index 000000000..a15df092d
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/tls/vis-flag-hidden.c
@@ -0,0 +1,12 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target fpic } */
+/* { dg-require-effective-target tls } */
+/* { dg-options "-O2 -fPIC -fdump-ipa-whole-program -fvisibility=hidden" } */
+
+
+// tls_model should be local-dynamic due to -fvisibility=hidden
+__thread int x;
+
+void reference() { x++; }
+
+/* { dg-final { scan-ipa-dump "Varpool flags: tls-local-dynamic" "whole-program" } } */
diff --git a/gcc/testsuite/gcc.dg/tls/vis-pragma-hidden-gd.c b/gcc/testsuite/gcc.dg/tls/vis-pragma-hidden-gd.c
new file mode 100644
index 000000000..3b3598134
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/tls/vis-pragma-hidden-gd.c
@@ -0,0 +1,17 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target fpic } */
+/* { dg-require-effective-target tls } */
+/* { dg-options "-O2 -fPIC -fdump-ipa-whole-program" } */
+
+
+#pragma GCC visibility push(hidden)
+
+// tls_model should be global-dynamic due to explicitly specified attribute
+__attribute__((tls_model("global-dynamic")))
+__thread int x;
+
+#pragma GCC visibility pop
+
+void reference() { x++; }
+
+/* { dg-final { scan-ipa-dump "Varpool flags: tls-global-dynamic" "whole-program" } } */
diff --git a/gcc/testsuite/gcc.dg/tls/vis-pragma-hidden.c b/gcc/testsuite/gcc.dg/tls/vis-pragma-hidden.c
new file mode 100644
index 000000000..1be976442
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/tls/vis-pragma-hidden.c
@@ -0,0 +1,16 @@
+/* { dg-do compile } */
+/* { dg-require-effective-target fpic } */
+/* { dg-require-effective-target tls } */
+/* { dg-options "-O2 -fPIC -fdump-ipa-whole-program" } */
+
+
+#pragma GCC visibility push(hidden)
+
+// tls_model should be local-dynamic due to a pragma
+__thread int x;
+
+#pragma GCC visibility pop
+
+void reference() { x++; }
+
+/* { dg-final { scan-ipa-dump "Varpool flags: tls-local-dynamic" "whole-program" } } */
--
2.35.1

This patch allows for strchr(x, c) to the replace with memchr(x, c,
strlen(x) + 1) if strlen(x) has already been computed earlier in the
tree.

Handles PR95821: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95821

Since memchr doesn't need to re-find the null terminator it is faster
than strchr.

bootstrapped and tested on x86_64-linux.

	PR tree-optimization/95821

gcc/

	* tree-ssa-strlen.cc (strlen_pass::handle_builtin_strchr): Emit
	memchr instead of strchr if strlen already computed.

gcc/testsuite/

	* c-c++-common/pr95821-1.c: New test.
	* c-c++-common/pr95821-2.c: New test.
	* c-c++-common/pr95821-3.c: New test.
	* c-c++-common/pr95821-4.c: New test.
	* c-c++-common/pr95821-5.c: New test.
	* c-c++-common/pr95821-6.c: New test.
	* c-c++-common/pr95821-7.c: New test.
	* c-c++-common/pr95821-8.c: New test.
---
 gcc/testsuite/c-c++-common/pr95821-1.c |  15 ++++
 gcc/testsuite/c-c++-common/pr95821-2.c |  17 ++++
 gcc/testsuite/c-c++-common/pr95821-3.c |  17 ++++
 gcc/testsuite/c-c++-common/pr95821-4.c |  16 ++++
 gcc/testsuite/c-c++-common/pr95821-5.c |  19 +++++
 gcc/testsuite/c-c++-common/pr95821-6.c |  18 ++++
 gcc/testsuite/c-c++-common/pr95821-7.c |  18 ++++
 gcc/testsuite/c-c++-common/pr95821-8.c |  19 +++++
 gcc/tree-ssa-strlen.cc                 | 113 ++++++++++++++++++++-----
 9 files changed, 233 insertions(+), 19 deletions(-)
 create mode 100644 gcc/testsuite/c-c++-common/pr95821-1.c
 create mode 100644 gcc/testsuite/c-c++-common/pr95821-2.c
 create mode 100644 gcc/testsuite/c-c++-common/pr95821-3.c
 create mode 100644 gcc/testsuite/c-c++-common/pr95821-4.c
 create mode 100644 gcc/testsuite/c-c++-common/pr95821-5.c
 create mode 100644 gcc/testsuite/c-c++-common/pr95821-6.c
 create mode 100644 gcc/testsuite/c-c++-common/pr95821-7.c
 create mode 100644 gcc/testsuite/c-c++-common/pr95821-8.c

diff --git a/gcc/testsuite/c-c++-common/pr95821-1.c b/gcc/testsuite/c-c++-common/pr95821-1.c
new file mode 100644
index 00000000000..e0beb609ea2
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/pr95821-1.c
@@ -0,0 +1,15 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "memchr" } } */
+
+#include <stddef.h>
+
+char *
+foo (char *s, char c)
+{
+	size_t slen = __builtin_strlen(s);
+	if(slen < 1000)
+		return NULL;
+
+	return __builtin_strchr(s, c);
+}
diff --git a/gcc/testsuite/c-c++-common/pr95821-2.c b/gcc/testsuite/c-c++-common/pr95821-2.c
new file mode 100644
index 00000000000..5429f0586be
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/pr95821-2.c
@@ -0,0 +1,17 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler-not "memchr" } } */
+
+#include <stddef.h>
+
+char *
+foo (char *s, char c, char * other)
+{
+	size_t slen = __builtin_strlen(s);
+	if(slen < 1000)
+		return NULL;
+
+	*other = 0;
+
+	return __builtin_strchr(s, c);
+}
diff --git a/gcc/testsuite/c-c++-common/pr95821-3.c b/gcc/testsuite/c-c++-common/pr95821-3.c
new file mode 100644
index 00000000000..bc929c6044b
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/pr95821-3.c
@@ -0,0 +1,17 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "memchr" } } */
+
+#include <stddef.h>
+
+char *
+foo (char * __restrict s, char c, char * __restrict other)
+{
+	size_t slen = __builtin_strlen(s);
+	if(slen < 1000)
+		return NULL;
+
+	*other = 0;
+
+	return __builtin_strchr(s, c);
+}
diff --git a/gcc/testsuite/c-c++-common/pr95821-4.c b/gcc/testsuite/c-c++-common/pr95821-4.c
new file mode 100644
index 00000000000..684b41d5b70
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/pr95821-4.c
@@ -0,0 +1,16 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "memchr" } } */
+
+#include <stddef.h>
+#include <string.h>
+
+char *
+foo (char *s, char c)
+{
+	size_t slen = strlen(s);
+	if(slen < 1000)
+		return NULL;
+
+	return strchr(s, c);
+}
diff --git a/gcc/testsuite/c-c++-common/pr95821-5.c b/gcc/testsuite/c-c++-common/pr95821-5.c
new file mode 100644
index 00000000000..00c1d93b614
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/pr95821-5.c
@@ -0,0 +1,19 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler-not "memchr" } } */
+
+#include <stddef.h>
+#include <string.h>
+
+char *
+foo (char *s, char c, char * other)
+{
+	size_t slen = strlen(s);
+	if(slen < 1000)
+		return NULL;
+
+	*other = 0;
+
+	return strchr(s, c);
+}
+int main() {}
diff --git a/gcc/testsuite/c-c++-common/pr95821-6.c b/gcc/testsuite/c-c++-common/pr95821-6.c
new file mode 100644
index 00000000000..dec839de5ea
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/pr95821-6.c
@@ -0,0 +1,18 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "memchr" } } */
+
+#include <stddef.h>
+#include <string.h>
+
+char *
+foo (char * __restrict s, char c, char * __restrict other)
+{
+	size_t slen = strlen(s);
+	if(slen < 1000)
+		return NULL;
+
+	*other = 0;
+
+	return strchr(s, c);
+}
diff --git a/gcc/testsuite/c-c++-common/pr95821-7.c b/gcc/testsuite/c-c++-common/pr95821-7.c
new file mode 100644
index 00000000000..9da0fff7250
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/pr95821-7.c
@@ -0,0 +1,18 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "memchr" } } */
+
+#include <stddef.h>
+#include <string.h>
+
+char *
+foo (char * __restrict s, char c, char * __restrict other)
+{
+	size_t slen = strlen(s);
+	if(slen < 1000 || c == 0)
+		return NULL;
+
+	*other = 0;
+
+	return strchr(s, c);
+}
diff --git a/gcc/testsuite/c-c++-common/pr95821-8.c b/gcc/testsuite/c-c++-common/pr95821-8.c
new file mode 100644
index 00000000000..5eb02c6fea4
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/pr95821-8.c
@@ -0,0 +1,19 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler-not "strchr" } } */
+/* { dg-final { scan-assembler-not "memchr" } } */
+
+#include <stddef.h>
+#include <string.h>
+
+char *
+foo (char * __restrict s, int c, char * __restrict other)
+{
+	size_t slen = strlen(s);
+	if(slen < 1000 || c != 0x100)
+		return NULL;
+
+	*other = 0;
+
+	return strchr(s, c);
+}
diff --git a/gcc/tree-ssa-strlen.cc b/gcc/tree-ssa-strlen.cc
index 1d4c0f78fbf..3c26ea7eb83 100644
--- a/gcc/tree-ssa-strlen.cc
+++ b/gcc/tree-ssa-strlen.cc
@@ -2405,9 +2405,12 @@ strlen_pass::handle_builtin_strlen ()
     }
 }

-/* Handle a strchr call.  If strlen of the first argument is known, replace
-   the strchr (x, 0) call with the endptr or x + strlen, otherwise remember
-   that lhs of the call is endptr and strlen of the argument is endptr - x.  */
+/* Handle a strchr call.  If strlen of the first argument is known,
+   replace the strchr (x, 0) call with the endptr or x + strlen,
+   otherwise remember that lhs of the call is endptr and strlen of the
+   argument is endptr - x.  If strlen of x is not know but has been
+   computed earlier in the tree then replace strchr (x, c) to
+   memchr (x, c, strlen + 1).  */

 void
 strlen_pass::handle_builtin_strchr ()
@@ -2418,8 +2421,12 @@ strlen_pass::handle_builtin_strchr ()
   if (lhs == NULL_TREE)
     return;

-  if (!integer_zerop (gimple_call_arg (stmt, 1)))
-    return;
+  tree chr = gimple_call_arg (stmt, 1);
+  /* strchr only uses the lower char of input so to check if its
+     strchr (s, zerop) only take into account the lower char.  */
+  bool is_strchr_zerop
+    = (TREE_CODE (chr) == INTEGER_CST
+       && integer_zerop (fold_convert (char_type_node, chr)));

   tree src = gimple_call_arg (stmt, 0);

@@ -2452,32 +2459,96 @@ strlen_pass::handle_builtin_strchr ()
 	      fprintf (dump_file, "Optimizing: ");
 	      print_gimple_stmt (dump_file, stmt, 0, TDF_SLIM);
 	    }
-	  if (si != NULL && si->endptr != NULL_TREE)
+	  /* Three potential optimizations assume t=strlen (s) has already been
+	     computed:
+	        1. strchr (s, chr) where chr is known to be zero -> t
+	        2. strchr (s, chr) where chr is known not to be zero ->
+	           memchr (s, chr, t)
+	        3. strchr (s, chr) where chr is not known to be zero or
+	           non-zero -> memchr (s, chr, t + 1).  */
+	  if (!is_strchr_zerop)
 	    {
-	      rhs = unshare_expr (si->endptr);
-	      if (!useless_type_conversion_p (TREE_TYPE (lhs),
-					      TREE_TYPE (rhs)))
-		rhs = fold_convert_loc (loc, TREE_TYPE (lhs), rhs);
+	      /* If its not strchr (s, zerop) then try and convert to
+	         memchr since strlen has already been computed.  */
+	      tree fn = builtin_decl_explicit (BUILT_IN_MEMCHR);
+
+	      /* Only need to check length strlen (s) + 1 if chr may be zero.
+	         Otherwise the last chr (which is known to be zero) can never
+	         be a match.  */
+	      bool chr_nonzero = false;
+	      if (TREE_CODE (chr) == INTEGER_CST
+		  && integer_nonzerop (fold_convert (char_type_node, chr)))
+		chr_nonzero = true;
+	      else if (TREE_CODE (chr) == SSA_NAME
+		       && CHAR_TYPE_SIZE < INT_TYPE_SIZE)
+		{
+		  value_range r;
+		  /* Try to determine using ranges if (char) chr must
+		     be always 0.  That is true e.g. if all the subranges
+		     have the INT_TYPE_SIZE - CHAR_TYPE_SIZE bits
+		     the same on lower and upper bounds.  */
+		  if (get_range_query (cfun)->range_of_expr (r, chr, stmt)
+		      && r.kind () == VR_RANGE)
+		    {
+		      wide_int mask
+			  = wi::mask (CHAR_TYPE_SIZE, true, INT_TYPE_SIZE);
+		      for (unsigned i = 0; i < r.num_pairs (); ++i)
+			if ((r.lower_bound (i) & mask)
+			    != (r.upper_bound (i) & mask))
+			  {
+			    chr_nonzero = false;
+			    break;
+			  }
+		    }
+		}
+	      if (!chr_nonzero)
+		{
+		  tree one = build_int_cst (TREE_TYPE (rhs), 1);
+		  rhs = fold_build2_loc (loc, PLUS_EXPR, TREE_TYPE (rhs),
+					 unshare_expr (rhs), one);
+		  tree size = make_ssa_name (TREE_TYPE (rhs));
+		  gassign *size_stmt = gimple_build_assign (size, rhs);
+		  gsi_insert_before (&m_gsi, size_stmt, GSI_SAME_STMT);
+		  rhs = size;
+		}
+	      if (!update_gimple_call (&m_gsi, fn, 3, src, chr, rhs))
+		return;
 	    }
 	  else
 	    {
-	      rhs = fold_convert_loc (loc, sizetype, unshare_expr (rhs));
-	      rhs = fold_build2_loc (loc, POINTER_PLUS_EXPR,
-				     TREE_TYPE (src), src, rhs);
-	      if (!useless_type_conversion_p (TREE_TYPE (lhs),
-					      TREE_TYPE (rhs)))
-		rhs = fold_convert_loc (loc, TREE_TYPE (lhs), rhs);
+	      if (si != NULL && si->endptr != NULL_TREE)
+		{
+		  rhs = unshare_expr (si->endptr);
+		  if (!useless_type_conversion_p (TREE_TYPE (lhs),
+						  TREE_TYPE (rhs)))
+		    rhs = fold_convert_loc (loc, TREE_TYPE (lhs), rhs);
+		}
+	      else
+		{
+		  rhs = fold_convert_loc (loc, sizetype, unshare_expr (rhs));
+		  rhs = fold_build2_loc (loc, POINTER_PLUS_EXPR,
+					 TREE_TYPE (src), src, rhs);
+		  if (!useless_type_conversion_p (TREE_TYPE (lhs),
+						  TREE_TYPE (rhs)))
+		    rhs = fold_convert_loc (loc, TREE_TYPE (lhs), rhs);
+		}
+	      gimplify_and_update_call_from_tree (&m_gsi, rhs);
 	    }
-	  gimplify_and_update_call_from_tree (&m_gsi, rhs);
+
 	  stmt = gsi_stmt (m_gsi);
 	  update_stmt (stmt);
+
 	  if (dump_file && (dump_flags & TDF_DETAILS) != 0)
 	    {
 	      fprintf (dump_file, "into: ");
 	      print_gimple_stmt (dump_file, stmt, 0, TDF_SLIM);
 	    }
-	  if (si != NULL
-	      && si->endptr == NULL_TREE
+
+	  /* Don't update strlen of lhs if search-char wasn't know to be zero.  */
+	  if (!is_strchr_zerop)
+	    return;
+
+	  if (si != NULL && si->endptr == NULL_TREE
 	      && !SSA_NAME_OCCURS_IN_ABNORMAL_PHI (lhs))
 	    {
 	      si = unshare_strinfo (si);
@@ -2487,6 +2558,10 @@ strlen_pass::handle_builtin_strchr ()
 	  return;
 	}
     }
+
+  if (!is_strchr_zerop)
+    return;
+
   if (SSA_NAME_OCCURS_IN_ABNORMAL_PHI (lhs))
     return;
   if (TREE_CODE (src) != SSA_NAME || !SSA_NAME_OCCURS_IN_ABNORMAL_PHI (src))
--
2.34.1

diff --git a/gcc/config/i386/i386.md b/gcc/config/i386/i386.md
index f9c06ff..33473c6 100644
--- a/gcc/config/i386/i386.md
+++ b/gcc/config/i386/i386.md
@@ -10401,6 +10401,40 @@
   [(set_attr "type" "bitmanip")
    (set_attr "btver2_decode" "direct, double")
    (set_attr "mode" "<MODE>")])
+
+;; Split *andnsi_1 after reload with -Oz when not;and is shorter.
+(define_split
+  [(set (match_operand:SI 0 "register_operand")
+	(and:SI (not:SI (match_operand:SI 1 "register_operand"))
+		(match_operand:SI 2 "nonimmediate_operand")))
+   (clobber (reg:CC FLAGS_REG))]
+  "reload_completed
+   && optimize_insn_for_size_p () && optimize_size > 1
+   && REGNO (operands[0]) == REGNO (operands[1])
+   && LEGACY_INT_REG_P (operands[0])
+   && !REX_INT_REG_P (operands[2])
+   && !reg_overlap_mentioned_p (operands[0], operands[2])"
+  [(set (match_dup 0) (not:SI (match_dup 1)))
+   (parallel [(set (match_dup 0) (and:SI (match_dup 0) (match_dup 2)))
+	      (clobber (reg:CC FLAGS_REG))])])
+
+;; Split *andn_si_ccno with -Oz when not;test is shorter.
+(define_split
+  [(set (match_operand 0 "flags_reg_operand")
+	(match_operator 1 "compare_operator"
+	  [(and:SI (not:SI (match_operand:SI 2 "general_reg_operand"))
+		   (match_operand:SI 3 "nonimmediate_operand"))
+	   (const_int 0)]))
+   (clobber (match_dup 2))]
+  "reload_completed
+   && optimize_insn_for_size_p () && optimize_size > 1
+   && LEGACY_INT_REG_P (operands[2])
+   && !REX_INT_REG_P (operands[3])
+   && !reg_overlap_mentioned_p (operands[2], operands[3])"
+  [(set (match_dup 2) (not:SI (match_dup 2)))
+   (set (match_dup 0) (match_op_dup 1
+                        [(and:SI (match_dup 3) (match_dup 2))
+			 (const_int 0)]))])

 ;; Logical inclusive and exclusive OR instructions

diff --git a/gcc/testsuite/gcc.target/i386/bmi-andn-3.c b/gcc/testsuite/gcc.target/i386/bmi-andn-3.c
new file mode 100644
index 0000000..16993a3
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/bmi-andn-3.c
@@ -0,0 +1,15 @@
+/* { dg-do compile } */
+/* { dg-options "-Oz -mbmi" } */
+int m;
+
+int foo(int x, int y)
+{
+  return (x & ~y) != 0;
+}
+
+int bar(int x)
+{
+  return (~x & m) != 0;
+}
+/* { dg-final { scan-assembler-not "andn\[ \\t\]+" } } */
+

This patch builds upon Richard Biener's suggestion of avoiding global
variables to track state/identify which passes have already been run.
In the early middle-end, the tree-ssa passes use the curr_properties
field in cfun to track this.  This patch uses a new rtl_pass_progress
int field in crtl to do something similar.
2022-07-10  Roger Sayle  <roger@nextmovesoftware.com>

diff --git a/gcc/bb-reorder.cc b/gcc/bb-reorder.cc
index 5cd4825..1c1cbae 100644
--- a/gcc/bb-reorder.cc
+++ b/gcc/bb-reorder.cc
@@ -2570,7 +2570,7 @@ reorder_basic_blocks (void)

   /* Signal that rtl_verify_flow_info_1 can now verify that there
      is at most one switch between hot/cold sections.  */
-  crtl->bb_reorder_complete = true;
+  crtl->rtl_pass_progress |= PROGRESS_bb_reorder_complete;
 }

 /* Determine which partition the first basic block in the function
diff --git a/gcc/cfgrtl.cc b/gcc/cfgrtl.cc
index a05c338..8fe367e 100644
--- a/gcc/cfgrtl.cc
+++ b/gcc/cfgrtl.cc
@@ -1907,7 +1907,7 @@ rtl_split_edge (edge edge_in)
              an extra partition crossing in the chain, which is illegal.
              It can't go after the src, because src may have a fall-through
              to a different block.  */
-          if (crtl->bb_reorder_complete
+          if (bb_reorder_complete
               && (edge_in->flags & EDGE_CROSSING))
             {
               after = last_bb_in_partition (edge_in->src);
@@ -2444,7 +2444,7 @@ fixup_partitions (void)
       while (! bbs_to_fix.is_empty ());

       /* Fix up hot cold block grouping if needed.  */
-      if (crtl->bb_reorder_complete && current_ir_type () == IR_RTL_CFGRTL)
+      if (bb_reorder_complete && current_ir_type () == IR_RTL_CFGRTL)
 	{
 	  basic_block bb, first = NULL, second = NULL;
 	  int current_partition = BB_UNPARTITIONED;
@@ -2507,7 +2507,7 @@ verify_hot_cold_block_grouping (void)
   /* Even after bb reordering is complete, we go into cfglayout mode
      again (in compgoto). Ensure we don't call this before going back
      into linearized RTL when any layout fixes would have been committed.  */
-  if (!crtl->bb_reorder_complete
+  if (!bb_reorder_complete
       || current_ir_type () != IR_RTL_CFGRTL)
     return err;

@@ -4481,7 +4481,7 @@ cfg_layout_initialize (int flags)
      layout required moving a block from the hot to the cold
      section. This would create an illegal partitioning unless some
      manual fixup was performed.  */
-  gcc_assert (!crtl->bb_reorder_complete || !crtl->has_bb_partition);
+  gcc_assert (!bb_reorder_complete || !crtl->has_bb_partition);

   initialize_original_copy_tables ();

diff --git a/gcc/combine.cc b/gcc/combine.cc
index a5fabf3..18e2a80 100644
--- a/gcc/combine.cc
+++ b/gcc/combine.cc
@@ -14991,6 +14991,7 @@ rest_of_handle_combine (void)
     }

   regstat_free_n_sets_and_refs ();
+  crtl->rtl_pass_progress |= PROGRESS_combine_completed;
   return 0;
 }

diff --git a/gcc/config/i386/x86-tune-sched-atom.cc b/gcc/config/i386/x86-tune-sched-atom.cc
index 07d2093..9fe3933 100644
--- a/gcc/config/i386/x86-tune-sched-atom.cc
+++ b/gcc/config/i386/x86-tune-sched-atom.cc
@@ -34,6 +34,8 @@ along with GCC; see the file COPYING3.  If not see
 #include "rtl-iter.h"
 #include "regset.h"
 #include "sched-int.h"
+#include "memmodel.h"
+#include "emit-rtl.h"

 /* Try to reorder ready list to take advantage of Atom pipelined IMUL
    execution. It is applied if
diff --git a/gcc/config/i386/x86-tune-sched.cc b/gcc/config/i386/x86-tune-sched.cc
index 1ffaeef..315ce04 100644
--- a/gcc/config/i386/x86-tune-sched.cc
+++ b/gcc/config/i386/x86-tune-sched.cc
@@ -32,6 +32,8 @@ along with GCC; see the file COPYING3.  If not see
 #include "insn-attr.h"
 #include "insn-opinit.h"
 #include "recog.h"
+#include "memmodel.h"
+#include "emit-rtl.h"

 /* Return the maximum number of instructions a cpu can issue.  */

diff --git a/gcc/cse.cc b/gcc/cse.cc
index b13afd4..b094a38 100644
--- a/gcc/cse.cc
+++ b/gcc/cse.cc
@@ -7533,7 +7533,7 @@ rest_of_handle_cse (void)

   /* If we are not running more CSE passes, then we are no longer
      expecting CSE to be run.  But always rerun it in a cheap mode.  */
-  cse_not_expected = !flag_rerun_cse_after_loop && !flag_gcse;
+  crtl->cse_not_expected = !flag_rerun_cse_after_loop && !flag_gcse;

   if (tem == 2)
     {
@@ -7617,7 +7617,7 @@ rest_of_handle_cse2 (void)
   else if (tem == 1 || cse_cfg_altered)
     cse_cfg_altered |= cleanup_cfg (0);

-  cse_not_expected = 1;
+  crtl->cse_not_expected = true;
   return 0;
 }

@@ -7681,7 +7681,7 @@ rest_of_handle_cse_after_global_opts (void)
   cse_cfg_altered |= purge_all_dead_edges ();
   delete_trivially_dead_insns (get_insns (), max_reg_num ());

-  cse_not_expected = !flag_rerun_cse_after_loop;
+  crtl->cse_not_expected = !flag_rerun_cse_after_loop;

   /* If cse altered any jumps, rerun jump opts to clean things up.  */
   if (tem == 2)
diff --git a/gcc/df-problems.cc b/gcc/df-problems.cc
index 238424c..8fd0470 100644
--- a/gcc/df-problems.cc
+++ b/gcc/df-problems.cc
@@ -38,6 +38,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "rtl-iter.h"
 #include "regs.h"
 #include "function-abi.h"
+#include "emit-rtl.h"

 /* Note that turning REG_DEAD_DEBUGGING on will cause
    gcc.c-torture/unsorted/dump-noaddr.c to fail because it prints
diff --git a/gcc/emit-rtl.h b/gcc/emit-rtl.h
index 7a58fed..8dcbb36 100644
--- a/gcc/emit-rtl.h
+++ b/gcc/emit-rtl.h
@@ -54,6 +54,16 @@ struct GTY(()) incoming_args {
   rtx internal_arg_pointer;
 };

+#define PROGRESS_combine_completed	(1 << 0)
+#define PROGRESS_lra_in_progress	(1 << 1)
+#define PROGRESS_reload_in_progress	(1 << 2)
+#define PROGRESS_reload_completed	(1 << 3)
+#define PROGRESS_epilogue_completed	(1 << 4)
+#define PROGRESS_bb_reorder_complete	(1 << 5)
+#define PROGRESS_regstack_completed	(1 << 6)
+
+#define PROGRESS_no_pseudos \
+	(PROGRESS_reload_in_progress | PROGRESS_reload_completed)

 /* Datastructures maintained for currently processed function in RTL form.  */
 struct GTY(()) rtl_data {
@@ -76,6 +86,9 @@ struct GTY(()) rtl_data {

   rtl_ssa::function_info *GTY((skip)) ssa;

+  /* Track progress of RTL passes, reload_completed etc.  */
+  int rtl_pass_progress;
+
   /* For function.cc  */

   /* # of bytes of outgoing arguments.  If ACCUMULATE_OUTGOING_ARGS is
@@ -303,9 +316,13 @@ struct GTY(()) rtl_data {
      block.  */
   bool has_bb_partition;

-  /* Nonzero if the function being compiled has completed the bb reordering
-     pass.  */
-  bool bb_reorder_complete;
+  /* If this is nonzero, we do not bother generating VOLATILE
+     around volatile memory references, and we are willing to
+     output indirect addresses.  If cse is to follow, we reject
+     indirect addresses so a useful potential cse is generated;
+     if it is used only once, instruction combination will produce
+     the same indirect address eventually.  */
+  bool cse_not_expected;

   /* Like regs_ever_live, but 1 if a reg is set or clobbered from an
      asm.  Unlike regs_ever_live, elements of this array corresponding
@@ -342,6 +359,20 @@ extern GTY(()) struct rtl_data x_rtl;
    want to do differently.  */
 #define crtl (&x_rtl)

+/* rtl_pass_progress macros.  */
+#define crtl_pass_progress (crtl->rtl_pass_progress)
+
+#define combine_completed (crtl_pass_progress & PROGRESS_combine_completed)
+#define lra_in_progress (crtl_pass_progress & PROGRESS_lra_in_progress)
+#define reload_in_progress (crtl_pass_progress & PROGRESS_reload_in_progress)
+#define reload_completed (crtl_pass_progress & PROGRESS_reload_completed)
+#define bb_reorder_complete (crtl_pass_progress & PROGRESS_bb_reorder_complete)
+#define epilogue_completed (crtl_pass_progress & PROGRESS_epilogue_completed)
+#define regstack_completed (crtl_pass_progress & PROGRESS_regstack_completed)
+
+/* This macro indicates whether you may create a new pseudo-register.  */
+#define can_create_pseudo_p() ((crtl_pass_progress & PROGRESS_no_pseudos) == 0)
+
 /* Return whether two MEM_ATTRs are equal.  */
 bool mem_attrs_eq_p (const class mem_attrs *, const class mem_attrs *);

diff --git a/gcc/explow.cc b/gcc/explow.cc
index ddb4d6ae..9fbeea7 100644
--- a/gcc/explow.cc
+++ b/gcc/explow.cc
@@ -439,7 +439,7 @@ memory_address_addr_space (machine_mode mode, rtx x, addr_space_t as)

   /* By passing constant addresses through registers
      we get a chance to cse them.  */
-  if (! cse_not_expected && CONSTANT_P (x) && CONSTANT_ADDRESS_P (x))
+  if (! crtl->cse_not_expected && CONSTANT_P (x) && CONSTANT_ADDRESS_P (x))
     x = force_reg (address_mode, x);

   /* We get better cse by rejecting indirect addressing at this stage.
@@ -448,7 +448,7 @@ memory_address_addr_space (machine_mode mode, rtx x, addr_space_t as)
      are visible.  But not if cse won't be done!  */
   else
     {
-      if (! cse_not_expected && !REG_P (x))
+      if (! crtl->cse_not_expected && !REG_P (x))
 	x = break_out_memory_refs (x);

       /* At this point, any valid address is accepted.  */
@@ -603,7 +603,7 @@ use_anchored_address (rtx x)
      We will then be able to reuse registers for several accesses, if the
      target costs say that that's worthwhile.  */
   mode = GET_MODE (base);
-  if (!cse_not_expected)
+  if (!crtl->cse_not_expected)
     base = force_reg (mode, base);

   return replace_equiv_address (x, plus_constant (mode, base, offset));
diff --git a/gcc/final.cc b/gcc/final.cc
index 0352786..5ee812e 100644
--- a/gcc/final.cc
+++ b/gcc/final.cc
@@ -4511,11 +4511,7 @@ rest_of_clean_state (void)
     }

   flag_rerun_cse_after_global_opts = 0;
-  reload_completed = 0;
-  epilogue_completed = 0;
-#ifdef STACK_REGS
-  regstack_completed = 0;
-#endif
+  crtl->rtl_pass_progress = 0;

   /* Clear out the insn_length contents now that they are no
      longer valid.  */
diff --git a/gcc/function.cc b/gcc/function.cc
index 31256b5..349aaa3 100644
--- a/gcc/function.cc
+++ b/gcc/function.cc
@@ -4924,7 +4924,7 @@ prepare_function_start (void)
   if (flag_stack_usage_info && !flag_callgraph_info)
     allocate_stack_usage_info ();

-  cse_not_expected = ! optimize;
+  crtl->cse_not_expected = ! optimize;

   /* Caller save not needed yet.  */
   caller_save_needed = 0;
@@ -6093,7 +6093,7 @@ thread_prologue_and_epilogue_insns (void)
   /* A small fib -- epilogue is not yet completed, but we wish to re-use
      this marker for the splits of EH_RETURN patterns, and nothing else
      uses the flag in the meantime.  */
-  epilogue_completed = 1;
+  crtl->rtl_pass_progress |= PROGRESS_epilogue_completed;

   /* Find non-fallthru edges that end with EH_RETURN instructions.  On
      some targets, these get split to a special version of the epilogue
@@ -6259,7 +6259,7 @@ thread_prologue_and_epilogue_insns (void)

   /* Threading the prologue and epilogue changes the artificial refs
      in the entry and exit blocks.  */
-  epilogue_completed = 1;
+  crtl->rtl_pass_progress |= PROGRESS_epilogue_completed;
   df_update_entry_exit_and_calls ();
 }

diff --git a/gcc/ifcvt.cc b/gcc/ifcvt.cc
index 2e8ab39..fd7d1ed 100644
--- a/gcc/ifcvt.cc
+++ b/gcc/ifcvt.cc
@@ -2128,7 +2128,7 @@ noce_try_cmove_arith (struct noce_if_info *if_info)
      conditional on their addresses followed by a load.  Don't do this
      early because it'll screw alias analysis.  Note that we've
      already checked for no side effects.  */
-  if (cse_not_expected
+  if (crtl->cse_not_expected
       && MEM_P (a) && MEM_P (b)
       && MEM_ADDR_SPACE (a) == MEM_ADDR_SPACE (b))
     {
diff --git a/gcc/lra-eliminations.cc b/gcc/lra-eliminations.cc
index c630ff4..434e4ec 100644
--- a/gcc/lra-eliminations.cc
+++ b/gcc/lra-eliminations.cc
@@ -1261,14 +1261,14 @@ init_elim_table (void)
      will cause, e.g., gen_rtx_REG (Pmode, STACK_POINTER_REGNUM) to
      equal stack_pointer_rtx.  We depend on this. Threfore we switch
      off that we are in LRA temporarily.  */
-  lra_in_progress = 0;
+  crtl->rtl_pass_progress &= ~PROGRESS_lra_in_progress;
   for (ep = reg_eliminate; ep < &reg_eliminate[NUM_ELIMINABLE_REGS]; ep++)
     {
       ep->from_rtx = gen_rtx_REG (Pmode, ep->from);
       ep->to_rtx = gen_rtx_REG (Pmode, ep->to);
       eliminable_reg_rtx[ep->from] = ep->from_rtx;
     }
-  lra_in_progress = 1;
+  crtl->rtl_pass_progress |= PROGRESS_lra_in_progress;
 }

 /* Function for initialization of elimination once per function.  It
diff --git a/gcc/lra.cc b/gcc/lra.cc
index 1444cb7..ce4843f 100644
--- a/gcc/lra.cc
+++ b/gcc/lra.cc
@@ -2218,9 +2218,6 @@ update_inc_notes (void)
       }
 }

-/* Set to 1 while in lra.  */
-int lra_in_progress;
-
 /* Start of pseudo regnos before the LRA.  */
 int lra_new_regno_start;

@@ -2316,7 +2313,7 @@ lra (FILE *f)
   if (flag_checking)
     check_rtl (false);

-  lra_in_progress = 1;
+  crtl->rtl_pass_progress |= PROGRESS_lra_in_progress;

   lra_live_range_iter = lra_coalesce_iter = lra_constraint_iter = 0;
   lra_assignment_iter = lra_assignment_iter_after_spill = 0;
@@ -2508,7 +2505,7 @@ lra (FILE *f)
   ira_restore_scratches (lra_dump_file);
   lra_eliminate (true, false);
   lra_final_code_change ();
-  lra_in_progress = 0;
+  crtl->rtl_pass_progress &= ~PROGRESS_lra_in_progress;
   if (live_p)
     lra_clear_live_ranges ();
   lra_live_ranges_finish ();
@@ -2519,7 +2516,7 @@ lra (FILE *f)
   finish_insn_recog_data ();
   regstat_free_n_sets_and_refs ();
   regstat_free_ri ();
-  reload_completed = 1;
+  crtl->rtl_pass_progress |= PROGRESS_reload_completed;
   update_inc_notes ();

   inserted_p = fixup_abnormal_edges ();
diff --git a/gcc/modulo-sched.cc b/gcc/modulo-sched.cc
index 162de19..f3b15a4 100644
--- a/gcc/modulo-sched.cc
+++ b/gcc/modulo-sched.cc
@@ -1369,11 +1369,11 @@ sms_schedule (void)
   /* Initialize issue_rate.  */
   if (targetm.sched.issue_rate)
     {
-      int temp = reload_completed;
+      int temp = crtl->rtl_pass_progress;

-      reload_completed = 1;
+      crtl->rtl_pass_progress |= PROGRESS_reload_completed;
       issue_rate = targetm.sched.issue_rate ();
-      reload_completed = temp;
+      crtl->rtl_pass_progress = temp;
     }
   else
     issue_rate = 1;
diff --git a/gcc/passes.cc b/gcc/passes.cc
index 78a07f8..9a1a0d8 100644
--- a/gcc/passes.cc
+++ b/gcc/passes.cc
@@ -2541,12 +2541,12 @@ skip_pass (opt_pass *pass)
   /* Pass "reload" sets the global "reload_completed", and many
      things depend on this (e.g. instructions in .md files).  */
   if (strcmp (pass->name, "reload") == 0)
-    reload_completed = 1;
+    crtl->rtl_pass_progress |= PROGRESS_reload_completed;

   /* Similar for pass "pro_and_epilogue" and the "epilogue_completed" global
      variable.  */
   if (strcmp (pass->name, "pro_and_epilogue") == 0)
-    epilogue_completed = 1;
+    crtl->rtl_pass_progress |= PROGRESS_epilogue_completed;

   /* The INSN_ADDRESSES vec is normally set up by
      shorten_branches; set it up for the benefit of passes that
diff --git a/gcc/recog.cc b/gcc/recog.cc
index dac172b..cb1e331 100644
--- a/gcc/recog.cc
+++ b/gcc/recog.cc
@@ -85,15 +85,6 @@ static operand_alternative asm_op_alt[MAX_RECOG_OPERANDS

 int which_alternative;

-/* Nonzero after end of reload pass.
-   Set to 1 or 0 by toplev.cc.
-   Controls the significance of (SUBREG (MEM)).  */
-
-int reload_completed;
-
-/* Nonzero after thread_prologue_and_epilogue_insns has run.  */
-int epilogue_completed;
-
 /* Initialize data used by the function `recog'.
    This must be called once in the compilation of a function
    before any insn recognition may be done in the function.  */
diff --git a/gcc/reg-stack.cc b/gcc/reg-stack.cc
index fd03250..a2580f1 100644
--- a/gcc/reg-stack.cc
+++ b/gcc/reg-stack.cc
@@ -188,8 +188,6 @@ static vec<char> stack_regs_mentioned_data;

 #define REG_STACK_SIZE (LAST_STACK_REG - FIRST_STACK_REG + 1)

-int regstack_completed = 0;
-
 /* This is the basic stack record.  TOP is an index into REG[] such
    that REG[TOP] is the top of stack.  If TOP is -1 the stack is empty.

@@ -3440,7 +3438,7 @@ rest_of_handle_stack_regs (void)
 #ifdef STACK_REGS
   if (reg_to_stack ())
     df_insn_rescan_all ();
-  regstack_completed = 1;
+  crtl->rtl_pass_progress |= PROGRESS_regstack_completed;
 #endif
   return 0;
 }
diff --git a/gcc/regstat.cc b/gcc/regstat.cc
index db28354..1825a4f 100644
--- a/gcc/regstat.cc
+++ b/gcc/regstat.cc
@@ -27,6 +27,8 @@ along with GCC; see the file COPYING3.  If not see
 #include "predict.h"
 #include "df.h"
 #include "regs.h"
+#include "memmodel.h"
+#include "emit-rtl.h"


 struct regstat_n_sets_and_refs_t *regstat_n_sets_and_refs;
diff --git a/gcc/reload1.cc b/gcc/reload1.cc
index 728dc2a..153315e 100644
--- a/gcc/reload1.cc
+++ b/gcc/reload1.cc
@@ -216,10 +216,6 @@ int reload_first_uid;
    a call-clobbered reg across calls.  */
 int caller_save_needed;

-/* Set to 1 while reload_as_needed is operating.
-   Required by some machines to handle any generated moves differently.  */
-int reload_in_progress = 0;
-
 /* This obstack is used for allocation of rtl during register elimination.
    The allocated storage can be freed once find_reloads has processed the
    insn.  */
@@ -877,7 +873,7 @@ reload (rtx_insn *first, int global)
   /* From now on, we may need to generate moves differently.  We may also
      allow modifications of insns which cause them to not be recognized.
      Any such modifications will be cleaned up during reload itself.  */
-  reload_in_progress = 1;
+  crtl->rtl_pass_progress |= PROGRESS_reload_in_progress;

   /* This loop scans the entire function each go-round
      and repeats until one repetition spills no additional hard regs.  */
@@ -1067,7 +1063,7 @@ reload (rtx_insn *first, int global)

   CLEAR_REG_SET (&changed_allocation_pseudos);
   CLEAR_REG_SET (&spilled_pseudos);
-  reload_in_progress = 0;
+  crtl->rtl_pass_progress &= ~PROGRESS_reload_in_progress;

   /* Now eliminate all pseudo regs by modifying them into
      their equivalent memory references.
@@ -1158,7 +1154,7 @@ reload (rtx_insn *first, int global)
   /* We must set reload_completed now since the cleanup_subreg_operands call
      below will re-recognize each insn and reload may have generated insns
      which are only valid during and after reload.  */
-  reload_completed = 1;
+  crtl->rtl_pass_progress |= PROGRESS_reload_completed;

   /* Make a pass over all the insns and delete all USEs which we inserted
      only to tag a REG_EQUAL note on them.  Remove all REG_DEAD and REG_UNUSED
@@ -1294,7 +1290,10 @@ reload (rtx_insn *first, int global)

   gcc_assert (bitmap_empty_p (&spilled_pseudos));

-  reload_completed = !failure;
+  if (failure)
+    crtl->rtl_pass_progress &= ~PROGRESS_reload_completed;
+  else
+    crtl->rtl_pass_progress |= PROGRESS_reload_completed;

   return need_dce;
 }
diff --git a/gcc/rtl.h b/gcc/rtl.h
index 488016b..55c3435 100644
--- a/gcc/rtl.h
+++ b/gcc/rtl.h
@@ -4089,41 +4089,6 @@ PUT_MODE (rtx x, machine_mode mode)
 extern rtx output_constant_def (tree, int);
 extern rtx lookup_constant_def (tree);

-/* Nonzero after end of reload pass.
-   Set to 1 or 0 by reload1.cc.  */
-
-extern int reload_completed;
-
-/* Nonzero after thread_prologue_and_epilogue_insns has run.  */
-extern int epilogue_completed;
-
-/* Set to 1 while reload_as_needed is operating.
-   Required by some machines to handle any generated moves differently.  */
-
-extern int reload_in_progress;
-
-/* Set to 1 while in lra.  */
-extern int lra_in_progress;
-
-/* This macro indicates whether you may create a new
-   pseudo-register.  */
-
-#define can_create_pseudo_p() (!reload_in_progress && !reload_completed)
-
-#ifdef STACK_REGS
-/* Nonzero after end of regstack pass.
-   Set to 1 or 0 by reg-stack.cc.  */
-extern int regstack_completed;
-#endif
-
-/* If this is nonzero, we do not bother generating VOLATILE
-   around volatile memory references, and we are willing to
-   output indirect addresses.  If cse is to follow, we reject
-   indirect addresses so a useful potential cse is generated;
-   if it is used only once, instruction combination will produce
-   the same indirect address eventually.  */
-extern int cse_not_expected;
-
 /* Translates rtx code to tree code, for those codes needed by
    real_arithmetic.  The function returns an int because the caller may not
    know what `enum tree_code' means.  */
diff --git a/gcc/sched-ebb.cc b/gcc/sched-ebb.cc
index 71d72b6..89e4be9 100644
--- a/gcc/sched-ebb.cc
+++ b/gcc/sched-ebb.cc
@@ -32,6 +32,8 @@ along with GCC; see the file COPYING3.  If not see
 #include "cfgrtl.h"
 #include "cfgbuild.h"
 #include "sched-int.h"
+#include "memmodel.h"
+#include "emit-rtl.h"


 #ifdef INSN_SCHEDULING

From 7d43f2b3b69420f1b57618dc8ccd225c266423a3 Mon Sep 17 00:00:00 2001
From: Eugene Rozenfeld <erozen@microsoft.com>
Date: Thu, 21 Apr 2022 15:42:15 -0700
Subject: [PATCH] Add instruction level discriminator support.

This is the first in a series of patches to enable discriminator support
in AutoFDO.

This patch switches to tracking discriminators per statement/instruction
instead of per basic block. Tracking per basic block was problematic since
not all statements in a basic block needed a discriminator and, also, later
optimizations could move statements between basic blocks making correlation
during AutoFDO compilation unreliable. Tracking per statement also allows
us to assign different discriminators to multiple function calls in the same
basic block. A subsequent patch will add that support.

The idea of this patch is based on commit 4c311d95cf6d9519c3c20f641cc77af7df491fdf
by Dehao Chen in vendors/google/heads/gcc-4_8 but uses a slightly different
approach. In Dehao's work special (normally unused) location ids and side tables
were used to keep track of locations with discriminators. Things have changed
since then and I don't think we have unused location ids anymore. Instead,
I made discriminators a part of ad-hoc locations.

The difference from Dehao's work also includes support for discriminator
reading/writing in lto streaming and in modules.

Tested on x86_64-pc-linux-gnu.

gcc/ChangeLog:

	* basic-block.h: Remove discriminator from basic blocks.
	* cfghooks.cc (split_block_1): Remove discriminator from basic blocks.
	* cp/module.cc (write_location): Write discriminator.
	(read_location): Read discriminator.
	* final.cc (final_start_function_1): Switch from per-bb to per statement
	discriminator.
	(final_scan_insn_1): Don't keep track of basic block discriminators.
	(compute_discriminator): Switch from basic block discriminators to
	instruction discriminators.
	(insn_discriminator): New function to return instruction discriminator.
	(notice_source_line): Use insn_discriminator.
	* gimple-pretty-print.cc (dump_gimple_bb_header): Remove dumping of
	basic block discriminators.
	* gimple-streamer-in.cc (input_bb): Remove reading of basic block
	discriminators.
	* gimple-streamer-out.cc (output_bb): Remove writing of basic block
	discriminators.
	* input.cc (make_location): Pass 0 discriminator to COMBINE_LOCATION_DATA.
	(location_with_discriminator): New function to combine locus with
	a discriminator.
	(has_discriminator): New function to check if a location has a discriminator.
	(get_discriminator_from_locus): New function to get the discriminator
	from a location.
	* input.h: Declarations of new functions and definition of
	LOCATION_DISCRIMINATOR.
	* lto-streamer-in.cc (cmp_loc): Use discriminators in location comparison.
	(apply_location_cache): Keep track of current discriminator.
	(input_location_and_block): Read discriminator from stream.
	* lto-streamer-out.cc (clear_line_info): Set current discriminator to
	UINT_MAX.
	(lto_output_location_1): Write discriminator to stream.
	* lto-streamer.h: Add discriminator to cached_location.
	Add current_discr to lto_location_cache.
	Add current_discr to output_block.
	* print-rtl.cc (print_rtx_operand_code_i): Print discriminator.
	* rtl.h: Add extern declaration of insn_discriminator.
	* tree-cfg.cc (assign_discriminator): New function to assign a unique
	discriminator value to all statements in a basic block that have the given
	line number.
	(assign_discriminators): Assign discriminators to statement locations.
	* tree-pretty-print.cc (dump_location): Dump discriminators.
	* tree.cc (set_block): Preserve discriminator when setting block.
	(set_source_range): Preserve discriminator when setting source range.

libcpp/ChangeLog:

	* include/line-map.h: Add discriminator to location_adhoc_data.
	(get_combined_adhoc_loc): Add discriminator parameter.
	(get_discriminator_from_adhoc_loc): Add external declaration.
	(get_discriminator_from_loc): Add external declaration.
	(COMBINE_LOCATION_DATA): Add discriminator parameter.
	* lex.cc (get_location_for_byte_range_in_cur_line) Pass 0 discriminator
	in a call to COMBINE_LOCATION_DATA.
	(warn_about_normalization): Pass 0 discriminator in a call to
	COMBINE_LOCATION_DATA.
	(_cpp_lex_direct): Pass 0 discriminator in a call to
	COMBINE_LOCATION_DATA.
	* line-map.cc (location_adhoc_data_hash): Use discriminator compute
	location_adhoc_data hash.
	(location_adhoc_data_eq): Use discriminator when comparing
	location_adhoc_data.
	(can_be_stored_compactly_p): Check discriminator to determine
	compact storage.
	(get_combined_adhoc_loc): Add discriminator parameter.
	(get_discriminator_from_adhoc_loc): New function to get the discriminator
	from an ad-hoc location.
	(get_discriminator_from_loc): New function to get the discriminator
	from a location.

gcc/testsuite/ChangeLog:

	* c-c++-common/ubsan/pr85213.c: Pass -gno-statement-frontiers.
---
 gcc/basic-block.h                          |  5 ---
 gcc/cfghooks.cc                            |  1 -
 gcc/cp/module.cc                           |  5 ++-
 gcc/final.cc                               | 26 +++++++--------
 gcc/gimple-pretty-print.cc                 |  2 --
 gcc/gimple-streamer-in.cc                  |  1 -
 gcc/gimple-streamer-out.cc                 |  1 -
 gcc/input.cc                               | 36 ++++++++++++++++++--
 gcc/input.h                                |  7 ++++
 gcc/lto-streamer-in.cc                     | 21 ++++++++++--
 gcc/lto-streamer-out.cc                    |  7 ++++
 gcc/lto-streamer.h                         |  3 ++
 gcc/print-rtl.cc                           |  4 +++
 gcc/rtl.h                                  |  1 +
 gcc/testsuite/c-c++-common/ubsan/pr85213.c |  7 +++-
 gcc/tree-cfg.cc                            | 39 ++++++++++++++++++----
 gcc/tree-pretty-print.cc                   |  6 ++++
 gcc/tree.cc                                | 10 ++++--
 libcpp/include/line-map.h                  | 10 ++++--
 libcpp/lex.cc                              |  7 ++--
 libcpp/line-map.cc                         | 38 +++++++++++++++++----
 21 files changed, 185 insertions(+), 52 deletions(-)

diff --git a/gcc/basic-block.h b/gcc/basic-block.h
index c9d1fc91bbb..1eae03d1aca 100644
--- a/gcc/basic-block.h
+++ b/gcc/basic-block.h
@@ -148,11 +148,6 @@ struct GTY((chain_next ("%h.next_bb"), chain_prev ("%h.prev_bb"))) basic_block_d

   /* Expected number of executions: calculated in profile.cc.  */
   profile_count count;
-
-  /* The discriminator for this block.  The discriminator distinguishes
-     among several basic blocks that share a common locus, allowing for
-     more accurate sample-based profiling.  */
-  int discriminator;
 };

 /* This ensures that struct gimple_bb_info is smaller than
diff --git a/gcc/cfghooks.cc b/gcc/cfghooks.cc
index e435891fac6..7a0c5f77ef9 100644
--- a/gcc/cfghooks.cc
+++ b/gcc/cfghooks.cc
@@ -541,7 +541,6 @@ split_block_1 (basic_block bb, void *i)
     return NULL;

   new_bb->count = bb->count;
-  new_bb->discriminator = bb->discriminator;

   if (dom_info_available_p (CDI_DOMINATORS))
     {
diff --git a/gcc/cp/module.cc b/gcc/cp/module.cc
index d1dc73724d1..5ed6b7b0f94 100644
--- a/gcc/cp/module.cc
+++ b/gcc/cp/module.cc
@@ -15587,6 +15587,8 @@ module_state::write_location (bytes_out &sec, location_t loc)
 	range.m_start = UNKNOWN_LOCATION;
       write_location (sec, range.m_start);
       write_location (sec, range.m_finish);
+      unsigned discriminator = get_discriminator_from_adhoc_loc (line_table, loc);
+      sec.u (discriminator);
     }
   else if (loc >= LINEMAPS_MACRO_LOWEST_LOCATION (line_table))
     {
@@ -15671,8 +15673,9 @@ module_state::read_location (bytes_in &sec) const
 	if (range.m_start == UNKNOWN_LOCATION)
 	  range.m_start = locus;
 	range.m_finish = read_location (sec);
+	unsigned discriminator = sec.u ();
 	if (locus != loc && range.m_start != loc && range.m_finish != loc)
-	  locus = get_combined_adhoc_loc (line_table, locus, range, NULL);
+	  locus = get_combined_adhoc_loc (line_table, locus, range, NULL, discriminator);
       }
       break;

diff --git a/gcc/final.cc b/gcc/final.cc
index a9868861bd2..0d8c21b0681 100644
--- a/gcc/final.cc
+++ b/gcc/final.cc
@@ -126,18 +126,10 @@ static int last_columnnum;
 /* Discriminator written to assembly.  */
 static int last_discriminator;

-/* Discriminator to be written to assembly for current instruction.
+/* Compute discriminator to be written to assembly for current instruction.
    Note: actual usage depends on loc_discriminator_kind setting.  */
-static int discriminator;
 static inline int compute_discriminator (location_t loc);

-/* Discriminator identifying current basic block among others sharing
-   the same locus.  */
-static int bb_discriminator;
-
-/* Basic block discriminator for previous instruction.  */
-static int last_bb_discriminator;
-
 /* Highest line number in current block.  */
 static int high_block_linenum;

@@ -1697,8 +1689,7 @@ final_start_function_1 (rtx_insn **firstp, FILE *file, int *seen,
   last_filename = LOCATION_FILE (prologue_location);
   last_linenum = LOCATION_LINE (prologue_location);
   last_columnnum = LOCATION_COLUMN (prologue_location);
-  last_discriminator = discriminator = 0;
-  last_bb_discriminator = bb_discriminator = 0;
+  last_discriminator = 0;
   force_source_line = false;

   high_block_linenum = high_function_linenum = last_linenum;
@@ -2243,7 +2234,6 @@ final_scan_insn_1 (rtx_insn *insn, FILE *file, int optimize_p ATTRIBUTE_UNUSED,
 	  if (targetm.asm_out.unwind_emit)
 	    targetm.asm_out.unwind_emit (asm_out_file, insn);

-	  bb_discriminator = NOTE_BASIC_BLOCK (insn)->discriminator;
 	  break;

 	case NOTE_INSN_EH_REGION_BEG:
@@ -2982,7 +2972,7 @@ compute_discriminator (location_t loc)
   int discriminator;

   if (!decl_to_instance_map)
-    discriminator = bb_discriminator;
+    discriminator = get_discriminator_from_locus (loc);
   else
     {
       tree block = LOCATION_BLOCK (loc);
@@ -3006,6 +2996,13 @@ compute_discriminator (location_t loc)
   return discriminator;
 }

+/* Return discriminator of the statement that produced this insn.  */
+int
+insn_discriminator (const rtx_insn *insn)
+{
+  return compute_discriminator (INSN_LOCATION (insn));
+}
+
 /* Return whether a source line note needs to be emitted before INSN.
    Sets IS_STMT to TRUE if the line should be marked as a possible
    breakpoint location.  */
@@ -3015,6 +3012,7 @@ notice_source_line (rtx_insn *insn, bool *is_stmt)
 {
   const char *filename;
   int linenum, columnnum;
+  int discriminator;

   if (NOTE_MARKER_P (insn))
     {
@@ -3044,7 +3042,7 @@ notice_source_line (rtx_insn *insn, bool *is_stmt)
       filename = xloc.file;
       linenum = xloc.line;
       columnnum = xloc.column;
-      discriminator = compute_discriminator (INSN_LOCATION (insn));
+      discriminator = insn_discriminator (insn);
     }
   else
     {
diff --git a/gcc/gimple-pretty-print.cc b/gcc/gimple-pretty-print.cc
index ebd87b20a0a..5e7039dbf66 100644
--- a/gcc/gimple-pretty-print.cc
+++ b/gcc/gimple-pretty-print.cc
@@ -2899,8 +2899,6 @@ dump_gimple_bb_header (FILE *outf, basic_block bb, int indent,
 			 indent, "", get_lineno (gsi_stmt (gsi)));
 		break;
 	      }
-	  if (bb->discriminator)
-	    fprintf (outf, ", discriminator %i", bb->discriminator);
 	  fputc ('\n', outf);
 	}
     }
diff --git a/gcc/gimple-streamer-in.cc b/gcc/gimple-streamer-in.cc
index e7f3256302f..ea8891e8e92 100644
--- a/gcc/gimple-streamer-in.cc
+++ b/gcc/gimple-streamer-in.cc
@@ -267,7 +267,6 @@ input_bb (class lto_input_block *ib, enum LTO_tags tag,
     bb->count
       = bb->count.apply_scale (count_materialization_scale, REG_BR_PROB_BASE);
   bb->flags = streamer_read_hwi (ib);
-  bb->discriminator = streamer_read_hwi (ib);

   /* LTO_bb1 has statements.  LTO_bb0 does not.  */
   if (tag == LTO_bb0)
diff --git a/gcc/gimple-streamer-out.cc b/gcc/gimple-streamer-out.cc
index 33365251295..45832547bf5 100644
--- a/gcc/gimple-streamer-out.cc
+++ b/gcc/gimple-streamer-out.cc
@@ -208,7 +208,6 @@ output_bb (struct output_block *ob, basic_block bb, struct function *fn)
   streamer_write_uhwi (ob, bb->index);
   bb->count.stream_out (ob);
   streamer_write_hwi (ob, bb->flags);
-  streamer_write_hwi (ob, bb->discriminator);

   if (!gsi_end_p (bsi) || phi_nodes (bb))
     {
diff --git a/gcc/input.cc b/gcc/input.cc
index 2acbfdea4f8..ef4bacf0da6 100644
--- a/gcc/input.cc
+++ b/gcc/input.cc
@@ -1045,7 +1045,8 @@ make_location (location_t caret, location_t start, location_t finish)
   location_t combined_loc = COMBINE_LOCATION_DATA (line_table,
 						   pure_loc,
 						   src_range,
-						   NULL);
+						   NULL,
+						   0);
   return combined_loc;
 }

@@ -1055,7 +1056,7 @@ location_t
 make_location (location_t caret, source_range src_range)
 {
   location_t pure_loc = get_pure_location (caret);
-  return COMBINE_LOCATION_DATA (line_table, pure_loc, src_range, NULL);
+  return COMBINE_LOCATION_DATA (line_table, pure_loc, src_range, NULL, 0);
 }

 /* An expanded_location stores the column in byte units.  This function
@@ -1729,6 +1730,37 @@ get_location_within_string (cpp_reader *pfile,
   return NULL;
 }

+/* Associate the DISCRIMINATOR with LOCUS, and return a new locus. */
+
+location_t
+location_with_discriminator (location_t locus, int discriminator)
+{
+  tree block = LOCATION_BLOCK (locus);
+  source_range src_range = get_range_from_loc (line_table, locus);
+  locus = get_pure_location (locus);
+
+  if (locus == UNKNOWN_LOCATION)
+    return locus;
+
+  return COMBINE_LOCATION_DATA (line_table, locus, src_range, block, discriminator);
+}
+
+/* Return TRUE if LOCUS represents a location with a discriminator.  */
+
+bool
+has_discriminator (location_t locus)
+{
+  return LOCATION_DISCRIMINATOR(locus) != 0;
+}
+
+/* Return the discriminator for LOCUS.  */
+
+int
+get_discriminator_from_locus (location_t locus)
+{
+  return LOCATION_DISCRIMINATOR(locus);
+}
+
 #if CHECKING_P

 namespace selftest {
diff --git a/gcc/input.h b/gcc/input.h
index f1ae3aec95c..564ebd893e9 100644
--- a/gcc/input.h
+++ b/gcc/input.h
@@ -165,6 +165,10 @@ extern location_t expansion_point_location (location_t);

 extern location_t input_location;

+extern location_t location_with_discriminator (location_t, int);
+extern bool has_discriminator (location_t);
+extern int get_discriminator_from_locus (location_t);
+
 #define LOCATION_FILE(LOC) ((expand_location (LOC)).file)
 #define LOCATION_LINE(LOC) ((expand_location (LOC)).line)
 #define LOCATION_COLUMN(LOC)((expand_location (LOC)).column)
@@ -174,6 +178,9 @@ extern location_t input_location;
 #define LOCATION_BLOCK(LOC) \
   ((tree) ((IS_ADHOC_LOC (LOC)) ? get_data_from_adhoc_loc (line_table, (LOC)) \
    : NULL))
+#define LOCATION_DISCRIMINATOR(LOC) \
+  ((IS_ADHOC_LOC (LOC)) ? get_discriminator_from_adhoc_loc (line_table, (LOC)) \
+   : 0)
 #define RESERVED_LOCATION_P(LOC) \
   (LOCATION_LOCUS (LOC) < RESERVED_LOCATION_COUNT)

diff --git a/gcc/lto-streamer-in.cc b/gcc/lto-streamer-in.cc
index fe5a4e7fe1d..271b8006ac0 100644
--- a/gcc/lto-streamer-in.cc
+++ b/gcc/lto-streamer-in.cc
@@ -409,6 +409,8 @@ lto_location_cache::cmp_loc (const void *pa, const void *pb)
     return a->line - b->line;
   if (a->col != b->col)
     return a->col - b->col;
+  if (a->discr != b->discr)
+    return a->discr - b->discr;
   if ((a->block == NULL_TREE) != (b->block == NULL_TREE))
     return a->block ? 1 : -1;
   if (a->block)
@@ -460,6 +462,8 @@ lto_location_cache::apply_location_cache ()
 	  current_loc = linemap_position_for_column (line_table, loc.col);
 	  if (loc.block)
 	    current_loc = set_block (current_loc, loc.block);
+	  if (loc.discr)
+	    current_loc = location_with_discriminator (current_loc, loc.discr);
 	}
       else if (current_block != loc.block)
 	{
@@ -467,12 +471,19 @@ lto_location_cache::apply_location_cache ()
 	    current_loc = set_block (current_loc, loc.block);
 	  else
 	    current_loc = LOCATION_LOCUS (current_loc);
+	  if (loc.discr)
+	    current_loc = location_with_discriminator (current_loc, loc.discr);
+	}
+      else if (current_discr != loc.discr)
+	{
+	    current_loc = location_with_discriminator (current_loc, loc.discr);
 	}
       *loc.loc = current_loc;
       current_line = loc.line;
       prev_file = current_file = loc.file;
       current_col = loc.col;
       current_block = loc.block;
+      current_discr = loc.discr;
     }
   loc_cache.truncate (0);
   accepted_length = 0;
@@ -512,6 +523,7 @@ lto_location_cache::input_location_and_block (location_t *loc,
   static int stream_col;
   static bool stream_sysp;
   static tree stream_block;
+  static unsigned stream_discr;
   static const char *stream_relative_path_prefix;

   gcc_assert (current_cache == this);
@@ -538,6 +550,7 @@ lto_location_cache::input_location_and_block (location_t *loc,
   *loc = RESERVED_LOCATION_COUNT;
   bool line_change = bp_unpack_value (bp, 1);
   bool column_change = bp_unpack_value (bp, 1);
+  bool discr_change = bp_unpack_value (bp, 1);

   if (file_change)
     {
@@ -563,6 +576,9 @@ lto_location_cache::input_location_and_block (location_t *loc,
   if (column_change)
     stream_col = bp_unpack_var_len_unsigned (bp);

+  if (discr_change)
+    stream_discr = bp_unpack_var_len_unsigned (bp);
+
   tree block = NULL_TREE;
   if (ib)
     {
@@ -578,7 +594,8 @@ lto_location_cache::input_location_and_block (location_t *loc,
   if (current_file == stream_file
       && current_line == stream_line
       && current_col == stream_col
-      && current_sysp == stream_sysp)
+      && current_sysp == stream_sysp
+      && current_discr == stream_discr)
     {
       if (current_block == block)
 	*loc = current_loc;
@@ -590,7 +607,7 @@ lto_location_cache::input_location_and_block (location_t *loc,
     }

   struct cached_location entry
-    = {stream_file, loc, stream_line, stream_col, stream_sysp, block};
+    = {stream_file, loc, stream_line, stream_col, stream_sysp, block, stream_discr};
   loc_cache.safe_push (entry);
 }

diff --git a/gcc/lto-streamer-out.cc b/gcc/lto-streamer-out.cc
index 471f35c315f..d2b6c69315f 100644
--- a/gcc/lto-streamer-out.cc
+++ b/gcc/lto-streamer-out.cc
@@ -67,6 +67,7 @@ clear_line_info (struct output_block *ob)
      so that the first location with block in a function etc.
      always streams a change_block bit and the first block.  */
   ob->current_block = void_node;
+  ob->current_discr = UINT_MAX;
 }


@@ -194,6 +195,7 @@ lto_output_location_1 (struct output_block *ob, struct bitpack_d *bp,
   if (loc >= RESERVED_LOCATION_COUNT)
     {
       expanded_location xloc = expand_location (loc);
+      unsigned discr = LOCATION_DISCRIMINATOR (orig_loc);

       if (ob->reset_locus)
 	{
@@ -216,6 +218,7 @@ lto_output_location_1 (struct output_block *ob, struct bitpack_d *bp,

       bp_pack_value (bp, ob->current_line != xloc.line, 1);
       bp_pack_value (bp, ob->current_col != xloc.column, 1);
+      bp_pack_value (bp, ob->current_discr != discr, 1);

       if (ob->current_file != xloc.file)
 	{
@@ -242,6 +245,10 @@ lto_output_location_1 (struct output_block *ob, struct bitpack_d *bp,
       if (ob->current_col != xloc.column)
 	bp_pack_var_len_unsigned (bp, xloc.column);
       ob->current_col = xloc.column;
+
+      if (ob->current_discr != discr)
+	bp_pack_var_len_unsigned (bp, discr);
+      ob->current_discr = discr;
     }
   else
     bp_pack_int_in_range (bp, 0, RESERVED_LOCATION_COUNT + 1, loc);
diff --git a/gcc/lto-streamer.h b/gcc/lto-streamer.h
index 597e9e405ec..2e3abd97959 100644
--- a/gcc/lto-streamer.h
+++ b/gcc/lto-streamer.h
@@ -311,6 +311,7 @@ private:
     int line, col;
     bool sysp;
     tree block;
+    unsigned discr;
   };

   /* The location cache.  */
@@ -333,6 +334,7 @@ private:
   bool current_sysp;
   location_t current_loc;
   tree current_block;
+  unsigned current_discr;
 };

 /* Structure used as buffer for reading an LTO file.  */
@@ -723,6 +725,7 @@ struct output_block
   bool reset_locus;
   bool emit_pwd;
   tree current_block;
+  unsigned current_discr;

   /* Cache of nodes written in this section.  */
   struct streamer_tree_cache_d *writer_cache;
diff --git a/gcc/print-rtl.cc b/gcc/print-rtl.cc
index 60c845485bc..e115f987173 100644
--- a/gcc/print-rtl.cc
+++ b/gcc/print-rtl.cc
@@ -453,6 +453,10 @@ rtx_writer::print_rtx_operand_code_i (const_rtx in_rtx, int idx)
 	  expanded_location xloc = insn_location (in_insn);
 	  fprintf (m_outfile, " \"%s\":%i:%i", xloc.file, xloc.line,
 		   xloc.column);
+	  int discriminator = insn_discriminator (in_insn);
+	    if (discriminator)
+	      fprintf (m_outfile, " discrim %d", discriminator);
+
 	}
 #endif
     }
diff --git a/gcc/rtl.h b/gcc/rtl.h
index 488016bb42a..b0528235ef8 100644
--- a/gcc/rtl.h
+++ b/gcc/rtl.h
@@ -3369,6 +3369,7 @@ extern int insn_line (const rtx_insn *);
 extern const char * insn_file (const rtx_insn *);
 extern tree insn_scope (const rtx_insn *);
 extern expanded_location insn_location (const rtx_insn *);
+extern int insn_discriminator (const rtx_insn *);
 extern location_t prologue_location, epilogue_location;

 /* In jump.cc */
diff --git a/gcc/testsuite/c-c++-common/ubsan/pr85213.c b/gcc/testsuite/c-c++-common/ubsan/pr85213.c
index 8a6be81d20f..e903e976f2c 100644
--- a/gcc/testsuite/c-c++-common/ubsan/pr85213.c
+++ b/gcc/testsuite/c-c++-common/ubsan/pr85213.c
@@ -1,6 +1,11 @@
 /* PR sanitizer/85213 */
 /* { dg-do compile } */
-/* { dg-options "-O1 -fsanitize=undefined -fcompare-debug" } */
+/* Pass -gno-statement-frontiers to work around
+   https://gcc.gnu.org/bugzilla/show_bug.cgi?id=100733 :
+   without it the IR coming from the front end may be different with and without
+   debug information turned on. That may cause e.g., different discriminator values
+   and -fcompare-debug failures. */
+/* { dg-options "-O1 -fsanitize=undefined -fcompare-debug -gno-statement-frontiers" } */

 int
 foo (int x)
diff --git a/gcc/tree-cfg.cc b/gcc/tree-cfg.cc
index 8de1b144a42..3b4063f18fd 100644
--- a/gcc/tree-cfg.cc
+++ b/gcc/tree-cfg.cc
@@ -1162,7 +1162,33 @@ same_line_p (location_t locus1, expanded_location *from, location_t locus2)
           && filename_cmp (from->file, to.file) == 0);
 }

-/* Assign discriminators to each basic block.  */
+/* Assign a unique discriminator value to all statements in block bb that
+   have the same line number as locus. */
+
+static void
+assign_discriminator (location_t locus, basic_block bb)
+{
+  gimple_stmt_iterator gsi;
+  int discriminator;
+
+  if (locus == UNKNOWN_LOCATION)
+    return;
+
+  expanded_location locus_e = expand_location (locus);
+
+  discriminator = next_discriminator_for_locus (locus_e.line);
+
+  for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))
+    {
+      gimple *stmt = gsi_stmt (gsi);
+      location_t stmt_locus = gimple_location (stmt);
+      if (same_line_p (locus, &locus_e, stmt_locus))
+	gimple_set_location (stmt,
+	    location_with_discriminator (stmt_locus, discriminator));
+    }
+}
+
+/* Assign discriminators to statement locations.  */

 static void
 assign_discriminators (void)
@@ -1177,6 +1203,7 @@ assign_discriminators (void)
       location_t locus = last ? gimple_location (last) : UNKNOWN_LOCATION;

       if (locus == UNKNOWN_LOCATION)
+
 	continue;

       expanded_location locus_e = expand_location (locus);
@@ -1190,12 +1217,12 @@ assign_discriminators (void)
 	      || (last && same_line_p (locus, &locus_e,
 				       gimple_location (last))))
 	    {
-	      if (e->dest->discriminator != 0 && bb->discriminator == 0)
-		bb->discriminator
-		  = next_discriminator_for_locus (locus_e.line);
+	      if (((first && has_discriminator (gimple_location (first)))
+		   || (last && has_discriminator (gimple_location (last))))
+		  && !has_discriminator (locus))
+		assign_discriminator (locus, bb);
 	      else
-		e->dest->discriminator
-		  = next_discriminator_for_locus (locus_e.line);
+		assign_discriminator (locus, e->dest);
 	    }
 	}
     }
diff --git a/gcc/tree-pretty-print.cc b/gcc/tree-pretty-print.cc
index 6acd394a079..ed9c368742e 100644
--- a/gcc/tree-pretty-print.cc
+++ b/gcc/tree-pretty-print.cc
@@ -1416,6 +1416,7 @@ void
 dump_location (pretty_printer *pp, location_t loc)
 {
   expanded_location xloc = expand_location (loc);
+  int discriminator = get_discriminator_from_locus (loc);

   pp_left_bracket (pp);
   if (xloc.file)
@@ -1426,6 +1427,11 @@ dump_location (pretty_printer *pp, location_t loc)
   pp_decimal_int (pp, xloc.line);
   pp_colon (pp);
   pp_decimal_int (pp, xloc.column);
+  if (discriminator)
+  {
+    pp_string (pp, " discrim ");
+    pp_decimal_int (pp, discriminator);
+  }
   pp_string (pp, "] ");
 }

diff --git a/gcc/tree.cc b/gcc/tree.cc
index 2bfb67489c6..a35a1e824d0 100644
--- a/gcc/tree.cc
+++ b/gcc/tree.cc
@@ -14124,7 +14124,8 @@ set_block (location_t loc, tree block)
 {
   location_t pure_loc = get_pure_location (loc);
   source_range src_range = get_range_from_loc (line_table, loc);
-  return COMBINE_LOCATION_DATA (line_table, pure_loc, src_range, block);
+  unsigned discriminator = get_discriminator_from_loc (line_table, loc);
+  return COMBINE_LOCATION_DATA (line_table, pure_loc, src_range, block, discriminator);
 }

 location_t
@@ -14142,11 +14143,14 @@ set_source_range (tree expr, source_range src_range)
   if (!EXPR_P (expr))
     return UNKNOWN_LOCATION;

-  location_t pure_loc = get_pure_location (EXPR_LOCATION (expr));
+  location_t expr_location = EXPR_LOCATION (expr);
+  location_t pure_loc = get_pure_location (expr_location);
+  unsigned discriminator = get_discriminator_from_locus (expr_location);
   location_t adhoc = COMBINE_LOCATION_DATA (line_table,
 					    pure_loc,
 					    src_range,
-					    NULL);
+					    NULL,
+					    discriminator);
   SET_EXPR_LOCATION (expr, adhoc);
   return adhoc;
 }
diff --git a/libcpp/include/line-map.h b/libcpp/include/line-map.h
index 80335721e03..f2d9e3cfbb7 100644
--- a/libcpp/include/line-map.h
+++ b/libcpp/include/line-map.h
@@ -755,6 +755,7 @@ struct GTY(()) location_adhoc_data {
   location_t locus;
   source_range src_range;
   void * GTY((skip)) data;
+  unsigned discriminator;
 };

 struct htab;
@@ -1032,12 +1033,14 @@ LINEMAPS_LAST_ALLOCATED_MACRO_MAP (const line_maps *set)
 }

 extern location_t get_combined_adhoc_loc (line_maps *, location_t,
-					  source_range, void *);
+					  source_range, void *, unsigned);
 extern void *get_data_from_adhoc_loc (const line_maps *, location_t);
+extern unsigned get_discriminator_from_adhoc_loc (const line_maps *, location_t);
 extern location_t get_location_from_adhoc_loc (const line_maps *,
 					       location_t);

 extern source_range get_range_from_loc (line_maps *set, location_t loc);
+extern unsigned get_discriminator_from_loc (line_maps *set, location_t loc);

 /* Get whether location LOC is a "pure" location, or
    whether it is an ad-hoc location, or embeds range information.  */
@@ -1056,9 +1059,10 @@ inline location_t
 COMBINE_LOCATION_DATA (class line_maps *set,
 		       location_t loc,
 		       source_range src_range,
-		       void *block)
+		       void *block,
+		       unsigned discriminator)
 {
-  return get_combined_adhoc_loc (set, loc, src_range, block);
+  return get_combined_adhoc_loc (set, loc, src_range, block, discriminator);
 }

 extern void rebuild_location_adhoc_htab (class line_maps *);
diff --git a/libcpp/lex.cc b/libcpp/lex.cc
index f891d3e17df..7bbd8c0f8e1 100644
--- a/libcpp/lex.cc
+++ b/libcpp/lex.cc
@@ -1359,7 +1359,8 @@ get_location_for_byte_range_in_cur_line (cpp_reader *pfile,
   location_t combined_loc = COMBINE_LOCATION_DATA (pfile->line_table,
 						   start_loc,
 						   src_range,
-						   NULL);
+						   NULL,
+						   0);
   return combined_loc;
 }

@@ -1828,7 +1829,7 @@ warn_about_normalization (cpp_reader *pfile,
 					   CPP_BUF_COLUMN (pfile->buffer,
 							   pfile->buffer->cur));
 	  loc = COMBINE_LOCATION_DATA (pfile->line_table,
-				       loc, tok_range, NULL);
+				       loc, tok_range, NULL, 0);
 	}

       encoding_rich_location rich_loc (pfile, loc);
@@ -4025,7 +4026,7 @@ _cpp_lex_direct (cpp_reader *pfile)

       result->src_loc = COMBINE_LOCATION_DATA (pfile->line_table,
 					       result->src_loc,
-					       tok_range, NULL);
+					       tok_range, NULL, 0);
     }

   return result;
diff --git a/libcpp/line-map.cc b/libcpp/line-map.cc
index 62077c3857c..e17d109d9f1 100644
--- a/libcpp/line-map.cc
+++ b/libcpp/line-map.cc
@@ -67,7 +67,8 @@ location_adhoc_data_hash (const void *l)
   return ((hashval_t) lb->locus
 	  + (hashval_t) lb->src_range.m_start
 	  + (hashval_t) lb->src_range.m_finish
-	  + (size_t) lb->data);
+	  + (size_t) lb->data
+	  + lb->discriminator);
 }

 /* Compare function for location_adhoc_data hashtable.  */
@@ -82,7 +83,8 @@ location_adhoc_data_eq (const void *l1, const void *l2)
   return (lb1->locus == lb2->locus
 	  && lb1->src_range.m_start == lb2->src_range.m_start
 	  && lb1->src_range.m_finish == lb2->src_range.m_finish
-	  && lb1->data == lb2->data);
+	  && lb1->data == lb2->data
+	  && lb1->discriminator == lb2->discriminator);
 }

 /* Update the hashtable when location_adhoc_data is reallocated.  */
@@ -116,13 +118,17 @@ static bool
 can_be_stored_compactly_p (line_maps *set,
 			   location_t locus,
 			   source_range src_range,
-			   void *data)
+			   void *data,
+			   unsigned discriminator)
 {
   /* If there's an ad-hoc pointer, we can't store it directly in the
      location_t, we need the lookaside.  */
   if (data)
     return false;

+  if (discriminator != 0)
+    return false;
+
   /* We only store ranges that begin at the locus and that are sufficiently
      "sane".  */
   if (src_range.m_start != locus)
@@ -157,7 +163,8 @@ location_t
 get_combined_adhoc_loc (line_maps *set,
 			location_t locus,
 			source_range src_range,
-			void *data)
+			void *data,
+			unsigned discriminator)
 {
   struct location_adhoc_data lb;
   struct location_adhoc_data **slot;
@@ -175,7 +182,7 @@ get_combined_adhoc_loc (line_maps *set,
 		  || pure_location_p (set, locus));

   /* Consider short-range optimization.  */
-  if (can_be_stored_compactly_p (set, locus, src_range, data))
+  if (can_be_stored_compactly_p (set, locus, src_range, data, discriminator))
     {
       /* The low bits ought to be clear.  */
       linemap_assert (pure_location_p (set, locus));
@@ -195,15 +202,16 @@ get_combined_adhoc_loc (line_maps *set,
      when locus == start == finish (and data is NULL).  */
   if (locus == src_range.m_start
       && locus == src_range.m_finish
-      && !data)
+      && !data && discriminator == 0)
     return locus;

-  if (!data)
+  if (!data && discriminator == 0)
     set->num_unoptimized_ranges++;

   lb.locus = locus;
   lb.src_range = src_range;
   lb.data = data;
+  lb.discriminator = discriminator;
   slot = (struct location_adhoc_data **)
       htab_find_slot (set->location_adhoc_data_map.htab, &lb, INSERT);
   if (*slot == NULL)
@@ -248,6 +256,13 @@ get_data_from_adhoc_loc (const class line_maps *set, location_t loc)
   return set->location_adhoc_data_map.data[loc & MAX_LOCATION_T].data;
 }

+unsigned
+get_discriminator_from_adhoc_loc (const class line_maps *set, location_t loc)
+{
+  linemap_assert (IS_ADHOC_LOC (loc));
+  return set->location_adhoc_data_map.data[loc & MAX_LOCATION_T].discriminator;
+}
+
 /* Return the location for the adhoc loc.  */

 location_t
@@ -293,6 +308,15 @@ get_range_from_loc (line_maps *set,
   return source_range::from_location (loc);
 }

+unsigned
+get_discriminator_from_loc (line_maps *set,
+			    location_t loc)
+{
+  if (IS_ADHOC_LOC (loc))
+    return get_discriminator_from_adhoc_loc (set, loc);
+  return 0;
+}
+
 /* Get whether location LOC is a "pure" location, or
    whether it is an ad-hoc location, or embeds range information.  */

--
2.25.1

When autopar uses graphites canonicalize_loop_closed_ssa it fails to
check whether propagation is allowed and thus it ends up messing up
abnormal constraints.

Bootstrapped and tested on x86_64-unknown-linux-gnu, pushed.

2022-07-01  Richard Biener  <rguenther@suse.de>

	PR tree-optimization/106055
	* graphite.cc (canonicalize_loop_closed_ssa): Check whether
	we can propagate.

	* gcc.dg/graphite/pr106055.c: New testcase.
---
 gcc/graphite.cc                          |  5 ++-
 gcc/testsuite/gcc.dg/graphite/pr106055.c | 41 ++++++++++++++++++++++++
 2 files changed, 45 insertions(+), 1 deletion(-)
 create mode 100644 gcc/testsuite/gcc.dg/graphite/pr106055.c

diff --git a/gcc/graphite.cc b/gcc/graphite.cc
index a88b13c0219..fd4f7a126e1 100644
--- a/gcc/graphite.cc
+++ b/gcc/graphite.cc
@@ -57,6 +57,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "tree-ssa-loop-manip.h"
 #include "tree-ssa.h"
 #include "tree-into-ssa.h"
+#include "tree-ssa-propagate.h"
 #include "graphite.h"

 /* Print global statistics to FILE.  */
@@ -337,7 +338,9 @@ canonicalize_loop_closed_ssa (loop_p loop, edge e)
       /* Iterate over the next phis and remove duplicates.  */
       gsi_next (&gsi);
       while (!gsi_end_p (gsi))
-	if (gimple_phi_arg_def (phi, 0) == gimple_phi_arg_def (gsi.phi (), 0))
+	if (gimple_phi_arg_def (phi, 0) == gimple_phi_arg_def (gsi.phi (), 0)
+	    && may_propagate_copy (gimple_phi_result (gsi.phi ()),
+				   gimple_phi_result (phi)))
 	  {
 	    replace_uses_by (gimple_phi_result (gsi.phi ()),
 			     gimple_phi_result (phi));
diff --git a/gcc/testsuite/gcc.dg/graphite/pr106055.c b/gcc/testsuite/gcc.dg/graphite/pr106055.c
new file mode 100644
index 00000000000..22be62b3607
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/graphite/pr106055.c
@@ -0,0 +1,41 @@
+/* { dg-do compile } */
+/* { dg-options "-Os -floop-parallelize-all -fno-tree-dce" } */
+
+__attribute__ ((returns_twice)) int
+bar (void);
+
+void
+quux (void);
+
+void
+empty (void)
+{
+}
+
+unsigned int
+choose (unsigned int x, unsigned int y)
+{
+  return y ? x : 0;
+}
+
+int
+foo (int *p, unsigned int x, int y)
+{
+  unsigned int acc = 0;
+
+  empty ();
+
+  while (x)
+    {
+      bar ();
+      ++x;
+    }
+
+  while (y)
+    acc += y;
+
+  *p = choose (acc, 1);
+  quux ();
+
+  return x;
+}
--
2.35.3

The following adds missing assignment of a virtual use operand to a
created load to vect_setup_realignment which shows as bootstrap
failure on powerpc64-linux and extra testsuite fails for targets
when misaligned loads are not supported or not optimal.

Bootstrapped on x86_64-unknown-linux-gnu, testing in progress.

	PR tree-optimization/106228
	* tree-vect-data-refs.cc (vect_setup_realignment): Properly
	set a VUSE operand on the emitted load.
---
 gcc/tree-vect-data-refs.cc | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/gcc/tree-vect-data-refs.cc b/gcc/tree-vect-data-refs.cc
index d20a10a1524..53e52cb58cb 100644
--- a/gcc/tree-vect-data-refs.cc
+++ b/gcc/tree-vect-data-refs.cc
@@ -5780,6 +5780,13 @@ vect_setup_realignment (vec_info *vinfo, stmt_vec_info stmt_info,
   if (loop_for_initial_load)
     pe = loop_preheader_edge (loop_for_initial_load);

+  tree vuse;
+  gphi *vphi = get_virtual_phi (loop_for_initial_load->header);
+  if (vphi)
+    vuse = PHI_ARG_DEF_FROM_EDGE (vphi, pe);
+  else
+    vuse = gimple_vuse (gsi_stmt (*gsi));
+
   /* 3. For the case of the optimized realignment, create the first vector
       load at the loop preheader.  */

@@ -5813,6 +5820,7 @@ vect_setup_realignment (vec_info *vinfo, stmt_vec_info stmt_info,
       new_stmt = gimple_build_assign (vec_dest, data_ref);
       new_temp = make_ssa_name (vec_dest, new_stmt);
       gimple_assign_set_lhs (new_stmt, new_temp);
+      gimple_set_vuse (new_stmt, vuse);
       if (pe)
         {
           new_bb = gsi_insert_on_edge_immediate (pe, new_stmt);
--
2.35.3

The following fixes the last commit to honor the case we are not
vectorizing a loop.

Bootstrapped on x86_64-unknown-linux-gnu, pushed.

	PR tree-optimization/106228
	* tree-vect-data-refs.cc (vect_setup_realignment): Adjust
	VUSE compute for the non-loop case.
---
 gcc/tree-vect-data-refs.cc | 14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/gcc/tree-vect-data-refs.cc b/gcc/tree-vect-data-refs.cc
index 53e52cb58cb..609cacc4971 100644
--- a/gcc/tree-vect-data-refs.cc
+++ b/gcc/tree-vect-data-refs.cc
@@ -5777,14 +5777,14 @@ vect_setup_realignment (vec_info *vinfo, stmt_vec_info stmt_info,
   if (at_loop)
     *at_loop = loop_for_initial_load;

+  tree vuse = NULL_TREE;
   if (loop_for_initial_load)
-    pe = loop_preheader_edge (loop_for_initial_load);
-
-  tree vuse;
-  gphi *vphi = get_virtual_phi (loop_for_initial_load->header);
-  if (vphi)
-    vuse = PHI_ARG_DEF_FROM_EDGE (vphi, pe);
-  else
+    {
+      pe = loop_preheader_edge (loop_for_initial_load);
+      if (gphi *vphi = get_virtual_phi (loop_for_initial_load->header))
+	vuse = PHI_ARG_DEF_FROM_EDGE (vphi, pe);
+    }
+  if (!vuse)
     vuse = gimple_vuse (gsi_stmt (*gsi));

   /* 3. For the case of the optimized realignment, create the first vector
--
2.35.3

When working on a smaller region like a loop version copy the main
time spent is now dominance fast query recompute which does a full
function DFS walk.  The dominance queries within the region of
interest should be O(log n) without fast queries and we should do
on the order of O(n) of them which overall means reasonable
complexity.

For the artificial testcase I'm looking at this shaves off
considerable time again.

Bootstrapped and tested on x86_64-unknown-linux-gnu, pushed.

	* tree-into-ssa.cc (update_ssa): Do not forcefully
	re-compute dominance fast queries for TODO_update_ssa_no_phi.
---
 gcc/tree-into-ssa.cc | 8 +++++---
 1 file changed, 5 insertions(+), 3 deletions(-)

diff --git a/gcc/tree-into-ssa.cc b/gcc/tree-into-ssa.cc
index be71b629f97..d13fb720b37 100644
--- a/gcc/tree-into-ssa.cc
+++ b/gcc/tree-into-ssa.cc
@@ -3451,11 +3451,13 @@ update_ssa (unsigned update_flags)
     phis_to_rewrite.create (last_basic_block_for_fn (cfun) + 1);
   blocks_to_update = BITMAP_ALLOC (NULL);

-  /* Ensure that the dominance information is up-to-date.  */
-  calculate_dominance_info (CDI_DOMINATORS);
-
   insert_phi_p = (update_flags != TODO_update_ssa_no_phi);

+  /* Ensure that the dominance information is up-to-date and when we
+     are going to compute dominance frontiers fast queries are possible.  */
+  if (insert_phi_p || dom_info_state (CDI_DOMINATORS) == DOM_NONE)
+    calculate_dominance_info (CDI_DOMINATORS);
+
   /* If there are names defined in the replacement table, prepare
      definition and use sites for all the names in NEW_SSA_NAMES and
      OLD_SSA_NAMES.  */
--
2.35.3

The patch is to fix _mm_[u]comixx_{ss,sd} codegen and add PF result.  These intrinsics have changed over time, like `_mm_comieq_ss ` old operation is `RETURN ( a[31:0] == b[31:0] ) ? 1 : 0`, and new operation update is `RETURN ( a[31:0] != NaN AND b[31:0] != NaN AND a[31:0] == b[31:0] ) ? 1 : 0`.

OK for master?

gcc/ChangeLog:

	PR target/106113
	* config/i386/i386-builtin.def (BDESC): Fix [u]comi{ss,sd}
	comparison due to intrinsics changed over time.
	* config/i386/i386-expand.cc (ix86_ssecom_setcc):
	Add unordered check and mode for sse comi codegen.
	(ix86_expand_sse_comi): Add unordered check and check a different
	CCmode.
	(ix86_expand_sse_comi_round):Extract unordered check and mode part
	in ix86_ssecom_setcc.

gcc/testsuite/ChangeLog:

	PR target/106113
	* gcc.target/i386/avx-vcomisd-pr106113-2.c: New test.
	* gcc.target/i386/avx-vcomiss-pr106113-2.c: Ditto.
	* gcc.target/i386/avx-vucomisd-pr106113-2.c: Ditto.
	* gcc.target/i386/avx-vucomiss-pr106113-2.c: Ditto.
	* gcc.target/i386/sse-comiss-pr106113-1.c: Ditto.
	* gcc.target/i386/sse-comiss-pr106113-2.c: Ditto.
	* gcc.target/i386/sse-ucomiss-pr106113-1.c: Ditto.
	* gcc.target/i386/sse-ucomiss-pr106113-2.c: Ditto.
	* gcc.target/i386/sse2-comisd-pr106113-1.c: Ditto.
	* gcc.target/i386/sse2-comisd-pr106113-2.c: Ditto.
	* gcc.target/i386/sse2-ucomisd-pr106113-1.c: Ditto.
	* gcc.target/i386/sse2-ucomisd-pr106113-2.c: Ditto.
---
 gcc/config/i386/i386-builtin.def              |  32 ++--
 gcc/config/i386/i386-expand.cc                | 140 +++++++++++-------
 .../gcc.target/i386/avx-vcomisd-pr106113-2.c  |   8 +
 .../gcc.target/i386/avx-vcomiss-pr106113-2.c  |   8 +
 .../gcc.target/i386/avx-vucomisd-pr106113-2.c |   8 +
 .../gcc.target/i386/avx-vucomiss-pr106113-2.c |   8 +
 .../gcc.target/i386/sse-comiss-pr106113-1.c   |  19 +++
 .../gcc.target/i386/sse-comiss-pr106113-2.c   |  59 ++++++++
 .../gcc.target/i386/sse-ucomiss-pr106113-1.c  |  19 +++
 .../gcc.target/i386/sse-ucomiss-pr106113-2.c  |  59 ++++++++
 .../gcc.target/i386/sse2-comisd-pr106113-1.c  |  19 +++
 .../gcc.target/i386/sse2-comisd-pr106113-2.c  |  59 ++++++++
 .../gcc.target/i386/sse2-ucomisd-pr106113-1.c |  19 +++
 .../gcc.target/i386/sse2-ucomisd-pr106113-2.c |  59 ++++++++
 14 files changed, 450 insertions(+), 66 deletions(-)
 create mode 100644 gcc/testsuite/gcc.target/i386/avx-vcomisd-pr106113-2.c
 create mode 100644 gcc/testsuite/gcc.target/i386/avx-vcomiss-pr106113-2.c
 create mode 100644 gcc/testsuite/gcc.target/i386/avx-vucomisd-pr106113-2.c
 create mode 100644 gcc/testsuite/gcc.target/i386/avx-vucomiss-pr106113-2.c
 create mode 100644 gcc/testsuite/gcc.target/i386/sse-comiss-pr106113-1.c
 create mode 100644 gcc/testsuite/gcc.target/i386/sse-comiss-pr106113-2.c
 create mode 100644 gcc/testsuite/gcc.target/i386/sse-ucomiss-pr106113-1.c
 create mode 100644 gcc/testsuite/gcc.target/i386/sse-ucomiss-pr106113-2.c
 create mode 100644 gcc/testsuite/gcc.target/i386/sse2-comisd-pr106113-1.c
 create mode 100644 gcc/testsuite/gcc.target/i386/sse2-comisd-pr106113-2.c
 create mode 100644 gcc/testsuite/gcc.target/i386/sse2-ucomisd-pr106113-1.c
 create mode 100644 gcc/testsuite/gcc.target/i386/sse2-ucomisd-pr106113-2.c

diff --git a/gcc/config/i386/i386-builtin.def b/gcc/config/i386/i386-builtin.def
index fd160935e67..acb7e8ca64b 100644
--- a/gcc/config/i386/i386-builtin.def
+++ b/gcc/config/i386/i386-builtin.def
@@ -35,30 +35,30 @@
         IX86_BUILTIN__BDESC_##NEXT_KIND##_FIRST - 1.  */

 BDESC_FIRST (comi, COMI,
-       OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comieq", IX86_BUILTIN_COMIEQSS, UNEQ, 0)
-BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comilt", IX86_BUILTIN_COMILTSS, UNLT, 0)
-BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comile", IX86_BUILTIN_COMILESS, UNLE, 0)
+       OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comieq", IX86_BUILTIN_COMIEQSS, EQ, 0)
+BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comilt", IX86_BUILTIN_COMILTSS, LT, 0)
+BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comile", IX86_BUILTIN_COMILESS, LE, 0)
 BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comigt", IX86_BUILTIN_COMIGTSS, GT, 0)
 BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comige", IX86_BUILTIN_COMIGESS, GE, 0)
-BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comineq", IX86_BUILTIN_COMINEQSS, LTGT, 0)
-BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomieq", IX86_BUILTIN_UCOMIEQSS, UNEQ, 0)
-BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomilt", IX86_BUILTIN_UCOMILTSS, UNLT, 0)
-BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomile", IX86_BUILTIN_UCOMILESS, UNLE, 0)
+BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_comi, "__builtin_ia32_comineq", IX86_BUILTIN_COMINEQSS, NE, 0)
+BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomieq", IX86_BUILTIN_UCOMIEQSS, EQ, 0)
+BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomilt", IX86_BUILTIN_UCOMILTSS, LT, 0)
+BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomile", IX86_BUILTIN_UCOMILESS, LE, 0)
 BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomigt", IX86_BUILTIN_UCOMIGTSS, GT, 0)
 BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomige", IX86_BUILTIN_UCOMIGESS, GE, 0)
-BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomineq", IX86_BUILTIN_UCOMINEQSS, LTGT, 0)
-BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdeq", IX86_BUILTIN_COMIEQSD, UNEQ, 0)
-BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdlt", IX86_BUILTIN_COMILTSD, UNLT, 0)
-BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdle", IX86_BUILTIN_COMILESD, UNLE, 0)
+BDESC (OPTION_MASK_ISA_SSE, 0, CODE_FOR_sse_ucomi, "__builtin_ia32_ucomineq", IX86_BUILTIN_UCOMINEQSS, NE, 0)
+BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdeq", IX86_BUILTIN_COMIEQSD, EQ, 0)
+BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdlt", IX86_BUILTIN_COMILTSD, LT, 0)
+BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdle", IX86_BUILTIN_COMILESD, LE, 0)
 BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdgt", IX86_BUILTIN_COMIGTSD, GT, 0)
 BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdge", IX86_BUILTIN_COMIGESD, GE, 0)
-BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdneq", IX86_BUILTIN_COMINEQSD, LTGT, 0)
-BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdeq", IX86_BUILTIN_UCOMIEQSD, UNEQ, 0)
-BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdlt", IX86_BUILTIN_UCOMILTSD, UNLT, 0)
-BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdle", IX86_BUILTIN_UCOMILESD, UNLE, 0)
+BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_comi, "__builtin_ia32_comisdneq", IX86_BUILTIN_COMINEQSD, NE, 0)
+BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdeq", IX86_BUILTIN_UCOMIEQSD, EQ, 0)
+BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdlt", IX86_BUILTIN_UCOMILTSD, LT, 0)
+BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdle", IX86_BUILTIN_UCOMILESD, LE, 0)
 BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdgt", IX86_BUILTIN_UCOMIGTSD, GT, 0)
 BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdge", IX86_BUILTIN_UCOMIGESD, GE, 0)
-BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdneq", IX86_BUILTIN_UCOMINEQSD, LTGT, 0)
+BDESC (OPTION_MASK_ISA_SSE2, 0, CODE_FOR_sse2_ucomi, "__builtin_ia32_ucomisdneq", IX86_BUILTIN_UCOMINEQSD, NE, 0)

 BDESC_END (COMI, PCMPESTR)

diff --git a/gcc/config/i386/i386-expand.cc b/gcc/config/i386/i386-expand.cc
index 6a3fcde5738..40f821e7a11 100644
--- a/gcc/config/i386/i386-expand.cc
+++ b/gcc/config/i386/i386-expand.cc
@@ -9770,47 +9770,121 @@ ix86_expand_sse_compare (const struct builtin_description *d,
   return target;
 }

+/* Subroutine of ix86_sse_comi and ix86_sse_comi_round to take care of
+ * ordered EQ or unordered NE, generate PF jump.  */
+
+static rtx
+ix86_ssecom_setcc (const enum rtx_code comparison,
+		   bool check_unordered, machine_mode mode,
+		   rtx set_dst, rtx target)
+{
+
+  rtx_code_label *label = NULL;
+
+  /* NB: For ordered EQ or unordered NE, check ZF alone isn't sufficient
+     with NAN operands.  */
+  if (check_unordered)
+    {
+      gcc_assert (comparison == EQ || comparison == NE);
+
+      rtx flag = gen_rtx_REG (CCFPmode, FLAGS_REG);
+      label = gen_label_rtx ();
+      rtx tmp = gen_rtx_fmt_ee (UNORDERED, VOIDmode, flag, const0_rtx);
+      tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp,
+				  gen_rtx_LABEL_REF (VOIDmode, label),
+				  pc_rtx);
+      emit_jump_insn (gen_rtx_SET (pc_rtx, tmp));
+    }
+
+  /* NB: Set CCFPmode and check a different CCmode which is in subset
+     of CCFPmode.  */
+  if (GET_MODE (set_dst) != mode)
+    {
+      gcc_assert (mode == CCAmode || mode == CCCmode
+		  || mode == CCOmode || mode == CCPmode
+		  || mode == CCSmode || mode == CCZmode);
+      set_dst = gen_rtx_REG (mode, FLAGS_REG);
+    }
+
+  emit_insn (gen_rtx_SET (gen_rtx_STRICT_LOW_PART (VOIDmode, target),
+			  gen_rtx_fmt_ee (comparison, QImode,
+					  set_dst,
+					  const0_rtx)));
+
+  if (label)
+    emit_label (label);
+
+  return SUBREG_REG (target);
+}
+
 /* Subroutine of ix86_expand_builtin to take care of comi insns.  */

 static rtx
 ix86_expand_sse_comi (const struct builtin_description *d, tree exp,
 		      rtx target)
 {
-  rtx pat;
+  rtx pat, set_dst;
   tree arg0 = CALL_EXPR_ARG (exp, 0);
   tree arg1 = CALL_EXPR_ARG (exp, 1);
   rtx op0 = expand_normal (arg0);
   rtx op1 = expand_normal (arg1);
-  machine_mode mode0 = insn_data[d->icode].operand[0].mode;
-  machine_mode mode1 = insn_data[d->icode].operand[1].mode;
-  enum rtx_code comparison = d->comparison;
+  enum insn_code icode = d->icode;
+  const struct insn_data_d *insn_p = &insn_data[icode];
+  machine_mode mode0 = insn_p->operand[0].mode;
+  machine_mode mode1 = insn_p->operand[1].mode;

   if (VECTOR_MODE_P (mode0))
     op0 = safe_vector_operand (op0, mode0);
   if (VECTOR_MODE_P (mode1))
     op1 = safe_vector_operand (op1, mode1);

+  enum rtx_code comparison = d->comparison;
+  rtx const_val = const0_rtx;
+
+  bool check_unordered = false;
+  machine_mode mode = CCFPmode;
+  switch (comparison)
+    {
+    case LE:	/* -> GE  */
+    case LT:	/* -> GT  */
+      std::swap (op0, op1);
+      comparison = swap_condition (comparison);
+      /* FALLTHRU */
+    case GT:
+    case GE:
+      break;
+    case EQ:
+      check_unordered = true;
+      mode = CCZmode;
+      break;
+    case NE:
+      check_unordered = true;
+      mode = CCZmode;
+      const_val = const1_rtx;
+      break;
+    default:
+      gcc_unreachable ();
+    }
+
   target = gen_reg_rtx (SImode);
-  emit_move_insn (target, const0_rtx);
+  emit_move_insn (target, const_val);
   target = gen_rtx_SUBREG (QImode, target, 0);

   if ((optimize && !register_operand (op0, mode0))
-      || !insn_data[d->icode].operand[0].predicate (op0, mode0))
+      || !insn_p->operand[0].predicate (op0, mode0))
     op0 = copy_to_mode_reg (mode0, op0);
   if ((optimize && !register_operand (op1, mode1))
-      || !insn_data[d->icode].operand[1].predicate (op1, mode1))
+      || !insn_p->operand[1].predicate (op1, mode1))
     op1 = copy_to_mode_reg (mode1, op1);

-  pat = GEN_FCN (d->icode) (op0, op1);
+  pat = GEN_FCN (icode) (op0, op1);
   if (! pat)
     return 0;
-  emit_insn (pat);
-  emit_insn (gen_rtx_SET (gen_rtx_STRICT_LOW_PART (VOIDmode, target),
-			  gen_rtx_fmt_ee (comparison, QImode,
-					  SET_DEST (pat),
-					  const0_rtx)));

-  return SUBREG_REG (target);
+  set_dst = SET_DEST (pat);
+  emit_insn (pat);
+  return ix86_ssecom_setcc (comparison, check_unordered, mode,
+			    set_dst, target);
 }

 /* Subroutines of ix86_expand_args_builtin to take care of round insns.  */
@@ -11410,42 +11484,8 @@ ix86_expand_sse_comi_round (const struct builtin_description *d,

   emit_insn (pat);

-  rtx_code_label *label = NULL;
-
-  /* NB: For ordered EQ or unordered NE, check ZF alone isn't sufficient
-     with NAN operands.  */
-  if (check_unordered)
-    {
-      gcc_assert (comparison == EQ || comparison == NE);
-
-      rtx flag = gen_rtx_REG (CCFPmode, FLAGS_REG);
-      label = gen_label_rtx ();
-      rtx tmp = gen_rtx_fmt_ee (UNORDERED, VOIDmode, flag, const0_rtx);
-      tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp,
-				  gen_rtx_LABEL_REF (VOIDmode, label),
-				  pc_rtx);
-      emit_jump_insn (gen_rtx_SET (pc_rtx, tmp));
-    }
-
-  /* NB: Set CCFPmode and check a different CCmode which is in subset
-     of CCFPmode.  */
-  if (GET_MODE (set_dst) != mode)
-    {
-      gcc_assert (mode == CCAmode || mode == CCCmode
-		  || mode == CCOmode || mode == CCPmode
-		  || mode == CCSmode || mode == CCZmode);
-      set_dst = gen_rtx_REG (mode, FLAGS_REG);
-    }
-
-  emit_insn (gen_rtx_SET (gen_rtx_STRICT_LOW_PART (VOIDmode, target),
-			  gen_rtx_fmt_ee (comparison, QImode,
-					  set_dst,
-					  const0_rtx)));
-
-  if (label)
-    emit_label (label);
-
-  return SUBREG_REG (target);
+  return ix86_ssecom_setcc (comparison, check_unordered, mode,
+			    set_dst, target);
 }

 static rtx
diff --git a/gcc/testsuite/gcc.target/i386/avx-vcomisd-pr106113-2.c b/gcc/testsuite/gcc.target/i386/avx-vcomisd-pr106113-2.c
new file mode 100644
index 00000000000..9025b1b57b6
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/avx-vcomisd-pr106113-2.c
@@ -0,0 +1,8 @@
+/* { dg-do run } */
+/* { dg-require-effective-target avx } */
+/* { dg-options "-O2 -mavx" } */
+
+#define CHECK_H "avx-check.h"
+#define TEST avx_test
+
+#include "sse2-comisd-pr106113-2.c"
diff --git a/gcc/testsuite/gcc.target/i386/avx-vcomiss-pr106113-2.c b/gcc/testsuite/gcc.target/i386/avx-vcomiss-pr106113-2.c
new file mode 100644
index 00000000000..dc0bf514069
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/avx-vcomiss-pr106113-2.c
@@ -0,0 +1,8 @@
+/* { dg-do run } */
+/* { dg-require-effective-target avx } */
+/* { dg-options "-O2 -mavx" } */
+
+#define CHECK_H "avx-check.h"
+#define TEST avx_test
+
+#include "sse-comiss-pr106113-2.c"
diff --git a/gcc/testsuite/gcc.target/i386/avx-vucomisd-pr106113-2.c b/gcc/testsuite/gcc.target/i386/avx-vucomisd-pr106113-2.c
new file mode 100644
index 00000000000..3b0c5db2332
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/avx-vucomisd-pr106113-2.c
@@ -0,0 +1,8 @@
+/* { dg-do run } */
+/* { dg-require-effective-target avx } */
+/* { dg-options "-O2 -mavx" } */
+
+#define CHECK_H "avx-check.h"
+#define TEST avx_test
+
+#include "sse2-ucomisd-pr106113-2.c"
diff --git a/gcc/testsuite/gcc.target/i386/avx-vucomiss-pr106113-2.c b/gcc/testsuite/gcc.target/i386/avx-vucomiss-pr106113-2.c
new file mode 100644
index 00000000000..d67e4adffeb
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/avx-vucomiss-pr106113-2.c
@@ -0,0 +1,8 @@
+/* { dg-do run } */
+/* { dg-require-effective-target avx } */
+/* { dg-options "-O2 -mavx" } */
+
+#define CHECK_H "avx-check.h"
+#define TEST avx_test
+
+#include "sse-ucomiss-pr106113-2.c"
diff --git a/gcc/testsuite/gcc.target/i386/sse-comiss-pr106113-1.c b/gcc/testsuite/gcc.target/i386/sse-comiss-pr106113-1.c
new file mode 100644
index 00000000000..95621029bf6
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/sse-comiss-pr106113-1.c
@@ -0,0 +1,19 @@
+/* { dg-do compile } */
+/* { dg-options "-msse -O2" } */
+/* { dg-final { scan-assembler-times "comiss\[ \\t\]+\[^\n\]*\[^\n\]*%xmm\[0-9\]+(?:\n|\[ \\t\]+#)" 6  } } */
+/* { dg-final { scan-assembler-times "jp" 2 } } */
+#include <xmmintrin.h>
+
+volatile __m128 x1, x2;
+volatile int res;
+
+void extern
+sse_comi_test (void)
+{
+  res = _mm_comieq_ss (x1, x2);
+  res = _mm_comilt_ss (x1, x2);
+  res = _mm_comile_ss (x1, x2);
+  res = _mm_comigt_ss (x1, x2);
+  res = _mm_comige_ss (x1, x2);
+  res = _mm_comineq_ss (x1, x2);
+}
diff --git a/gcc/testsuite/gcc.target/i386/sse-comiss-pr106113-2.c b/gcc/testsuite/gcc.target/i386/sse-comiss-pr106113-2.c
new file mode 100644
index 00000000000..a90f3337034
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/sse-comiss-pr106113-2.c
@@ -0,0 +1,59 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -msse" } */
+/* { dg-require-effective-target sse } */
+
+#ifndef CHECK_H
+#define CHECK_H "sse-check.h"
+#endif
+
+#ifndef TEST
+#define TEST sse_test
+#endif
+
+#include CHECK_H
+
+#include <xmmintrin.h>
+
+#define CMP(PRED, EXP) \
+      res = _mm_comi##PRED##_ss (__A, __B);           \
+        if (res != EXP)                               \
+	    abort ();
+static void
+__attribute__((noinline, unused))
+do_check (float s1, float s2)
+{
+  __m128 __A = _mm_load_ss (&s1);
+  __m128 __B = _mm_load_ss (&s2);
+  int res;
+
+  CMP (eq, (!__builtin_isunordered (s1, s2) && s1 == s2));
+  CMP (ge, (!__builtin_isunordered (s1, s2) && s1 >= s2));
+  CMP (gt, (!__builtin_isunordered (s1, s2) && s1 > s2));
+  CMP (lt, (!__builtin_isunordered (s1, s2) && s1 < s2));
+  CMP (le, (!__builtin_isunordered (s1, s2) && s1 <= s2));
+  CMP (neq, (__builtin_isunordered (s1, s2) || s1 != s2));
+}
+
+static void
+TEST (void)
+{
+  struct
+    {
+      float x1;
+      float x2;
+    }
+  inputs[] =
+    {
+      { 4.3, 2.18 },
+      { -4.3, 3.18 },
+      { __builtin_nanf (""), -5.8 },
+      { -4.8, __builtin_nansf ("") },
+      { 3.8, __builtin_nansf ("") },
+      { 4.2, 4.2 },
+      { __builtin_nanf (""), __builtin_nansf ("") },
+    };
+  int i;
+
+  for (i = 0; i < sizeof (inputs) / sizeof (inputs[0]); i++)
+    do_check (inputs[i].x1, inputs[i].x2);
+}
diff --git a/gcc/testsuite/gcc.target/i386/sse-ucomiss-pr106113-1.c b/gcc/testsuite/gcc.target/i386/sse-ucomiss-pr106113-1.c
new file mode 100644
index 00000000000..e337e11a557
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/sse-ucomiss-pr106113-1.c
@@ -0,0 +1,19 @@
+/* { dg-do compile } */
+/* { dg-options "-msse -O2" } */
+/* { dg-final { scan-assembler-times "ucomiss\[ \\t\]+\[^\n\]*\[^\n\]*%xmm\[0-9\]+(?:\n|\[ \\t\]+#)" 6  } } */
+/* { dg-final { scan-assembler-times "jp" 2 } } */
+#include <xmmintrin.h>
+
+volatile __m128 x1, x2;
+volatile int res;
+
+void extern
+sse_ucomi_test (void)
+{
+  res = _mm_ucomieq_ss (x1, x2);
+  res = _mm_ucomilt_ss (x1, x2);
+  res = _mm_ucomile_ss (x1, x2);
+  res = _mm_ucomigt_ss (x1, x2);
+  res = _mm_ucomige_ss (x1, x2);
+  res = _mm_ucomineq_ss (x1, x2);
+}
diff --git a/gcc/testsuite/gcc.target/i386/sse-ucomiss-pr106113-2.c b/gcc/testsuite/gcc.target/i386/sse-ucomiss-pr106113-2.c
new file mode 100644
index 00000000000..37d845025c8
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/sse-ucomiss-pr106113-2.c
@@ -0,0 +1,59 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -msse" } */
+/* { dg-require-effective-target sse } */
+
+#ifndef CHECK_H
+#define CHECK_H "sse-check.h"
+#endif
+
+#ifndef TEST
+#define TEST sse_test
+#endif
+
+#include CHECK_H
+
+#include <xmmintrin.h>
+
+#define CMP(PRED, EXP) \
+      res = _mm_ucomi##PRED##_ss (__A, __B);           \
+        if (res != EXP)                               \
+	    abort ();
+static void
+__attribute__((noinline, unused))
+do_check (float s1, float s2)
+{
+  __m128 __A = _mm_load_ss (&s1);
+  __m128 __B = _mm_load_ss (&s2);
+  int res;
+
+  CMP (eq, (!__builtin_isunordered (s1, s2) && s1 == s2));
+  CMP (ge, (!__builtin_isunordered (s1, s2) && s1 >= s2));
+  CMP (gt, (!__builtin_isunordered (s1, s2) && s1 > s2));
+  CMP (lt, (!__builtin_isunordered (s1, s2) && s1 < s2));
+  CMP (le, (!__builtin_isunordered (s1, s2) && s1 <= s2));
+  CMP (neq, (__builtin_isunordered (s1, s2) || s1 != s2));
+}
+
+static void
+TEST (void)
+{
+  struct
+    {
+      float x1;
+      float x2;
+    }
+  inputs[] =
+    {
+      { 4.3, 2.18 },
+      { -4.3, 3.18 },
+      { __builtin_nanf (""), -5.8 },
+      { -4.8, __builtin_nansf ("") },
+      { 3.8, __builtin_nansf ("") },
+      { 4.2, 4.2 },
+      { __builtin_nanf (""), __builtin_nansf ("") },
+    };
+  int i;
+
+  for (i = 0; i < sizeof (inputs) / sizeof (inputs[0]); i++)
+    do_check (inputs[i].x1, inputs[i].x2);
+}
diff --git a/gcc/testsuite/gcc.target/i386/sse2-comisd-pr106113-1.c b/gcc/testsuite/gcc.target/i386/sse2-comisd-pr106113-1.c
new file mode 100644
index 00000000000..6268977d268
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/sse2-comisd-pr106113-1.c
@@ -0,0 +1,19 @@
+/* { dg-do compile } */
+/* { dg-options "-msse2 -O2" } */
+/* { dg-final { scan-assembler-times "comisd\[ \\t\]+\[^\n\]*\[^\n\]*%xmm\[0-9\]+(?:\n|\[ \\t\]+#)" 6  } } */
+/* { dg-final { scan-assembler-times "jp" 2 } } */
+#include <xmmintrin.h>
+
+volatile __m128d x1, x2;
+volatile int res;
+
+void extern
+sse2_comisd_test (void)
+{
+  res = _mm_comieq_sd (x1, x2);
+  res = _mm_comilt_sd (x1, x2);
+  res = _mm_comile_sd (x1, x2);
+  res = _mm_comigt_sd (x1, x2);
+  res = _mm_comige_sd (x1, x2);
+  res = _mm_comineq_sd (x1, x2);
+}
diff --git a/gcc/testsuite/gcc.target/i386/sse2-comisd-pr106113-2.c b/gcc/testsuite/gcc.target/i386/sse2-comisd-pr106113-2.c
new file mode 100644
index 00000000000..f49771c9212
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/sse2-comisd-pr106113-2.c
@@ -0,0 +1,59 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -msse2" } */
+/* { dg-require-effective-target sse2 } */
+
+#ifndef CHECK_H
+#define CHECK_H "sse2-check.h"
+#endif
+
+#ifndef TEST
+#define TEST sse2_test
+#endif
+
+#include CHECK_H
+
+#include <emmintrin.h>
+
+#define CMP(PRED, EXP) \
+      res = _mm_comi##PRED##_sd (__A, __B);           \
+        if (res != EXP)                               \
+	    abort ();
+static void
+__attribute__((noinline, unused))
+do_check (double s1, double s2)
+{
+  __m128d __A = _mm_load_sd (&s1);
+  __m128d __B = _mm_load_sd (&s2);
+  int res;
+
+  CMP (eq, (!__builtin_isunordered (s1, s2) && s1 == s2));
+  CMP (ge, (!__builtin_isunordered (s1, s2) && s1 >= s2));
+  CMP (gt, (!__builtin_isunordered (s1, s2) && s1 > s2));
+  CMP (lt, (!__builtin_isunordered (s1, s2) && s1 < s2));
+  CMP (le, (!__builtin_isunordered (s1, s2) && s1 <= s2));
+  CMP (neq, (__builtin_isunordered (s1, s2) || s1 != s2));
+}
+
+static void
+TEST (void)
+{
+  struct
+    {
+      double x1;
+      double x2;
+    }
+  inputs[] =
+    {
+      { 4.3, 2.18 },
+      { -4.3, 3.18 },
+      { __builtin_nan (""), -5.8 },
+      { -4.8, __builtin_nans ("") },
+      { 3.8, __builtin_nans ("") },
+      { 4.2, 4.2 },
+      { __builtin_nan (""), __builtin_nans ("") },
+    };
+  int i;
+
+  for (i = 0; i < sizeof (inputs) / sizeof (inputs[0]); i++)
+    do_check (inputs[i].x1, inputs[i].x2);
+}
diff --git a/gcc/testsuite/gcc.target/i386/sse2-ucomisd-pr106113-1.c b/gcc/testsuite/gcc.target/i386/sse2-ucomisd-pr106113-1.c
new file mode 100644
index 00000000000..e64c0ace0cc
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/sse2-ucomisd-pr106113-1.c
@@ -0,0 +1,19 @@
+/* { dg-do compile } */
+/* { dg-options "-msse2 -O2" } */
+/* { dg-final { scan-assembler-times "ucomisd\[ \\t\]+\[^\n\]*\[^\n\]*%xmm\[0-9\]+(?:\n|\[ \\t\]+#)" 6  } } */
+/* { dg-final { scan-assembler-times "jp" 2 } } */
+#include <xmmintrin.h>
+
+volatile __m128d x1, x2;
+volatile int res;
+
+void extern
+sse2_ucomisd_test (void)
+{
+  res = _mm_ucomieq_sd (x1, x2);
+  res = _mm_ucomilt_sd (x1, x2);
+  res = _mm_ucomile_sd (x1, x2);
+  res = _mm_ucomigt_sd (x1, x2);
+  res = _mm_ucomige_sd (x1, x2);
+  res = _mm_ucomineq_sd (x1, x2);
+}
diff --git a/gcc/testsuite/gcc.target/i386/sse2-ucomisd-pr106113-2.c b/gcc/testsuite/gcc.target/i386/sse2-ucomisd-pr106113-2.c
new file mode 100644
index 00000000000..606a8971c26
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/sse2-ucomisd-pr106113-2.c
@@ -0,0 +1,59 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -msse2" } */
+/* { dg-require-effective-target sse2 } */
+
+#ifndef CHECK_H
+#define CHECK_H "sse2-check.h"
+#endif
+
+#ifndef TEST
+#define TEST sse2_test
+#endif
+
+#include CHECK_H
+
+#include <emmintrin.h>
+
+#define CMP(PRED, EXP) \
+      res = _mm_ucomi##PRED##_sd (__A, __B);           \
+        if (res != EXP)                               \
+	    abort ();
+static void
+__attribute__((noinline, unused))
+do_check (double s1, double s2)
+{
+  __m128d __A = _mm_load_sd (&s1);
+  __m128d __B = _mm_load_sd (&s2);
+  int res;
+
+  CMP (eq, (!__builtin_isunordered (s1, s2) && s1 == s2));
+  CMP (ge, (!__builtin_isunordered (s1, s2) && s1 >= s2));
+  CMP (gt, (!__builtin_isunordered (s1, s2) && s1 > s2));
+  CMP (lt, (!__builtin_isunordered (s1, s2) && s1 < s2));
+  CMP (le, (!__builtin_isunordered (s1, s2) && s1 <= s2));
+  CMP (neq, (__builtin_isunordered (s1, s2) || s1 != s2));
+}
+
+static void
+TEST (void)
+{
+  struct
+    {
+      double x1;
+      double x2;
+    }
+  inputs[] =
+    {
+      { 4.3, 2.18 },
+      { -4.3, 3.18 },
+      { __builtin_nan (""), -5.8 },
+      { -4.8, __builtin_nans ("") },
+      { 3.8, __builtin_nans ("") },
+      { 4.2, 4.2 },
+      { __builtin_nan (""), __builtin_nans ("") },
+    };
+  int i;
+
+  for (i = 0; i < sizeof (inputs) / sizeof (inputs[0]); i++)
+    do_check (inputs[i].x1, inputs[i].x2);
+}
--
2.18.2

diff --git a/gcc/config/i386/predicates.md b/gcc/config/i386/predicates.md
index c71c453..42053ea 100644
--- a/gcc/config/i386/predicates.md
+++ b/gcc/config/i386/predicates.md
@@ -1199,6 +1199,10 @@
 (define_predicate "x86_64_const_vector_operand"
   (match_code "const_vector")
 {
+  if (mode == VOIDmode)
+    mode = GET_MODE (op);
+  else if (GET_MODE (op) != mode)
+    return false;
   if (GET_MODE_SIZE (mode) > UNITS_PER_WORD)
     return false;
   HOST_WIDE_INT val = ix86_convert_const_vector_to_integer (op, mode);

diff --git a/gcc/config/i386/i386.md b/gcc/config/i386/i386.md
index 3b02d0c..164b0c2 100644
--- a/gcc/config/i386/i386.md
+++ b/gcc/config/i386/i386.md
@@ -16431,6 +16431,66 @@
    (set_attr "prefix_rep" "1")
    (set_attr "mode" "SI")])

+(define_insn_and_split "*ctzsidi2_<s>ext"
+  [(set (match_operand:DI 0 "register_operand" "=r")
+	(any_extend:DI
+	  (ctz:SI
+	    (match_operand:SI 1 "nonimmediate_operand" "rm"))))
+   (clobber (reg:CC FLAGS_REG))]
+  "TARGET_64BIT"
+{
+  if (TARGET_BMI)
+    return "tzcnt{l}\t{%1, %k0|%k0, %1}";
+  else if (TARGET_CPU_P (GENERIC)
+	   && !optimize_function_for_size_p (cfun))
+    /* tzcnt expands to 'rep bsf' and we can use it even if !TARGET_BMI.  */
+    return "rep%; bsf{l}\t{%1, %k0|%k0, %1}";
+  return "bsf{l}\t{%1, %k0|%k0, %1}";
+}
+  "(TARGET_BMI || TARGET_CPU_P (GENERIC))
+   && TARGET_AVOID_FALSE_DEP_FOR_BMI && epilogue_completed
+   && optimize_function_for_speed_p (cfun)
+   && !reg_mentioned_p (operands[0], operands[1])"
+  [(parallel
+    [(set (match_dup 0)
+	  (any_extend:DI (ctz:SI (match_dup 1))))
+     (unspec [(match_dup 0)] UNSPEC_INSN_FALSE_DEP)
+     (clobber (reg:CC FLAGS_REG))])]
+  "ix86_expand_clear (operands[0]);"
+  [(set_attr "type" "alu1")
+   (set_attr "prefix_0f" "1")
+   (set (attr "prefix_rep")
+     (if_then_else
+       (ior (match_test "TARGET_BMI")
+	    (and (not (match_test "optimize_function_for_size_p (cfun)"))
+		 (match_test "TARGET_CPU_P (GENERIC)")))
+       (const_string "1")
+       (const_string "0")))
+   (set_attr "mode" "SI")])
+
+(define_insn "*ctzsidi2_<s>ext_falsedep"
+  [(set (match_operand:DI 0 "register_operand" "=r")
+	(any_extend:DI
+	  (ctz:SI
+	    (match_operand:SI 1 "nonimmediate_operand" "rm"))))
+   (unspec [(match_operand:DI 2 "register_operand" "0")]
+	   UNSPEC_INSN_FALSE_DEP)
+   (clobber (reg:CC FLAGS_REG))]
+  "TARGET_64BIT"
+{
+  if (TARGET_BMI)
+    return "tzcnt{l}\t{%1, %k0|%k0, %1}";
+  else if (TARGET_CPU_P (GENERIC))
+    /* tzcnt expands to 'rep bsf' and we can use it even if !TARGET_BMI.  */
+    return "rep%; bsf{l}\t{%1, %k0|%k0, %1}";
+  else
+    gcc_unreachable ();
+}
+  [(set_attr "type" "alu1")
+   (set_attr "prefix_0f" "1")
+   (set_attr "prefix_rep" "1")
+   (set_attr "mode" "SI")])
+
 (define_insn "bsr_rex64"
   [(set (reg:CCZ FLAGS_REG)
 	(compare:CCZ (match_operand:DI 1 "nonimmediate_operand" "rm")
diff --git a/gcc/testsuite/gcc.target/i386/pr106231-1.c b/gcc/testsuite/gcc.target/i386/pr106231-1.c
new file mode 100644
index 0000000..d17297f
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106231-1.c
@@ -0,0 +1,8 @@
+/* { dg-do compile { target { ! ia32 } } } */
+/* { dg-options "-O2 -mtune=generic" } */
+long long
+foo(long long x, unsigned bits)
+{
+  return x + (unsigned) __builtin_ctz(bits);
+}
+/* { dg-final { scan-assembler-not "cltq" } } */
diff --git a/gcc/testsuite/gcc.target/i386/pr106231-2.c b/gcc/testsuite/gcc.target/i386/pr106231-2.c
new file mode 100644
index 0000000..fd3a8e3
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106231-2.c
@@ -0,0 +1,8 @@
+/* { dg-do compile { target { ! ia32 } } } */
+/* { dg-options "-O2 -mtune=ivybridge" } */
+long long
+foo(long long x, unsigned bits)
+{
+  return x + (unsigned) __builtin_ctz(bits);
+}
+/* { dg-final { scan-assembler-not "cltq" } } */

__builtin_cexpi can't be vectorized since there's gap between it and
vectorized sincos version(In libmvec, it passes a double and two
double pointer and returns nothing.) And it will lose some
vectorization opportunity if sin & cos are optimized to cexpi before
vectorizer.

I'm trying to add vect_recog_cexpi_pattern to split cexpi to sin and
cos, but it failed vectorizable_simd_clone_call since NULL is returned
by cgraph_node::get (fndecl).  So alternatively, the patch try to move
pass_cse_sincos after vectorizer, just before pas_cse_reciprocals.

Also original pass_cse_sincos additionaly expands pow&cabs, this patch
split that part into a separate pass named pass_expand_powcabs which
remains the old pass position.

Bootstrapped and regtested on x86_64-pc-linux-gnu{-m32,}.
Observe more libmvec sin/cos vectorization in specfp, but no big performance.

Ok for trunk?

gcc/ChangeLog:

	* passes.def: (Split pass_cse_sincos to pass_expand_powcabs
	and pass_cse_sincos, and move pass_cse_sincos after vectorizer).
	* timevar.def (TV_TREE_POWCABS): New timevar.
	* tree-pass.h (make_pass_expand_powcabs): Split from pass_cse_sincos.
	* tree-ssa-math-opts.cc (gimple_expand_builtin_cabs): Ditto.
	(class pass_expand_powcabs): Ditto.
	(pass_expand_powcabs::execute): Ditto.
	(make_pass_expand_powcabs): Ditto.
	(pass_cse_sincos::execute): Remove pow/cabs expand part.
	(make_pass_cse_sincos): Ditto.

gcc/testsuite/ChangeLog:

	* gcc.dg/pow-sqrt-synth-1.c: Adjust testcase.
---
 gcc/passes.def                          |   3 +-
 gcc/testsuite/gcc.dg/pow-sqrt-synth-1.c |   4 +-
 gcc/timevar.def                         |   1 +
 gcc/tree-pass.h                         |   1 +
 gcc/tree-ssa-math-opts.cc               | 112 +++++++++++++++++++-----
 5 files changed, 97 insertions(+), 24 deletions(-)

diff --git a/gcc/passes.def b/gcc/passes.def
index 375d3d62d51..6bb92efacd4 100644
--- a/gcc/passes.def
+++ b/gcc/passes.def
@@ -253,7 +253,7 @@ along with GCC; see the file COPYING3.  If not see
       NEXT_PASS (pass_ccp, true /* nonzero_p */);
       /* After CCP we rewrite no longer addressed locals into SSA
 	 form if possible.  */
-      NEXT_PASS (pass_cse_sincos);
+      NEXT_PASS (pass_expand_powcabs);
       NEXT_PASS (pass_optimize_bswap);
       NEXT_PASS (pass_laddress);
       NEXT_PASS (pass_lim);
@@ -328,6 +328,7 @@ along with GCC; see the file COPYING3.  If not see
       NEXT_PASS (pass_simduid_cleanup);
       NEXT_PASS (pass_lower_vector_ssa);
       NEXT_PASS (pass_lower_switch);
+      NEXT_PASS (pass_cse_sincos);
       NEXT_PASS (pass_cse_reciprocals);
       NEXT_PASS (pass_reassoc, false /* early_p */);
       NEXT_PASS (pass_strength_reduction);
diff --git a/gcc/testsuite/gcc.dg/pow-sqrt-synth-1.c b/gcc/testsuite/gcc.dg/pow-sqrt-synth-1.c
index 4a94325cdb3..484b29a8fc8 100644
--- a/gcc/testsuite/gcc.dg/pow-sqrt-synth-1.c
+++ b/gcc/testsuite/gcc.dg/pow-sqrt-synth-1.c
@@ -1,5 +1,5 @@
 /* { dg-do compile { target sqrt_insn } } */
-/* { dg-options "-fdump-tree-sincos -Ofast --param max-pow-sqrt-depth=8" } */
+/* { dg-options "-fdump-tree-powcabs -Ofast --param max-pow-sqrt-depth=8" } */
 /* { dg-additional-options "-mfloat-abi=softfp -mfpu=neon-vfpv4" { target arm*-*-* } } */

 double
@@ -34,4 +34,4 @@ vecfoo (double *a)
     a[i] = __builtin_pow (a[i], 1.25);
 }

-/* { dg-final { scan-tree-dump-times "synthesizing" 7 "sincos" } } */
+/* { dg-final { scan-tree-dump-times "synthesizing" 7 "powcabs" } } */
diff --git a/gcc/timevar.def b/gcc/timevar.def
index 2dae5e1c760..651af19876f 100644
--- a/gcc/timevar.def
+++ b/gcc/timevar.def
@@ -220,6 +220,7 @@ DEFTIMEVAR (TV_TREE_SWITCH_CONVERSION, "tree switch conversion")
 DEFTIMEVAR (TV_TREE_SWITCH_LOWERING,   "tree switch lowering")
 DEFTIMEVAR (TV_TREE_RECIP            , "gimple CSE reciprocals")
 DEFTIMEVAR (TV_TREE_SINCOS           , "gimple CSE sin/cos")
+DEFTIMEVAR (TV_TREE_POWCABS           , "gimple expand pow/cabs")
 DEFTIMEVAR (TV_TREE_WIDEN_MUL        , "gimple widening/fma detection")
 DEFTIMEVAR (TV_TRANS_MEM             , "transactional memory")
 DEFTIMEVAR (TV_TREE_STRLEN           , "tree strlen optimization")
diff --git a/gcc/tree-pass.h b/gcc/tree-pass.h
index 606d1d60b85..4dfe05ed8e0 100644
--- a/gcc/tree-pass.h
+++ b/gcc/tree-pass.h
@@ -444,6 +444,7 @@ extern gimple_opt_pass *make_pass_early_warn_uninitialized (gcc::context *ctxt);
 extern gimple_opt_pass *make_pass_late_warn_uninitialized (gcc::context *ctxt);
 extern gimple_opt_pass *make_pass_cse_reciprocals (gcc::context *ctxt);
 extern gimple_opt_pass *make_pass_cse_sincos (gcc::context *ctxt);
+extern gimple_opt_pass *make_pass_expand_powcabs (gcc::context *ctxt);
 extern gimple_opt_pass *make_pass_optimize_bswap (gcc::context *ctxt);
 extern gimple_opt_pass *make_pass_store_merging (gcc::context *ctxt);
 extern gimple_opt_pass *make_pass_optimize_widening_mul (gcc::context *ctxt);
diff --git a/gcc/tree-ssa-math-opts.cc b/gcc/tree-ssa-math-opts.cc
index a4492c96419..58152b5a01c 100644
--- a/gcc/tree-ssa-math-opts.cc
+++ b/gcc/tree-ssa-math-opts.cc
@@ -2226,8 +2226,7 @@ gimple_expand_builtin_cabs (gimple_stmt_iterator *gsi, location_t loc, tree arg)
 }

 /* Go through all calls to sin, cos and cexpi and call execute_cse_sincos_1
-   on the SSA_NAME argument of each of them.  Also expand powi(x,n) into
-   an optimal number of multiplies, when n is a constant.  */
+   on the SSA_NAME argument of each of them.  */

 namespace {

@@ -2254,8 +2253,6 @@ public:
   /* opt_pass methods: */
   bool gate (function *) final override
     {
-      /* We no longer require either sincos or cexp, since powi expansion
-	 piggybacks on this pass.  */
       return optimize;
     }

@@ -2275,24 +2272,15 @@ pass_cse_sincos::execute (function *fun)
   FOR_EACH_BB_FN (bb, fun)
     {
       gimple_stmt_iterator gsi;
-      bool cleanup_eh = false;

       for (gsi = gsi_after_labels (bb); !gsi_end_p (gsi); gsi_next (&gsi))
         {
 	  gimple *stmt = gsi_stmt (gsi);

-	  /* Only the last stmt in a bb could throw, no need to call
-	     gimple_purge_dead_eh_edges if we change something in the middle
-	     of a basic block.  */
-	  cleanup_eh = false;
-
 	  if (is_gimple_call (stmt)
 	      && gimple_call_lhs (stmt))
 	    {
-	      tree arg, arg0, arg1, result;
-	      HOST_WIDE_INT n;
-	      location_t loc;
-
+	      tree arg;
 	      switch (gimple_call_combined_fn (stmt))
 		{
 		CASE_CFN_COS:
@@ -2309,7 +2297,94 @@ pass_cse_sincos::execute (function *fun)
 		  if (TREE_CODE (arg) == SSA_NAME)
 		    cfg_changed |= execute_cse_sincos_1 (arg);
 		  break;
+		default:
+		  break;
+		}
+	    }
+	}
+    }
+
+  statistics_counter_event (fun, "sincos statements inserted",
+			    sincos_stats.inserted);
+  statistics_counter_event (fun, "conv statements removed",
+			    sincos_stats.conv_removed);
+
+  return cfg_changed ? TODO_cleanup_cfg : 0;
+}
+
+} // anon namespace
+
+gimple_opt_pass *
+make_pass_cse_sincos (gcc::context *ctxt)
+{
+  return new pass_cse_sincos (ctxt);
+}
+
+/* Expand powi(x,n) into an optimal number of multiplies, when n is a constant.
+   Also expand CABS.  */
+namespace {
+
+const pass_data pass_data_expand_powcabs =
+{
+  GIMPLE_PASS, /* type */
+  "powcabs", /* name */
+  OPTGROUP_NONE, /* optinfo_flags */
+  TV_TREE_POWCABS, /* tv_id */
+  PROP_ssa, /* properties_required */
+  0, /* properties_provided */
+  0, /* properties_destroyed */
+  0, /* todo_flags_start */
+  TODO_update_ssa, /* todo_flags_finish */
+};
+
+class pass_expand_powcabs : public gimple_opt_pass
+{
+public:
+  pass_expand_powcabs (gcc::context *ctxt)
+    : gimple_opt_pass (pass_data_expand_powcabs, ctxt)
+  {}

+  /* opt_pass methods: */
+  bool gate (function *) final override
+    {
+      return optimize;
+    }
+
+  unsigned int execute (function *) final override;
+
+}; // class pass_expand_powcabs
+
+unsigned int
+pass_expand_powcabs::execute (function *fun)
+{
+  basic_block bb;
+  bool cfg_changed = false;
+
+  calculate_dominance_info (CDI_DOMINATORS);
+
+  FOR_EACH_BB_FN (bb, fun)
+    {
+      gimple_stmt_iterator gsi;
+      bool cleanup_eh = false;
+
+      for (gsi = gsi_after_labels (bb); !gsi_end_p (gsi); gsi_next (&gsi))
+        {
+	  gimple *stmt = gsi_stmt (gsi);
+
+	  /* Only the last stmt in a bb could throw, no need to call
+	     gimple_purge_dead_eh_edges if we change something in the middle
+	     of a basic block.  */
+	  cleanup_eh = false;
+
+	  if (is_gimple_call (stmt)
+	      && gimple_call_lhs (stmt))
+	    {
+	      tree arg0, arg1, result;
+	      HOST_WIDE_INT n;
+	      location_t loc;
+
+	      switch (gimple_call_combined_fn (stmt))
+		{
 		CASE_CFN_POW:
 		  arg0 = gimple_call_arg (stmt, 0);
 		  arg1 = gimple_call_arg (stmt, 1);
@@ -2405,20 +2480,15 @@ pass_cse_sincos::execute (function *fun)
 	cfg_changed |= gimple_purge_dead_eh_edges (bb);
     }

-  statistics_counter_event (fun, "sincos statements inserted",
-			    sincos_stats.inserted);
-  statistics_counter_event (fun, "conv statements removed",
-			    sincos_stats.conv_removed);
-
   return cfg_changed ? TODO_cleanup_cfg : 0;
 }

 } // anon namespace

 gimple_opt_pass *
-make_pass_cse_sincos (gcc::context *ctxt)
+make_pass_expand_powcabs (gcc::context *ctxt)
 {
-  return new pass_cse_sincos (ctxt);
+  return new pass_expand_powcabs (ctxt);
 }

 /* Return true if stmt is a type conversion operation that can be stripped
--
2.18.1

This is the patch as suggested, one additional change is handling COMPLEX_CST
for rhs. And it will enable vectorization for pr106010-8a.c.

Bootstrapped and regtested on x86_64-pc-linux-gnu{-m32,}.
Ok for trunk?

2022-07-20  Richard Biener  <richard.guenther@gmail.com>
	    Hongtao Liu  <hongtao.liu@intel.com>

gcc/ChangeLog:

	PR tree-optimization/106010
	* tree-complex.cc (init_dont_simulate_again): Lower complex
	type move.
	(expand_complex_move): Also expand COMPLEX_CST for rhs.

gcc/testsuite/ChangeLog:

	* gcc.target/i386/pr106010-1a.c: New test.
	* gcc.target/i386/pr106010-1b.c: New test.
	* gcc.target/i386/pr106010-1c.c: New test.
	* gcc.target/i386/pr106010-2a.c: New test.
	* gcc.target/i386/pr106010-2b.c: New test.
	* gcc.target/i386/pr106010-2c.c: New test.
	* gcc.target/i386/pr106010-3a.c: New test.
	* gcc.target/i386/pr106010-3b.c: New test.
	* gcc.target/i386/pr106010-3c.c: New test.
	* gcc.target/i386/pr106010-4a.c: New test.
	* gcc.target/i386/pr106010-4b.c: New test.
	* gcc.target/i386/pr106010-4c.c: New test.
	* gcc.target/i386/pr106010-5a.c: New test.
	* gcc.target/i386/pr106010-5b.c: New test.
	* gcc.target/i386/pr106010-5c.c: New test.
	* gcc.target/i386/pr106010-6a.c: New test.
	* gcc.target/i386/pr106010-6b.c: New test.
	* gcc.target/i386/pr106010-6c.c: New test.
	* gcc.target/i386/pr106010-7a.c: New test.
	* gcc.target/i386/pr106010-7b.c: New test.
	* gcc.target/i386/pr106010-7c.c: New test.
	* gcc.target/i386/pr106010-8a.c: New test.
	* gcc.target/i386/pr106010-8b.c: New test.
	* gcc.target/i386/pr106010-8c.c: New test.
	* gcc.target/i386/pr106010-9a.c: New test.
	* gcc.target/i386/pr106010-9b.c: New test.
	* gcc.target/i386/pr106010-9c.c: New test.
	* gcc.target/i386/pr106010-9d.c: New test.
---
 gcc/testsuite/gcc.target/i386/pr106010-1a.c |  58 ++++++++
 gcc/testsuite/gcc.target/i386/pr106010-1b.c |  63 ++++++++
 gcc/testsuite/gcc.target/i386/pr106010-1c.c |  41 +++++
 gcc/testsuite/gcc.target/i386/pr106010-2a.c |  82 ++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-2b.c |  62 ++++++++
 gcc/testsuite/gcc.target/i386/pr106010-2c.c |  47 ++++++
 gcc/testsuite/gcc.target/i386/pr106010-3a.c |  80 ++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-3b.c | 126 ++++++++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-3c.c |  69 +++++++++
 gcc/testsuite/gcc.target/i386/pr106010-4a.c | 101 +++++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-4b.c |  67 +++++++++
 gcc/testsuite/gcc.target/i386/pr106010-4c.c |  54 +++++++
 gcc/testsuite/gcc.target/i386/pr106010-5a.c | 117 +++++++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-5b.c |  80 ++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-5c.c |  62 ++++++++
 gcc/testsuite/gcc.target/i386/pr106010-6a.c | 115 ++++++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-6b.c | 157 ++++++++++++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-6c.c |  80 ++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-7a.c |  58 ++++++++
 gcc/testsuite/gcc.target/i386/pr106010-7b.c |  63 ++++++++
 gcc/testsuite/gcc.target/i386/pr106010-7c.c |  41 +++++
 gcc/testsuite/gcc.target/i386/pr106010-8a.c |  58 ++++++++
 gcc/testsuite/gcc.target/i386/pr106010-8b.c |  53 +++++++
 gcc/testsuite/gcc.target/i386/pr106010-8c.c |  38 +++++
 gcc/testsuite/gcc.target/i386/pr106010-9a.c |  89 +++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-9b.c |  90 +++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-9c.c |  90 +++++++++++
 gcc/testsuite/gcc.target/i386/pr106010-9d.c |  92 ++++++++++++
 gcc/tree-complex.cc                         |   9 +-
 29 files changed, 2141 insertions(+), 1 deletion(-)
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-1a.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-1b.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-1c.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-2a.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-2b.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-2c.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-3a.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-3b.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-3c.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-4a.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-4b.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-4c.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-5a.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-5b.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-5c.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-6a.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-6b.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-6c.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-7a.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-7b.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-7c.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-8a.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-8b.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-8c.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-9a.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-9b.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-9c.c
 create mode 100644 gcc/testsuite/gcc.target/i386/pr106010-9d.c

diff --git a/gcc/testsuite/gcc.target/i386/pr106010-1a.c b/gcc/testsuite/gcc.target/i386/pr106010-1a.c
new file mode 100644
index 00000000000..b608f484934
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-1a.c
@@ -0,0 +1,58 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -fdump-tree-vect-details -mprefer-vector-width=256" } */
+/* { dg-final { scan-tree-dump-times "vectorized 1 loops" 6 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) double>} 2 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) float>} 2 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) long long int>} 2 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) int>} 2 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) short int>} 2 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(32\) char>} 2 "vect" } } */
+
+#define N 10000
+void
+__attribute__((noipa))
+foo_pd (_Complex double* a, _Complex double* b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b[i];
+}
+
+void
+__attribute__((noipa))
+foo_ps (_Complex float* a, _Complex float* b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b[i];
+}
+
+void
+__attribute__((noipa))
+foo_epi64 (_Complex long long* a, _Complex long long* b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b[i];
+}
+
+void
+__attribute__((noipa))
+foo_epi32 (_Complex int* a, _Complex int* b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b[i];
+}
+
+void
+__attribute__((noipa))
+foo_epi16 (_Complex short* a, _Complex short* b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b[i];
+}
+
+void
+__attribute__((noipa))
+foo_epi8 (_Complex char* a, _Complex char* b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b[i];
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-1b.c b/gcc/testsuite/gcc.target/i386/pr106010-1b.c
new file mode 100644
index 00000000000..0f377c3a548
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-1b.c
@@ -0,0 +1,63 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx } */
+
+#include "avx-check.h"
+#include <string.h>
+#include "pr106010-1a.c"
+
+void
+avx_test (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (2 * N * sizeof (double));
+  _Complex double* pd_dst = (_Complex double*) malloc (2 * N * sizeof (double));
+  _Complex float* ps_src = (_Complex float*) malloc (2 * N * sizeof (float));
+  _Complex float* ps_dst = (_Complex float*) malloc (2 * N * sizeof (float));
+  _Complex long long* epi64_src = (_Complex long long*) malloc (2 * N * sizeof (long long));
+  _Complex long long* epi64_dst = (_Complex long long*) malloc (2 * N * sizeof (long long));
+  _Complex int* epi32_src = (_Complex int*) malloc (2 * N * sizeof (int));
+  _Complex int* epi32_dst = (_Complex int*) malloc (2 * N * sizeof (int));
+  _Complex short* epi16_src = (_Complex short*) malloc (2 * N * sizeof (short));
+  _Complex short* epi16_dst = (_Complex short*) malloc (2 * N * sizeof (short));
+  _Complex char* epi8_src = (_Complex char*) malloc (2 * N * sizeof (char));
+  _Complex char* epi8_dst = (_Complex char*) malloc (2 * N * sizeof (char));
+  char* p_init = (char*) malloc (2 * N * sizeof (double));
+
+  __builtin_memset (pd_dst, 0, 2 * N * sizeof (double));
+  __builtin_memset (ps_dst, 0, 2 * N * sizeof (float));
+  __builtin_memset (epi64_dst, 0, 2 * N * sizeof (long long));
+  __builtin_memset (epi32_dst, 0, 2 * N * sizeof (int));
+  __builtin_memset (epi16_dst, 0, 2 * N * sizeof (short));
+  __builtin_memset (epi8_dst, 0, 2 * N * sizeof (char));
+
+  for (int i = 0; i != 2 * N * sizeof (double); i++)
+    p_init[i] = i;
+
+  memcpy (pd_src, p_init, 2 * N * sizeof (double));
+  memcpy (ps_src, p_init, 2 * N * sizeof (float));
+  memcpy (epi64_src, p_init, 2 * N * sizeof (long long));
+  memcpy (epi32_src, p_init, 2 * N * sizeof (int));
+  memcpy (epi16_src, p_init, 2 * N * sizeof (short));
+  memcpy (epi8_src, p_init, 2 * N * sizeof (char));
+
+  foo_pd (pd_dst, pd_src);
+  foo_ps (ps_dst, ps_src);
+  foo_epi64 (epi64_dst, epi64_src);
+  foo_epi32 (epi32_dst, epi32_src);
+  foo_epi16 (epi16_dst, epi16_src);
+  foo_epi8 (epi8_dst, epi8_src);
+  if (__builtin_memcmp (pd_dst, pd_src, N * 2 * sizeof (double)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (ps_dst, ps_src, N * 2 * sizeof (float)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi64_dst, epi64_src, N * 2 * sizeof (long long)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi32_dst, epi32_src, N * 2 * sizeof (int)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi16_dst, epi16_src, N * 2 * sizeof (short)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi8_dst, epi8_src, N * 2 * sizeof (char)) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-1c.c b/gcc/testsuite/gcc.target/i386/pr106010-1c.c
new file mode 100644
index 00000000000..f07e9fb2d3d
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-1c.c
@@ -0,0 +1,41 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx512fp16 -mavx512vl -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256 -fdump-tree-vect-details" } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) _Float16>} 2 "vect" } } */
+/* { dg-require-effective-target avx512fp16 } */
+
+#include <string.h>
+
+static void do_test (void);
+
+#define DO_TEST do_test
+#define AVX512FP16
+#include "avx512-check.h"
+
+#define N 10000
+
+void
+__attribute__((noipa))
+foo_ph (_Complex _Float16* a, _Complex _Float16* b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b[i];
+}
+
+static void
+do_test (void)
+{
+  _Complex _Float16* ph_src = (_Complex _Float16*) malloc (2 * N * sizeof (_Float16));
+  _Complex _Float16* ph_dst = (_Complex _Float16*) malloc (2 * N * sizeof (_Float16));
+  char* p_init = (char*) malloc (2 * N * sizeof (_Float16));
+
+  __builtin_memset (ph_dst, 0, 2 * N * sizeof (_Float16));
+
+  for (int i = 0; i != 2 * N * sizeof (_Float16); i++)
+    p_init[i] = i;
+
+  memcpy (ph_src, p_init, 2 * N * sizeof (_Float16));
+
+  foo_ph (ph_dst, ph_src);
+  if (__builtin_memcmp (ph_dst, ph_src, N * 2 * sizeof (_Float16)) != 0)
+    __builtin_abort ();
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-2a.c b/gcc/testsuite/gcc.target/i386/pr106010-2a.c
new file mode 100644
index 00000000000..d2e2f8d4f43
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-2a.c
@@ -0,0 +1,82 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -fdump-tree-slp-details -mprefer-vector-width=256" } */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 6 "slp2" } }*/
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) double>} 2 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) float>} 2 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) long long int>} 2 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) int>} 2 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) short int>} 2 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(32\) char>} 2 "slp2" } } */
+
+void
+__attribute__((noipa))
+foo_pd (_Complex double* a, _Complex double* __restrict b)
+{
+  a[0] = b[0];
+  a[1] = b[1];
+}
+
+void
+__attribute__((noipa))
+foo_ps (_Complex float* a, _Complex float* __restrict b)
+{
+  a[0] = b[0];
+  a[1] = b[1];
+  a[2] = b[2];
+  a[3] = b[3];
+
+}
+
+void
+__attribute__((noipa))
+foo_epi64 (_Complex long long* a, _Complex long long* __restrict b)
+{
+  a[0] = b[0];
+  a[1] = b[1];
+}
+
+void
+__attribute__((noipa))
+foo_epi32 (_Complex int* a, _Complex int* __restrict b)
+{
+  a[0] = b[0];
+  a[1] = b[1];
+  a[2] = b[2];
+  a[3] = b[3];
+}
+
+void
+__attribute__((noipa))
+foo_epi16 (_Complex short* a, _Complex short* __restrict b)
+{
+  a[0] = b[0];
+  a[1] = b[1];
+  a[2] = b[2];
+  a[3] = b[3];
+  a[4] = b[4];
+  a[5] = b[5];
+  a[6] = b[6];
+  a[7] = b[7];
+}
+
+void
+__attribute__((noipa))
+foo_epi8 (_Complex char* a, _Complex char* __restrict b)
+{
+  a[0] = b[0];
+  a[1] = b[1];
+  a[2] = b[2];
+  a[3] = b[3];
+  a[4] = b[4];
+  a[5] = b[5];
+  a[6] = b[6];
+  a[7] = b[7];
+  a[8] = b[8];
+  a[9] = b[9];
+  a[10] = b[10];
+  a[11] = b[11];
+  a[12] = b[12];
+  a[13] = b[13];
+  a[14] = b[14];
+  a[15] = b[15];
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-2b.c b/gcc/testsuite/gcc.target/i386/pr106010-2b.c
new file mode 100644
index 00000000000..ac360752693
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-2b.c
@@ -0,0 +1,62 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx } */
+
+#include "avx-check.h"
+#include <string.h>
+#include "pr106010-2a.c"
+
+void
+avx_test (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (32);
+  _Complex double* pd_dst = (_Complex double*) malloc (32);
+  _Complex float* ps_src = (_Complex float*) malloc (32);
+  _Complex float* ps_dst = (_Complex float*) malloc (32);
+  _Complex long long* epi64_src = (_Complex long long*) malloc (32);
+  _Complex long long* epi64_dst = (_Complex long long*) malloc (32);
+  _Complex int* epi32_src = (_Complex int*) malloc (32);
+  _Complex int* epi32_dst = (_Complex int*) malloc (32);
+  _Complex short* epi16_src = (_Complex short*) malloc (32);
+  _Complex short* epi16_dst = (_Complex short*) malloc (32);
+  _Complex char* epi8_src = (_Complex char*) malloc (32);
+  _Complex char* epi8_dst = (_Complex char*) malloc (32);
+  char* p = (char* ) malloc (32);
+
+  __builtin_memset (pd_dst, 0, 32);
+  __builtin_memset (ps_dst, 0, 32);
+  __builtin_memset (epi64_dst, 0, 32);
+  __builtin_memset (epi32_dst, 0, 32);
+  __builtin_memset (epi16_dst, 0, 32);
+  __builtin_memset (epi8_dst, 0, 32);
+
+  for (int i = 0; i != 32; i++)
+    p[i] = i;
+  __builtin_memcpy (pd_src, p, 32);
+  __builtin_memcpy (ps_src, p, 32);
+  __builtin_memcpy (epi64_src, p, 32);
+  __builtin_memcpy (epi32_src, p, 32);
+  __builtin_memcpy (epi16_src, p, 32);
+  __builtin_memcpy (epi8_src, p, 32);
+
+  foo_pd (pd_dst, pd_src);
+  foo_ps (ps_dst, ps_src);
+  foo_epi64 (epi64_dst, epi64_src);
+  foo_epi32 (epi32_dst, epi32_src);
+  foo_epi16 (epi16_dst, epi16_src);
+  foo_epi8 (epi8_dst, epi8_src);
+  if (__builtin_memcmp (pd_dst, pd_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (ps_dst, ps_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi64_dst, epi64_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi32_dst, epi32_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi16_dst, epi16_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi16_dst, epi16_src, 32) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-2c.c b/gcc/testsuite/gcc.target/i386/pr106010-2c.c
new file mode 100644
index 00000000000..a002f209ec9
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-2c.c
@@ -0,0 +1,47 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx512fp16 -mavx512vl -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256 -fdump-tree-slp-details" } */
+/* { dg-require-effective-target avx512fp16 } */
+
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) _Float16>} 2 "slp2" } } */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 1 "slp2" } }*/
+
+#include <string.h>
+
+static void do_test (void);
+#define DO_TEST do_test
+#define AVX512FP16
+#include "avx512-check.h"
+
+void
+__attribute__((noipa))
+foo_ph (_Complex _Float16* a, _Complex _Float16* __restrict b)
+{
+  a[0] = b[0];
+  a[1] = b[1];
+  a[2] = b[2];
+  a[3] = b[3];
+  a[4] = b[4];
+  a[5] = b[5];
+  a[6] = b[6];
+  a[7] = b[7];
+}
+
+void
+do_test (void)
+{
+  _Complex _Float16* ph_src = (_Complex _Float16*) malloc (32);
+  _Complex _Float16* ph_dst = (_Complex _Float16*) malloc (32);
+  char* p = (char* ) malloc (32);
+
+   __builtin_memset (ph_dst, 0, 32);
+
+  for (int i = 0; i != 32; i++)
+    p[i] = i;
+  __builtin_memcpy (ph_src, p, 32);
+
+  foo_ph (ph_dst, ph_src);
+  if (__builtin_memcmp (ph_dst, ph_src, 32) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-3a.c b/gcc/testsuite/gcc.target/i386/pr106010-3a.c
new file mode 100644
index 00000000000..c1b64b56b1c
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-3a.c
@@ -0,0 +1,80 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -mavx2 -ftree-vectorize -fvect-cost-model=unlimited -fdump-tree-slp-details" } */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 6 "slp2" } }*/
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 2, 3, 0, 1 \}} 2 "slp2" } }  */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 6, 7, 4, 5, 2, 3, 0, 1 \}} 1 "slp2" } }  */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 2, 3, 0, 1, 6, 7, 4, 5 \}} 1 "slp2" } }  */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1 \}} 1 "slp2" } }  */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1, 30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17 \}} 1 "slp2" } }  */
+
+void
+__attribute__((noipa))
+foo_pd (_Complex double* a, _Complex double* __restrict b)
+{
+  a[0] = b[1];
+  a[1] = b[0];
+}
+
+void
+__attribute__((noipa))
+foo_ps (_Complex float* a, _Complex float* __restrict b)
+{
+  a[0] = b[1];
+  a[1] = b[0];
+  a[2] = b[3];
+  a[3] = b[2];
+}
+
+void
+__attribute__((noipa))
+foo_epi64 (_Complex long long* a, _Complex long long* __restrict b)
+{
+  a[0] = b[1];
+  a[1] = b[0];
+}
+
+void
+__attribute__((noipa))
+foo_epi32 (_Complex int* a, _Complex int* __restrict b)
+{
+  a[0] = b[3];
+  a[1] = b[2];
+  a[2] = b[1];
+  a[3] = b[0];
+}
+
+void
+__attribute__((noipa))
+foo_epi16 (_Complex short* a, _Complex short* __restrict b)
+{
+  a[0] = b[7];
+  a[1] = b[6];
+  a[2] = b[5];
+  a[3] = b[4];
+  a[4] = b[3];
+  a[5] = b[2];
+  a[6] = b[1];
+  a[7] = b[0];
+}
+
+void
+__attribute__((noipa))
+foo_epi8 (_Complex char* a, _Complex char* __restrict b)
+{
+  a[0] = b[7];
+  a[1] = b[6];
+  a[2] = b[5];
+  a[3] = b[4];
+  a[4] = b[3];
+  a[5] = b[2];
+  a[6] = b[1];
+  a[7] = b[0];
+  a[8] = b[15];
+  a[9] = b[14];
+  a[10] = b[13];
+  a[11] = b[12];
+  a[12] = b[11];
+  a[13] = b[10];
+  a[14] = b[9];
+  a[15] = b[8];
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-3b.c b/gcc/testsuite/gcc.target/i386/pr106010-3b.c
new file mode 100644
index 00000000000..e4fa3f3a541
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-3b.c
@@ -0,0 +1,126 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx2 -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx2 } */
+
+#include "avx2-check.h"
+#include <string.h>
+#include "pr106010-3a.c"
+
+void
+avx2_test (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (32);
+  _Complex double* pd_dst = (_Complex double*) malloc (32);
+  _Complex double* pd_exp = (_Complex double*) malloc (32);
+  _Complex float* ps_src = (_Complex float*) malloc (32);
+  _Complex float* ps_dst = (_Complex float*) malloc (32);
+  _Complex float* ps_exp = (_Complex float*) malloc (32);
+  _Complex long long* epi64_src = (_Complex long long*) malloc (32);
+  _Complex long long* epi64_dst = (_Complex long long*) malloc (32);
+  _Complex long long* epi64_exp = (_Complex long long*) malloc (32);
+  _Complex int* epi32_src = (_Complex int*) malloc (32);
+  _Complex int* epi32_dst = (_Complex int*) malloc (32);
+  _Complex int* epi32_exp = (_Complex int*) malloc (32);
+  _Complex short* epi16_src = (_Complex short*) malloc (32);
+  _Complex short* epi16_dst = (_Complex short*) malloc (32);
+  _Complex short* epi16_exp = (_Complex short*) malloc (32);
+  _Complex char* epi8_src = (_Complex char*) malloc (32);
+  _Complex char* epi8_dst = (_Complex char*) malloc (32);
+  _Complex char* epi8_exp = (_Complex char*) malloc (32);
+  char* p = (char* ) malloc (32);
+  char* q = (char* ) malloc (32);
+
+  __builtin_memset (pd_dst, 0, 32);
+  __builtin_memset (ps_dst, 0, 32);
+  __builtin_memset (epi64_dst, 0, 32);
+  __builtin_memset (epi32_dst, 0, 32);
+  __builtin_memset (epi16_dst, 0, 32);
+  __builtin_memset (epi8_dst, 0, 32);
+
+  for (int i = 0; i != 32; i++)
+    p[i] = i;
+  __builtin_memcpy (pd_src, p, 32);
+  __builtin_memcpy (ps_src, p, 32);
+  __builtin_memcpy (epi64_src, p, 32);
+  __builtin_memcpy (epi32_src, p, 32);
+  __builtin_memcpy (epi16_src, p, 32);
+  __builtin_memcpy (epi8_src, p, 32);
+
+  for (int i = 0; i != 16; i++)
+    {
+      p[i] = i + 16;
+      p[i + 16] = i;
+    }
+  __builtin_memcpy (pd_exp, p, 32);
+  __builtin_memcpy (epi64_exp, p, 32);
+
+  for (int i = 0; i != 8; i++)
+    {
+      p[i] = i + 8;
+      p[i + 8] = i;
+      p[i + 16] = i + 24;
+      p[i + 24] = i + 16;
+      q[i] = i + 24;
+      q[i + 8] = i + 16;
+      q[i + 16] = i + 8;
+      q[i + 24] = i;
+    }
+  __builtin_memcpy (ps_exp, p, 32);
+  __builtin_memcpy (epi32_exp, q, 32);
+
+
+  for (int i = 0; i != 4; i++)
+    {
+      q[i] = i + 28;
+      q[i + 4] = i + 24;
+      q[i + 8] = i + 20;
+      q[i + 12] = i + 16;
+      q[i + 16] = i + 12;
+      q[i + 20] = i + 8;
+      q[i + 24] = i + 4;
+      q[i + 28] = i;
+    }
+  __builtin_memcpy (epi16_exp, q, 32);
+
+  for (int i = 0; i != 2; i++)
+    {
+      q[i] = i + 14;
+      q[i + 2] = i + 12;
+      q[i + 4] = i + 10;
+      q[i + 6] = i + 8;
+      q[i + 8] = i + 6;
+      q[i + 10] = i + 4;
+      q[i + 12] = i + 2;
+      q[i + 14] = i;
+      q[i + 16] = i + 30;
+      q[i + 18] = i + 28;
+      q[i + 20] = i + 26;
+      q[i + 22] = i + 24;
+      q[i + 24] = i + 22;
+      q[i + 26] = i + 20;
+      q[i + 28] = i + 18;
+      q[i + 30] = i + 16;
+    }
+  __builtin_memcpy (epi8_exp, q, 32);
+
+  foo_pd (pd_dst, pd_src);
+  foo_ps (ps_dst, ps_src);
+  foo_epi64 (epi64_dst, epi64_src);
+  foo_epi32 (epi32_dst, epi32_src);
+  foo_epi16 (epi16_dst, epi16_src);
+  foo_epi8 (epi8_dst, epi8_src);
+  if (__builtin_memcmp (pd_dst, pd_exp, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (ps_dst, ps_exp, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi64_dst, epi64_exp, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi32_dst, epi32_exp, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi16_dst, epi16_exp, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi8_dst, epi8_exp, 32) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-3c.c b/gcc/testsuite/gcc.target/i386/pr106010-3c.c
new file mode 100644
index 00000000000..5a5a3d4b992
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-3c.c
@@ -0,0 +1,69 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx512fp16 -mavx512vl -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256 -fdump-tree-slp-details" } */
+/* { dg-require-effective-target avx512fp16 } */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 1 "slp2" } }*/
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 2, 3, 0, 1, 8, 9, 6, 7, 14, 15, 12, 13, 4, 5, 10, 11 \}} 1 "slp2" } }  */
+
+#include <string.h>
+
+static void do_test (void);
+#define DO_TEST do_test
+#define AVX512FP16
+#include "avx512-check.h"
+
+void
+__attribute__((noipa))
+foo_ph (_Complex _Float16* a, _Complex _Float16* __restrict b)
+{
+  a[0] = b[1];
+  a[1] = b[0];
+  a[2] = b[4];
+  a[3] = b[3];
+  a[4] = b[7];
+  a[5] = b[6];
+  a[6] = b[2];
+  a[7] = b[5];
+}
+
+void
+do_test (void)
+{
+  _Complex _Float16* ph_src = (_Complex _Float16*) malloc (32);
+  _Complex _Float16* ph_dst = (_Complex _Float16*) malloc (32);
+  _Complex _Float16* ph_exp = (_Complex _Float16*) malloc (32);
+  char* p = (char* ) malloc (32);
+  char* q = (char* ) malloc (32);
+
+  __builtin_memset (ph_dst, 0, 32);
+
+  for (int i = 0; i != 32; i++)
+    p[i] = i;
+  __builtin_memcpy (ph_src, p, 32);
+
+  for (int i = 0; i != 4; i++)
+    {
+      p[i] = i + 4;
+      p[i + 4] = i;
+      p[i + 8] = i + 16;
+      p[i + 12] = i + 12;
+      p[i + 16] = i + 28;
+      p[i + 20] = i + 24;
+      p[i + 24] = i + 8;
+      p[i + 28] = i + 20;
+      q[i] = i + 28;
+      q[i + 4] = i + 24;
+      q[i + 8] = i + 20;
+      q[i + 12] = i + 16;
+      q[i + 16] = i + 12;
+      q[i + 20] = i + 8;
+      q[i + 24] = i + 4;
+      q[i + 28] = i;
+    }
+  __builtin_memcpy (ph_exp, p, 32);
+
+  foo_ph (ph_dst, ph_src);
+  if (__builtin_memcmp (ph_dst, ph_exp, 32) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-4a.c b/gcc/testsuite/gcc.target/i386/pr106010-4a.c
new file mode 100644
index 00000000000..b7b0b532bb1
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-4a.c
@@ -0,0 +1,101 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -fdump-tree-slp-details" } */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 6 "slp2" } }*/
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) double>} 1 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) float>} 1 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) long long int>} 1 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) int>} 1 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) short int>} 1 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(32\) char>} 1 "slp2" } } */
+
+void
+__attribute__((noipa))
+foo_pd (_Complex double* a,
+	_Complex double b1,
+	_Complex double b2)
+{
+  a[0] = b1;
+  a[1] = b2;
+}
+
+void
+__attribute__((noipa))
+foo_ps (_Complex float* a,
+	_Complex float b1, _Complex float b2,
+	_Complex float b3, _Complex float b4)
+{
+  a[0] = b1;
+  a[1] = b2;
+  a[2] = b3;
+  a[3] = b4;
+}
+
+void
+__attribute__((noipa))
+foo_epi64 (_Complex long long* a,
+	   _Complex long long b1,
+	   _Complex long long b2)
+{
+  a[0] = b1;
+  a[1] = b2;
+}
+
+void
+__attribute__((noipa))
+foo_epi32 (_Complex int* a,
+	   _Complex int b1, _Complex int b2,
+	   _Complex int b3, _Complex int b4)
+{
+  a[0] = b1;
+  a[1] = b2;
+  a[2] = b3;
+  a[3] = b4;
+}
+
+void
+__attribute__((noipa))
+foo_epi16 (_Complex short* a,
+	   _Complex short b1, _Complex short b2,
+	   _Complex short b3, _Complex short b4,
+	   _Complex short b5, _Complex short b6,
+	   _Complex short b7,_Complex short b8)
+{
+  a[0] = b1;
+  a[1] = b2;
+  a[2] = b3;
+  a[3] = b4;
+  a[4] = b5;
+  a[5] = b6;
+  a[6] = b7;
+  a[7] = b8;
+}
+
+void
+__attribute__((noipa))
+foo_epi8 (_Complex char* a,
+	  _Complex char b1, _Complex char b2,
+	  _Complex char b3, _Complex char b4,
+	  _Complex char b5, _Complex char b6,
+	  _Complex char b7,_Complex char b8,
+	  _Complex char b9, _Complex char b10,
+	  _Complex char b11, _Complex char b12,
+	  _Complex char b13, _Complex char b14,
+	  _Complex char b15,_Complex char b16)
+{
+  a[0] = b1;
+  a[1] = b2;
+  a[2] = b3;
+  a[3] = b4;
+  a[4] = b5;
+  a[5] = b6;
+  a[6] = b7;
+  a[7] = b8;
+  a[8] = b9;
+  a[9] = b10;
+  a[10] = b11;
+  a[11] = b12;
+  a[12] = b13;
+  a[13] = b14;
+  a[14] = b15;
+  a[15] = b16;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-4b.c b/gcc/testsuite/gcc.target/i386/pr106010-4b.c
new file mode 100644
index 00000000000..e2e79508c4b
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-4b.c
@@ -0,0 +1,67 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx } */
+
+#include "avx-check.h"
+#include <string.h>
+#include "pr106010-4a.c"
+
+void
+avx_test (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (32);
+  _Complex double* pd_dst = (_Complex double*) malloc (32);
+  _Complex float* ps_src = (_Complex float*) malloc (32);
+  _Complex float* ps_dst = (_Complex float*) malloc (32);
+  _Complex long long* epi64_src = (_Complex long long*) malloc (32);
+  _Complex long long* epi64_dst = (_Complex long long*) malloc (32);
+  _Complex int* epi32_src = (_Complex int*) malloc (32);
+  _Complex int* epi32_dst = (_Complex int*) malloc (32);
+  _Complex short* epi16_src = (_Complex short*) malloc (32);
+  _Complex short* epi16_dst = (_Complex short*) malloc (32);
+  _Complex char* epi8_src = (_Complex char*) malloc (32);
+  _Complex char* epi8_dst = (_Complex char*) malloc (32);
+  char* p = (char* ) malloc (32);
+
+  __builtin_memset (pd_dst, 0, 32);
+  __builtin_memset (ps_dst, 0, 32);
+  __builtin_memset (epi64_dst, 0, 32);
+  __builtin_memset (epi32_dst, 0, 32);
+  __builtin_memset (epi16_dst, 0, 32);
+  __builtin_memset (epi8_dst, 0, 32);
+
+  for (int i = 0; i != 32; i++)
+    p[i] = i;
+  __builtin_memcpy (pd_src, p, 32);
+  __builtin_memcpy (ps_src, p, 32);
+  __builtin_memcpy (epi64_src, p, 32);
+  __builtin_memcpy (epi32_src, p, 32);
+  __builtin_memcpy (epi16_src, p, 32);
+  __builtin_memcpy (epi8_src, p, 32);
+
+  foo_pd (pd_dst, pd_src[0], pd_src[1]);
+  foo_ps (ps_dst, ps_src[0], ps_src[1], ps_src[2], ps_src[3]);
+  foo_epi64 (epi64_dst, epi64_src[0], epi64_src[1]);
+  foo_epi32 (epi32_dst, epi32_src[0], epi32_src[1], epi32_src[2], epi32_src[3]);
+  foo_epi16 (epi16_dst, epi16_src[0], epi16_src[1], epi16_src[2], epi16_src[3],
+	     epi16_src[4], epi16_src[5], epi16_src[6], epi16_src[7]);
+  foo_epi8 (epi8_dst, epi8_src[0], epi8_src[1], epi8_src[2], epi8_src[3],
+	    epi8_src[4], epi8_src[5], epi8_src[6], epi8_src[7],
+	    epi8_src[8], epi8_src[9], epi8_src[10], epi8_src[11],
+	    epi8_src[12], epi8_src[13], epi8_src[14], epi8_src[15]);
+
+  if (__builtin_memcmp (pd_dst, pd_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (ps_dst, ps_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi64_dst, epi64_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi32_dst, epi32_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi16_dst, epi16_src, 32) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi8_dst, epi8_src, 32) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-4c.c b/gcc/testsuite/gcc.target/i386/pr106010-4c.c
new file mode 100644
index 00000000000..8e02aefe3b5
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-4c.c
@@ -0,0 +1,54 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx512fp16 -mavx512vl -fdump-tree-slp-details -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx512fp16 } */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 1 "slp2" } }*/
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) _Float16>} 1 "slp2" } } */
+
+#include <string.h>
+
+static void do_test (void);
+#define DO_TEST do_test
+#define AVX512FP16
+#include "avx512-check.h"
+
+void
+__attribute__((noipa))
+foo_ph (_Complex _Float16* a,
+	_Complex _Float16 b1, _Complex _Float16 b2,
+	_Complex _Float16 b3, _Complex _Float16 b4,
+	_Complex _Float16 b5, _Complex _Float16 b6,
+	_Complex _Float16 b7,_Complex _Float16 b8)
+{
+  a[0] = b1;
+  a[1] = b2;
+  a[2] = b3;
+  a[3] = b4;
+  a[4] = b5;
+  a[5] = b6;
+  a[6] = b7;
+  a[7] = b8;
+}
+
+void
+do_test (void)
+{
+
+  _Complex _Float16* ph_src = (_Complex _Float16*) malloc (32);
+  _Complex _Float16* ph_dst = (_Complex _Float16*) malloc (32);
+
+  char* p = (char* ) malloc (32);
+
+  __builtin_memset (ph_dst, 0, 32);
+
+  for (int i = 0; i != 32; i++)
+    p[i] = i;
+
+  __builtin_memcpy (ph_src, p, 32);
+
+  foo_ph (ph_dst, ph_src[0], ph_src[1], ph_src[2], ph_src[3],
+	  ph_src[4], ph_src[5], ph_src[6], ph_src[7]);
+
+  if (__builtin_memcmp (ph_dst, ph_src, 32) != 0)
+    __builtin_abort ();
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-5a.c b/gcc/testsuite/gcc.target/i386/pr106010-5a.c
new file mode 100644
index 00000000000..9d4a6f9846b
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-5a.c
@@ -0,0 +1,117 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -fdump-tree-slp-details -mprefer-vector-width=256" } */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 6 "slp2" } }*/
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) double>} 4 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) float>} 4 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) long long int>} 4 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) int>} 4 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) short int>} 4 "slp2" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(32\) char>} 4 "slp2" } } */
+
+void
+__attribute__((noipa))
+foo_pd (_Complex double* a, _Complex double* __restrict b)
+{
+  a[0] = b[2];
+  a[1] = b[3];
+  a[2] = b[0];
+  a[3] = b[1];
+}
+
+void
+__attribute__((noipa))
+foo_ps (_Complex float* a, _Complex float* __restrict b)
+{
+  a[0] = b[4];
+  a[1] = b[5];
+  a[2] = b[6];
+  a[3] = b[7];
+  a[4] = b[0];
+  a[5] = b[1];
+  a[6] = b[2];
+  a[7] = b[3];
+}
+
+void
+__attribute__((noipa))
+foo_epi64 (_Complex long long* a, _Complex long long* __restrict b)
+{
+  a[0] = b[2];
+  a[1] = b[3];
+  a[2] = b[0];
+  a[3] = b[1];
+}
+
+void
+__attribute__((noipa))
+foo_epi32 (_Complex int* a, _Complex int* __restrict b)
+{
+  a[0] = b[4];
+  a[1] = b[5];
+  a[2] = b[6];
+  a[3] = b[7];
+  a[4] = b[0];
+  a[5] = b[1];
+  a[6] = b[2];
+  a[7] = b[3];
+}
+
+void
+__attribute__((noipa))
+foo_epi16 (_Complex short* a, _Complex short* __restrict b)
+{
+  a[0] = b[8];
+  a[1] = b[9];
+  a[2] = b[10];
+  a[3] = b[11];
+  a[4] = b[12];
+  a[5] = b[13];
+  a[6] = b[14];
+  a[7] = b[15];
+  a[8] = b[0];
+  a[9] = b[1];
+  a[10] = b[2];
+  a[11] = b[3];
+  a[12] = b[4];
+  a[13] = b[5];
+  a[14] = b[6];
+  a[15] = b[7];
+}
+
+void
+__attribute__((noipa))
+foo_epi8 (_Complex char* a, _Complex char* __restrict b)
+{
+  a[0] = b[16];
+  a[1] = b[17];
+  a[2] = b[18];
+  a[3] = b[19];
+  a[4] = b[20];
+  a[5] = b[21];
+  a[6] = b[22];
+  a[7] = b[23];
+  a[8] = b[24];
+  a[9] = b[25];
+  a[10] = b[26];
+  a[11] = b[27];
+  a[12] = b[28];
+  a[13] = b[29];
+  a[14] = b[30];
+  a[15] = b[31];
+  a[16] = b[0];
+  a[17] = b[1];
+  a[18] = b[2];
+  a[19] = b[3];
+  a[20] = b[4];
+  a[21] = b[5];
+  a[22] = b[6];
+  a[23] = b[7];
+  a[24] = b[8];
+  a[25] = b[9];
+  a[26] = b[10];
+  a[27] = b[11];
+  a[28] = b[12];
+  a[29] = b[13];
+  a[30] = b[14];
+  a[31] = b[15];
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-5b.c b/gcc/testsuite/gcc.target/i386/pr106010-5b.c
new file mode 100644
index 00000000000..d5c6ebeb5cf
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-5b.c
@@ -0,0 +1,80 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx } */
+
+#include "avx-check.h"
+#include <string.h>
+#include "pr106010-5a.c"
+
+void
+avx_test (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (64);
+  _Complex double* pd_dst = (_Complex double*) malloc (64);
+  _Complex double* pd_exp = (_Complex double*) malloc (64);
+  _Complex float* ps_src = (_Complex float*) malloc (64);
+  _Complex float* ps_dst = (_Complex float*) malloc (64);
+  _Complex float* ps_exp = (_Complex float*) malloc (64);
+  _Complex long long* epi64_src = (_Complex long long*) malloc (64);
+  _Complex long long* epi64_dst = (_Complex long long*) malloc (64);
+  _Complex long long* epi64_exp = (_Complex long long*) malloc (64);
+  _Complex int* epi32_src = (_Complex int*) malloc (64);
+  _Complex int* epi32_dst = (_Complex int*) malloc (64);
+  _Complex int* epi32_exp = (_Complex int*) malloc (64);
+  _Complex short* epi16_src = (_Complex short*) malloc (64);
+  _Complex short* epi16_dst = (_Complex short*) malloc (64);
+  _Complex short* epi16_exp = (_Complex short*) malloc (64);
+  _Complex char* epi8_src = (_Complex char*) malloc (64);
+  _Complex char* epi8_dst = (_Complex char*) malloc (64);
+  _Complex char* epi8_exp = (_Complex char*) malloc (64);
+  char* p = (char* ) malloc (64);
+  char* q = (char* ) malloc (64);
+
+  __builtin_memset (pd_dst, 0, 64);
+  __builtin_memset (ps_dst, 0, 64);
+  __builtin_memset (epi64_dst, 0, 64);
+  __builtin_memset (epi32_dst, 0, 64);
+  __builtin_memset (epi16_dst, 0, 64);
+  __builtin_memset (epi8_dst, 0, 64);
+
+  for (int i = 0; i != 64; i++)
+    {
+      p[i] = i;
+      q[i] = (i + 32) % 64;
+    }
+  __builtin_memcpy (pd_src, p, 64);
+  __builtin_memcpy (ps_src, p, 64);
+  __builtin_memcpy (epi64_src, p, 64);
+  __builtin_memcpy (epi32_src, p, 64);
+  __builtin_memcpy (epi16_src, p, 64);
+  __builtin_memcpy (epi8_src, p, 64);
+
+  __builtin_memcpy (pd_exp, q, 64);
+  __builtin_memcpy (ps_exp, q, 64);
+  __builtin_memcpy (epi64_exp, q, 64);
+  __builtin_memcpy (epi32_exp, q, 64);
+  __builtin_memcpy (epi16_exp, q, 64);
+  __builtin_memcpy (epi8_exp, q, 64);
+
+  foo_pd (pd_dst, pd_src);
+  foo_ps (ps_dst, ps_src);
+  foo_epi64 (epi64_dst, epi64_src);
+  foo_epi32 (epi32_dst, epi32_src);
+  foo_epi16 (epi16_dst, epi16_src);
+  foo_epi8 (epi8_dst, epi8_src);
+
+  if (__builtin_memcmp (pd_dst, pd_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (ps_dst, ps_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi64_dst, epi64_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi32_dst, epi32_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi16_dst, epi16_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi8_dst, epi8_exp, 64) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-5c.c b/gcc/testsuite/gcc.target/i386/pr106010-5c.c
new file mode 100644
index 00000000000..9ce4e6dd5c0
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-5c.c
@@ -0,0 +1,62 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx512fp16 -mavx512vl -ftree-vectorize -fvect-cost-model=unlimited -fdump-tree-slp-details -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx512fp16 } */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 1 "slp2" } }*/
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) _Float16>} 4 "slp2" } } */
+
+#include <string.h>
+
+static void do_test (void);
+#define DO_TEST do_test
+#define AVX512FP16
+#include "avx512-check.h"
+
+void
+__attribute__((noipa))
+foo_ph (_Complex _Float16* a, _Complex _Float16* __restrict b)
+{
+  a[0] = b[8];
+  a[1] = b[9];
+  a[2] = b[10];
+  a[3] = b[11];
+  a[4] = b[12];
+  a[5] = b[13];
+  a[6] = b[14];
+  a[7] = b[15];
+  a[8] = b[0];
+  a[9] = b[1];
+  a[10] = b[2];
+  a[11] = b[3];
+  a[12] = b[4];
+  a[13] = b[5];
+  a[14] = b[6];
+  a[15] = b[7];
+}
+
+void
+do_test (void)
+{
+  _Complex _Float16* ph_src = (_Complex _Float16*) malloc (64);
+  _Complex _Float16* ph_dst = (_Complex _Float16*) malloc (64);
+  _Complex _Float16* ph_exp = (_Complex _Float16*) malloc (64);
+  char* p = (char* ) malloc (64);
+  char* q = (char* ) malloc (64);
+
+  __builtin_memset (ph_dst, 0, 64);
+
+  for (int i = 0; i != 64; i++)
+    {
+      p[i] = i;
+      q[i] = (i + 32) % 64;
+    }
+  __builtin_memcpy (ph_src, p, 64);
+
+  __builtin_memcpy (ph_exp, q, 64);
+
+  foo_ph (ph_dst, ph_src);
+
+  if (__builtin_memcmp (ph_dst, ph_exp, 64) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-6a.c b/gcc/testsuite/gcc.target/i386/pr106010-6a.c
new file mode 100644
index 00000000000..65a90d03684
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-6a.c
@@ -0,0 +1,115 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -mavx2 -ftree-vectorize -fvect-cost-model=unlimited -fdump-tree-slp-details -mprefer-vector-width=256" } */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 6 "slp2" } }*/
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 2, 3, 0, 1 \}} 4 "slp2" } }  */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 6, 7, 4, 5, 2, 3, 0, 1 \}} 4 "slp2" } }  */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1 \}} 2 "slp2" } }  */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 30, 31, 28, 29, 26, 27, 24, 25, 22, 23, 20, 21, 18, 19, 16, 17, 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1 \}} 2 "slp2" } }  */
+
+void
+__attribute__((noipa))
+foo_pd (_Complex double* a, _Complex double* __restrict b)
+{
+  a[0] = b[3];
+  a[1] = b[2];
+  a[2] = b[1];
+  a[3] = b[0];
+}
+
+void
+__attribute__((noipa))
+foo_ps (_Complex float* a, _Complex float* __restrict b)
+{
+  a[0] = b[7];
+  a[1] = b[6];
+  a[2] = b[5];
+  a[3] = b[4];
+  a[4] = b[3];
+  a[5] = b[2];
+  a[6] = b[1];
+  a[7] = b[0];
+}
+
+void
+__attribute__((noipa))
+foo_epi64 (_Complex long long* a, _Complex long long* __restrict b)
+{
+  a[0] = b[3];
+  a[1] = b[2];
+  a[2] = b[1];
+  a[3] = b[0];
+}
+
+void
+__attribute__((noipa))
+foo_epi32 (_Complex int* a, _Complex int* __restrict b)
+{
+  a[0] = b[7];
+  a[1] = b[6];
+  a[2] = b[5];
+  a[3] = b[4];
+  a[4] = b[3];
+  a[5] = b[2];
+  a[6] = b[1];
+  a[7] = b[0];
+}
+
+void
+__attribute__((noipa))
+foo_epi16 (_Complex short* a, _Complex short* __restrict b)
+{
+  a[0] = b[15];
+  a[1] = b[14];
+  a[2] = b[13];
+  a[3] = b[12];
+  a[4] = b[11];
+  a[5] = b[10];
+  a[6] = b[9];
+  a[7] = b[8];
+  a[8] = b[7];
+  a[9] = b[6];
+  a[10] = b[5];
+  a[11] = b[4];
+  a[12] = b[3];
+  a[13] = b[2];
+  a[14] = b[1];
+  a[15] = b[0];
+}
+
+void
+__attribute__((noipa))
+foo_epi8 (_Complex char* a, _Complex char* __restrict b)
+{
+  a[0] = b[31];
+  a[1] = b[30];
+  a[2] = b[29];
+  a[3] = b[28];
+  a[4] = b[27];
+  a[5] = b[26];
+  a[6] = b[25];
+  a[7] = b[24];
+  a[8] = b[23];
+  a[9] = b[22];
+  a[10] = b[21];
+  a[11] = b[20];
+  a[12] = b[19];
+  a[13] = b[18];
+  a[14] = b[17];
+  a[15] = b[16];
+  a[16] = b[15];
+  a[17] = b[14];
+  a[18] = b[13];
+  a[19] = b[12];
+  a[20] = b[11];
+  a[21] = b[10];
+  a[22] = b[9];
+  a[23] = b[8];
+  a[24] = b[7];
+  a[25] = b[6];
+  a[26] = b[5];
+  a[27] = b[4];
+  a[28] = b[3];
+  a[29] = b[2];
+  a[30] = b[1];
+  a[31] = b[0];
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-6b.c b/gcc/testsuite/gcc.target/i386/pr106010-6b.c
new file mode 100644
index 00000000000..1c5bb020939
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-6b.c
@@ -0,0 +1,157 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx2 -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx2 } */
+
+#include "avx2-check.h"
+#include <string.h>
+#include "pr106010-6a.c"
+
+void
+avx2_test (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (64);
+  _Complex double* pd_dst = (_Complex double*) malloc (64);
+  _Complex double* pd_exp = (_Complex double*) malloc (64);
+  _Complex float* ps_src = (_Complex float*) malloc (64);
+  _Complex float* ps_dst = (_Complex float*) malloc (64);
+  _Complex float* ps_exp = (_Complex float*) malloc (64);
+  _Complex long long* epi64_src = (_Complex long long*) malloc (64);
+  _Complex long long* epi64_dst = (_Complex long long*) malloc (64);
+  _Complex long long* epi64_exp = (_Complex long long*) malloc (64);
+  _Complex int* epi32_src = (_Complex int*) malloc (64);
+  _Complex int* epi32_dst = (_Complex int*) malloc (64);
+  _Complex int* epi32_exp = (_Complex int*) malloc (64);
+  _Complex short* epi16_src = (_Complex short*) malloc (64);
+  _Complex short* epi16_dst = (_Complex short*) malloc (64);
+  _Complex short* epi16_exp = (_Complex short*) malloc (64);
+  _Complex char* epi8_src = (_Complex char*) malloc (64);
+  _Complex char* epi8_dst = (_Complex char*) malloc (64);
+  _Complex char* epi8_exp = (_Complex char*) malloc (64);
+  char* p = (char* ) malloc (64);
+  char* q = (char* ) malloc (64);
+
+  __builtin_memset (pd_dst, 0, 64);
+  __builtin_memset (ps_dst, 0, 64);
+  __builtin_memset (epi64_dst, 0, 64);
+  __builtin_memset (epi32_dst, 0, 64);
+  __builtin_memset (epi16_dst, 0, 64);
+  __builtin_memset (epi8_dst, 0, 64);
+
+  for (int i = 0; i != 64; i++)
+    p[i] = i;
+
+  __builtin_memcpy (pd_src, p, 64);
+  __builtin_memcpy (ps_src, p, 64);
+  __builtin_memcpy (epi64_src, p, 64);
+  __builtin_memcpy (epi32_src, p, 64);
+  __builtin_memcpy (epi16_src, p, 64);
+  __builtin_memcpy (epi8_src, p, 64);
+
+
+  for (int i = 0; i != 16; i++)
+    {
+      q[i] = i + 48;
+      q[i + 16] = i + 32;
+      q[i + 32] = i + 16;
+      q[i + 48] = i;
+    }
+
+  __builtin_memcpy (pd_exp, q, 64);
+  __builtin_memcpy (epi64_exp, q, 64);
+
+   for (int i = 0; i != 8; i++)
+    {
+      q[i] = i + 56;
+      q[i + 8] = i + 48;
+      q[i + 16] = i + 40;
+      q[i + 24] = i + 32;
+      q[i + 32] = i + 24;
+      q[i + 40] = i + 16;
+      q[i + 48] = i + 8;
+      q[i + 56] = i;
+    }
+
+  __builtin_memcpy (ps_exp, q, 64);
+  __builtin_memcpy (epi32_exp, q, 64);
+
+  for (int i = 0; i != 4; i++)
+    {
+      q[i] = i + 60;
+      q[i + 4] = i + 56;
+      q[i + 8] = i + 52;
+      q[i + 12] = i + 48;
+      q[i + 16] = i + 44;
+      q[i + 20] = i + 40;
+      q[i + 24] = i + 36;
+      q[i + 28] = i + 32;
+      q[i + 32] = i + 28;
+      q[i + 36] = i + 24;
+      q[i + 40] = i + 20;
+      q[i + 44] = i + 16;
+      q[i + 48] = i + 12;
+      q[i + 52] = i + 8;
+      q[i + 56] = i + 4;
+      q[i + 60] = i;
+    }
+
+  __builtin_memcpy (epi16_exp, q, 64);
+
+  for (int i = 0; i != 2; i++)
+    {
+      q[i] = i + 62;
+      q[i + 2] = i + 60;
+      q[i + 4] = i + 58;
+      q[i + 6] = i + 56;
+      q[i + 8] = i + 54;
+      q[i + 10] = i + 52;
+      q[i + 12] = i + 50;
+      q[i + 14] = i + 48;
+      q[i + 16] = i + 46;
+      q[i + 18] = i + 44;
+      q[i + 20] = i + 42;
+      q[i + 22] = i + 40;
+      q[i + 24] = i + 38;
+      q[i + 26] = i + 36;
+      q[i + 28] = i + 34;
+      q[i + 30] = i + 32;
+      q[i + 32] = i + 30;
+      q[i + 34] = i + 28;
+      q[i + 36] = i + 26;
+      q[i + 38] = i + 24;
+      q[i + 40] = i + 22;
+      q[i + 42] = i + 20;
+      q[i + 44] = i + 18;
+      q[i + 46] = i + 16;
+      q[i + 48] = i + 14;
+      q[i + 50] = i + 12;
+      q[i + 52] = i + 10;
+      q[i + 54] = i + 8;
+      q[i + 56] = i + 6;
+      q[i + 58] = i + 4;
+      q[i + 60] = i + 2;
+      q[i + 62] = i;
+    }
+  __builtin_memcpy (epi8_exp, q, 64);
+
+  foo_pd (pd_dst, pd_src);
+  foo_ps (ps_dst, ps_src);
+  foo_epi64 (epi64_dst, epi64_src);
+  foo_epi32 (epi32_dst, epi32_src);
+  foo_epi16 (epi16_dst, epi16_src);
+  foo_epi8 (epi8_dst, epi8_src);
+
+  if (__builtin_memcmp (pd_dst, pd_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (ps_dst, ps_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi64_dst, epi64_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi32_dst, epi32_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi16_dst, epi16_exp, 64) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi8_dst, epi8_exp, 64) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-6c.c b/gcc/testsuite/gcc.target/i386/pr106010-6c.c
new file mode 100644
index 00000000000..b859d884a7f
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-6c.c
@@ -0,0 +1,80 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx512fp16 -mavx512vl -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256 -fdump-tree-slp-details" } */
+/* { dg-require-effective-target avx512fp16 } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*VEC_PERM_EXPR.*\{ 14, 15, 12, 13, 10, 11, 8, 9, 6, 7, 4, 5, 2, 3, 0, 1 \}} 2 "slp2" } }  */
+/* { dg-final { scan-tree-dump-times "basic block part vectorized using (?:32|64) byte vectors" 1 "slp2" } } */
+
+#include <string.h>
+
+static void do_test (void);
+#define DO_TEST do_test
+#define AVX512FP16
+#include "avx512-check.h"
+
+void
+__attribute__((noipa))
+foo_ph (_Complex _Float16* a, _Complex _Float16* __restrict b)
+{
+  a[0] = b[15];
+  a[1] = b[14];
+  a[2] = b[13];
+  a[3] = b[12];
+  a[4] = b[11];
+  a[5] = b[10];
+  a[6] = b[9];
+  a[7] = b[8];
+  a[8] = b[7];
+  a[9] = b[6];
+  a[10] = b[5];
+  a[11] = b[4];
+  a[12] = b[3];
+  a[13] = b[2];
+  a[14] = b[1];
+  a[15] = b[0];
+}
+
+void
+do_test (void)
+{
+  _Complex _Float16* ph_src = (_Complex _Float16*) malloc (64);
+  _Complex _Float16* ph_dst = (_Complex _Float16*) malloc (64);
+  _Complex _Float16* ph_exp = (_Complex _Float16*) malloc (64);
+  char* p = (char* ) malloc (64);
+  char* q = (char* ) malloc (64);
+
+  __builtin_memset (ph_dst, 0, 64);
+
+  for (int i = 0; i != 64; i++)
+    p[i] = i;
+
+  __builtin_memcpy (ph_src, p, 64);
+
+  for (int i = 0; i != 4; i++)
+    {
+      q[i] = i + 60;
+      q[i + 4] = i + 56;
+      q[i + 8] = i + 52;
+      q[i + 12] = i + 48;
+      q[i + 16] = i + 44;
+      q[i + 20] = i + 40;
+      q[i + 24] = i + 36;
+      q[i + 28] = i + 32;
+      q[i + 32] = i + 28;
+      q[i + 36] = i + 24;
+      q[i + 40] = i + 20;
+      q[i + 44] = i + 16;
+      q[i + 48] = i + 12;
+      q[i + 52] = i + 8;
+      q[i + 56] = i + 4;
+      q[i + 60] = i;
+    }
+
+  __builtin_memcpy (ph_exp, q, 64);
+
+  foo_ph (ph_dst, ph_src);
+
+  if (__builtin_memcmp (ph_dst, ph_exp, 64) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-7a.c b/gcc/testsuite/gcc.target/i386/pr106010-7a.c
new file mode 100644
index 00000000000..2ea01fac927
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-7a.c
@@ -0,0 +1,58 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -fdump-tree-vect-details -mprefer-vector-width=256" } */
+/* { dg-final { scan-tree-dump-times "vectorized 1 loops" 6 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) double>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) float>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) long long int>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) int>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) short int>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(32\) char>} 1 "vect" } } */
+
+#define N 10000
+void
+__attribute__((noipa))
+foo_pd (_Complex double* a, _Complex double b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b;
+}
+
+void
+__attribute__((noipa))
+foo_ps (_Complex float* a, _Complex float b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b;
+}
+
+void
+__attribute__((noipa))
+foo_epi64 (_Complex long long* a, _Complex long long b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b;
+}
+
+void
+__attribute__((noipa))
+foo_epi32 (_Complex int* a, _Complex int b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b;
+}
+
+void
+__attribute__((noipa))
+foo_epi16 (_Complex short* a, _Complex short b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b;
+}
+
+void
+__attribute__((noipa))
+foo_epi8 (_Complex char* a, _Complex char b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-7b.c b/gcc/testsuite/gcc.target/i386/pr106010-7b.c
new file mode 100644
index 00000000000..26482cc10f5
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-7b.c
@@ -0,0 +1,63 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx } */
+
+#include "avx-check.h"
+#include <string.h>
+#include "pr106010-7a.c"
+
+void
+avx_test (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (2 * N * sizeof (double));
+  _Complex double* pd_dst = (_Complex double*) malloc (2 * N * sizeof (double));
+  _Complex float* ps_src = (_Complex float*) malloc (2 * N * sizeof (float));
+  _Complex float* ps_dst = (_Complex float*) malloc (2 * N * sizeof (float));
+  _Complex long long* epi64_src = (_Complex long long*) malloc (2 * N * sizeof (long long));
+  _Complex long long* epi64_dst = (_Complex long long*) malloc (2 * N * sizeof (long long));
+  _Complex int* epi32_src = (_Complex int*) malloc (2 * N * sizeof (int));
+  _Complex int* epi32_dst = (_Complex int*) malloc (2 * N * sizeof (int));
+  _Complex short* epi16_src = (_Complex short*) malloc (2 * N * sizeof (short));
+  _Complex short* epi16_dst = (_Complex short*) malloc (2 * N * sizeof (short));
+  _Complex char* epi8_src = (_Complex char*) malloc (2 * N * sizeof (char));
+  _Complex char* epi8_dst = (_Complex char*) malloc (2 * N * sizeof (char));
+  char* p_init = (char*) malloc (2 * N * sizeof (double));
+
+  __builtin_memset (pd_dst, 0, 2 * N * sizeof (double));
+  __builtin_memset (ps_dst, 0, 2 * N * sizeof (float));
+  __builtin_memset (epi64_dst, 0, 2 * N * sizeof (long long));
+  __builtin_memset (epi32_dst, 0, 2 * N * sizeof (int));
+  __builtin_memset (epi16_dst, 0, 2 * N * sizeof (short));
+  __builtin_memset (epi8_dst, 0, 2 * N * sizeof (char));
+
+  for (int i = 0; i != 2 * N * sizeof (double); i++)
+    p_init[i] = i % 2 + 3;
+
+  memcpy (pd_src, p_init, 2 * N * sizeof (double));
+  memcpy (ps_dst, p_init, 2 * N * sizeof (float));
+  memcpy (epi64_dst, p_init, 2 * N * sizeof (long long));
+  memcpy (epi32_dst, p_init, 2 * N * sizeof (int));
+  memcpy (epi16_dst, p_init, 2 * N * sizeof (short));
+  memcpy (epi8_dst, p_init, 2 * N * sizeof (char));
+
+  foo_pd (pd_dst, pd_src[0]);
+  foo_ps (ps_dst, ps_src[0]);
+  foo_epi64 (epi64_dst, epi64_src[0]);
+  foo_epi32 (epi32_dst, epi32_src[0]);
+  foo_epi16 (epi16_dst, epi16_src[0]);
+  foo_epi8 (epi8_dst, epi8_src[0]);
+  if (__builtin_memcmp (pd_dst, pd_src, N * 2 * sizeof (double)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (ps_dst, ps_src, N * 2 * sizeof (float)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi64_dst, epi64_src, N * 2 * sizeof (long long)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi32_dst, epi32_src, N * 2 * sizeof (int)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi16_dst, epi16_src, N * 2 * sizeof (short)) != 0)
+    __builtin_abort ();
+  if (__builtin_memcmp (epi8_dst, epi8_src, N * 2 * sizeof (char)) != 0)
+    __builtin_abort ();
+
+  return;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-7c.c b/gcc/testsuite/gcc.target/i386/pr106010-7c.c
new file mode 100644
index 00000000000..7f4056a5ecc
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-7c.c
@@ -0,0 +1,41 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx512fp16 -mavx512vl -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256 -fdump-tree-vect-details" } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) _Float16>} 1 "vect" } } */
+/* { dg-require-effective-target avx512fp16 } */
+
+#include <string.h>
+
+static void do_test (void);
+
+#define DO_TEST do_test
+#define AVX512FP16
+#include "avx512-check.h"
+
+#define N 10000
+
+void
+__attribute__((noipa))
+foo_ph (_Complex _Float16* a, _Complex _Float16 b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b;
+}
+
+static void
+do_test (void)
+{
+  _Complex _Float16* ph_src = (_Complex _Float16*) malloc (2 * N * sizeof (_Float16));
+  _Complex _Float16* ph_dst = (_Complex _Float16*) malloc (2 * N * sizeof (_Float16));
+  char* p_init = (char*) malloc (2 * N * sizeof (_Float16));
+
+  __builtin_memset (ph_dst, 0, 2 * N * sizeof (_Float16));
+
+  for (int i = 0; i != 2 * N * sizeof (_Float16); i++)
+    p_init[i] = i % 2 + 3;
+
+  memcpy (ph_src, p_init, 2 * N * sizeof (_Float16));
+
+  foo_ph (ph_dst, ph_src[0]);
+  if (__builtin_memcmp (ph_dst, ph_src, N * 2 * sizeof (_Float16)) != 0)
+    __builtin_abort ();
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-8a.c b/gcc/testsuite/gcc.target/i386/pr106010-8a.c
new file mode 100644
index 00000000000..11054b60d30
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-8a.c
@@ -0,0 +1,58 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -fdump-tree-vect-details -mprefer-vector-width=256" } */
+/* { dg-final { scan-tree-dump-times "vectorized 1 loops" 6 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) double>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) float>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(4\) long long int>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(8\) int>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) short int>} 1 "vect" } } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(32\) char>} 1 "vect" } } */
+
+#define N 10000
+void
+__attribute__((noipa))
+foo_pd (_Complex double* a)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = 1.0 + 2.0i;
+}
+
+void
+__attribute__((noipa))
+foo_ps (_Complex float* a)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = 1.0f + 2.0fi;
+}
+
+void
+__attribute__((noipa))
+foo_epi64 (_Complex long long* a)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = 1 + 2i;
+}
+
+void
+__attribute__((noipa))
+foo_epi32 (_Complex int* a)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = 1 + 2i;
+}
+
+void
+__attribute__((noipa))
+foo_epi16 (_Complex short* a)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = 1 + 2i;
+}
+
+void
+__attribute__((noipa))
+foo_epi8 (_Complex char* a)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = 1 + 2i;
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-8b.c b/gcc/testsuite/gcc.target/i386/pr106010-8b.c
new file mode 100644
index 00000000000..6bb0073b691
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-8b.c
@@ -0,0 +1,53 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256" } */
+/* { dg-require-effective-target avx } */
+
+#include "avx-check.h"
+#include <string.h>
+#include "pr106010-8a.c"
+
+void
+avx_test (void)
+{
+  _Complex double pd_src = 1.0 + 2.0i;
+  _Complex double* pd_dst = (_Complex double*) malloc (2 * N * sizeof (double));
+  _Complex float ps_src = 1.0 + 2.0i;
+  _Complex float* ps_dst = (_Complex float*) malloc (2 * N * sizeof (float));
+  _Complex long long epi64_src = 1 + 2i;;
+  _Complex long long* epi64_dst = (_Complex long long*) malloc (2 * N * sizeof (long long));
+  _Complex int epi32_src = 1 + 2i;
+  _Complex int* epi32_dst = (_Complex int*) malloc (2 * N * sizeof (int));
+  _Complex short epi16_src = 1 + 2i;
+  _Complex short* epi16_dst = (_Complex short*) malloc (2 * N * sizeof (short));
+  _Complex char epi8_src = 1 + 2i;
+  _Complex char* epi8_dst = (_Complex char*) malloc (2 * N * sizeof (char));
+
+  __builtin_memset (pd_dst, 0, 2 * N * sizeof (double));
+  __builtin_memset (ps_dst, 0, 2 * N * sizeof (float));
+  __builtin_memset (epi64_dst, 0, 2 * N * sizeof (long long));
+  __builtin_memset (epi32_dst, 0, 2 * N * sizeof (int));
+  __builtin_memset (epi16_dst, 0, 2 * N * sizeof (short));
+  __builtin_memset (epi8_dst, 0, 2 * N * sizeof (char));
+
+  foo_pd (pd_dst);
+  foo_ps (ps_dst);
+  foo_epi64 (epi64_dst);
+  foo_epi32 (epi32_dst);
+  foo_epi16 (epi16_dst);
+  foo_epi8 (epi8_dst);
+  for (int i = 0 ; i != N; i++)
+    {
+      if (pd_dst[i] != pd_src)
+	__builtin_abort ();
+      if (ps_dst[i] != ps_src)
+	__builtin_abort ();
+      if (epi64_dst[i] != epi64_src)
+	__builtin_abort ();
+      if (epi32_dst[i] != epi32_src)
+	__builtin_abort ();
+      if (epi16_dst[i] != epi16_src)
+	__builtin_abort ();
+      if (epi8_dst[i] != epi8_src)
+	__builtin_abort ();
+    }
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-8c.c b/gcc/testsuite/gcc.target/i386/pr106010-8c.c
new file mode 100644
index 00000000000..61ae131829d
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-8c.c
@@ -0,0 +1,38 @@
+/* { dg-do run } */
+/* { dg-options "-O2 -mavx512fp16 -mavx512vl -ftree-vectorize -fvect-cost-model=unlimited -mprefer-vector-width=256 -fdump-tree-vect-details" } */
+/* { dg-final { scan-tree-dump-times {(?n)add new stmt:.*MEM <vector\(16\) _Float16>} 1 "vect" } } */
+/* { dg-require-effective-target avx512fp16 } */
+
+#include <string.h>
+
+static void do_test (void);
+
+#define DO_TEST do_test
+#define AVX512FP16
+#include "avx512-check.h"
+
+#define N 10000
+
+void
+__attribute__((noipa))
+foo_ph (_Complex _Float16* a)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = 1.0f16 + 2.0f16i;
+}
+
+static void
+do_test (void)
+{
+  _Complex _Float16 ph_src = 1.0f16 + 2.0f16i;
+  _Complex _Float16* ph_dst = (_Complex _Float16*) malloc (2 * N * sizeof (_Float16));
+
+  __builtin_memset (ph_dst, 0, 2 * N * sizeof (_Float16));
+
+  foo_ph (ph_dst);
+  for (int i = 0; i != N; i++)
+    {
+      if (ph_dst[i] != ph_src)
+	__builtin_abort ();
+    }
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-9a.c b/gcc/testsuite/gcc.target/i386/pr106010-9a.c
new file mode 100644
index 00000000000..e922f7b5400
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-9a.c
@@ -0,0 +1,89 @@
+/* { dg-do compile } */
+/* { dg-options "-O3 -mavx2 -fvect-cost-model=unlimited -fdump-tree-vect-details" } */
+/* { dg-final { scan-tree-dump-times "vectorized 1 loops" 6 "vect" } } */
+
+typedef struct { _Complex double c; double a1; double a2;}
+  cdf;
+typedef struct { _Complex double c; double a1; double a2; double a3; double a4;}
+  cdf2;
+typedef struct { _Complex double c1; _Complex double c2; double a1; double a2; double a3; double a4;}
+  cdf3;
+typedef struct { _Complex double c1; _Complex double c2; double a1; double a2;}
+  cdf4;
+
+#define N 100
+/* VMAT_ELEMENTWISE.  */
+void
+__attribute__((noipa))
+foo (cdf* a, cdf* __restrict b)
+{
+   for (int i = 0; i < N; ++i)
+    {
+      a[i].c = b[i].c;
+      a[i].a1 = b[i].a1;
+      a[i].a2 = b[i].a2;
+    }
+}
+
+/* VMAT_CONTIGUOUS_PERMUTE.  */
+void
+__attribute__((noipa))
+foo1 (cdf2* a, cdf2* __restrict b)
+{
+   for (int i = 0; i < N; ++i)
+    {
+      a[i].c = b[i].c;
+      a[i].a1 = b[i].a1;
+      a[i].a2 = b[i].a2;
+      a[i].a3 = b[i].a3;
+      a[i].a4 = b[i].a4;
+    }
+}
+
+/* VMAT_CONTIGUOUS.  */
+void
+__attribute__((noipa))
+foo2 (cdf3* a, cdf3* __restrict b)
+{
+   for (int i = 0; i < N; ++i)
+    {
+      a[i].c1 = b[i].c1;
+      a[i].c2 = b[i].c2;
+      a[i].a1 = b[i].a1;
+      a[i].a2 = b[i].a2;
+      a[i].a3 = b[i].a3;
+      a[i].a4 = b[i].a4;
+    }
+}
+
+/* VMAT_STRIDED_SLP.  */
+void
+__attribute__((noipa))
+foo3 (cdf4* a, cdf4* __restrict b)
+{
+   for (int i = 0; i < N; ++i)
+    {
+      a[i].c1 = b[i].c1;
+      a[i].c2 = b[i].c2;
+      a[i].a1 = b[i].a1;
+      a[i].a2 = b[i].a2;
+    }
+}
+
+/* VMAT_CONTIGUOUS_REVERSE.  */
+void
+__attribute__((noipa))
+foo4 (_Complex double* a, _Complex double* __restrict b)
+{
+  for (int i = 0; i != N; i++)
+    a[i] = b[N-i-1];
+}
+
+/* VMAT_CONTIGUOUS_DOWN.  */
+void
+__attribute__((noipa))
+foo5 (_Complex double* a, _Complex double* __restrict b)
+{
+  for (int i = 0; i != N; i++)
+    a[N-i-1] = b[0];
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-9b.c b/gcc/testsuite/gcc.target/i386/pr106010-9b.c
new file mode 100644
index 00000000000..e220445e6e3
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-9b.c
@@ -0,0 +1,90 @@
+/* { dg-do run } */
+/* { dg-options "-O3 -msse2 -fvect-cost-model=unlimited" } */
+/* { dg-require-effective-target sse2 } */
+
+#include <string.h>
+#include "sse2-check.h"
+#include "pr106010-9a.c"
+
+static void
+sse2_test (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (N * sizeof (_Complex double));
+  _Complex double* pd_dst = (_Complex double*) malloc (N * sizeof (_Complex double));
+  _Complex double* pd_src2 = (_Complex double*) malloc (N * sizeof (_Complex double));
+  _Complex double* pd_dst2 = (_Complex double*) malloc (N * sizeof (_Complex double));
+  cdf* cdf_src = (cdf*) malloc (N * sizeof (cdf));
+  cdf* cdf_dst = (cdf*) malloc (N * sizeof (cdf));
+  cdf2* cdf2_src = (cdf2*) malloc (N * sizeof (cdf2));
+  cdf2* cdf2_dst = (cdf2*) malloc (N * sizeof (cdf2));
+  cdf3* cdf3_src = (cdf3*) malloc (N * sizeof (cdf3));
+  cdf3* cdf3_dst = (cdf3*) malloc (N * sizeof (cdf3));
+  cdf4* cdf4_src = (cdf4*) malloc (N * sizeof (cdf4));
+  cdf4* cdf4_dst = (cdf4*) malloc (N * sizeof (cdf4));
+
+  char* p_init = (char*) malloc (N * sizeof (cdf3));
+
+  __builtin_memset (cdf_dst, 0, N * sizeof (cdf));
+  __builtin_memset (cdf2_dst, 0, N * sizeof (cdf2));
+  __builtin_memset (cdf3_dst, 0, N * sizeof (cdf3));
+  __builtin_memset (cdf4_dst, 0, N * sizeof (cdf4));
+  __builtin_memset (pd_dst, 0, N * sizeof (_Complex double));
+  __builtin_memset (pd_dst2, 0, N * sizeof (_Complex double));
+
+  for (int i = 0; i != N * sizeof (cdf3); i++)
+    p_init[i] = i;
+
+  memcpy (cdf_src, p_init, N * sizeof (cdf));
+  memcpy (cdf2_src, p_init, N * sizeof (cdf2));
+  memcpy (cdf3_src, p_init, N * sizeof (cdf3));
+  memcpy (cdf4_src, p_init, N * sizeof (cdf4));
+  memcpy (pd_src, p_init, N * sizeof (_Complex double));
+  for (int i = 0; i != 2 * N * sizeof (double); i++)
+    p_init[i] = i % 16;
+  memcpy (pd_src2, p_init, N * sizeof (_Complex double));
+
+  foo (cdf_dst, cdf_src);
+  foo1 (cdf2_dst, cdf2_src);
+  foo2 (cdf3_dst, cdf3_src);
+  foo3 (cdf4_dst, cdf4_src);
+  foo4 (pd_dst, pd_src);
+  foo5 (pd_dst2, pd_src2);
+  for (int i = 0; i != N; i++)
+    {
+      p_init[(N - i - 1) * 16] = i * 16;
+      p_init[(N - i - 1) * 16 + 1] = i * 16 + 1;
+      p_init[(N - i - 1) * 16 + 2] = i * 16 + 2;
+      p_init[(N - i - 1) * 16 + 3] = i * 16 + 3;
+      p_init[(N - i - 1) * 16 + 4] = i * 16 + 4;
+      p_init[(N - i - 1) * 16 + 5] = i * 16 + 5;
+      p_init[(N - i - 1) * 16 + 6] = i * 16 + 6;
+      p_init[(N - i - 1) * 16 + 7] = i * 16 + 7;
+      p_init[(N - i - 1) * 16 + 8] = i * 16 + 8;
+      p_init[(N - i - 1) * 16 + 9] = i * 16 + 9;
+      p_init[(N - i - 1) * 16 + 10] = i * 16 + 10;
+      p_init[(N - i - 1) * 16 + 11] = i * 16 + 11;
+      p_init[(N - i - 1) * 16 + 12] = i * 16 + 12;
+      p_init[(N - i - 1) * 16 + 13] = i * 16 + 13;
+      p_init[(N - i - 1) * 16 + 14] = i * 16 + 14;
+      p_init[(N - i - 1) * 16 + 15] = i * 16 + 15;
+    }
+  memcpy (pd_src, p_init, N * 16);
+
+  if (__builtin_memcmp (pd_dst, pd_src, N * 2 * sizeof (double)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (pd_dst2, pd_src2, N * 2 * sizeof (double)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf_dst, cdf_src, N * sizeof (cdf)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf2_dst, cdf2_src, N * sizeof (cdf2)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf3_dst, cdf3_src, N * sizeof (cdf3)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf4_dst, cdf4_src, N * sizeof (cdf4)) != 0)
+    __builtin_abort ();
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-9c.c b/gcc/testsuite/gcc.target/i386/pr106010-9c.c
new file mode 100644
index 00000000000..ff51f6195b7
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-9c.c
@@ -0,0 +1,90 @@
+/* { dg-do run } */
+/* { dg-options "-O3 -mavx2 -fvect-cost-model=unlimited" } */
+/* { dg-require-effective-target avx2 } */
+
+#include <string.h>
+#include "avx2-check.h"
+#include "pr106010-9a.c"
+
+static void
+avx2_test (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (N * sizeof (_Complex double));
+  _Complex double* pd_dst = (_Complex double*) malloc (N * sizeof (_Complex double));
+  _Complex double* pd_src2 = (_Complex double*) malloc (N * sizeof (_Complex double));
+  _Complex double* pd_dst2 = (_Complex double*) malloc (N * sizeof (_Complex double));
+  cdf* cdf_src = (cdf*) malloc (N * sizeof (cdf));
+  cdf* cdf_dst = (cdf*) malloc (N * sizeof (cdf));
+  cdf2* cdf2_src = (cdf2*) malloc (N * sizeof (cdf2));
+  cdf2* cdf2_dst = (cdf2*) malloc (N * sizeof (cdf2));
+  cdf3* cdf3_src = (cdf3*) malloc (N * sizeof (cdf3));
+  cdf3* cdf3_dst = (cdf3*) malloc (N * sizeof (cdf3));
+  cdf4* cdf4_src = (cdf4*) malloc (N * sizeof (cdf4));
+  cdf4* cdf4_dst = (cdf4*) malloc (N * sizeof (cdf4));
+
+  char* p_init = (char*) malloc (N * sizeof (cdf3));
+
+  __builtin_memset (cdf_dst, 0, N * sizeof (cdf));
+  __builtin_memset (cdf2_dst, 0, N * sizeof (cdf2));
+  __builtin_memset (cdf3_dst, 0, N * sizeof (cdf3));
+  __builtin_memset (cdf4_dst, 0, N * sizeof (cdf4));
+  __builtin_memset (pd_dst, 0, N * sizeof (_Complex double));
+  __builtin_memset (pd_dst2, 0, N * sizeof (_Complex double));
+
+  for (int i = 0; i != N * sizeof (cdf3); i++)
+    p_init[i] = i;
+
+  memcpy (cdf_src, p_init, N * sizeof (cdf));
+  memcpy (cdf2_src, p_init, N * sizeof (cdf2));
+  memcpy (cdf3_src, p_init, N * sizeof (cdf3));
+  memcpy (cdf4_src, p_init, N * sizeof (cdf4));
+  memcpy (pd_src, p_init, N * sizeof (_Complex double));
+  for (int i = 0; i != 2 * N * sizeof (double); i++)
+    p_init[i] = i % 16;
+  memcpy (pd_src2, p_init, N * sizeof (_Complex double));
+
+  foo (cdf_dst, cdf_src);
+  foo1 (cdf2_dst, cdf2_src);
+  foo2 (cdf3_dst, cdf3_src);
+  foo3 (cdf4_dst, cdf4_src);
+  foo4 (pd_dst, pd_src);
+  foo5 (pd_dst2, pd_src2);
+  for (int i = 0; i != N; i++)
+    {
+      p_init[(N - i - 1) * 16] = i * 16;
+      p_init[(N - i - 1) * 16 + 1] = i * 16 + 1;
+      p_init[(N - i - 1) * 16 + 2] = i * 16 + 2;
+      p_init[(N - i - 1) * 16 + 3] = i * 16 + 3;
+      p_init[(N - i - 1) * 16 + 4] = i * 16 + 4;
+      p_init[(N - i - 1) * 16 + 5] = i * 16 + 5;
+      p_init[(N - i - 1) * 16 + 6] = i * 16 + 6;
+      p_init[(N - i - 1) * 16 + 7] = i * 16 + 7;
+      p_init[(N - i - 1) * 16 + 8] = i * 16 + 8;
+      p_init[(N - i - 1) * 16 + 9] = i * 16 + 9;
+      p_init[(N - i - 1) * 16 + 10] = i * 16 + 10;
+      p_init[(N - i - 1) * 16 + 11] = i * 16 + 11;
+      p_init[(N - i - 1) * 16 + 12] = i * 16 + 12;
+      p_init[(N - i - 1) * 16 + 13] = i * 16 + 13;
+      p_init[(N - i - 1) * 16 + 14] = i * 16 + 14;
+      p_init[(N - i - 1) * 16 + 15] = i * 16 + 15;
+    }
+  memcpy (pd_src, p_init, N * 16);
+
+  if (__builtin_memcmp (pd_dst, pd_src, N * 2 * sizeof (double)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (pd_dst2, pd_src2, N * 2 * sizeof (double)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf_dst, cdf_src, N * sizeof (cdf)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf2_dst, cdf2_src, N * sizeof (cdf2)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf3_dst, cdf3_src, N * sizeof (cdf3)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf4_dst, cdf4_src, N * sizeof (cdf4)) != 0)
+    __builtin_abort ();
+}
diff --git a/gcc/testsuite/gcc.target/i386/pr106010-9d.c b/gcc/testsuite/gcc.target/i386/pr106010-9d.c
new file mode 100644
index 00000000000..d4d8f1dd722
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106010-9d.c
@@ -0,0 +1,92 @@
+/* { dg-do run } */
+/* { dg-options "-O3 -mavx512f -mavx512vl -fvect-cost-model=unlimited -mprefer-vector-width=512" } */
+/* { dg-require-effective-target avx512f } */
+
+#include <string.h>
+#include <stdlib.h>
+#define AVX512F
+#include "avx512-check.h"
+#include "pr106010-9a.c"
+
+static void
+test_512 (void)
+{
+  _Complex double* pd_src = (_Complex double*) malloc (N * sizeof (_Complex double));
+  _Complex double* pd_dst = (_Complex double*) malloc (N * sizeof (_Complex double));
+  _Complex double* pd_src2 = (_Complex double*) malloc (N * sizeof (_Complex double));
+  _Complex double* pd_dst2 = (_Complex double*) malloc (N * sizeof (_Complex double));
+  cdf* cdf_src = (cdf*) malloc (N * sizeof (cdf));
+  cdf* cdf_dst = (cdf*) malloc (N * sizeof (cdf));
+  cdf2* cdf2_src = (cdf2*) malloc (N * sizeof (cdf2));
+  cdf2* cdf2_dst = (cdf2*) malloc (N * sizeof (cdf2));
+  cdf3* cdf3_src = (cdf3*) malloc (N * sizeof (cdf3));
+  cdf3* cdf3_dst = (cdf3*) malloc (N * sizeof (cdf3));
+  cdf4* cdf4_src = (cdf4*) malloc (N * sizeof (cdf4));
+  cdf4* cdf4_dst = (cdf4*) malloc (N * sizeof (cdf4));
+
+  char* p_init = (char*) malloc (N * sizeof (cdf3));
+
+  __builtin_memset (cdf_dst, 0, N * sizeof (cdf));
+  __builtin_memset (cdf2_dst, 0, N * sizeof (cdf2));
+  __builtin_memset (cdf3_dst, 0, N * sizeof (cdf3));
+  __builtin_memset (cdf4_dst, 0, N * sizeof (cdf4));
+  __builtin_memset (pd_dst, 0, N * sizeof (_Complex double));
+  __builtin_memset (pd_dst2, 0, N * sizeof (_Complex double));
+
+  for (int i = 0; i != N * sizeof (cdf3); i++)
+    p_init[i] = i;
+
+  memcpy (cdf_src, p_init, N * sizeof (cdf));
+  memcpy (cdf2_src, p_init, N * sizeof (cdf2));
+  memcpy (cdf3_src, p_init, N * sizeof (cdf3));
+  memcpy (cdf4_src, p_init, N * sizeof (cdf4));
+  memcpy (pd_src, p_init, N * sizeof (_Complex double));
+  for (int i = 0; i != 2 * N * sizeof (double); i++)
+    p_init[i] = i % 16;
+  memcpy (pd_src2, p_init, N * sizeof (_Complex double));
+
+  foo (cdf_dst, cdf_src);
+  foo1 (cdf2_dst, cdf2_src);
+  foo2 (cdf3_dst, cdf3_src);
+  foo3 (cdf4_dst, cdf4_src);
+  foo4 (pd_dst, pd_src);
+  foo5 (pd_dst2, pd_src2);
+  for (int i = 0; i != N; i++)
+    {
+      p_init[(N - i - 1) * 16] = i * 16;
+      p_init[(N - i - 1) * 16 + 1] = i * 16 + 1;
+      p_init[(N - i - 1) * 16 + 2] = i * 16 + 2;
+      p_init[(N - i - 1) * 16 + 3] = i * 16 + 3;
+      p_init[(N - i - 1) * 16 + 4] = i * 16 + 4;
+      p_init[(N - i - 1) * 16 + 5] = i * 16 + 5;
+      p_init[(N - i - 1) * 16 + 6] = i * 16 + 6;
+      p_init[(N - i - 1) * 16 + 7] = i * 16 + 7;
+      p_init[(N - i - 1) * 16 + 8] = i * 16 + 8;
+      p_init[(N - i - 1) * 16 + 9] = i * 16 + 9;
+      p_init[(N - i - 1) * 16 + 10] = i * 16 + 10;
+      p_init[(N - i - 1) * 16 + 11] = i * 16 + 11;
+      p_init[(N - i - 1) * 16 + 12] = i * 16 + 12;
+      p_init[(N - i - 1) * 16 + 13] = i * 16 + 13;
+      p_init[(N - i - 1) * 16 + 14] = i * 16 + 14;
+      p_init[(N - i - 1) * 16 + 15] = i * 16 + 15;
+    }
+  memcpy (pd_src, p_init, N * 16);
+
+  if (__builtin_memcmp (pd_dst, pd_src, N * 2 * sizeof (double)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (pd_dst2, pd_src2, N * 2 * sizeof (double)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf_dst, cdf_src, N * sizeof (cdf)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf2_dst, cdf2_src, N * sizeof (cdf2)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf3_dst, cdf3_src, N * sizeof (cdf3)) != 0)
+    __builtin_abort ();
+
+  if (__builtin_memcmp (cdf4_dst, cdf4_src, N * sizeof (cdf4)) != 0)
+    __builtin_abort ();
+}
diff --git a/gcc/tree-complex.cc b/gcc/tree-complex.cc
index 61950a0f099..ea9df6114a1 100644
--- a/gcc/tree-complex.cc
+++ b/gcc/tree-complex.cc
@@ -297,6 +297,11 @@ init_dont_simulate_again (void)
 		break;

 	      default:
+		/* When expand_complex_move would trigger make sure we
+		   perform lowering even when there is no actual complex
+		   operation.  This helps consistency and vectorization.  */
+		if (TREE_CODE (TREE_TYPE (gimple_op (stmt, 0))) == COMPLEX_TYPE)
+		  saw_a_complex_op = true;
 		break;
 	      }

@@ -869,7 +874,9 @@ expand_complex_move (gimple_stmt_iterator *gsi, tree type)
 	  update_complex_assignment (gsi, r, i);
 	}
     }
-  else if (rhs && TREE_CODE (rhs) == SSA_NAME && !TREE_SIDE_EFFECTS (lhs))
+  else if (rhs
+	   && (TREE_CODE (rhs) == SSA_NAME || TREE_CODE (rhs) == COMPLEX_CST)
+	   && !TREE_SIDE_EFFECTS (lhs))
     {
       tree x;
       gimple *t;
--
2.18.1

The following adjusts vectorizer code generation to avoid splitting
out address increments for invariant addresses which causes objects
to get TREE_ADDRESSABLE when not necessary.

Bootstrapped and tested on x86_64-unknown-linux-gnu, pushed.

	* tree-vect-data-refs.cc (bump_vector_ptr): Return an
	invariant updated address when the input was invariant.
---
 gcc/tree-vect-data-refs.cc | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/gcc/tree-vect-data-refs.cc b/gcc/tree-vect-data-refs.cc
index 609cacc4971..b279a82551e 100644
--- a/gcc/tree-vect-data-refs.cc
+++ b/gcc/tree-vect-data-refs.cc
@@ -5195,6 +5195,14 @@ bump_vector_ptr (vec_info *vinfo,

   if (TREE_CODE (dataref_ptr) == SSA_NAME)
     new_dataref_ptr = copy_ssa_name (dataref_ptr);
+  else if (is_gimple_min_invariant (dataref_ptr))
+    /* When possible avoid emitting a separate increment stmt that will
+       force the addressed object addressable.  */
+    return build1 (ADDR_EXPR, TREE_TYPE (dataref_ptr),
+		   fold_build2 (MEM_REF,
+				TREE_TYPE (TREE_TYPE (dataref_ptr)),
+				dataref_ptr,
+				fold_convert (ptr_type_node, update)));
   else
     new_dataref_ptr = make_ssa_name (TREE_TYPE (dataref_ptr));
   incr_stmt = gimple_build_assign (new_dataref_ptr, POINTER_PLUS_EXPR,
--
2.35.3

This function remains unused since remove_node_from_insn_list was cloned
from it.

gcc/ChangeLog:

	* rtl.h (remove_node_from_expr_list): Remove declaration.
	* rtlanal.cc (remove_node_from_expr_list): Remove (no uses).
---
 gcc/rtl.h      |  1 -
 gcc/rtlanal.cc | 29 -----------------------------
 2 files changed, 30 deletions(-)

diff --git a/gcc/rtl.h b/gcc/rtl.h
index 488016bb4..645c009a3 100644
--- a/gcc/rtl.h
+++ b/gcc/rtl.h
@@ -3712,7 +3712,6 @@ extern unsigned hash_rtx_cb (const_rtx, machine_mode, int *, int *,
 extern rtx regno_use_in (unsigned int, rtx);
 extern int auto_inc_p (const_rtx);
 extern bool in_insn_list_p (const rtx_insn_list *, const rtx_insn *);
-extern void remove_node_from_expr_list (const_rtx, rtx_expr_list **);
 extern void remove_node_from_insn_list (const rtx_insn *, rtx_insn_list **);
 extern int loc_mentioned_in_p (rtx *, const_rtx);
 extern rtx_insn *find_first_parameter_load (rtx_insn *, rtx_insn *);
diff --git a/gcc/rtlanal.cc b/gcc/rtlanal.cc
index d78cc6024..ec95ecd6c 100644
--- a/gcc/rtlanal.cc
+++ b/gcc/rtlanal.cc
@@ -2878,35 +2878,6 @@ in_insn_list_p (const rtx_insn_list *listp, const rtx_insn *node)
   return false;
 }

-/* Search LISTP (an EXPR_LIST) for an entry whose first operand is NODE and
-   remove that entry from the list if it is found.
-
-   A simple equality test is used to determine if NODE matches.  */
-
-void
-remove_node_from_expr_list (const_rtx node, rtx_expr_list **listp)
-{
-  rtx_expr_list *temp = *listp;
-  rtx_expr_list *prev = NULL;
-
-  while (temp)
-    {
-      if (node == temp->element ())
-	{
-	  /* Splice the node out of the list.  */
-	  if (prev)
-	    XEXP (prev, 1) = temp->next ();
-	  else
-	    *listp = temp->next ();
-
-	  return;
-	}
-
-      prev = temp;
-      temp = temp->next ();
-    }
-}
-
 /* Search LISTP (an INSN_LIST) for an entry whose first operand is NODE and
    remove that entry from the list if it is found.

--
2.35.1

The testcase in the PR demonstrates how it is possible for one
__builtin_setjmp_receiver label to appear in
nonlocal_goto_handler_labels list twice (after the block with
__builtin_setjmp_setup referring to it was duplicated).

remove_node_from_insn_list did not account for this possibility and
removed only the first copy from the list. Add an assert verifying that
duplicates are not present.

To avoid adding a label to the list twice, move registration of the
label from __builtin_setjmp_setup handling to __builtin_setjmp_receiver.

gcc/ChangeLog:

	PR rtl-optimization/101347
	* builtins.cc (expand_builtin) [BUILT_IN_SETJMP_SETUP]: Move
	population of nonlocal_goto_handler_labels from here ...
	(expand_builtin) [BUILT_IN_SETJMP_RECEIVER]: ... to here.
	* rtlanal.cc (remove_node_from_insn_list): Verify that a
	duplicate is not present in the remainder of the list.
---
 gcc/builtins.cc | 15 +++++++--------
 gcc/rtlanal.cc  |  1 +
 2 files changed, 8 insertions(+), 8 deletions(-)

diff --git a/gcc/builtins.cc b/gcc/builtins.cc
index e6816d5c8..12a688dd8 100644
--- a/gcc/builtins.cc
+++ b/gcc/builtins.cc
@@ -7467,15 +7467,7 @@ expand_builtin (tree exp, rtx target, rtx subtarget, machine_mode mode,
 	  tree label = TREE_OPERAND (CALL_EXPR_ARG (exp, 1), 0);
 	  rtx_insn *label_r = label_rtx (label);

-	  /* This is copied from the handling of non-local gotos.  */
 	  expand_builtin_setjmp_setup (buf_addr, label_r);
-	  nonlocal_goto_handler_labels
-	    = gen_rtx_INSN_LIST (VOIDmode, label_r,
-				 nonlocal_goto_handler_labels);
-	  /* ??? Do not let expand_label treat us as such since we would
-	     not want to be both on the list of non-local labels and on
-	     the list of forced labels.  */
-	  FORCED_LABEL (label) = 0;
 	  return const0_rtx;
 	}
       break;
@@ -7488,6 +7480,13 @@ expand_builtin (tree exp, rtx target, rtx subtarget, machine_mode mode,
 	  rtx_insn *label_r = label_rtx (label);

 	  expand_builtin_setjmp_receiver (label_r);
+	  nonlocal_goto_handler_labels
+	    = gen_rtx_INSN_LIST (VOIDmode, label_r,
+				 nonlocal_goto_handler_labels);
+	  /* ??? Do not let expand_label treat us as such since we would
+	     not want to be both on the list of non-local labels and on
+	     the list of forced labels.  */
+	  FORCED_LABEL (label) = 0;
 	  return const0_rtx;
 	}
       break;
diff --git a/gcc/rtlanal.cc b/gcc/rtlanal.cc
index ec95ecd6c..56da7435a 100644
--- a/gcc/rtlanal.cc
+++ b/gcc/rtlanal.cc
@@ -2899,6 +2899,7 @@ remove_node_from_insn_list (const rtx_insn *node, rtx_insn_list **listp)
 	  else
 	    *listp = temp->next ();

+	  gcc_checking_assert (!in_insn_list_p (temp->next (), node));
 	  return;
 	}

--
2.35.1

The following enhances DSE to handle LEN_STORE (optimally) and
MASK_STORE (conservatively).

Bootstrapped on x86_64-unknown-linux-gnu, testing in progress.
Kewen is testing on powerpc.  Handling MASK_STORE_LANES in
a similar way to MASK_STORE is probably possible but I couldn't
figure a way to generate one for testing.  STORE_LANES is
probably handled already since it's ECF_CONST.

	PR tree-optimization/106365
	* tree-ssa-dse.cc (initialize_ao_ref_for_dse): Handle
	LEN_STORE, add mode to initialize a may-def and handle
	MASK_STORE that way.
	(dse_optimize_stmt): Query may-defs.  Handle internal
	functions LEN_STORE and MASK_STORE similar to how
	we handle memory builtins but without byte tracking.
---
 gcc/tree-ssa-dse.cc | 55 +++++++++++++++++++++++++++++++++++++++++----
 1 file changed, 51 insertions(+), 4 deletions(-)

diff --git a/gcc/tree-ssa-dse.cc b/gcc/tree-ssa-dse.cc
index 8d1739a4510..34cfd1a8802 100644
--- a/gcc/tree-ssa-dse.cc
+++ b/gcc/tree-ssa-dse.cc
@@ -93,7 +93,9 @@ static bitmap need_eh_cleanup;
 static bitmap need_ab_cleanup;

 /* STMT is a statement that may write into memory.  Analyze it and
-   initialize WRITE to describe how STMT affects memory.
+   initialize WRITE to describe how STMT affects memory.  When
+   MAY_DEF_OK is true then the function initializes WRITE to what
+   the stmt may define.

    Return TRUE if the statement was analyzed, FALSE otherwise.

@@ -101,7 +103,7 @@ static bitmap need_ab_cleanup;
    can be achieved by analyzing more statements.  */

 static bool
-initialize_ao_ref_for_dse (gimple *stmt, ao_ref *write)
+initialize_ao_ref_for_dse (gimple *stmt, ao_ref *write, bool may_def_ok = false)
 {
   /* It's advantageous to handle certain mem* functions.  */
   if (gimple_call_builtin_p (stmt, BUILT_IN_NORMAL))
@@ -146,6 +148,32 @@ initialize_ao_ref_for_dse (gimple *stmt, ao_ref *write)
 	  break;
 	}
     }
+  else if (is_gimple_call (stmt)
+	   && gimple_call_internal_p (stmt))
+    {
+      switch (gimple_call_internal_fn (stmt))
+	{
+	case IFN_LEN_STORE:
+	  ao_ref_init_from_ptr_and_size
+	      (write, gimple_call_arg (stmt, 0),
+	       int_const_binop (MINUS_EXPR,
+				gimple_call_arg (stmt, 2),
+				gimple_call_arg (stmt, 4)));
+	  return true;
+	case IFN_MASK_STORE:
+	  /* We cannot initialize a must-def ao_ref (in all cases) but we
+	     can provide a may-def variant.  */
+	  if (may_def_ok)
+	    {
+	      ao_ref_init_from_ptr_and_size
+		  (write, gimple_call_arg (stmt, 0),
+		   TYPE_SIZE_UNIT (TREE_TYPE (gimple_call_arg (stmt, 2))));
+	      return true;
+	    }
+	  break;
+	default:;
+	}
+    }
   else if (tree lhs = gimple_get_lhs (stmt))
     {
       if (TREE_CODE (lhs) != SSA_NAME)
@@ -1328,8 +1356,10 @@ dse_optimize_stmt (function *fun, gimple_stmt_iterator *gsi, sbitmap live_bytes)

   ao_ref ref;
   /* If this is not a store we can still remove dead call using
-     modref summary.  */
-  if (!initialize_ao_ref_for_dse (stmt, &ref))
+     modref summary.  Note we specifically allow ref to be initialized
+     to a conservative may-def since we are looking for followup stores
+     to kill all of it.  */
+  if (!initialize_ao_ref_for_dse (stmt, &ref, true))
     {
       dse_optimize_call (gsi, live_bytes);
       return;
@@ -1398,6 +1428,23 @@ dse_optimize_stmt (function *fun, gimple_stmt_iterator *gsi, sbitmap live_bytes)
 	  return;
 	}
     }
+  else if (is_gimple_call (stmt)
+	   && gimple_call_internal_p (stmt))
+    {
+      switch (gimple_call_internal_fn (stmt))
+	{
+	case IFN_LEN_STORE:
+	case IFN_MASK_STORE:
+	  {
+	    enum dse_store_status store_status;
+	    store_status = dse_classify_store (&ref, stmt, false, live_bytes);
+	    if (store_status == DSE_STORE_DEAD)
+	      delete_dead_or_redundant_call (gsi, "dead");
+	    return;
+	  }
+	default:;
+	}
+    }

   bool by_clobber_p = false;

--
2.35.3

The following teaches VN to handle reads from .MASK_STORE and
.LEN_STORE.  For this push_partial_def is extended first for
convenience so we don't have to handle the full def case in the
caller (possibly other paths can be simplified then).  Also
the partial definition stored value can have an offset applied
so we don't have to build a fake RHS when we register the pieces
of an existing store.

Bootstrapped and tested on x86_64-unknown-linux-gnu, Kewen is
going to test on powerpc.

I'm not sure about whether it's worth (or easily possible) to
handle .MASK_STORE_LANES, I think handling the constant def case
might be possible but since it has an intrinsic permute it might
make more sense to rewrite the constant def case into a .MASK_STORE?
(does the mask apply to the destination memory order or the source
lane order?)

	PR tree-optimization/106365
	* tree-ssa-sccvn.cc (pd_data::rhs_off): New field determining
	the offset to start encoding of RHS from.
	(vn_walk_cb_data::vn_walk_cb_data): Initialize it.
	(vn_walk_cb_data::push_partial_def): Allow the first partial
	definition to be fully providing the def.  Offset RHS
	before encoding if requested.
	(vn_reference_lookup_3): Initialize def_rhs everywhere.
	Add support for .MASK_STORE and .LEN_STORE (partial) definitions.

	* gcc.target/i386/vec-maskstore-vn.c: New testcase.
---
 .../gcc.target/i386/vec-maskstore-vn.c        |  30 +++
 gcc/tree-ssa-sccvn.cc                         | 255 ++++++++++++++----
 2 files changed, 228 insertions(+), 57 deletions(-)
 create mode 100644 gcc/testsuite/gcc.target/i386/vec-maskstore-vn.c

diff --git a/gcc/testsuite/gcc.target/i386/vec-maskstore-vn.c b/gcc/testsuite/gcc.target/i386/vec-maskstore-vn.c
new file mode 100644
index 00000000000..98213905ece
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/vec-maskstore-vn.c
@@ -0,0 +1,30 @@
+/* { dg-do compile } */
+/* { dg-options "-O3 -mavx2 -fdump-tree-fre5" } */
+
+void __attribute__((noinline,noclone))
+foo (int *out, int *res)
+{
+  int mask[] = { 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1 };
+  int i;
+  for (i = 0; i < 16; ++i)
+    {
+      if (mask[i])
+        out[i] = i;
+    }
+  int o0 = out[0];
+  int o7 = out[7];
+  int o14 = out[14];
+  int o15 = out[15];
+  res[0] = o0;
+  res[2] = o7;
+  res[4] = o14;
+  res[6] = o15;
+}
+
+/* Vectorization produces .MASK_STORE, unrolling will unroll the two
+   vector iterations.  FRE5 after that should be able to CSE
+   out[7] and out[15], but leave out[0] and out[14] alone.  */
+/* { dg-final { scan-tree-dump " = o0_\[0-9\]+;" "fre5" } } */
+/* { dg-final { scan-tree-dump " = 7;" "fre5" } } */
+/* { dg-final { scan-tree-dump " = o14_\[0-9\]+;" "fre5" } } */
+/* { dg-final { scan-tree-dump " = 15;" "fre5" } } */
diff --git a/gcc/tree-ssa-sccvn.cc b/gcc/tree-ssa-sccvn.cc
index f41d5031365..7d947b55a27 100644
--- a/gcc/tree-ssa-sccvn.cc
+++ b/gcc/tree-ssa-sccvn.cc
@@ -1790,6 +1790,7 @@ struct pd_range
 struct pd_data
 {
   tree rhs;
+  HOST_WIDE_INT rhs_off;
   HOST_WIDE_INT offset;
   HOST_WIDE_INT size;
 };
@@ -1816,6 +1817,7 @@ struct vn_walk_cb_data
 	unsigned int pos = 0, prec = w.get_precision ();
 	pd_data pd;
 	pd.rhs = build_constructor (NULL_TREE, NULL);
+	pd.rhs_off = 0;
 	/* When bitwise and with a constant is done on a memory load,
 	   we don't really need all the bits to be defined or defined
 	   to constants, we don't really care what is in the position
@@ -1976,6 +1978,7 @@ vn_walk_cb_data::push_partial_def (pd_data pd,

   bool pd_constant_p = (TREE_CODE (pd.rhs) == CONSTRUCTOR
 			|| CONSTANT_CLASS_P (pd.rhs));
+  pd_range *r;
   if (partial_defs.is_empty ())
     {
       /* If we get a clobber upfront, fail.  */
@@ -1989,65 +1992,70 @@ vn_walk_cb_data::push_partial_def (pd_data pd,
       first_set = set;
       first_base_set = base_set;
       last_vuse_ptr = NULL;
-      /* Continue looking for partial defs.  */
-      return NULL;
-    }
-
-  if (!known_ranges)
-    {
-      /* ???  Optimize the case where the 2nd partial def completes things.  */
-      gcc_obstack_init (&ranges_obstack);
-      known_ranges = splay_tree_new_with_allocator (pd_range_compare, 0, 0,
-						    pd_tree_alloc,
-						    pd_tree_dealloc, this);
-      splay_tree_insert (known_ranges,
-			 (splay_tree_key)&first_range.offset,
-			 (splay_tree_value)&first_range);
-    }
-
-  pd_range newr = { pd.offset, pd.size };
-  splay_tree_node n;
-  pd_range *r;
-  /* Lookup the predecessor of offset + 1 and see if we need to merge.  */
-  HOST_WIDE_INT loffset = newr.offset + 1;
-  if ((n = splay_tree_predecessor (known_ranges, (splay_tree_key)&loffset))
-      && ((r = (pd_range *)n->value), true)
-      && ranges_known_overlap_p (r->offset, r->size + 1,
-				 newr.offset, newr.size))
-    {
-      /* Ignore partial defs already covered.  Here we also drop shadowed
-         clobbers arriving here at the floor.  */
-      if (known_subrange_p (newr.offset, newr.size, r->offset, r->size))
-	return NULL;
-      r->size = MAX (r->offset + r->size, newr.offset + newr.size) - r->offset;
+      r = &first_range;
+      /* Go check if the first partial definition was a full one in case
+	 the caller didn't optimize for this.  */
     }
   else
     {
-      /* newr.offset wasn't covered yet, insert the range.  */
-      r = XOBNEW (&ranges_obstack, pd_range);
-      *r = newr;
-      splay_tree_insert (known_ranges, (splay_tree_key)&r->offset,
-			 (splay_tree_value)r);
-    }
-  /* Merge r which now contains newr and is a member of the splay tree with
-     adjacent overlapping ranges.  */
-  pd_range *rafter;
-  while ((n = splay_tree_successor (known_ranges, (splay_tree_key)&r->offset))
-	 && ((rafter = (pd_range *)n->value), true)
-	 && ranges_known_overlap_p (r->offset, r->size + 1,
-				    rafter->offset, rafter->size))
-    {
-      r->size = MAX (r->offset + r->size,
-		     rafter->offset + rafter->size) - r->offset;
-      splay_tree_remove (known_ranges, (splay_tree_key)&rafter->offset);
-    }
-  /* If we get a clobber, fail.  */
-  if (TREE_CLOBBER_P (pd.rhs))
-    return (void *)-1;
-  /* Non-constants are OK as long as they are shadowed by a constant.  */
-  if (!pd_constant_p)
-    return (void *)-1;
-  partial_defs.safe_push (pd);
+      if (!known_ranges)
+	{
+	  /* ???  Optimize the case where the 2nd partial def completes
+	     things.  */
+	  gcc_obstack_init (&ranges_obstack);
+	  known_ranges = splay_tree_new_with_allocator (pd_range_compare, 0, 0,
+							pd_tree_alloc,
+							pd_tree_dealloc, this);
+	  splay_tree_insert (known_ranges,
+			     (splay_tree_key)&first_range.offset,
+			     (splay_tree_value)&first_range);
+	}
+
+      pd_range newr = { pd.offset, pd.size };
+      splay_tree_node n;
+      /* Lookup the predecessor of offset + 1 and see if we need to merge.  */
+      HOST_WIDE_INT loffset = newr.offset + 1;
+      if ((n = splay_tree_predecessor (known_ranges, (splay_tree_key)&loffset))
+	  && ((r = (pd_range *)n->value), true)
+	  && ranges_known_overlap_p (r->offset, r->size + 1,
+				     newr.offset, newr.size))
+	{
+	  /* Ignore partial defs already covered.  Here we also drop shadowed
+	     clobbers arriving here at the floor.  */
+	  if (known_subrange_p (newr.offset, newr.size, r->offset, r->size))
+	    return NULL;
+	  r->size
+	    = MAX (r->offset + r->size, newr.offset + newr.size) - r->offset;
+	}
+      else
+	{
+	  /* newr.offset wasn't covered yet, insert the range.  */
+	  r = XOBNEW (&ranges_obstack, pd_range);
+	  *r = newr;
+	  splay_tree_insert (known_ranges, (splay_tree_key)&r->offset,
+			     (splay_tree_value)r);
+	}
+      /* Merge r which now contains newr and is a member of the splay tree with
+	 adjacent overlapping ranges.  */
+      pd_range *rafter;
+      while ((n = splay_tree_successor (known_ranges,
+					(splay_tree_key)&r->offset))
+	     && ((rafter = (pd_range *)n->value), true)
+	     && ranges_known_overlap_p (r->offset, r->size + 1,
+					rafter->offset, rafter->size))
+	{
+	  r->size = MAX (r->offset + r->size,
+			 rafter->offset + rafter->size) - r->offset;
+	  splay_tree_remove (known_ranges, (splay_tree_key)&rafter->offset);
+	}
+      /* If we get a clobber, fail.  */
+      if (TREE_CLOBBER_P (pd.rhs))
+	return (void *)-1;
+      /* Non-constants are OK as long as they are shadowed by a constant.  */
+      if (!pd_constant_p)
+	return (void *)-1;
+      partial_defs.safe_push (pd);
+    }

   /* Now we have merged newr into the range tree.  When we have covered
      [offseti, sizei] then the tree will contain exactly one node which has
@@ -2081,7 +2089,8 @@ vn_walk_cb_data::push_partial_def (pd_data pd,
       else
 	{
 	  len = native_encode_expr (pd.rhs, this_buffer, bufsize,
-				    MAX (0, -pd.offset) / BITS_PER_UNIT);
+				    (MAX (0, -pd.offset)
+				     + pd.rhs_off) / BITS_PER_UNIT);
 	  if (len <= 0
 	      || len < (ROUND_UP (pd.size, BITS_PER_UNIT) / BITS_PER_UNIT
 			- MAX (0, -pd.offset) / BITS_PER_UNIT))
@@ -2906,6 +2915,7 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,
 	{
 	  pd_data pd;
 	  pd.rhs = build_constructor (NULL_TREE, NULL);
+	  pd.rhs_off = 0;
 	  pd.offset = offset2i;
 	  pd.size = leni << LOG2_BITS_PER_UNIT;
 	  return data->push_partial_def (pd, 0, 0, offseti, maxsizei);
@@ -2955,6 +2965,7 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,
 		 by a later def.  */
 	      pd_data pd;
 	      pd.rhs = gimple_assign_rhs1 (def_stmt);
+	      pd.rhs_off = 0;
 	      pd.offset = offset2i;
 	      pd.size = size2i;
 	      return data->push_partial_def (pd, ao_ref_alias_set (&lhs_ref),
@@ -3107,6 +3118,7 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,
 	      if (TREE_CODE (rhs) == SSA_NAME)
 		rhs = SSA_VAL (rhs);
 	      pd.rhs = rhs;
+	      pd.rhs_off = 0;
 	      pd.offset = offset2i;
 	      pd.size = size2i;
 	      return data->push_partial_def (pd, ao_ref_alias_set (&lhs_ref),
@@ -3186,6 +3198,7 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,
 	    {
 	      pd_data pd;
 	      pd.rhs = SSA_VAL (def_rhs);
+	      pd.rhs_off = 0;
 	      pd.offset = offset2i;
 	      pd.size = size2i;
 	      return data->push_partial_def (pd, ao_ref_alias_set (&lhs_ref),
@@ -3195,6 +3208,133 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,
 	}
     }

+  /* 4b) Assignment done via one of the vectorizer internal store
+     functions where we may be able to access pieces from or we can
+     combine to a larger entity.  */
+  else if (known_eq (ref->size, maxsize)
+	   && is_gimple_reg_type (vr->type)
+	   && !reverse_storage_order_for_component_p (vr->operands)
+	   && !contains_storage_order_barrier_p (vr->operands)
+	   && is_gimple_call (def_stmt)
+	   && gimple_call_internal_p (def_stmt)
+	   && internal_store_fn_p (gimple_call_internal_fn (def_stmt)))
+    {
+      gcall *call = as_a <gcall *> (def_stmt);
+      internal_fn fn = gimple_call_internal_fn (call);
+      tree def_rhs = gimple_call_arg (call,
+				      internal_fn_stored_value_index (fn));
+      def_rhs = vn_valueize (def_rhs);
+      if (TREE_CODE (def_rhs) != VECTOR_CST)
+	return (void *)-1;
+
+      tree mask = NULL_TREE, len = NULL_TREE, bias = NULL_TREE;
+      switch (fn)
+	{
+	case IFN_MASK_STORE:
+	  mask = gimple_call_arg (call, internal_fn_mask_index (fn));
+	  mask = vn_valueize (mask);
+	  if (TREE_CODE (mask) != VECTOR_CST)
+	    return (void *)-1;
+	  break;
+	case IFN_LEN_STORE:
+	  len = gimple_call_arg (call, 2);
+	  bias = gimple_call_arg (call, 4);
+	  if (!tree_fits_uhwi_p (len) || !tree_fits_shwi_p (bias))
+	    return (void *)-1;
+	  break;
+	default:
+	  return (void *)-1;
+	}
+      ao_ref_init_from_ptr_and_size (&lhs_ref,
+				     vn_valueize (gimple_call_arg (call, 0)),
+				     TYPE_SIZE_UNIT (TREE_TYPE (def_rhs)));
+      tree base2;
+      poly_int64 offset2, size2, maxsize2;
+      HOST_WIDE_INT offset2i, size2i, offseti;
+      base2 = ao_ref_base (&lhs_ref);
+      offset2 = lhs_ref.offset;
+      size2 = lhs_ref.size;
+      maxsize2 = lhs_ref.max_size;
+      if (known_size_p (maxsize2)
+	  && known_eq (maxsize2, size2)
+	  && adjust_offsets_for_equal_base_address (base, &offset,
+						    base2, &offset2)
+	  && maxsize.is_constant (&maxsizei)
+	  && offset.is_constant (&offseti)
+	  && offset2.is_constant (&offset2i)
+	  && size2.is_constant (&size2i))
+	{
+	  if (!ranges_maybe_overlap_p (offset, maxsize, offset2, size2))
+	    /* Poor-mans disambiguation.  */
+	    return NULL;
+	  else if (ranges_known_overlap_p (offset, maxsize, offset2, size2))
+	    {
+	      pd_data pd;
+	      pd.rhs = def_rhs;
+	      tree aa = gimple_call_arg (call, 1);
+	      alias_set_type set = get_deref_alias_set (TREE_TYPE (aa));
+	      tree vectype = TREE_TYPE (def_rhs);
+	      unsigned HOST_WIDE_INT elsz
+		= tree_to_uhwi (TYPE_SIZE (TREE_TYPE (vectype)));
+	      if (mask)
+		{
+		  HOST_WIDE_INT start = 0, len = 0;
+		  unsigned mask_idx = 0;
+		  do
+		    {
+		      if (integer_zerop (VECTOR_CST_ELT (mask, mask_idx)))
+			{
+			  if (len != 0)
+			    {
+			      pd.rhs_off = start;
+			      pd.offset = offset2i + start;
+			      pd.size = len;
+			      if (ranges_known_overlap_p
+				    (offset, maxsize, pd.offset, pd.size))
+				{
+				  void *res = data->push_partial_def
+					      (pd, set, set, offseti, maxsizei);
+				  if (res != NULL)
+				    return res;
+				}
+			    }
+			  start = (mask_idx + 1) * elsz;
+			  len = 0;
+			}
+		      else
+			len += elsz;
+		      mask_idx++;
+		    }
+		  while (known_lt (mask_idx, TYPE_VECTOR_SUBPARTS (vectype)));
+		  if (len != 0)
+		    {
+		      pd.rhs_off = start;
+		      pd.offset = offset2i + start;
+		      pd.size = len;
+		      if (ranges_known_overlap_p (offset, maxsize,
+						  pd.offset, pd.size))
+			return data->push_partial_def (pd, set, set,
+						       offseti, maxsizei);
+		    }
+		}
+	      else if (fn == IFN_LEN_STORE)
+		{
+		  pd.rhs_off = 0;
+		  pd.offset = offset2i;
+		  pd.size = (tree_to_uhwi (len)
+			     + -tree_to_shwi (bias)) * BITS_PER_UNIT;
+		  if (ranges_known_overlap_p (offset, maxsize,
+					      pd.offset, pd.size))
+		    return data->push_partial_def (pd, set, set,
+						   offseti, maxsizei);
+		}
+	      else
+		gcc_unreachable ();
+	      return NULL;
+	    }
+	}
+    }
+
   /* 5) For aggregate copies translate the reference through them if
      the copy kills ref.  */
   else if (data->vn_walk_kind == VN_WALKREWRITE
@@ -3327,6 +3467,7 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,
 	    {
 	      pd_data pd;
 	      pd.rhs = val;
+	      pd.rhs_off = 0;
 	      pd.offset = 0;
 	      pd.size = maxsizei;
 	      return data->push_partial_def (pd, ao_ref_alias_set (&lhs_ref),
--
2.35.3

The following adds support for MASK_STORE, MASK_LOAD and friends
to call_may_clobber_ref_p and ref_maybe_used_by_call_p.  Since
they all use a special argument to specify TBAA they are not really
suited for fnspec handling thus the manual support.

Bootstrapped and tested on x86_64-unknown-linux-gnu, pushed.

PR106365 shows this can be important though in many cases seen there
we miss PTA info.

	* tree-ssa-alias.cc (ref_maybe_used_by_call_p_1): Special-case
	store internal functions and IFN_MASK_LOAD, IFN_LEN_LOAD
	and IFN_MASK_LOAD_LANES.
	(call_may_clobber_ref_p_1): Special-case IFN_MASK_STORE,
	IFN_LEN_STORE and IFN_MASK_STORE_LANES.
---
 gcc/tree-ssa-alias.cc | 49 +++++++++++++++++++++++++++++++++++++++++--
 1 file changed, 47 insertions(+), 2 deletions(-)

diff --git a/gcc/tree-ssa-alias.cc b/gcc/tree-ssa-alias.cc
index 782266bdad8..390cd875074 100644
--- a/gcc/tree-ssa-alias.cc
+++ b/gcc/tree-ssa-alias.cc
@@ -47,6 +47,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "print-tree.h"
 #include "tree-ssa-alias-compare.h"
 #include "builtins.h"
+#include "internal-fn.h"

 /* Broad overview of how alias analysis on gimple works:

@@ -2793,8 +2794,38 @@ ref_maybe_used_by_call_p_1 (gcall *call, ao_ref *ref, bool tbaa_p)
   if (ref->volatile_p)
     return true;

-  callee = gimple_call_fndecl (call);
+  if (gimple_call_internal_p (call))
+    switch (gimple_call_internal_fn (call))
+      {
+      case IFN_MASK_STORE:
+      case IFN_SCATTER_STORE:
+      case IFN_MASK_SCATTER_STORE:
+      case IFN_LEN_STORE:
+	return false;
+      case IFN_MASK_STORE_LANES:
+	goto process_args;
+      case IFN_MASK_LOAD:
+      case IFN_LEN_LOAD:
+      case IFN_MASK_LOAD_LANES:
+	{
+	  ao_ref rhs_ref;
+	  tree lhs = gimple_call_lhs (call);
+	  if (lhs)
+	    {
+	      ao_ref_init_from_ptr_and_size (&rhs_ref,
+					     gimple_call_arg (call, 0),
+					     TYPE_SIZE_UNIT (TREE_TYPE (lhs)));
+	      rhs_ref.ref_alias_set = rhs_ref.base_alias_set
+		= tbaa_p ? get_deref_alias_set (TREE_TYPE
+					(gimple_call_arg (call, 1))) : 0;
+	      return refs_may_alias_p_1 (ref, &rhs_ref, tbaa_p);
+	    }
+	  break;
+	}
+      default:;
+      }

+  callee = gimple_call_fndecl (call);
   if (callee != NULL_TREE)
     {
       struct cgraph_node *node = cgraph_node::get (callee);
@@ -3005,7 +3036,7 @@ call_may_clobber_ref_p_1 (gcall *call, ao_ref *ref, bool tbaa_p)
       & (ECF_PURE|ECF_CONST|ECF_LOOPING_CONST_OR_PURE|ECF_NOVOPS))
     return false;
   if (gimple_call_internal_p (call))
-    switch (gimple_call_internal_fn (call))
+    switch (auto fn = gimple_call_internal_fn (call))
       {
 	/* Treat these internal calls like ECF_PURE for aliasing,
 	   they don't write to any memory the program should care about.
@@ -3018,6 +3049,20 @@ call_may_clobber_ref_p_1 (gcall *call, ao_ref *ref, bool tbaa_p)
       case IFN_UBSAN_PTR:
       case IFN_ASAN_CHECK:
 	return false;
+      case IFN_MASK_STORE:
+      case IFN_LEN_STORE:
+      case IFN_MASK_STORE_LANES:
+	{
+	  tree rhs = gimple_call_arg (call,
+				      internal_fn_stored_value_index (fn));
+	  ao_ref lhs_ref;
+	  ao_ref_init_from_ptr_and_size (&lhs_ref, gimple_call_arg (call, 0),
+					 TYPE_SIZE_UNIT (TREE_TYPE (rhs)));
+	  lhs_ref.ref_alias_set = lhs_ref.base_alias_set
+	    = tbaa_p ? get_deref_alias_set
+				   (TREE_TYPE (gimple_call_arg (call, 1))) : 0;
+	  return refs_may_alias_p_1 (ref, &lhs_ref, tbaa_p);
+	}
       default:
 	break;
       }
--
2.35.3

The following makes sure to fold ~(a ^ b) to a == b for truth
values (but not vectors, we'd have to check for vector support of
equality).  That turns the PR106379 testcase into a ranger one.

Note that while we arrive at ~(a ^ b) in a convoluted way from
original !a == !b one can eventually write the expression this
way directly as well.

Bootstrapped and tested on x86_64-unknown-linux-gnu, pushed.

	PR tree-optimization/106379
	* match.pd (~(a ^ b) -> a == b): New pattern.

	* gcc.dg/pr106379-1.c: New testcase.
---
 gcc/match.pd                      | 6 ++++++
 gcc/testsuite/gcc.dg/pr106379-1.c | 9 +++++++++
 2 files changed, 15 insertions(+)
 create mode 100644 gcc/testsuite/gcc.dg/pr106379-1.c

diff --git a/gcc/match.pd b/gcc/match.pd
index 8bbc0dbd5cd..88a1a5aa9cc 100644
--- a/gcc/match.pd
+++ b/gcc/match.pd
@@ -1938,6 +1938,12 @@ DEFINE_INT_AND_FLOAT_ROUND_FN (RINT)
  (if (tree_nop_conversion_p (type, TREE_TYPE (@0)))
   (bit_not (bit_xor (view_convert @0) @1))))

+/* ~(a ^ b) is a == b for truth valued a and b.  */
+(simplify
+ (bit_not (bit_xor:s truth_valued_p@0 truth_valued_p@1))
+ (if (!VECTOR_TYPE_P (type))
+  (convert (eq @0 @1))))
+
 /* (x & ~m) | (y & m) -> ((x ^ y) & m) ^ x */
 (simplify
  (bit_ior:c (bit_and:cs @0 (bit_not @2)) (bit_and:cs @1 @2))
diff --git a/gcc/testsuite/gcc.dg/pr106379-1.c b/gcc/testsuite/gcc.dg/pr106379-1.c
new file mode 100644
index 00000000000..7f2575e02dc
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/pr106379-1.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-options "-O -fdump-tree-forwprop1" } */
+
+_Bool foo (_Bool a, _Bool b)
+{
+  return !a == !b;
+}
+
+/* { dg-final { scan-tree-dump "\[ab\]_\[0-9\]+\\(D\\) == \[ba\]_\[0-9\]+\\(D\\)" "forwprop1" } } */
--
2.35.3

Subject: [PATCH] libcpp: Handle extended characters in user-defined literal suffix [PR103902]

The PR complains that we do not handle UTF-8 in the suffix for a user-defined
literal, such as:

bool operator ""_Ï€ (unsigned long long);

In fact we don't handle any extended identifier characters there, whether
UTF-8, UCNs, or the $ sign. We do handle it fine if the optional space after
the "" tokens is included, since then the identifier is lexed in the "normal"
way as its own token. But when it is lexed as part of the string token, this
is handled in lex_string() with a one-off loop that is not aware of extended
characters.

This patch fixes it by adding a new function scan_cur_identifier() that can be
used to lex an identifier while in the middle of lexing another token. It is
somewhat duplicative of the code in lex_identifier(), which handles the normal
case, but I think there's no good way to avoid that without pessimizing the
usual case, since lex_identifier() takes advantage of the fact that the first
character of the identifier has already been analyzed. The code duplication is
somewhat offset by factoring out the identifier lexing diagnostics (e.g. for
poisoned identifiers), which were formerly duplicated in two places, and have
been factored into their own function that's used in (now) 3 places.

BTW, the other place that was lexing identifiers is lex_identifier_intern(),
which is used to implement #pragma push_macro and #pragma pop_macro. This does
not support extended characters either. I will add that in a subsequent patch,
because it can't directly reuse the new function, but rather needs to lex from
a string instead of a cpp_buffer.

With scan_cur_identifier(), we do also correctly warn about bidi and
normalization issues in the extended identifiers comprising the suffix, and we
check for poisoned identifiers there as well.

PR preprocessor/103902

libcpp/ChangeLog:

	* lex.cc (identifier_diagnostics_on_lex): New function refactors
	common code from...
	(lex_identifier_intern): ...here, and...
	(lex_identifier): ...here.
	(struct scan_id_result): New struct to hold the result of...
	(scan_cur_identifier): ...new function.
	(create_literal2): New function.
	(is_macro): Removed function that is now handled directly in
	lex_string() and lex_raw_string().
	(is_macro_not_literal_suffix): Likewise.
	(lit_accum::create_literal2): New function.
	(lex_raw_string): Make use of new function scan_cur_identifier().
	(lex_string): Likewise.

gcc/testsuite/ChangeLog:

	* g++.dg/cpp0x/udlit-extended-id-1.C: New test.
	* g++.dg/cpp0x/udlit-extended-id-2.C: New test.
	* g++.dg/cpp0x/udlit-extended-id-3.C: New test.
	* g++.dg/cpp0x/udlit-extended-id-4.C: New test.

diff --git a/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-1.C b/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-1.C
new file mode 100644
index 00000000000..411d4fdd0ba
--- /dev/null
+++ b/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-1.C
@@ -0,0 +1,68 @@
+// { dg-do run { target c++11 } }
+// { dg-additional-options "-Wno-error=normalized" }
+#include <cstring>
+using namespace std;
+
+constexpr unsigned long long operator "" _Ï€ (unsigned long long x)
+{
+  return 3 * x;
+}
+
+/* Historically we didn't parse properly as part of the "" token, so check that
+   as well.  */
+constexpr unsigned long long operator ""_Î 2 (unsigned long long x)
+{
+  return 4 * x;
+}
+
+char x1[1_Ï€];
+char x2[2_Î 2];
+
+static_assert (sizeof x1 == 3, "test1");
+static_assert (sizeof x2 == 8, "test2");
+
+const char * operator "" _1Ïƒ (const char *s, unsigned long)
+{
+  return s + 1;
+}
+
+const char * operator ""_Î£2 (const char *s, unsigned long)
+{
+  return s + 2;
+}
+
+const char * operator "" _\U000000e61 (const char *s, unsigned long)
+{
+  return "ae";
+}
+
+const char* operator ""_\u01532 (const char *s, unsigned long)
+{
+  return "oe";
+}
+
+bool operator "" _\u0BC7\u0BBE (unsigned long long); // { dg-warning "not in NFC" }
+bool operator ""_\u0B47\U00000B3E (unsigned long long); // { dg-warning "not in NFC" }
+
+#define xÏ„y
+const char * str = ""xÏ„y; // { dg-warning "invalid suffix on literal" }
+
+int main()
+{
+  if (3_Ï€ != 9)
+    __builtin_abort ();
+  if (4_Î 2 != 16)
+    __builtin_abort ();
+  if (strcmp ("abc"_1Ïƒ, "bc"))
+    __builtin_abort ();
+  if (strcmp ("abcd"_Î£2, "cd"))
+    __builtin_abort ();
+  if (strcmp (R"(abcdef)"_1Ïƒ, "bcdef"))
+    __builtin_abort ();
+  if (strcmp (R"(abcdef)"_Î£2, "cdef"))
+    __builtin_abort ();
+  if (strcmp ("xyz"_Ã¦1, "ae"))
+    __builtin_abort ();
+  if (strcmp ("xyz"_Å“2, "oe"))
+    __builtin_abort ();
+}
diff --git a/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-2.C b/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-2.C
new file mode 100644
index 00000000000..05a2804a463
--- /dev/null
+++ b/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-2.C
@@ -0,0 +1,6 @@
+// { dg-do compile { target c++11 } }
+// { dg-additional-options "-Wbidi-chars=any,ucn" }
+bool operator ""_d\u202ae\u202cf (unsigned long long); // { dg-line line1 }
+// { dg-error "universal character \\\\u202a is not valid in an identifier" "test1" { target *-*-* } line1 }
+// { dg-error "universal character \\\\u202c is not valid in an identifier" "test2" { target *-*-* } line1 }
+// { dg-warning "found problematic Unicode character" "test3" { target *-*-* } line1 }
diff --git a/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-3.C b/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-3.C
new file mode 100644
index 00000000000..6db729c3432
--- /dev/null
+++ b/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-3.C
@@ -0,0 +1,7 @@
+// { dg-do compile { target c++11 } }
+int _Ä§;
+const char * operator ""_Ä§ (const char *, unsigned long);
+bool operator ""_Ä§ (unsigned long long x);
+#pragma GCC poison _Ä§
+bool b = 1_Ä§; // This currently is allowed, is that intended?
+const char *x = "hbar"_Ä§; // { dg-error "attempt to use poisoned" }
diff --git a/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-4.C b/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-4.C
new file mode 100644
index 00000000000..a356eba4a3c
--- /dev/null
+++ b/gcc/testsuite/g++.dg/cpp0x/udlit-extended-id-4.C
@@ -0,0 +1,15 @@
+// { dg-options "-std=c++98 -Wc++11-compat" }
+#define END ;
+#define ÎµND ;
+#define EÎ·D ;
+#define EN\u0394 ;
+
+const char *s1 = "s1"END // { dg-warning "requires a space between string literal and macro" }
+const char *s2 = "s2"ÎµND // { dg-warning "requires a space between string literal and macro" }
+const char *s3 = "s3"EÎ·D // { dg-warning "requires a space between string literal and macro" }
+const char *s4 = "s4"ENÎ” // { dg-warning "requires a space between string literal and macro" }
+
+/* Make sure we did not skip the token also in the case that it wasn't found to
+   be a macro; compilation should fail here.  */
+const char *s5 = "s5"NÃ˜T_A_MACRO; // { dg-error "expected ',' or ';' before" }
+
diff --git a/libcpp/lex.cc b/libcpp/lex.cc
index f891d3e17df..b41292f641b 100644
--- a/libcpp/lex.cc
+++ b/libcpp/lex.cc
@@ -1854,8 +1854,11 @@ warn_about_normalization (cpp_reader *pfile,

 static const cppchar_t utf8_signifier = 0xC0;

-/* Returns TRUE if the sequence starting at buffer->cur is valid in
-   an identifier.  FIRST is TRUE if this starts an identifier.  */
+/* Returns TRUE if the byte sequence starting at buffer->cur is a valid
+   extended character in an identifier.  If FIRST is TRUE, then the character
+   must be valid at the beginning of an identifier as well.  If the return
+   value is TRUE, then pfile->buffer->cur has been moved to point to the next
+   byte after the extended character.  */

 static bool
 forms_identifier_p (cpp_reader *pfile, int first,
@@ -1941,6 +1944,122 @@ maybe_va_opt_error (cpp_reader *pfile)
     }
 }

+/* Helper function to perform diagnostics that are needed (rarely)
+   when an identifier is lexed.  */
+static void identifier_diagnostics_on_lex (cpp_reader *pfile,
+					   cpp_hashnode *node)
+{
+  if (__builtin_expect (!(node->flags & NODE_DIAGNOSTIC)
+			|| pfile->state.skipping, 1))
+    return;
+
+  /* It is allowed to poison the same identifier twice.  */
+  if ((node->flags & NODE_POISONED) && !pfile->state.poisoned_ok)
+    cpp_error (pfile, CPP_DL_ERROR, "attempt to use poisoned \"%s\"",
+	       NODE_NAME (node));
+
+  /* Constraint 6.10.3.5: __VA_ARGS__ should only appear in the
+     replacement list of a variadic macro.  */
+  if (node == pfile->spec_nodes.n__VA_ARGS__
+      && !pfile->state.va_args_ok)
+    {
+      if (CPP_OPTION (pfile, cplusplus))
+	cpp_error (pfile, CPP_DL_PEDWARN,
+		   "__VA_ARGS__ can only appear in the expansion"
+		   " of a C++11 variadic macro");
+      else
+	cpp_error (pfile, CPP_DL_PEDWARN,
+		   "__VA_ARGS__ can only appear in the expansion"
+		   " of a C99 variadic macro");
+    }
+
+  if (node == pfile->spec_nodes.n__VA_OPT__)
+    maybe_va_opt_error (pfile);
+
+  /* For -Wc++-compat, warn about use of C++ named operators.  */
+  if (node->flags & NODE_WARN_OPERATOR)
+    cpp_warning (pfile, CPP_W_CXX_OPERATOR_NAMES,
+		 "identifier \"%s\" is a special operator name in C++",
+		 NODE_NAME (node));
+}
+
+/* Helper function to scan an entire identifier beginning at
+   pfile->buffer->cur, and possibly containing extended characters (UCNs
+   and/or UTF-8).  Returns the cpp_hashnode for the identifier on success, or
+   else nullptr, as well as a normalize_state so that normalization warnings
+   may be issued once the token lexing is complete.  */
+
+struct scan_id_result
+{
+  cpp_hashnode *node;
+  normalize_state nst;
+
+  scan_id_result ()
+    : node (nullptr)
+  {
+    nst = INITIAL_NORMALIZE_STATE;
+  }
+
+  explicit operator bool () const { return node; }
+};
+
+static scan_id_result
+scan_cur_identifier (cpp_reader *pfile)
+{
+  cpp_buffer *const buffer = pfile->buffer;
+  const uchar *const begin = buffer->cur;
+  scan_id_result result;
+  bool need_extended;
+  unsigned int hash = 0;
+  if (ISIDST (*buffer->cur))
+    {
+      hash = HT_HASHSTEP (0, *buffer->cur);
+      ++buffer->cur;
+      while (ISIDNUM (*buffer->cur))
+	{
+	  hash = HT_HASHSTEP (hash, *buffer->cur);
+	  ++buffer->cur;
+	}
+      NORMALIZE_STATE_UPDATE_IDNUM (&result.nst, buffer->cur[-1]);
+      need_extended = forms_identifier_p (pfile, false, &result.nst);
+    }
+  else
+    {
+      if (!forms_identifier_p (pfile, true, &result.nst))
+	return result;
+      need_extended = true;
+    }
+
+  if (need_extended)
+    {
+      do {
+	while (ISIDNUM (*buffer->cur))
+	  {
+	    NORMALIZE_STATE_UPDATE_IDNUM (&result.nst, *buffer->cur);
+	    ++buffer->cur;
+	  }
+      } while (forms_identifier_p (pfile, false, &result.nst));
+
+      if (pfile->warn_bidi_p ())
+	maybe_warn_bidi_on_close (pfile, buffer->cur);
+
+      result.node = _cpp_interpret_identifier (pfile, begin,
+					       buffer->cur - begin);
+    }
+  else
+    {
+      const size_t len = buffer->cur - begin;
+      hash = HT_HASHFINISH (hash, len);
+      result.node = CPP_HASHNODE (ht_lookup_with_hash (pfile->hash_table,
+						       begin, len,
+						       hash, HT_ALLOC));
+    }
+
+  identifier_diagnostics_on_lex (pfile, result.node);
+  return result;
+}
+
+
 /* Helper function to get the cpp_hashnode of the identifier BASE.  */
 static cpp_hashnode *
 lex_identifier_intern (cpp_reader *pfile, const uchar *base)
@@ -1960,41 +2079,7 @@ lex_identifier_intern (cpp_reader *pfile, const uchar *base)
   hash = HT_HASHFINISH (hash, len);
   result = CPP_HASHNODE (ht_lookup_with_hash (pfile->hash_table,
 					      base, len, hash, HT_ALLOC));
-
-  /* Rarely, identifiers require diagnostics when lexed.  */
-  if (__builtin_expect ((result->flags & NODE_DIAGNOSTIC)
-			&& !pfile->state.skipping, 0))
-    {
-      /* It is allowed to poison the same identifier twice.  */
-      if ((result->flags & NODE_POISONED) && !pfile->state.poisoned_ok)
-	cpp_error (pfile, CPP_DL_ERROR, "attempt to use poisoned \"%s\"",
-		   NODE_NAME (result));
-
-      /* Constraint 6.10.3.5: __VA_ARGS__ should only appear in the
-	 replacement list of a variadic macro.  */
-      if (result == pfile->spec_nodes.n__VA_ARGS__
-	  && !pfile->state.va_args_ok)
-	{
-	  if (CPP_OPTION (pfile, cplusplus))
-	    cpp_error (pfile, CPP_DL_PEDWARN,
-		       "__VA_ARGS__ can only appear in the expansion"
-		       " of a C++11 variadic macro");
-	  else
-	    cpp_error (pfile, CPP_DL_PEDWARN,
-		       "__VA_ARGS__ can only appear in the expansion"
-		       " of a C99 variadic macro");
-	}
-
-      if (result == pfile->spec_nodes.n__VA_OPT__)
-	maybe_va_opt_error (pfile);
-
-      /* For -Wc++-compat, warn about use of C++ named operators.  */
-      if (result->flags & NODE_WARN_OPERATOR)
-	cpp_warning (pfile, CPP_W_CXX_OPERATOR_NAMES,
-		     "identifier \"%s\" is a special operator name in C++",
-		     NODE_NAME (result));
-    }
-
+  identifier_diagnostics_on_lex (pfile, result);
   return result;
 }

@@ -2057,42 +2142,7 @@ lex_identifier (cpp_reader *pfile, const uchar *base, bool starts_ucn,
       *spelling = result;
     }

-  /* Rarely, identifiers require diagnostics when lexed.  */
-  if (__builtin_expect ((result->flags & NODE_DIAGNOSTIC)
-			&& !pfile->state.skipping, 0))
-    {
-      /* It is allowed to poison the same identifier twice.  */
-      if ((result->flags & NODE_POISONED) && !pfile->state.poisoned_ok)
-	cpp_error (pfile, CPP_DL_ERROR, "attempt to use poisoned \"%s\"",
-		   NODE_NAME (result));
-
-      /* Constraint 6.10.3.5: __VA_ARGS__ should only appear in the
-	 replacement list of a variadic macro.  */
-      if (result == pfile->spec_nodes.n__VA_ARGS__
-	  && !pfile->state.va_args_ok)
-	{
-	  if (CPP_OPTION (pfile, cplusplus))
-	    cpp_error (pfile, CPP_DL_PEDWARN,
-		       "__VA_ARGS__ can only appear in the expansion"
-		       " of a C++11 variadic macro");
-	  else
-	    cpp_error (pfile, CPP_DL_PEDWARN,
-		       "__VA_ARGS__ can only appear in the expansion"
-		       " of a C99 variadic macro");
-	}
-
-      /* __VA_OPT__ should only appear in the replacement list of a
-	 variadic macro.  */
-      if (result == pfile->spec_nodes.n__VA_OPT__)
-	maybe_va_opt_error (pfile);
-
-      /* For -Wc++-compat, warn about use of C++ named operators.  */
-      if (result->flags & NODE_WARN_OPERATOR)
-	cpp_warning (pfile, CPP_W_CXX_OPERATOR_NAMES,
-		     "identifier \"%s\" is a special operator name in C++",
-		     NODE_NAME (result));
-    }
-
+  identifier_diagnostics_on_lex (pfile, result);
   return result;
 }

@@ -2152,6 +2202,24 @@ create_literal (cpp_reader *pfile, cpp_token *token, const uchar *base,
   token->val.str.text = cpp_alloc_token_string (pfile, base, len);
 }

+/* Like create_literal(), but construct it from two separate strings
+   which are concatenated.  LEN2 may be 0 if no second string is
+   required.  */
+static void
+create_literal2 (cpp_reader *pfile, cpp_token *token, const uchar *base1,
+		 unsigned int len1, const uchar *base2, unsigned int len2,
+		 enum cpp_ttype type)
+{
+  token->type = type;
+  token->val.str.len = len1 + len2;
+  uchar *const dest = _cpp_unaligned_alloc (pfile, len1 + len2 + 1);
+  memcpy (dest, base1, len1);
+  if (len2)
+    memcpy (dest+len1, base2, len2);
+  dest[len1 + len2] = 0;
+  token->val.str.text = dest;
+}
+
 const uchar *
 cpp_alloc_token_string (cpp_reader *pfile,
 			const unsigned char *ptr, unsigned len)
@@ -2190,6 +2258,11 @@ struct lit_accum {
       rpos = NULL;
     return c;
   }
+
+  void create_literal2 (cpp_reader *pfile, cpp_token *token,
+			const uchar *base1, unsigned int len1,
+			const uchar *base2, unsigned int len2,
+			enum cpp_ttype type);
 };

 /* Subroutine of lex_raw_string: Append LEN chars from BASE to the buffer
@@ -2232,45 +2305,31 @@ lit_accum::read_begin (cpp_reader *pfile)
   rpos = BUFF_FRONT (last);
 }

-/* Returns true if a macro has been defined.
-   This might not work if compile with -save-temps,
-   or preprocess separately from compilation.  */
-
-static bool
-is_macro(cpp_reader *pfile, const uchar *base)
+/* Like create_literal2(), but also prepend all the accumulated data from
+   the lit_accum struct.  */
+void
+lit_accum::create_literal2 (cpp_reader *pfile, cpp_token *token,
+			    const uchar *base1, unsigned int len1,
+			    const uchar *base2, unsigned int len2,
+			    enum cpp_ttype type)
 {
-  const uchar *cur = base;
-  if (! ISIDST (*cur))
-    return false;
-  unsigned int hash = HT_HASHSTEP (0, *cur);
-  ++cur;
-  while (ISIDNUM (*cur))
+  const unsigned int tot_len = accum + len1 + len2;
+  uchar *dest = _cpp_unaligned_alloc (pfile, tot_len + 1);
+  token->type = type;
+  token->val.str.len = tot_len;
+  token->val.str.text = dest;
+  for (_cpp_buff *buf = first; buf; buf = buf->next)
     {
-      hash = HT_HASHSTEP (hash, *cur);
-      ++cur;
+      size_t len = BUFF_FRONT (buf) - buf->base;
+      memcpy (dest, buf->base, len);
+      dest += len;
     }
-  hash = HT_HASHFINISH (hash, cur - base);
-
-  cpp_hashnode *result = CPP_HASHNODE (ht_lookup_with_hash (pfile->hash_table,
-					base, cur - base, hash, HT_NO_INSERT));
-
-  return result && cpp_macro_p (result);
-}
-
-/* Returns true if a literal suffix does not have the expected form
-   and is defined as a macro.  */
-
-static bool
-is_macro_not_literal_suffix(cpp_reader *pfile, const uchar *base)
-{
-  /* User-defined literals outside of namespace std must start with a single
-     underscore, so assume anything of that form really is a UDL suffix.
-     We don't need to worry about UDLs defined inside namespace std because
-     their names are reserved, so cannot be used as macro names in valid
-     programs.  */
-  if (base[0] == '_' && base[1] != '_')
-    return false;
-  return is_macro (pfile, base);
+  memcpy (dest, base1, len1);
+  dest += len1;
+  if (len2)
+    memcpy (dest, base2, len2);
+  dest += len2;
+  *dest = '\0';
 }

 /* Lexes a raw string.  The stored string contains the spelling,
@@ -2540,26 +2599,53 @@ lex_raw_string (cpp_reader *pfile, cpp_token *token, const uchar *base)

   if (CPP_OPTION (pfile, user_literals))
     {
-      /* If a string format macro, say from inttypes.h, is placed touching
-	 a string literal it could be parsed as a C++11 user-defined string
-	 literal thus breaking the program.  */
-      if (is_macro_not_literal_suffix (pfile, pos))
-	{
-	  /* Raise a warning, but do not consume subsequent tokens.  */
-	  if (CPP_OPTION (pfile, warn_literal_suffix) && !pfile->state.skipping)
-	    cpp_warning_with_line (pfile, CPP_W_LITERAL_SUFFIX,
-				   token->src_loc, 0,
-				   "invalid suffix on literal; C++11 requires "
-				   "a space between literal and string macro");
-	}
-      /* Grab user defined literal suffix.  */
-      else if (ISIDST (*pos))
-	{
-	  type = cpp_userdef_string_add_type (type);
-	  ++pos;
+      const uchar *const suffix_begin = pos;
+      pfile->buffer->cur = pos;

-	  while (ISIDNUM (*pos))
-	    ++pos;
+      if (const auto sr = scan_cur_identifier (pfile))
+	{
+	  /* If a string format macro, say from inttypes.h, is placed touching
+	     a string literal it could be parsed as a C++11 user-defined
+	     string literal thus breaking the program.  User-defined literals
+	     outside of namespace std must start with a single underscore, so
+	     assume anything of that form really is a UDL suffix.  We don't
+	     need to worry about UDLs defined inside namespace std because
+	     their names are reserved, so cannot be used as macro names in
+	     valid programs.  */
+	  if ((suffix_begin[0] != '_' || suffix_begin[1] == '_')
+	      && cpp_macro_p (sr.node))
+	    {
+	      /* Maybe raise a warning, but do not consume the tokens.  */
+	      pfile->buffer->cur = suffix_begin;
+	      if (CPP_OPTION (pfile, warn_literal_suffix)
+		  && !pfile->state.skipping)
+		cpp_warning_with_line
+		  (pfile, CPP_W_LITERAL_SUFFIX,
+		   token->src_loc, 0,
+		   "invalid suffix on literal; C++11 requires "
+		   "a space between literal and string macro");
+	    }
+	  else
+	    {
+	      type = cpp_userdef_string_add_type (type);
+	      if (!accum.accum)
+		create_literal2 (pfile, token, base,
+				 suffix_begin - base,
+				 NODE_NAME (sr.node),
+				 NODE_LEN (sr.node),
+				 type);
+	      else
+		{
+		  accum.create_literal2 (pfile, token, base,
+					 suffix_begin - base,
+					 NODE_NAME (sr.node),
+					 NODE_LEN (sr.node),
+					 type);
+		  _cpp_release_buff (pfile, accum.first);
+		}
+	      warn_about_normalization (pfile, token, &sr.nst);
+	      return;
+	    }
 	}
     }

@@ -2569,21 +2655,8 @@ lex_raw_string (cpp_reader *pfile, cpp_token *token, const uchar *base)
     create_literal (pfile, token, base, pos - base, type);
   else
     {
-      size_t extra_len = pos - base;
-      uchar *dest = _cpp_unaligned_alloc (pfile, accum.accum + extra_len + 1);
-
-      token->type = type;
-      token->val.str.len = accum.accum + extra_len;
-      token->val.str.text = dest;
-      for (_cpp_buff *buf = accum.first; buf; buf = buf->next)
-	{
-	  size_t len = BUFF_FRONT (buf) - buf->base;
-	  memcpy (dest, buf->base, len);
-	  dest += len;
-	}
+      accum.create_literal2 (pfile, token, base, pos - base, nullptr, 0, type);
       _cpp_release_buff (pfile, accum.first);
-      memcpy (dest, base, extra_len);
-      dest[extra_len] = '\0';
     }
 }

@@ -2687,39 +2760,58 @@ lex_string (cpp_reader *pfile, cpp_token *token, const uchar *base)
     cpp_error (pfile, CPP_DL_PEDWARN, "missing terminating %c character",
 	       (int) terminator);

+  pfile->buffer->cur = cur;
+  const uchar *const suffix_begin = cur;
+
   if (CPP_OPTION (pfile, user_literals))
     {
-      /* If a string format macro, say from inttypes.h, is placed touching
-	 a string literal it could be parsed as a C++11 user-defined string
-	 literal thus breaking the program.  */
-      if (is_macro_not_literal_suffix (pfile, cur))
-	{
-	  /* Raise a warning, but do not consume subsequent tokens.  */
-	  if (CPP_OPTION (pfile, warn_literal_suffix) && !pfile->state.skipping)
-	    cpp_warning_with_line (pfile, CPP_W_LITERAL_SUFFIX,
-				   token->src_loc, 0,
-				   "invalid suffix on literal; C++11 requires "
-				   "a space between literal and string macro");
-	}
-      /* Grab user defined literal suffix.  */
-      else if (ISIDST (*cur))
+      if (const auto sr = scan_cur_identifier (pfile))
 	{
-	  type = cpp_userdef_char_add_type (type);
-	  type = cpp_userdef_string_add_type (type);
-          ++cur;
-
-	  while (ISIDNUM (*cur))
-	    ++cur;
+	  /* If a string format macro, say from inttypes.h, is placed touching
+	     a string literal it could be parsed as a C++11 user-defined
+	     string literal thus breaking the program.  User-defined literals
+	     outside of namespace std must start with a single underscore, so
+	     assume anything of that form really is a UDL suffix.  We don't
+	     need to worry about UDLs defined inside namespace std because
+	     their names are reserved, so cannot be used as macro names in
+	     valid programs.  */
+	  if ((suffix_begin[0] != '_' || suffix_begin[1] == '_')
+	      && cpp_macro_p (sr.node))
+	    {
+	      /* Maybe raise a warning, but do not consume the tokens.  */
+	      pfile->buffer->cur = suffix_begin;
+	      if (CPP_OPTION (pfile, warn_literal_suffix)
+		  && !pfile->state.skipping)
+		cpp_warning_with_line
+		  (pfile, CPP_W_LITERAL_SUFFIX,
+		   token->src_loc, 0,
+		   "invalid suffix on literal; C++11 requires "
+		   "a space between literal and string macro");
+	    }
+	  else
+	    {
+	      /* Grab user defined literal suffix.  */
+	      type = cpp_userdef_char_add_type (type);
+	      type = cpp_userdef_string_add_type (type);
+	      create_literal2 (pfile, token, base, suffix_begin - base,
+			       NODE_NAME (sr.node), NODE_LEN (sr.node), type);
+	      warn_about_normalization (pfile, token, &sr.nst);
+	      return;
+	    }
 	}
     }
   else if (CPP_OPTION (pfile, cpp_warn_cxx11_compat)
-	   && is_macro (pfile, cur)
 	   && !pfile->state.skipping)
-    cpp_warning_with_line (pfile, CPP_W_CXX11_COMPAT,
-			   token->src_loc, 0, "C++11 requires a space "
-			   "between string literal and macro");
+    {
+      const auto sr = scan_cur_identifier (pfile);
+      /* Maybe raise a warning, but do not consume the tokens.  */
+      pfile->buffer->cur = suffix_begin;
+      if (sr && cpp_macro_p (sr.node))
+	cpp_warning_with_line (pfile, CPP_W_CXX11_COMPAT,
+			       token->src_loc, 0, "C++11 requires a space "
+			       "between string literal and macro");
+    }

-  pfile->buffer->cur = cur;
   create_literal (pfile, token, base, cur - base, type);
 }

@@ -4091,7 +4183,7 @@ cpp_digraph2name (enum cpp_ttype type)
 }

 /* Write the spelling of an identifier IDENT, using UCNs, to BUFFER.
-   The buffer must already contain the enough space to hold the
+   The buffer must already contain enough space to hold the
    token's spelling.  Returns a pointer to the character after the
    last character written.  */
 unsigned char *
@@ -4113,7 +4205,7 @@ _cpp_spell_ident_ucns (unsigned char *buffer, cpp_hashnode *ident)
 }

 /* Write the spelling of a token TOKEN to BUFFER.  The buffer must
-   already contain the enough space to hold the token's spelling.
+   already contain enough space to hold the token's spelling.
    Returns a pointer to the character after the last character written.
    FORSTRING is true if this is to be the spelling after translation
    phase 1 (with the original spelling of extended identifiers), false

[PATCH] libcpp: Support raw strings with newlines while processing directives [PR55971]

It's not currently possible to use a C++11 raw string containing a newline as
part of the definition of a macro, or in any other preprocessing directive,
such as:

 #define X R"(two
lines)"

 #error R"(this error has
two lines)"

This patch adds support for that by relaxing the conditions under which
_cpp_get_fresh_line() refuses to get a new line. For the case of lexing a raw
string, it's OK to do so as long as there is another line within the current
buffer. The code in cpp_get_fresh_line() was refactored into a new function
get_fresh_line_impl(), so that the new logic is applied only when processing a
raw string and not any other times.

gcc -E needed a small tweak now that it's possible to get a token from
macro expansion which contains a newline; in that case, c-ppoutput.c needs
to check and avoid incrementing its internal line counter in that case,
otherwise it erroneously prints a line change marker after printing the
expansion of a macro with an embedded newline.

I have added testcases for all preprocessing directives to make sure they are
OK with these kinds of raw strings. While doing that it became apparent that
we do not currently accept a raw string (with or without embedded newlines) as
the argument to _Pragma(). That was pretty straightforward to add, so I have
done that as well, since it seems potentially handy to avoid needing to escape
all the quotes inside the pragma, plus clang accepts this as well.

PR preprocessor/55971

libcpp/ChangeLog:

	* directives.cc (destringize_and_run): Support C++11 raw strings
	as the argument to _Pragma().
	* lex.cc (get_fresh_line_impl): New function refactoring the code
	from...
	(_cpp_get_fresh_line): ...here.
	(lex_raw_string): Use the new version of get_fresh_line_impl() to
	support raw strings containing new lines when processing a directive.

gcc/testsuite/ChangeLog:

	* c-c++-common/raw-string-directive-1.c: New test.
	* c-c++-common/raw-string-directive-2.c: New test.

gcc/c-family/ChangeLog:

	* c-ppoutput.cc (token_streamer::stream): Don't call
	account_for_newlines() if the tokens came from macro expansion.

diff --git a/gcc/c-family/c-ppoutput.cc b/gcc/c-family/c-ppoutput.cc
index 9de46a9655f..4f3576fa273 100644
--- a/gcc/c-family/c-ppoutput.cc
+++ b/gcc/c-family/c-ppoutput.cc
@@ -292,11 +292,13 @@ token_streamer::stream (cpp_reader *pfile, const cpp_token *token,
       print.printed = true;
     }

-  /* CPP_COMMENT tokens and raw-string literal tokens can have
-     embedded new-line characters.  Rather than enumerating all the
-     possible token types just check if token uses val.str union
-     member.  */
-  if (cpp_token_val_index (token) == CPP_TOKEN_FLD_STR)
+  /* CPP_COMMENT tokens and raw-string literal tokens can have embedded
+     new-line characters.  Rather than enumerating all the possible token
+     types, just check if token uses val.str union member.  If the token came
+     from a macro expansion, then no adjustment should be made since the
+     new-line characters did not appear in the source.  */
+  if (cpp_token_val_index (token) == CPP_TOKEN_FLD_STR
+      && !from_macro_expansion_at (loc))
     account_for_newlines (token->val.str.text, token->val.str.len);
 }

diff --git a/gcc/testsuite/c-c++-common/raw-string-directive-1.c b/gcc/testsuite/c-c++-common/raw-string-directive-1.c
new file mode 100644
index 00000000000..810f11256fa
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/raw-string-directive-1.c
@@ -0,0 +1,77 @@
+/* { dg-do compile } */
+/* { dg-options "-std=gnu99" { target c } } */
+/* { dg-options "-std=c++11" { target c++ } } */
+
+/* Test that multi-line raw strings are lexed OK for all preprocessing
+   directives where one could appear. Test raw-string-directive-2.c
+   checks that #define is also processed properly.  */
+
+/* Note that in cases where we cause GCC to produce a multi-line error
+   message, we construct the string so that the second line looks enough
+   like an error message for DejaGNU to process it as such, so that we
+   can use dg-warning or dg-error directives to check for it.  */
+
+#warning R"delim(line1 /* { dg-warning "line1" } */
+file:15:1: warning: line2)delim" /* { dg-warning "line2" } */
+
+#error R"delim(line3 /* { dg-error "line3" } */
+file:18:1: error: line4)delim" /* { dg-error "line4" } */
+
+#define X1 R"(line 5
+line 6
+line 7
+line 8
+/*
+//
+line 9)" R"delim(
+line10)delim"
+
+#define X2(a) X1 #a R"(line 11
+/*
+line12
+)"
+
+#if R"(line 13 /* { dg-error "line13" } */
+file:35:1: error: line14)" /* { dg-error "line14\\)\"\" is not valid" } */
+#endif R"(line 15 /* { dg-warning "extra tokens at end of #endif" } */
+\
+line16)" ""
+
+#ifdef XYZ R"(line17 /* { dg-warning "extra tokens at end of #ifdef" } */
+\
+\
+line18)"
+#endif
+
+#if 1
+#else R"(line23 /* { dg-warning "extra tokens at end of #else" } */
+\
+
+line24)"
+#endif
+
+#if 0
+#elif R"(line 25 /* { dg-error "line25" } */
+file:55:1: error: line26)" /* { dg-error "line26\\)\"\" is not valid" } */
+#endif
+
+#line 60 R"(file:60:1: warning: this file has a space
+in it!)"
+#warning "line27" /* { dg-warning "line27" } */
+/* { dg-warning "this file has a space" "#line check" { target *-*-* } 60 } */
+#line 63 "file"
+
+#undef X1 R"(line28 /* { dg-warning "extra tokens at end of #undef" } */
+line29
+\
+)"
+
+#ident R"(line30
+line31)" R"(line 32 /* { dg-warning "extra tokens at end of #ident" } */
+line 33)"
+
+#pragma GCC diagnostic ignored R"(-Woption /* { dg-warning "-Wpragmas" } */
+-with-a-newline)"
+
+_Pragma(R"delim1(GCC diagnostic ignored R"delim2(-Woption /* { dg-warning "-Wpragmas" } */
+-with-a-newline)delim2")delim1")
diff --git a/gcc/testsuite/c-c++-common/raw-string-directive-2.c b/gcc/testsuite/c-c++-common/raw-string-directive-2.c
new file mode 100644
index 00000000000..6fc673ccd82
--- /dev/null
+++ b/gcc/testsuite/c-c++-common/raw-string-directive-2.c
@@ -0,0 +1,33 @@
+/* { dg-do run } */
+/* { dg-options "-std=gnu99" { target c } } */
+/* { dg-options "-std=c++11" { target c++ } } */
+
+#define S1 R"(three
+line
+string)"
+
+#define S2 R"(pasted
+two line)" " string"
+
+#define X(a, b) a b R"(
+one more)"
+
+const char *s1 = S1;
+const char *s2 = S2;
+const char *s3 = X(S1, R"(
+with this line plus)");
+
+int main ()
+{
+  const char s1_correct[] = "three\nline\nstring";
+  if (__builtin_memcmp (s1, s1_correct, sizeof s1_correct))
+    __builtin_abort ();
+
+  const char s2_correct[] = "pasted\ntwo line string";
+  if (__builtin_memcmp (s2, s2_correct, sizeof s2_correct))
+    __builtin_abort ();
+
+  const char s3_correct[] = "three\nline\nstring\nwith this line plus\none more";
+  if (__builtin_memcmp (s3, s3_correct, sizeof s3_correct))
+    __builtin_abort ();
+}
diff --git a/libcpp/directives.cc b/libcpp/directives.cc
index f804a441f39..72c7f6fd0ab 100644
--- a/libcpp/directives.cc
+++ b/libcpp/directives.cc
@@ -1859,8 +1859,7 @@ static void
 destringize_and_run (cpp_reader *pfile, const cpp_string *in,
 		     location_t expansion_loc)
 {
-  const unsigned char *src, *limit;
-  char *dest, *result;
+  uchar *dest, *result;
   cpp_context *saved_context;
   cpp_token *saved_cur_token;
   tokenrun *saved_cur_run;
@@ -1868,15 +1867,34 @@ destringize_and_run (cpp_reader *pfile, const cpp_string *in,
   int count;
   const struct directive *save_directive;

-  dest = result = (char *) alloca (in->len - 1);
-  src = in->text + 1 + (in->text[0] == 'L');
-  limit = in->text + in->len - 1;
-  while (src < limit)
+  /* If we were given a raw string literal, we don't need to destringize it,
+     but we do need to strip off the prefix and the suffix.  */
+  if (in->text[0] == 'R')
     {
-      /* We know there is a character following the backslash.  */
-      if (*src == '\\' && (src[1] == '\\' || src[1] == '"'))
-	src++;
-      *dest++ = *src++;
+      cpp_string buf;
+      const bool ok
+	= cpp_interpret_string_notranslate (pfile, in, 1, &buf, CPP_STRING);
+      gcc_assert (ok);
+      result = (uchar *) alloca (buf.len);
+
+      /* (Terminating null will be replaced by a newline shortly.)  */
+      memcpy (result, buf.text, buf.len - 1);
+      dest = result + (buf.len - 1);
+      XDELETEVEC (buf.text);
+    }
+  else
+    {
+      const uchar *src, *limit;
+      dest = result = (uchar *) alloca (in->len - 1);
+      src = in->text + 1 + (in->text[0] == 'L');
+      limit = in->text + in->len - 1;
+      while (src < limit)
+	{
+	  /* We know there is a character following the backslash.  */
+	  if (*src == '\\' && (src[1] == '\\' || src[1] == '"'))
+	    src++;
+	  *dest++ = *src++;
+	}
     }
   *dest = '\n';

@@ -1896,9 +1914,10 @@ destringize_and_run (cpp_reader *pfile, const cpp_string *in,

   /* Inline run_directive, since we need to delay the _cpp_pop_buffer
      until we've read all of the tokens that we want.  */
-  cpp_push_buffer (pfile, (const uchar *) result, dest - result,
-		   /* from_stage3 */ true);
-  /* ??? Antique Disgusting Hack.  What does this do?  */
+  cpp_push_buffer (pfile, result, dest - result, /* from_stage3 */ true);
+
+  /* This is needed to make _Pragma("once") work correctly, as it needs
+   pfile->buffer->file to be set to the current source file.  */
   if (pfile->buffer->prev)
     pfile->buffer->file = pfile->buffer->prev->file;

diff --git a/libcpp/lex.cc b/libcpp/lex.cc
index f891d3e17df..73e239b2a01 100644
--- a/libcpp/lex.cc
+++ b/libcpp/lex.cc
@@ -1073,6 +1073,9 @@ _cpp_clean_line (cpp_reader *pfile)
   buffer->next_line = s + 1;
 }

+template <bool lexing_raw_string>
+static bool get_fresh_line_impl (cpp_reader *pfile);
+
 /* Return true if the trigraph indicated by NOTE should be warned
    about in a comment.  */
 static bool
@@ -2489,9 +2492,8 @@ lex_raw_string (cpp_reader *pfile, cpp_token *token, const uchar *base)
 	{
 	  pos--;
 	  pfile->buffer->cur = pos;
-	  if (pfile->state.in_directive
-	      || (pfile->state.parsing_args
-		  && pfile->buffer->next_line >= pfile->buffer->rlimit))
+	  if ((pfile->state.in_directive || pfile->state.parsing_args)
+	      && pfile->buffer->next_line >= pfile->buffer->rlimit)
 	    {
 	      cpp_error_with_line (pfile, CPP_DL_ERROR, token->src_loc, 0,
 				   "unterminated raw string");
@@ -2506,7 +2508,7 @@ lex_raw_string (cpp_reader *pfile, cpp_token *token, const uchar *base)
 	    CPP_INCREMENT_LINE (pfile, 0);
 	  pfile->buffer->need_line = true;

-	  if (!_cpp_get_fresh_line (pfile))
+	  if (!get_fresh_line_impl<true> (pfile))
 	    {
 	      /* We ran out of file and failed to get a line.  */
 	      location_t src_loc = token->src_loc;
@@ -2518,8 +2520,15 @@ lex_raw_string (cpp_reader *pfile, cpp_token *token, const uchar *base)
 		_cpp_release_buff (pfile, accum.first);
 	      cpp_error_with_line (pfile, CPP_DL_ERROR, src_loc, 0,
 				   "unterminated raw string");
-	      /* Now pop the buffer that _cpp_get_fresh_line did not.  */
+
+	      /* Now pop the buffer that get_fresh_line_impl() did not.  Popping
+		 is not safe if processing a directive, however this cannot
+		 happen as we already checked above that a line would be
+		 available, and get_fresh_line_impl() can't fail in this
+		 case.  */
+	      gcc_assert (!pfile->state.in_directive);
 	      _cpp_pop_buffer (pfile);
+
 	      return;
 	    }

@@ -3453,11 +3462,14 @@ _cpp_lex_token (cpp_reader *pfile)
 }

 /* Returns true if a fresh line has been loaded.  */
-bool
-_cpp_get_fresh_line (cpp_reader *pfile)
+template <bool lexing_raw_string>
+static bool
+get_fresh_line_impl (cpp_reader *pfile)
 {
-  /* We can't get a new line until we leave the current directive.  */
-  if (pfile->state.in_directive)
+  /* We can't get a new line until we leave the current directive, unless we
+     are lexing a raw string, in which case it will be OK as long as we don't
+     pop the current buffer.  */
+  if (!lexing_raw_string && pfile->state.in_directive)
     return false;

   for (;;)
@@ -3473,6 +3485,10 @@ _cpp_get_fresh_line (cpp_reader *pfile)
 	  return true;
 	}

+      /* We can't change buffers until we leave the current directive.  */
+      if (lexing_raw_string && pfile->state.in_directive)
+	return false;
+
       /* First, get out of parsing arguments state.  */
       if (pfile->state.parsing_args)
 	return false;
@@ -3500,6 +3516,13 @@ _cpp_get_fresh_line (cpp_reader *pfile)
     }
 }

+bool
+_cpp_get_fresh_line (cpp_reader *pfile)
+{
+  return get_fresh_line_impl<false> (pfile);
+}
+
+
 #define IF_NEXT_IS(CHAR, THEN_TYPE, ELSE_TYPE)		\
   do							\
     {							\


During CTAD, we currently perform the first phase of overload resolution
from [over.match.list] only if the class template has a list constructor.
But according to [over.match.class.deduct]/4 it should be enough to just
have a guide that looks like a list constructor (which is a more general
criterion in light of user-defined guides).

Bootstrapped and regtested on x86_64-pc-linux-gnu, does this look OK for
trunk?

	PR c++/106366

gcc/cp/ChangeLog:

	* pt.cc (do_class_deduction): Don't consider TYPE_HAS_LIST_CTOR
	when setting try_list_ctor.  Reset args even when try_list_ctor
	is true and there are no list candidates.  Call resolve_args on
	the reset args.

gcc/testsuite/ChangeLog:

	* g++.dg/cpp1z/class-deduction112.C: New test.
---
 gcc/cp/pt.cc                                  | 25 +++++++++----------
 .../g++.dg/cpp1z/class-deduction112.C         | 14 +++++++++++
 2 files changed, 26 insertions(+), 13 deletions(-)
 create mode 100644 gcc/testsuite/g++.dg/cpp1z/class-deduction112.C

diff --git a/gcc/cp/pt.cc b/gcc/cp/pt.cc
index 718dfa5bfa8..0f26d6f5bce 100644
--- a/gcc/cp/pt.cc
+++ b/gcc/cp/pt.cc
@@ -30250,8 +30250,8 @@ do_class_deduction (tree ptype, tree tmpl, tree init,
   else if (BRACE_ENCLOSED_INITIALIZER_P (init))
     {
       list_init_p = true;
-      try_list_ctor = TYPE_HAS_LIST_CTOR (type);
-      if (try_list_ctor && CONSTRUCTOR_NELTS (init) == 1
+      try_list_ctor = true;
+      if (CONSTRUCTOR_NELTS (init) == 1
 	  && !CONSTRUCTOR_IS_DESIGNATED_INIT (init))
 	{
 	  /* As an exception, the first phase in 16.3.1.7 (considering the
@@ -30310,26 +30310,25 @@ do_class_deduction (tree ptype, tree tmpl, tree init,

   tree fndecl = error_mark_node;

-  /* If this is list-initialization and the class has a list constructor, first
+  /* If this is list-initialization and the class has a list guide, first
      try deducing from the list as a single argument, as [over.match.list].  */
-  tree list_cands = NULL_TREE;
-  if (try_list_ctor && cands)
-    for (lkp_iterator iter (cands); iter; ++iter)
-      {
-	tree dg = *iter;
+  if (try_list_ctor)
+    {
+      tree list_cands = NULL_TREE;
+      for (tree dg : lkp_range (cands))
 	if (is_list_ctor (dg))
 	  list_cands = lookup_add (dg, list_cands);
-      }
-  if (list_cands)
-    {
-      fndecl = perform_dguide_overload_resolution (list_cands, args, tf_none);
-
+      if (list_cands)
+	fndecl = perform_dguide_overload_resolution (list_cands, args, tf_none);
       if (fndecl == error_mark_node)
 	{
 	  /* That didn't work, now try treating the list as a sequence of
 	     arguments.  */
 	  release_tree_vector (args);
 	  args = make_tree_vector_from_ctor (init);
+	  args = resolve_args (args, complain);
+	  if (args == NULL)
+	    return error_mark_node;
 	}
     }

diff --git a/gcc/testsuite/g++.dg/cpp1z/class-deduction112.C b/gcc/testsuite/g++.dg/cpp1z/class-deduction112.C
new file mode 100644
index 00000000000..8da5868ff98
--- /dev/null
+++ b/gcc/testsuite/g++.dg/cpp1z/class-deduction112.C
@@ -0,0 +1,14 @@
+// PR c++/106366
+// { dg-do compile { target c++17 } }
+
+#include <initializer_list>
+
+template<class T>
+struct A { A(...); };
+
+template<typename T>
+A(std::initializer_list<T>) -> A<T>;
+
+A a{1,2,3};
+using type = decltype(a);
+using type = A<int>;
--
2.37.1.208.ge72d93e88c

The following fixes an oversight triggering after the recent change
to bump_vector_ptr.

Bootstrapped on x86_64-unknown-linux-gnu, pushed.

	PR tree-optimization/106387
	* tree-vect-stmts.cc (vectorizable_load): Use make_ssa_name
	if ptr is not an SSA name.
---
 gcc/tree-vect-stmts.cc | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/gcc/tree-vect-stmts.cc b/gcc/tree-vect-stmts.cc
index 01d982eea98..f582d238984 100644
--- a/gcc/tree-vect-stmts.cc
+++ b/gcc/tree-vect-stmts.cc
@@ -10017,7 +10017,10 @@ vectorizable_load (vec_info *vinfo,
 				 (NULL_TREE, BIT_AND_EXPR, ptr,
 				  build_int_cst
 				  (TREE_TYPE (ptr), -(HOST_WIDE_INT) align));
-		    ptr = copy_ssa_name (ptr, new_stmt);
+		    if (TREE_CODE (ptr) == SSA_NAME)
+		      ptr = copy_ssa_name (ptr, new_stmt);
+		    else
+		      ptr = make_ssa_name (TREE_TYPE (ptr), new_stmt);
 		    gimple_assign_set_lhs (new_stmt, ptr);
 		    vect_finish_stmt_generation (vinfo, stmt_info,
 						 new_stmt, gsi);
--
2.35.3

While .STORE_LANES is not supported by the recent VN patch we were
still accessing the stored value and valueizing it - but
internal_fn_stored_value_index does not support .STORE_LANES and
we failed to honor that case.  Fixed by simply moving the affected
code below the check for the actual supported internal functions.

Bootstrap / regtest running on x86_64-unknown-linux-gnu.

	PR tree-optimization/106403
	* tree-ssa-sccvn.cc (vn_reference_lookup_3): Move stored
	value valueization after check for IFN_MASKED_STORE or
	IFN_LEN_STORE.
---
 gcc/tree-ssa-sccvn.cc | 11 ++++++-----
 1 file changed, 6 insertions(+), 5 deletions(-)

diff --git a/gcc/tree-ssa-sccvn.cc b/gcc/tree-ssa-sccvn.cc
index 0ebbc69b502..741e6ebc4ba 100644
--- a/gcc/tree-ssa-sccvn.cc
+++ b/gcc/tree-ssa-sccvn.cc
@@ -3227,11 +3227,6 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,
     {
       gcall *call = as_a <gcall *> (def_stmt);
       internal_fn fn = gimple_call_internal_fn (call);
-      tree def_rhs = gimple_call_arg (call,
-				      internal_fn_stored_value_index (fn));
-      def_rhs = vn_valueize (def_rhs);
-      if (TREE_CODE (def_rhs) != VECTOR_CST)
-	return (void *)-1;

       tree mask = NULL_TREE, len = NULL_TREE, bias = NULL_TREE;
       switch (fn)
@@ -3251,6 +3246,12 @@ vn_reference_lookup_3 (ao_ref *ref, tree vuse, void *data_,
 	default:
 	  return (void *)-1;
 	}
+      tree def_rhs = gimple_call_arg (call,
+				      internal_fn_stored_value_index (fn));
+      def_rhs = vn_valueize (def_rhs);
+      if (TREE_CODE (def_rhs) != VECTOR_CST)
+	return (void *)-1;
+
       ao_ref_init_from_ptr_and_size (&lhs_ref,
 				     vn_valueize (gimple_call_arg (call, 0)),
 				     TYPE_SIZE_UNIT (TREE_TYPE (def_rhs)));
--
2.35.3

The following fixes maintaining LC SSA when array prefetch inserts
mfence instructions on loop exits that do not use memory.  It also
fixes the latent issue that it might split exit edges for this
which will break LC SSA for non-virtuals as well.  It should also
make the process cheaper by accumulating the required (LC) SSA
update until the end of the pass.

Bootstrap and regtest running on x86_64-unknown-linux-gnu.

	PR tree-optimization/106397
	* tree-ssa-loop-prefetch.cc (emit_mfence_after_loop): Do
	not update SSA form here.
	(mark_nontemporal_stores): Return whether we marked any
	non-temporal stores and inserted mfence.
	(loop_prefetch_arrays): Note when we need to update SSA.
	(tree_ssa_prefetch_arrays): Perform required (LC) SSA update
	at the end of the pass.

	* gcc.dg/pr106397.c: New testcase.
---
 gcc/testsuite/gcc.dg/pr106397.c | 17 +++++++++++++++++
 gcc/tree-ssa-loop-prefetch.cc   | 27 +++++++++++++++++----------
 2 files changed, 34 insertions(+), 10 deletions(-)
 create mode 100644 gcc/testsuite/gcc.dg/pr106397.c

diff --git a/gcc/testsuite/gcc.dg/pr106397.c b/gcc/testsuite/gcc.dg/pr106397.c
new file mode 100644
index 00000000000..a6b2e913346
--- /dev/null
+++ b/gcc/testsuite/gcc.dg/pr106397.c
@@ -0,0 +1,17 @@
+/* { dg-do compile } */
+/* { dg-options "-O3 -fprefetch-loop-arrays --param l2-cache-size=0 --param prefetch-latency=3 -fprefetch-loop-arrays" } */
+
+int
+bar (void)
+{
+  /* No return statement. */
+}
+
+__attribute__ ((simd)) int
+foo (void)
+{
+  if (bar ())
+    return 0;
+
+  __builtin_unreachable ();
+}
diff --git a/gcc/tree-ssa-loop-prefetch.cc b/gcc/tree-ssa-loop-prefetch.cc
index 8f190ae469b..b6690b0e805 100644
--- a/gcc/tree-ssa-loop-prefetch.cc
+++ b/gcc/tree-ssa-loop-prefetch.cc
@@ -1308,8 +1308,6 @@ emit_mfence_after_loop (class loop *loop)

       gsi_insert_before (&bsi, call, GSI_NEW_STMT);
     }
-
-  update_ssa (TODO_update_ssa_only_virtuals);
 }

 /* Returns true if we can use storent in loop, false otherwise.  */
@@ -1340,23 +1338,27 @@ may_use_storent_in_loop_p (class loop *loop)
 }

 /* Marks nontemporal stores in LOOP.  GROUPS contains the description of memory
-   references in the loop.  */
+   references in the loop.  Returns whether we inserted any mfence call.  */

-static void
+static bool
 mark_nontemporal_stores (class loop *loop, struct mem_ref_group *groups)
 {
   struct mem_ref *ref;
   bool any = false;

   if (!may_use_storent_in_loop_p (loop))
-    return;
+    return false;

   for (; groups; groups = groups->next)
     for (ref = groups->refs; ref; ref = ref->next)
       any |= mark_nontemporal_store (ref);

   if (any && FENCE_FOLLOWING_MOVNT != NULL_TREE)
-    emit_mfence_after_loop (loop);
+    {
+      emit_mfence_after_loop (loop);
+      return true;
+    }
+  return false;
 }

 /* Determines whether we can profitably unroll LOOP FACTOR times, and if
@@ -1874,10 +1876,11 @@ insn_to_prefetch_ratio_too_small_p (unsigned ninsns, unsigned prefetch_count,


 /* Issue prefetch instructions for array references in LOOP.  Returns
-   true if the LOOP was unrolled.  */
+   true if the LOOP was unrolled and updates NEED_LC_SSA_UPDATE if we need
+   to update SSA for virtual operands and LC SSA for a split edge.  */

 static bool
-loop_prefetch_arrays (class loop *loop)
+loop_prefetch_arrays (class loop *loop, bool &need_lc_ssa_update)
 {
   struct mem_ref_group *refs;
   unsigned ahead, ninsns, time, unroll_factor;
@@ -1952,7 +1955,7 @@ loop_prefetch_arrays (class loop *loop)
 					  unroll_factor))
     goto fail;

-  mark_nontemporal_stores (loop, refs);
+  need_lc_ssa_update |= mark_nontemporal_stores (loop, refs);

   /* Step 4: what to prefetch?  */
   if (!schedule_prefetches (refs, unroll_factor, ahead))
@@ -1980,6 +1983,7 @@ unsigned int
 tree_ssa_prefetch_arrays (void)
 {
   bool unrolled = false;
+  bool need_lc_ssa_update = false;
   int todo_flags = 0;

   if (!targetm.have_prefetch ()
@@ -2028,12 +2032,15 @@ tree_ssa_prefetch_arrays (void)
       if (dump_file && (dump_flags & TDF_DETAILS))
 	fprintf (dump_file, "Processing loop %d:\n", loop->num);

-      unrolled |= loop_prefetch_arrays (loop);
+      unrolled |= loop_prefetch_arrays (loop, need_lc_ssa_update);

       if (dump_file && (dump_flags & TDF_DETAILS))
 	fprintf (dump_file, "\n\n");
     }

+  if (need_lc_ssa_update)
+    rewrite_into_loop_closed_ssa (NULL, TODO_update_ssa_only_virtuals);
+
   if (unrolled)
     {
       scev_reset ();
--
2.35.3

While looking into LWG 3741 I came up with this small change to
chrono::abs, which reduces how much work the compiler does to compile
it, but makes the code less clear. The current implementation is very
easy to understand, and compiling chrono::abs probably isn't a hotspot
in anybody's build. Is this worth it?

-- >8 --

This change manually inlines the call to duration::zero, the comparison
using chrono::operator< with duration arguments, the call to
duration::operator- (and the common_type instantiation it does). This
also avoids calling the duration(const duration<R2,P2>&) constructor
(and its constraint checks).

By performing the arithmetic operations directly on the Rep value we
improve compilation throughput and also runtime performance for
unoptimized builds.

libstdc++-v3/ChangeLog:

	* include/bits/chrono.h (chrono::abs): Optimize.
---
 libstdc++-v3/include/bits/chrono.h | 42 +++++++++++++++---------------
 1 file changed, 21 insertions(+), 21 deletions(-)

diff --git a/libstdc++-v3/include/bits/chrono.h b/libstdc++-v3/include/bits/chrono.h
index 05987ca09df..99d47503af3 100644
--- a/libstdc++-v3/include/bits/chrono.h
+++ b/libstdc++-v3/include/bits/chrono.h
@@ -317,6 +317,23 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       { };
 #endif // C++20

+    /// duration_values
+    template<typename _Rep>
+      struct duration_values
+      {
+	static constexpr _Rep
+	zero() noexcept
+	{ return _Rep(0); }
+
+	static constexpr _Rep
+	max() noexcept
+	{ return numeric_limits<_Rep>::max(); }
+
+	static constexpr _Rep
+	min() noexcept
+	{ return numeric_limits<_Rep>::lowest(); }
+      };
+
 #if __cplusplus >= 201703L
 # define __cpp_lib_chrono 201611L

@@ -365,11 +382,11 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     template<typename _Rep, typename _Period>
       constexpr
       enable_if_t<numeric_limits<_Rep>::is_signed, duration<_Rep, _Period>>
-      abs(duration<_Rep, _Period> __d)
+      abs(duration<_Rep, _Period> __d) noexcept(is_arithmetic_v<_Rep>)
       {
-	if (__d >= __d.zero())
-	  return __d;
-	return -__d;
+	if (_Rep __c = __d.count(); __c < duration_values<_Rep>::zero())
+	  return duration<_Rep, _Period>(-__c);
+	return __d;
       }

     // Make chrono::ceil<D> also usable as chrono::__detail::ceil<D>.
@@ -399,23 +416,6 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     }
 #endif // C++17

-    /// duration_values
-    template<typename _Rep>
-      struct duration_values
-      {
-	static constexpr _Rep
-	zero() noexcept
-	{ return _Rep(0); }
-
-	static constexpr _Rep
-	max() noexcept
-	{ return numeric_limits<_Rep>::max(); }
-
-	static constexpr _Rep
-	min() noexcept
-	{ return numeric_limits<_Rep>::lowest(); }
-      };
-
     /// @cond undocumented

     template<typename _Tp>
--
2.37.2

This introduces an early exit test to most_specialized_partial_spec for
the common case where we have no partial specializations, which allows
us to avoid some unnecessary work.  In passing, clean the function up a
bit.

Bootstrapped and regtested on x86_64-pc-linux-gnu, does this look OK for
trunk?

gcc/cp/ChangeLog:

	* pt.cc (most_specialized_partial_spec): Exit early when
	DECL_TEMPLATE_SPECIALIZATIONS is empty.  Move local variable
	declarations closer to their first use.  Remove redundant
	flag_concepts test.  Remove redundant forward declaration.
---
 gcc/cp/pt.cc | 45 +++++++++++++++++++--------------------------
 1 file changed, 19 insertions(+), 26 deletions(-)

diff --git a/gcc/cp/pt.cc b/gcc/cp/pt.cc
index fe7e809fc2d..497a18ef728 100644
--- a/gcc/cp/pt.cc
+++ b/gcc/cp/pt.cc
@@ -187,7 +187,6 @@ static int unify_pack_expansion (tree, tree, tree,
 static tree copy_template_args (tree);
 static tree tsubst_template_parms (tree, tree, tsubst_flags_t);
 static void tsubst_each_template_parm_constraints (tree, tree, tsubst_flags_t);
-tree most_specialized_partial_spec (tree, tsubst_flags_t);
 static tree tsubst_aggr_type (tree, tree, tsubst_flags_t, tree, int);
 static tree tsubst_arg_types (tree, tree, tree, tsubst_flags_t, tree);
 static tree tsubst_function_type (tree, tree, tsubst_flags_t, tree);
@@ -25756,15 +25755,7 @@ most_general_template (tree decl)
 tree
 most_specialized_partial_spec (tree target, tsubst_flags_t complain)
 {
-  tree list = NULL_TREE;
-  tree t;
-  tree champ;
-  int fate;
-  bool ambiguous_p;
-  tree outer_args = NULL_TREE;
-  tree tmpl, args;
-
-  tree decl;
+  tree tmpl, args, decl;
   if (TYPE_P (target))
     {
       tree tinfo = CLASSTYPE_TEMPLATE_INFO (target);
@@ -25788,13 +25779,18 @@ most_specialized_partial_spec (tree target, tsubst_flags_t complain)
   else
     gcc_unreachable ();

+  tree main_tmpl = most_general_template (tmpl);
+  tree specs = DECL_TEMPLATE_SPECIALIZATIONS (main_tmpl);
+  if (!specs)
+    /* There are no partial specializations of this template.  */
+    return NULL_TREE;
+
   push_access_scope_guard pas (decl);
   deferring_access_check_sentinel acs (dk_no_deferred);

-  tree main_tmpl = most_general_template (tmpl);
-
   /* For determining which partial specialization to use, only the
      innermost args are interesting.  */
+  tree outer_args = NULL_TREE;
   if (TMPL_ARGS_HAVE_MULTIPLE_LEVELS (args))
     {
       outer_args = strip_innermost_template_args (args, 1);
@@ -25806,7 +25802,8 @@ most_specialized_partial_spec (tree target, tsubst_flags_t complain)
      fully resolve everything.  */
   processing_template_decl_sentinel ptds;

-  for (t = DECL_TEMPLATE_SPECIALIZATIONS (main_tmpl); t; t = TREE_CHAIN (t))
+  tree list = NULL_TREE;
+  for (tree t = specs; t; t = TREE_CHAIN (t))
     {
       const tree ospec_tmpl = TREE_VALUE (t);

@@ -25829,10 +25826,8 @@ most_specialized_partial_spec (tree target, tsubst_flags_t complain)
 	  if (outer_args)
 	    spec_args = add_to_template_args (outer_args, spec_args);

-          /* Keep the candidate only if the constraints are satisfied,
-             or if we're not compiling with concepts.  */
-          if (!flag_concepts
-	      || constraints_satisfied_p (ospec_tmpl, spec_args))
+	  /* Keep the candidate only if the constraints are satisfied.  */
+	  if (constraints_satisfied_p (ospec_tmpl, spec_args))
             {
 	      list = tree_cons (spec_args, ospec_tmpl, list);
               TREE_TYPE (list) = TREE_TYPE (t);
@@ -25843,13 +25838,11 @@ most_specialized_partial_spec (tree target, tsubst_flags_t complain)
   if (! list)
     return NULL_TREE;

-  ambiguous_p = false;
-  t = list;
-  champ = t;
-  t = TREE_CHAIN (t);
-  for (; t; t = TREE_CHAIN (t))
+  tree champ = list;
+  bool ambiguous_p = false;
+  for (tree t = TREE_CHAIN (list); t; t = TREE_CHAIN (t))
     {
-      fate = more_specialized_partial_spec (tmpl, champ, t);
+      int fate = more_specialized_partial_spec (tmpl, champ, t);
       if (fate == 1)
 	;
       else
@@ -25868,9 +25861,9 @@ most_specialized_partial_spec (tree target, tsubst_flags_t complain)
     }

   if (!ambiguous_p)
-    for (t = list; t && t != champ; t = TREE_CHAIN (t))
+    for (tree t = list; t && t != champ; t = TREE_CHAIN (t))
       {
-	fate = more_specialized_partial_spec (tmpl, champ, t);
+	int fate = more_specialized_partial_spec (tmpl, champ, t);
 	if (fate != 1)
 	  {
 	    ambiguous_p = true;
@@ -25889,7 +25882,7 @@ most_specialized_partial_spec (tree target, tsubst_flags_t complain)
       else
 	error ("ambiguous template instantiation for %q#D", target);
       str = ngettext ("candidate is:", "candidates are:", list_length (list));
-      for (t = list; t; t = TREE_CHAIN (t))
+      for (tree t = list; t; t = TREE_CHAIN (t))
         {
 	  tree subst = build_tree_list (TREE_VALUE (t), TREE_PURPOSE (t));
           inform (DECL_SOURCE_LOCATION (TREE_VALUE (t)),
--
2.37.2.490.g6c8e4ee870

Tested powerpc64le-linux, pushed to trunk.

This is the first in a series of patches to optimize compile time for
the contents of <type_traits>.

-- >8 --

Improve compile times by avoiding unnecessary class template
instantiations.

__is_array_known_bounds and __is_array_unknown_bounds can be defined
without instantiating extent, by providing partial specializations for
the true cases.

std::extent can avoid recursing down through a multidimensional array,
so it stops after providing the result. Previously extent<T[n][m], 0>
would instantiate extent<T[n], -1u> and extent<T, -2u> as well.

std::is_array_v can use partial specializations to avoid instantiating
std::is_array, and similarly for std::rank_v and std::extent_v.

std::is_bounded_array_v and std::is_unbounded_array_v can also use
partial specializations, and then the class templates can be defined in
terms of the variable templates. This makes sense for these traits,
because they are new in C++20 and so the variable templates are always
available, which isn't true in general for C++11 and C++14 traits.

libstdc++-v3/ChangeLog:

	* include/std/type_traits (__is_array_known_bounds): Add partial
	specialization instead of using std::extent.
	(__is_array_unknown_bounds): Likewise.
	(extent): Add partial specializations to stop recursion after
	the result is found.
	(is_array_v): Add partial specializations instead of
	instantiating the class template.
	(rank_v, extent_v): Likewise.
	(is_bounded_array_v, is_unbounded_array_v): Likewise.
	(is_bounded_array, is_unbounded_array): Define in terms of the
	variable templates.
---
 libstdc++-v3/include/std/type_traits | 102 ++++++++++++++++++---------
 1 file changed, 69 insertions(+), 33 deletions(-)

diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index c2f5cb9c806..5984442c0aa 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -867,21 +867,28 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   template<typename _Tp>
     auto declval() noexcept -> decltype(__declval<_Tp>(0));

-  template<typename, unsigned = 0>
-    struct extent;
-
   template<typename>
     struct remove_all_extents;

   /// @cond undocumented
   template<typename _Tp>
     struct __is_array_known_bounds
-    : public integral_constant<bool, (extent<_Tp>::value > 0)>
+    : public false_type
+    { };
+
+  template<typename _Tp, size_t _Size>
+    struct __is_array_known_bounds<_Tp[_Size]>
+    : public true_type
     { };

   template<typename _Tp>
     struct __is_array_unknown_bounds
-    : public __and_<is_array<_Tp>, __not_<extent<_Tp>>>
+    : public false_type
+    { };
+
+  template<typename _Tp>
+    struct __is_array_unknown_bounds<_Tp[]>
+    : public true_type
     { };

   // Destructible and constructible type properties.
@@ -1430,23 +1437,25 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     : public integral_constant<std::size_t, 1 + rank<_Tp>::value> { };

   /// extent
-  template<typename, unsigned _Uint>
+  template<typename, unsigned _Uint = 0>
     struct extent
-    : public integral_constant<std::size_t, 0> { };
+    : public integral_constant<size_t, 0> { };

-  template<typename _Tp, unsigned _Uint, std::size_t _Size>
+  template<typename _Tp, size_t _Size>
+    struct extent<_Tp[_Size], 0>
+    : public integral_constant<size_t, _Size> { };
+
+  template<typename _Tp, unsigned _Uint, size_t _Size>
     struct extent<_Tp[_Size], _Uint>
-    : public integral_constant<std::size_t,
-			       _Uint == 0 ? _Size : extent<_Tp,
-							   _Uint - 1>::value>
-    { };
+    : public extent<_Tp, _Uint - 1>::type { };
+
+  template<typename _Tp>
+    struct extent<_Tp[], 0>
+    : public integral_constant<size_t, 0> { };

   template<typename _Tp, unsigned _Uint>
     struct extent<_Tp[], _Uint>
-    : public integral_constant<std::size_t,
-			       _Uint == 0 ? 0 : extent<_Tp,
-						       _Uint - 1>::value>
-    { };
+    : public extent<_Tp, _Uint - 1>::type { };


   // Type relations.
@@ -3133,8 +3142,14 @@ template <typename _Tp>
   inline constexpr bool is_integral_v = is_integral<_Tp>::value;
 template <typename _Tp>
   inline constexpr bool is_floating_point_v = is_floating_point<_Tp>::value;
+
 template <typename _Tp>
-  inline constexpr bool is_array_v = is_array<_Tp>::value;
+  inline constexpr bool is_array_v = false;
+template <typename _Tp>
+  inline constexpr bool is_array_v<_Tp[]> = true;
+template <typename _Tp, size_t _Num>
+  inline constexpr bool is_array_v<_Tp[_Num]> = true;
+
 template <typename _Tp>
   inline constexpr bool is_pointer_v = is_pointer<_Tp>::value;
 template <typename _Tp>
@@ -3276,10 +3291,25 @@ template <typename _Tp>
     has_virtual_destructor<_Tp>::value;
 template <typename _Tp>
   inline constexpr size_t alignment_of_v = alignment_of<_Tp>::value;
+
 template <typename _Tp>
-  inline constexpr size_t rank_v = rank<_Tp>::value;
+  inline constexpr size_t rank_v = 0;
+template <typename _Tp, size_t _Size>
+  inline constexpr size_t rank_v<_Tp[_Size]> = 1 + rank_v<_Tp>;
+template <typename _Tp>
+  inline constexpr size_t rank_v<_Tp[]> = 1 + rank_v<_Tp>;
+
 template <typename _Tp, unsigned _Idx = 0>
-  inline constexpr size_t extent_v = extent<_Tp, _Idx>::value;
+  inline constexpr size_t extent_v = 0;
+template <typename _Tp, size_t _Size>
+  inline constexpr size_t extent_v<_Tp[_Size], 0> = _Size;
+template <typename _Tp, unsigned _Idx, size_t _Size>
+  inline constexpr size_t extent_v<_Tp[_Size], _Idx> = extent_v<_Tp, _Idx - 1>;
+template <typename _Tp>
+  inline constexpr size_t extent_v<_Tp[], 0> = 0;
+template <typename _Tp, unsigned _Idx>
+  inline constexpr size_t extent_v<_Tp[], _Idx> = extent_v<_Tp, _Idx - 1>;
+
 #ifdef _GLIBCXX_HAVE_BUILTIN_IS_SAME
 template <typename _Tp, typename _Up>
   inline constexpr bool is_same_v = __is_same(_Tp, _Up);
@@ -3407,32 +3437,38 @@ template<typename _Ret, typename _Fn, typename... _Args>

 #define __cpp_lib_bounded_array_traits 201902L

+  /// True for a type that is an array of known bound.
+  /// @ingroup variable_templates
+  /// @since C++20
+  template<typename _Tp>
+    inline constexpr bool is_bounded_array_v = false;
+
+  template<typename _Tp, size_t _Size>
+    inline constexpr bool is_bounded_array_v<_Tp[_Size]> = true;
+
+  /// True for a type that is an array of unknown bound.
+  /// @ingroup variable_templates
+  /// @since C++20
+  template<typename _Tp>
+    inline constexpr bool is_unbounded_array_v = false;
+
+  template<typename _Tp>
+    inline constexpr bool is_unbounded_array_v<_Tp[]> = true;
+
   /// True for a type that is an array of known bound.
   /// @since C++20
   template<typename _Tp>
     struct is_bounded_array
-    : public __is_array_known_bounds<_Tp>
+    : public bool_constant<is_bounded_array_v<_Tp>>
     { };

   /// True for a type that is an array of unknown bound.
   /// @since C++20
   template<typename _Tp>
     struct is_unbounded_array
-    : public __is_array_unknown_bounds<_Tp>
+    : public bool_constant<is_unbounded_array_v<_Tp>>
     { };

-  /// @ingroup variable_templates
-  /// @since C++20
-  template<typename _Tp>
-    inline constexpr bool is_bounded_array_v
-      = is_bounded_array<_Tp>::value;
-
-  /// @ingroup variable_templates
-  /// @since C++20
-  template<typename _Tp>
-    inline constexpr bool is_unbounded_array_v
-      = is_unbounded_array<_Tp>::value;
-
 #if __has_builtin(__is_layout_compatible)

   /// @since C++20
--
2.37.2

Tested powerpc64le-linux, pushed to trunk.

-- >8 --

This avoids having to instantiate a class template that just uses the
same built-in anyway.

None of the corresponding class templates have any type-completeness
static assertions, so we're not losing any diagnostics by using the
built-ins directly.

libstdc++-v3/ChangeLog:

	* include/std/type_traits (is_enum_v, is_class_v, is_union_v)
	(is_empty_v, is_polymoprhic_v, is_abstract_v, is_final_v)
	(is_base_of_v, is_aggregate_v): Use built-in directly instead of
	instantiating class template.
---
 libstdc++-v3/include/std/type_traits | 27 +++++++++++++++------------
 1 file changed, 15 insertions(+), 12 deletions(-)

diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index 5b8314f24fd..52cca8bf3af 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -3165,11 +3165,11 @@ template <typename _Tp>
   inline constexpr bool is_member_function_pointer_v =
     is_member_function_pointer<_Tp>::value;
 template <typename _Tp>
-  inline constexpr bool is_enum_v = is_enum<_Tp>::value;
+  inline constexpr bool is_enum_v = __is_enum(_Tp);
 template <typename _Tp>
-  inline constexpr bool is_union_v = is_union<_Tp>::value;
+  inline constexpr bool is_union_v = __is_union(_Tp);
 template <typename _Tp>
-  inline constexpr bool is_class_v = is_class<_Tp>::value;
+  inline constexpr bool is_class_v = __is_class(_Tp);
 template <typename _Tp>
   inline constexpr bool is_function_v = is_function<_Tp>::value;
 template <typename _Tp>
@@ -3206,14 +3206,14 @@ template <typename _Tp>
   _GLIBCXX17_DEPRECATED
   inline constexpr bool is_literal_type_v = is_literal_type<_Tp>::value;
 #pragma GCC diagnostic pop
- template <typename _Tp>
-  inline constexpr bool is_empty_v = is_empty<_Tp>::value;
 template <typename _Tp>
-  inline constexpr bool is_polymorphic_v = is_polymorphic<_Tp>::value;
+  inline constexpr bool is_empty_v = __is_empty(_Tp);
 template <typename _Tp>
-  inline constexpr bool is_abstract_v = is_abstract<_Tp>::value;
+  inline constexpr bool is_polymorphic_v = __is_polymorphic(_Tp);
 template <typename _Tp>
-  inline constexpr bool is_final_v = is_final<_Tp>::value;
+  inline constexpr bool is_abstract_v = __is_abstract(_Tp);
+template <typename _Tp>
+  inline constexpr bool is_final_v = __is_final(_Tp);
 template <typename _Tp>
   inline constexpr bool is_signed_v = is_signed<_Tp>::value;
 template <typename _Tp>
@@ -3318,7 +3318,7 @@ template <typename _Tp, typename _Up>
   inline constexpr bool is_same_v = std::is_same<_Tp, _Up>::value;
 #endif
 template <typename _Base, typename _Derived>
-  inline constexpr bool is_base_of_v = is_base_of<_Base, _Derived>::value;
+  inline constexpr bool is_base_of_v = __is_base_of(_Base, _Derived);
 template <typename _From, typename _To>
   inline constexpr bool is_convertible_v = is_convertible<_From, _To>::value;
 template<typename _Fn, typename... _Args>
@@ -3356,16 +3356,19 @@ template<typename _Ret, typename _Fn, typename... _Args>

 #ifdef _GLIBCXX_HAVE_BUILTIN_IS_AGGREGATE
 # define __cpp_lib_is_aggregate 201703L
-  /// is_aggregate
+  /// is_aggregate - true if the type is an aggregate.
   /// @since C++17
   template<typename _Tp>
     struct is_aggregate
     : bool_constant<__is_aggregate(remove_cv_t<_Tp>)>
     { };

-  /// @ingroup variable_templates
+  /** is_aggregate_v - true if the type is an aggregate.
+   *  @ingroup variable_templates
+   *  @since C++17
+   */
   template<typename _Tp>
-    inline constexpr bool is_aggregate_v = is_aggregate<_Tp>::value;
+    inline constexpr bool is_aggregate_v = __is_aggregate(remove_cv_t<_Tp>);
 #endif
 #endif // C++17

--
2.37.2

Tested powerpc64le-linux, pushed to trunk.

-- >8 --

This avoids having to instantiate a class template when we can detect
the true cases easily with a partial specialization.

libstdc++-v3/ChangeLog:

	* include/std/type_traits (is_lvalue_reference_v)
	(is_rvalue_reference_v, is_reference_v, is_const_v)
	(is_volatile_v): Define using partial specializations instead
	of instantiating class templates.
---
 libstdc++-v3/include/std/type_traits | 24 +++++++++++++++++-------
 1 file changed, 17 insertions(+), 7 deletions(-)

diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index 52cca8bf3af..e4b9b59ce08 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -3153,11 +3153,13 @@ template <typename _Tp, size_t _Num>
 template <typename _Tp>
   inline constexpr bool is_pointer_v = is_pointer<_Tp>::value;
 template <typename _Tp>
-  inline constexpr bool is_lvalue_reference_v =
-    is_lvalue_reference<_Tp>::value;
+  inline constexpr bool is_lvalue_reference_v = false;
 template <typename _Tp>
-  inline constexpr bool is_rvalue_reference_v =
-    is_rvalue_reference<_Tp>::value;
+  inline constexpr bool is_lvalue_reference_v<_Tp&> = true;
+template <typename _Tp>
+  inline constexpr bool is_rvalue_reference_v = false;
+template <typename _Tp>
+  inline constexpr bool is_rvalue_reference_v<_Tp&&> = true;
 template <typename _Tp>
   inline constexpr bool is_member_object_pointer_v =
     is_member_object_pointer<_Tp>::value;
@@ -3173,7 +3175,11 @@ template <typename _Tp>
 template <typename _Tp>
   inline constexpr bool is_function_v = is_function<_Tp>::value;
 template <typename _Tp>
-  inline constexpr bool is_reference_v = is_reference<_Tp>::value;
+  inline constexpr bool is_reference_v = false;
+template <typename _Tp>
+  inline constexpr bool is_reference_v<_Tp&> = true;
+template <typename _Tp>
+  inline constexpr bool is_reference_v<_Tp&&> = true;
 template <typename _Tp>
   inline constexpr bool is_arithmetic_v = is_arithmetic<_Tp>::value;
 template <typename _Tp>
@@ -3187,9 +3193,13 @@ template <typename _Tp>
 template <typename _Tp>
   inline constexpr bool is_member_pointer_v = is_member_pointer<_Tp>::value;
 template <typename _Tp>
-  inline constexpr bool is_const_v = is_const<_Tp>::value;
+  inline constexpr bool is_const_v = false;
 template <typename _Tp>
-  inline constexpr bool is_volatile_v = is_volatile<_Tp>::value;
+  inline constexpr bool is_const_v<const _Tp> = true;
+template <typename _Tp>
+  inline constexpr bool is_volatile_v = false;
+template <typename _Tp>
+  inline constexpr bool is_volatile_v<volatile _Tp> = true;
 template <typename _Tp>
   inline constexpr bool is_trivial_v = is_trivial<_Tp>::value;
 template <typename _Tp>
--
2.37.2

Tested powerpc64le-linux, pushed to trunk.

-- >8 --

Define partial specializations of std::decay and its __decay_selector
helper so that remove_reference, is_array and is_function are not
instantiated for every type, and remove_extent is not instantiated for
arrays.

libstdc++-v3/ChangeLog:

	* include/std/type_traits (__decay_selector): Add partial
	specializations for array types. Only check for function types
	when not dealing with an array.
	(decay): Add partial specializations for reference types.
---
 libstdc++-v3/include/std/type_traits | 39 ++++++++++++++--------------
 1 file changed, 20 insertions(+), 19 deletions(-)

diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index e4b9b59ce08..639c351df8a 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -2203,34 +2203,35 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION

   // Decay trait for arrays and functions, used for perfect forwarding
   // in make_pair, make_tuple, etc.
-  template<typename _Up,
-	   bool _IsArray = is_array<_Up>::value,
-	   bool _IsFunction = is_function<_Up>::value>
-    struct __decay_selector;
-
-  // NB: DR 705.
   template<typename _Up>
-    struct __decay_selector<_Up, false, false>
-    { typedef __remove_cv_t<_Up> __type; };
+    struct __decay_selector
+    : __conditional_t<is_const<const _Up>::value, // false for functions
+		      remove_cv<_Up>,		  // N.B. DR 705.
+		      add_pointer<_Up>>		  // function decays to pointer
+    { };
+
+  template<typename _Up, size_t _Nm>
+    struct __decay_selector<_Up[_Nm]>
+    { using type = _Up*; };

   template<typename _Up>
-    struct __decay_selector<_Up, true, false>
-    { typedef typename remove_extent<_Up>::type* __type; };
+    struct __decay_selector<_Up[]>
+    { using type = _Up*; };

-  template<typename _Up>
-    struct __decay_selector<_Up, false, true>
-    { typedef typename add_pointer<_Up>::type __type; };
   /// @endcond

   /// decay
   template<typename _Tp>
-    class decay
-    {
-      typedef typename remove_reference<_Tp>::type __remove_type;
+    struct decay
+    { using type = typename __decay_selector<_Tp>::type; };

-    public:
-      typedef typename __decay_selector<__remove_type>::__type type;
-    };
+  template<typename _Tp>
+    struct decay<_Tp&>
+    { using type = typename __decay_selector<_Tp>::type; };
+
+  template<typename _Tp>
+    struct decay<_Tp&&>
+    { using type = typename __decay_selector<_Tp>::type; };

   /// @cond undocumented

--
2.37.2

Tested powerpc64le-linux, pushed to trunk.

-- >8 --

We can replace some class template helpers with alias templates, which
are cheaper to instantiate.

For example, replace the __is_copy_constructible_impl class template
with an alias template that uses just evaluates the __is_constructible
built-in, using add_lvalue_reference<const T> to get the argument type
in a way that works for non-referenceable types. For a given
specialization of is_copy_constructible this results in the same number
of class templates being instantiated (for the common case of non-void,
non-function types), but the add_lvalue_reference instantiations are not
specific to the is_copy_constructible specialization and so can be
reused by other traits. Previously __is_copy_constructible_impl was a
distinct class template and its specializations were never used for
anything except is_copy_constructible.

With the new definitions of these traits that don't depend on helper
classes, it becomes more practical to optimize the
is_xxx_constructible_v variable templates to avoid instantiations.
Previously doing so would have meant two entirely separate
implementation strategies for these traits.

libstdc++-v3/ChangeLog:

	* include/std/type_traits (__is_constructible_impl): Replace
	class template with alias template.
	(is_default_constructible, is_nothrow_constructible)
	(is_nothrow_constructible): Simplify base-specifier.
	(__is_copy_constructible_impl, __is_move_constructible_impl)
	(__is_nothrow_copy_constructible_impl)
	(__is_nothrow_move_constructible_impl): Remove class templates.
	(is_copy_constructible, is_move_constructible)
	(is_nothrow_constructible, is_nothrow_default_constructible)
	(is_nothrow_copy_constructible, is_nothrow_move_constructible):
	Adjust base-specifiers to use __is_constructible_impl.
	(__is_copy_assignable_impl, __is_move_assignable_impl)
	(__is_nt_copy_assignable_impl, __is_nt_move_assignable_impl):
	Remove class templates.
	(__is_assignable_impl): New alias template.
	(is_assignable, is_copy_assignable, is_move_assignable):
	Adjust base-specifiers to use new alias template.
	(is_nothrow_copy_assignable, is_nothrow_move_assignable):
	Adjust base-specifiers to use existing alias template.
	(__is_trivially_constructible_impl): New alias template.
	(is_trivially_constructible, is_trivially_default_constructible)
	(is_trivially_copy_constructible)
	(is_trivially_move_constructible): Adjust base-specifiers to use
	new alias template.
	(__is_trivially_assignable_impl): New alias template.
	(is_trivially_assignable, is_trivially_copy_assignable)
	(is_trivially_move_assignable): Adjust base-specifier to use
	new alias template.
	(__add_lval_ref_t, __add_rval_ref_t): New alias templates.
	(add_lvalue_reference, add_rvalue_reference): Use new alias
	templates.
---
 libstdc++-v3/include/std/type_traits | 249 +++++++--------------------
 1 file changed, 62 insertions(+), 187 deletions(-)

diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index 639c351df8a..3041ac3c941 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -1001,9 +1001,8 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION

   /// @cond undocumented
   template<typename _Tp, typename... _Args>
-    struct __is_constructible_impl
-    : public __bool_constant<__is_constructible(_Tp, _Args...)>
-    { };
+    using __is_constructible_impl
+      = __bool_constant<__is_constructible(_Tp, _Args...)>;
   /// @endcond

   /// is_constructible
@@ -1018,7 +1017,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   /// is_default_constructible
   template<typename _Tp>
     struct is_default_constructible
-    : public __is_constructible_impl<_Tp>::type
+    : public __is_constructible_impl<_Tp>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
@@ -1026,22 +1025,21 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION

   /// @cond undocumented
   template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_copy_constructible_impl;
+    struct __add_lvalue_reference_helper
+    { using type = _Tp; };

   template<typename _Tp>
-    struct __is_copy_constructible_impl<_Tp, false>
-    : public false_type { };
+    struct __add_lvalue_reference_helper<_Tp, true>
+    { using type = _Tp&; };

   template<typename _Tp>
-    struct __is_copy_constructible_impl<_Tp, true>
-    : public __is_constructible_impl<_Tp, const _Tp&>
-    { };
+    using __add_lval_ref_t = typename __add_lvalue_reference_helper<_Tp>::type;
   /// @endcond

   /// is_copy_constructible
   template<typename _Tp>
     struct is_copy_constructible
-    : public __is_copy_constructible_impl<_Tp>
+    : public __is_constructible_impl<_Tp, __add_lval_ref_t<const _Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
@@ -1049,22 +1047,21 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION

   /// @cond undocumented
   template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_move_constructible_impl;
+    struct __add_rvalue_reference_helper
+    { using type = _Tp; };

   template<typename _Tp>
-    struct __is_move_constructible_impl<_Tp, false>
-    : public false_type { };
+    struct __add_rvalue_reference_helper<_Tp, true>
+    { using type = _Tp&&; };

   template<typename _Tp>
-    struct __is_move_constructible_impl<_Tp, true>
-    : public __is_constructible_impl<_Tp, _Tp&&>
-    { };
+    using __add_rval_ref_t = typename __add_rvalue_reference_helper<_Tp>::type;
   /// @endcond

   /// is_move_constructible
   template<typename _Tp>
     struct is_move_constructible
-    : public __is_move_constructible_impl<_Tp>
+    : public __is_constructible_impl<_Tp, __add_rval_ref_t<_Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
@@ -1079,7 +1076,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   /// is_nothrow_constructible
   template<typename _Tp, typename... _Args>
     struct is_nothrow_constructible
-    : public __is_nothrow_constructible_impl<_Tp, _Args...>::type
+    : public __is_nothrow_constructible_impl<_Tp, _Args...>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
@@ -1088,112 +1085,68 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   /// is_nothrow_default_constructible
   template<typename _Tp>
     struct is_nothrow_default_constructible
-    : public __bool_constant<__is_nothrow_constructible(_Tp)>
+    : public __is_nothrow_constructible_impl<_Tp>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

-  /// @cond undocumented
-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_nothrow_copy_constructible_impl;
-
-  template<typename _Tp>
-    struct __is_nothrow_copy_constructible_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_nothrow_copy_constructible_impl<_Tp, true>
-    : public __is_nothrow_constructible_impl<_Tp, const _Tp&>
-    { };
-  /// @endcond
-
   /// is_nothrow_copy_constructible
   template<typename _Tp>
     struct is_nothrow_copy_constructible
-    : public __is_nothrow_copy_constructible_impl<_Tp>::type
+    : public __is_nothrow_constructible_impl<_Tp, __add_lval_ref_t<const _Tp>>
+    {
+      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
+	"template argument must be a complete class or an unbounded array");
+    };
+
+  /// is_nothrow_move_constructible
+  template<typename _Tp>
+    struct is_nothrow_move_constructible
+    : public __is_nothrow_constructible_impl<_Tp, __add_rval_ref_t<_Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

   /// @cond undocumented
-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_nothrow_move_constructible_impl;
-
-  template<typename _Tp>
-    struct __is_nothrow_move_constructible_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_nothrow_move_constructible_impl<_Tp, true>
-    : public __is_nothrow_constructible_impl<_Tp, _Tp&&>
-    { };
+  template<typename _Tp, typename _Up>
+    using __is_assignable_impl = __bool_constant<__is_assignable(_Tp, _Up)>;
   /// @endcond

-  /// is_nothrow_move_constructible
-  template<typename _Tp>
-    struct is_nothrow_move_constructible
-    : public __is_nothrow_move_constructible_impl<_Tp>::type
-    {
-      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
-	"template argument must be a complete class or an unbounded array");
-    };
-
   /// is_assignable
   template<typename _Tp, typename _Up>
     struct is_assignable
-    : public __bool_constant<__is_assignable(_Tp, _Up)>
+    : public __is_assignable_impl<_Tp, _Up>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_copy_assignable_impl;
-
-  template<typename _Tp>
-    struct __is_copy_assignable_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_copy_assignable_impl<_Tp, true>
-    : public __bool_constant<__is_assignable(_Tp&, const _Tp&)>
-    { };
-
   /// is_copy_assignable
   template<typename _Tp>
     struct is_copy_assignable
-    : public __is_copy_assignable_impl<_Tp>::type
+    : public __is_assignable_impl<__add_lval_ref_t<_Tp>,
+				  __add_lval_ref_t<const _Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_move_assignable_impl;
-
-  template<typename _Tp>
-    struct __is_move_assignable_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_move_assignable_impl<_Tp, true>
-    : public __bool_constant<__is_assignable(_Tp&, _Tp&&)>
-    { };
-
   /// is_move_assignable
   template<typename _Tp>
     struct is_move_assignable
-    : public __is_move_assignable_impl<_Tp>::type
+    : public __is_assignable_impl<__add_lval_ref_t<_Tp>, __add_rval_ref_t<_Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

+  /// @cond undocumented
   template<typename _Tp, typename _Up>
     using __is_nothrow_assignable_impl
       = __bool_constant<__is_nothrow_assignable(_Tp, _Up)>;
+  /// @endcond

   /// is_nothrow_assignable
   template<typename _Tp, typename _Up>
@@ -1204,52 +1157,36 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 	"template argument must be a complete class or an unbounded array");
     };

-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_nt_copy_assignable_impl;
-
-  template<typename _Tp>
-    struct __is_nt_copy_assignable_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_nt_copy_assignable_impl<_Tp, true>
-    : public __is_nothrow_assignable_impl<_Tp&, const _Tp&>
-    { };
-
   /// is_nothrow_copy_assignable
   template<typename _Tp>
     struct is_nothrow_copy_assignable
-    : public __is_nt_copy_assignable_impl<_Tp>
+    : public __is_nothrow_assignable_impl<__add_lval_ref_t<_Tp>,
+					  __add_lval_ref_t<const _Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_nt_move_assignable_impl;
-
-  template<typename _Tp>
-    struct __is_nt_move_assignable_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_nt_move_assignable_impl<_Tp, true>
-    : public __is_nothrow_assignable_impl<_Tp&, _Tp&&>
-    { };
-
   /// is_nothrow_move_assignable
   template<typename _Tp>
     struct is_nothrow_move_assignable
-    : public __is_nt_move_assignable_impl<_Tp>
+    : public __is_nothrow_assignable_impl<__add_lval_ref_t<_Tp>,
+					  __add_rval_ref_t<_Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

+  /// @cond undocumented
+  template<typename _Tp, typename... _Args>
+    using __is_trivially_constructible_impl
+      = __bool_constant<__is_trivially_constructible(_Tp, _Args...)>;
+  /// @endcond
+
   /// is_trivially_constructible
   template<typename _Tp, typename... _Args>
     struct is_trivially_constructible
-    : public __bool_constant<__is_trivially_constructible(_Tp, _Args...)>
+    : public __is_trivially_constructible_impl<_Tp, _Args...>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
@@ -1258,7 +1195,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   /// is_trivially_default_constructible
   template<typename _Tp>
     struct is_trivially_default_constructible
-    : public __bool_constant<__is_trivially_constructible(_Tp)>
+    : public __is_trivially_constructible_impl<_Tp>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
@@ -1294,98 +1231,54 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 		    __is_implicitly_default_constructible_safe<_Tp>>
     { };

-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_trivially_copy_constructible_impl;
-
-  template<typename _Tp>
-    struct __is_trivially_copy_constructible_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_trivially_copy_constructible_impl<_Tp, true>
-    : public __and_<__is_copy_constructible_impl<_Tp>,
-		    integral_constant<bool,
-			__is_trivially_constructible(_Tp, const _Tp&)>>
-    { };
-
   /// is_trivially_copy_constructible
   template<typename _Tp>
     struct is_trivially_copy_constructible
-    : public __is_trivially_copy_constructible_impl<_Tp>
+    : public __is_trivially_constructible_impl<_Tp, __add_lval_ref_t<const _Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_trivially_move_constructible_impl;
-
-  template<typename _Tp>
-    struct __is_trivially_move_constructible_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_trivially_move_constructible_impl<_Tp, true>
-    : public __and_<__is_move_constructible_impl<_Tp>,
-		    integral_constant<bool,
-			__is_trivially_constructible(_Tp, _Tp&&)>>
-    { };
-
   /// is_trivially_move_constructible
   template<typename _Tp>
     struct is_trivially_move_constructible
-    : public __is_trivially_move_constructible_impl<_Tp>
+    : public __is_trivially_constructible_impl<_Tp, __add_rval_ref_t<_Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

+  /// @cond undocumented
+  template<typename _Tp, typename _Up>
+    using __is_trivially_assignable_impl
+      = __bool_constant<__is_trivially_assignable(_Tp, _Up)>;
+  /// @endcond
+
   /// is_trivially_assignable
   template<typename _Tp, typename _Up>
     struct is_trivially_assignable
-    : public __bool_constant<__is_trivially_assignable(_Tp, _Up)>
+    : public __is_trivially_assignable_impl<_Tp, _Up>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_trivially_copy_assignable_impl;
-
-  template<typename _Tp>
-    struct __is_trivially_copy_assignable_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_trivially_copy_assignable_impl<_Tp, true>
-    : public __bool_constant<__is_trivially_assignable(_Tp&, const _Tp&)>
-    { };
-
   /// is_trivially_copy_assignable
   template<typename _Tp>
     struct is_trivially_copy_assignable
-    : public __is_trivially_copy_assignable_impl<_Tp>
+    : public __is_trivially_assignable_impl<__add_lval_ref_t<_Tp>,
+					    __add_lval_ref_t<const _Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
     };

-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __is_trivially_move_assignable_impl;
-
-  template<typename _Tp>
-    struct __is_trivially_move_assignable_impl<_Tp, false>
-    : public false_type { };
-
-  template<typename _Tp>
-    struct __is_trivially_move_assignable_impl<_Tp, true>
-    : public __bool_constant<__is_trivially_assignable(_Tp&, _Tp&&)>
-    { };
-
   /// is_trivially_move_assignable
   template<typename _Tp>
     struct is_trivially_move_assignable
-    : public __is_trivially_move_assignable_impl<_Tp>
+    : public __is_trivially_assignable_impl<__add_lval_ref_t<_Tp>,
+					    __add_rval_ref_t<_Tp>>
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
@@ -1669,33 +1562,15 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     struct remove_reference<_Tp&&>
     { typedef _Tp   type; };

-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __add_lvalue_reference_helper
-    { typedef _Tp   type; };
-
-  template<typename _Tp>
-    struct __add_lvalue_reference_helper<_Tp, true>
-    { typedef _Tp&   type; };
-
   /// add_lvalue_reference
   template<typename _Tp>
     struct add_lvalue_reference
-    : public __add_lvalue_reference_helper<_Tp>
-    { };
-
-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
-    struct __add_rvalue_reference_helper
-    { typedef _Tp   type; };
-
-  template<typename _Tp>
-    struct __add_rvalue_reference_helper<_Tp, true>
-    { typedef _Tp&&   type; };
+    { using type = __add_lval_ref_t<_Tp>; };

   /// add_rvalue_reference
   template<typename _Tp>
     struct add_rvalue_reference
-    : public __add_rvalue_reference_helper<_Tp>
-    { };
+    { using type = __add_rval_ref_t<_Tp>; };

 #if __cplusplus > 201103L
   /// Alias template for remove_reference
--
2.37.2

Tested powerpc64le-linux, pushed to trunk.

-- >8 --

We only use the __is_referenceable helper in three places now:
add_pointer, add_lvalue_reference, and add_rvalue_reference. But lots of
other traits depend on add_[lr]value_reference, and decay depends on
add_pointer, so removing the instantiation of __is_referenceable helps
compile all those other traits slightly faster.

We can just use void_t<T&> to check for a referenceable type in the
add_[lr]value_reference traits.

Then we can specialize add_pointer for reference types, so that we don't
need to use remove_reference, and then use void_t<T*> for all
non-reference types to detect when we can form a pointer to the type.

libstdc++-v3/ChangeLog:

	* include/std/type_traits (__is_referenceable): Remove.
	(__add_lvalue_reference_helper, __add_rvalue_reference_helper):
	Use __void_t instead of __is_referenceable.
	(__add_pointer_helper): Likewise.
	(add_pointer): Add partial specializations for reference types.
---
 libstdc++-v3/include/std/type_traits | 37 ++++++++++++----------------
 1 file changed, 16 insertions(+), 21 deletions(-)

diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index 3041ac3c941..8b11f31741b 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -712,18 +712,6 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION

   // __void_t (std::void_t for C++11)
   template<typename...> using __void_t = void;
-
-  // Utility to detect referenceable types ([defns.referenceable]).
-
-  template<typename _Tp, typename = void>
-    struct __is_referenceable
-    : public false_type
-    { };
-
-  template<typename _Tp>
-    struct __is_referenceable<_Tp, __void_t<_Tp&>>
-    : public true_type
-    { };
   /// @endcond

   // Type properties.
@@ -1024,12 +1012,12 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     };

   /// @cond undocumented
-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
+  template<typename _Tp, typename = void>
     struct __add_lvalue_reference_helper
     { using type = _Tp; };

   template<typename _Tp>
-    struct __add_lvalue_reference_helper<_Tp, true>
+    struct __add_lvalue_reference_helper<_Tp, __void_t<_Tp&>>
     { using type = _Tp&; };

   template<typename _Tp>
@@ -1046,12 +1034,12 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     };

   /// @cond undocumented
-  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
+  template<typename _Tp, typename = void>
     struct __add_rvalue_reference_helper
     { using type = _Tp; };

   template<typename _Tp>
-    struct __add_rvalue_reference_helper<_Tp, true>
+    struct __add_rvalue_reference_helper<_Tp, __void_t<_Tp&&>>
     { using type = _Tp&&; };

   template<typename _Tp>
@@ -1971,14 +1959,13 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     : public __remove_pointer_helper<_Tp, __remove_cv_t<_Tp>>
     { };

-  template<typename _Tp, bool = __or_<__is_referenceable<_Tp>,
-				      is_void<_Tp>>::value>
+  template<typename _Tp, typename = void>
     struct __add_pointer_helper
-    { typedef _Tp     type; };
+    { using type = _Tp; };

   template<typename _Tp>
-    struct __add_pointer_helper<_Tp, true>
-    { typedef typename remove_reference<_Tp>::type*     type; };
+    struct __add_pointer_helper<_Tp, __void_t<_Tp*>>
+    { using type = _Tp*; };

   /// add_pointer
   template<typename _Tp>
@@ -1986,6 +1973,14 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     : public __add_pointer_helper<_Tp>
     { };

+  template<typename _Tp>
+    struct add_pointer<_Tp&>
+    { using type = _Tp*; };
+
+  template<typename _Tp>
+    struct add_pointer<_Tp&&>
+    { using type = _Tp*; };
+
 #if __cplusplus > 201103L
   /// Alias template for remove_pointer
   template<typename _Tp>
--
2.37.2

Now that these internal type traits are again class templates, it's
better to derive from the trait's ::type (which is either false_type or
true_type) instead of from the trait itself, for sake of a shallower
inheritance chain.  We usually do this but not always; this patch makes
us consistently do so.

Tested on x86_64-pc-lnux-gnu, does this look OK for trunk?  (Compile
time for join.cc decreases by about 0.5% with this, avg of 10 runs.)

libstdc++-v3/ChangeLog:

	* include/std/tuple (tuple::_UseOtherCtor): Do ::type when
	deriving from __and_, __or_ or __not_.
	* include/std/type_traits (negation): Likewise.
	(is_unsigned): Likewise.
	(__is_implicitly_default_constructible): Likewise.
	(is_trivially_destructible): Likewise.
	(__is_nt_invocable_impl): Likewise.
---
 libstdc++-v3/include/std/tuple       |  2 +-
 libstdc++-v3/include/std/type_traits | 10 +++++-----
 2 files changed, 6 insertions(+), 6 deletions(-)

diff --git a/libstdc++-v3/include/std/tuple b/libstdc++-v3/include/std/tuple
index ddd7c226d80..26e248431ec 100644
--- a/libstdc++-v3/include/std/tuple
+++ b/libstdc++-v3/include/std/tuple
@@ -826,7 +826,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       // then TUPLE should match tuple(UTypes&&...) instead.
       template<typename _Tuple, typename _Tp, typename _Up>
 	struct _UseOtherCtor<_Tuple, tuple<_Tp>, tuple<_Up>>
-	: __or_<is_convertible<_Tuple, _Tp>, is_constructible<_Tp, _Tuple>>
+	: __or_<is_convertible<_Tuple, _Tp>, is_constructible<_Tp, _Tuple>>::type
 	{ };
       // If TUPLE and *this each have a single element of the same type,
       // then TUPLE should match a copy/move constructor instead.
diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index be9f2955539..c0bb1cf64e3 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -235,7 +235,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION

   template<typename _Pp>
     struct negation
-    : __not_<_Pp>
+    : __not_<_Pp>::type
     { };

   /** @ingroup variable_templates
@@ -845,7 +845,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   /// is_unsigned
   template<typename _Tp>
     struct is_unsigned
-    : public __and_<is_arithmetic<_Tp>, __not_<is_signed<_Tp>>>
+    : public __and_<is_arithmetic<_Tp>, __not_<is_signed<_Tp>>>::type
     { };

   /// @cond undocumented
@@ -1222,7 +1222,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   template <typename _Tp>
     struct __is_implicitly_default_constructible
     : public __and_<__is_constructible_impl<_Tp>,
-		    __is_implicitly_default_constructible_safe<_Tp>>
+		    __is_implicitly_default_constructible_safe<_Tp>>::type
     { };

   /// is_trivially_copy_constructible
@@ -1282,7 +1282,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   template<typename _Tp>
     struct is_trivially_destructible
     : public __and_<__is_destructible_safe<_Tp>,
-		    __bool_constant<__has_trivial_destructor(_Tp)>>
+		    __bool_constant<__has_trivial_destructor(_Tp)>>::type
     {
       static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 	"template argument must be a complete class or an unbounded array");
@@ -2975,7 +2975,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     struct __is_nt_invocable_impl<_Result, _Ret,
 				  __void_t<typename _Result::type>>
     : __or_<is_void<_Ret>,
-	    __is_nothrow_convertible<typename _Result::type, _Ret>>
+	    __is_nothrow_convertible<typename _Result::type, _Ret>>::type
     { };
   /// @endcond

--
2.37.2.490.g6c8e4ee870

diff --git a/gcc/config/i386/i386.md b/gcc/config/i386/i386.md
index 1aef1af594d..57771ed84f5 100644
--- a/gcc/config/i386/i386.md
+++ b/gcc/config/i386/i386.md
@@ -23823,10 +23823,11 @@ (define_insn "sse4_2_crc32<mode>"

 (define_insn "sse4_2_crc32di"
   [(set (match_operand:DI 0 "register_operand" "=r")
-	(unspec:DI
-	  [(match_operand:DI 1 "register_operand" "0")
-	   (match_operand:DI 2 "nonimmediate_operand" "rm")]
-	  UNSPEC_CRC32))]
+	(zero_extend:DI
+	  (unspec:SI
+	    [(match_operand:SI 1 "register_operand" "0")
+	     (match_operand:DI 2 "nonimmediate_operand" "rm")]
+	    UNSPEC_CRC32)))]
   "TARGET_64BIT && TARGET_CRC32"
   "crc32{q}\t{%2, %0|%0, %2}"
   [(set_attr "type" "sselog1")
diff --git a/gcc/testsuite/gcc.target/i386/pr106453.c b/gcc/testsuite/gcc.target/i386/pr106453.c
new file mode 100644
index 00000000000..bd2e7282cf6
--- /dev/null
+++ b/gcc/testsuite/gcc.target/i386/pr106453.c
@@ -0,0 +1,13 @@
+/* { dg-do compile { target { ! ia32 } } } */
+/* { dg-options "-O2 -mcrc32 -dp" } */
+/* { dg-final { scan-assembler-not "zero_extendsidi" } } */
+
+#include <immintrin.h>
+#include <stdint.h>
+
+uint32_t f(uint32_t c, uint64_t *p, size_t n)
+{
+    for (size_t i = 0; i < n; i++)
+        c = _mm_crc32_u64(c, p[i]);
+    return c;
+}

Tested x86_64-linux, pushed to trunk.

-- >8 --

libstdc++-v3/ChangeLog:

	* include/std/type_traits (__success_type, __failure_type): Move
	definitions later in the file.
---
 libstdc++-v3/include/std/type_traits | 25 +++++++++++++------------
 1 file changed, 13 insertions(+), 12 deletions(-)

diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index e19d964fa9c..e4d167939d9 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -286,18 +286,6 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     >::type __is_complete_or_unbounded(_TypeIdentity)
     { return {}; }

-  // For several sfinae-friendly trait implementations we transport both the
-  // result information (as the member type) and the failure information (no
-  // member type). This is very similar to std::enable_if, but we cannot use
-  // them, because we need to derive from them as an implementation detail.
-
-  template<typename _Tp>
-    struct __success_type
-    { typedef _Tp type; };
-
-  struct __failure_type
-  { };
-
   // __remove_cv_t (std::remove_cv_t for C++11).
   template<typename _Tp>
     using __remove_cv_t = typename remove_cv<_Tp>::type;
@@ -2162,6 +2150,19 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   // Sfinae-friendly common_type implementation:

   /// @cond undocumented
+
+  // For several sfinae-friendly trait implementations we transport both the
+  // result information (as the member type) and the failure information (no
+  // member type). This is very similar to std::enable_if, but we cannot use
+  // that, because we need to derive from them as an implementation detail.
+
+  template<typename _Tp>
+    struct __success_type
+    { typedef _Tp type; };
+
+  struct __failure_type
+  { };
+
   struct __do_common_type_impl
   {
     template<typename _Tp, typename _Up>
--
2.37.3

Use string length of input to strdup to determine the usable size of the
resulting object.  Avoid doing the same for strndup since there's a
chance that the input may be too large, resulting in an unnecessary
overhead or worse, the input may not be NULL terminated, resulting in a
crash where there would otherwise have been none.

gcc/ChangeLog:

	* tree-object-size.cc (get_whole_object): New function.
	(addr_object_size): Use it.
	(strdup_object_size): New function.
	(call_object_size): Use it.
	(pass_data_object_sizes, pass_data_early_object_sizes): Set
	todo_flags_finish to TODO_update_ssa_no_phi.

gcc/testsuite/ChangeLog:

	* gcc.dg/builtin-dynamic-object-size-0.c (test_strdup,
	test_strndup, test_strdup_min, test_strndup_min): New tests.
	(main): Call them.
	* gcc.dg/builtin-dynamic-object-size-1.c: Silence overread
	warnings.
	* gcc.dg/builtin-dynamic-object-size-2.c: Likewise.
	* gcc.dg/builtin-dynamic-object-size-3.c: Likewise.
	* gcc.dg/builtin-dynamic-object-size-4.c: Likewise.
	* gcc.dg/builtin-object-size-1.c: Silence overread warnings.
	Declare free, strdup and strndup.
	(test11): New test.
	(main): Call it.
	* gcc.dg/builtin-object-size-2.c: Silence overread warnings.
	Declare free, strdup and strndup.
	(test9): New test.
	(main): Call it.
	* gcc.dg/builtin-object-size-3.c: Silence overread warnings.
	Declare free, strdup and strndup.
	(test11): New test.
	(main): Call it.
	* gcc.dg/builtin-object-size-4.c: Silence overread warnings.
	Declare free, strdup and strndup.
	(test9): New test.
	(main): Call it.
---
 .../gcc.dg/builtin-dynamic-object-size-0.c    | 43 +++++++++++
 .../gcc.dg/builtin-dynamic-object-size-1.c    |  2 +-
 .../gcc.dg/builtin-dynamic-object-size-2.c    |  2 +-
 .../gcc.dg/builtin-dynamic-object-size-3.c    |  2 +-
 .../gcc.dg/builtin-dynamic-object-size-4.c    |  2 +-
 gcc/testsuite/gcc.dg/builtin-object-size-1.c  | 64 +++++++++++++++-
 gcc/testsuite/gcc.dg/builtin-object-size-2.c  | 63 ++++++++++++++-
 gcc/testsuite/gcc.dg/builtin-object-size-3.c  | 63 ++++++++++++++-
 gcc/testsuite/gcc.dg/builtin-object-size-4.c  | 63 ++++++++++++++-
 gcc/tree-object-size.cc                       | 76 +++++++++++++++++--
 10 files changed, 366 insertions(+), 14 deletions(-)

diff --git a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-0.c b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-0.c
index 01a280b2d7b..7f023708b15 100644
--- a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-0.c
+++ b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-0.c
@@ -479,6 +479,40 @@ test_loop (int *obj, size_t sz, size_t start, size_t end, int incr)
   return __builtin_dynamic_object_size (ptr, 0);
 }

+/* strdup/strndup.  */
+
+size_t
+__attribute__ ((noinline))
+test_strdup (const char *in)
+{
+  char *res = __builtin_strdup (in);
+  return __builtin_dynamic_object_size (res, 0);
+}
+
+size_t
+__attribute__ ((noinline))
+test_strndup (const char *in, size_t bound)
+{
+  char *res = __builtin_strndup (in, bound);
+  return __builtin_dynamic_object_size (res, 0);
+}
+
+size_t
+__attribute__ ((noinline))
+test_strdup_min (const char *in)
+{
+  char *res = __builtin_strdup (in);
+  return __builtin_dynamic_object_size (res, 2);
+}
+
+size_t
+__attribute__ ((noinline))
+test_strndup_min (const char *in, size_t bound)
+{
+  char *res = __builtin_strndup (in, bound);
+  return __builtin_dynamic_object_size (res, 2);
+}
+
 /* Other tests.  */

 struct TV4
@@ -651,6 +685,15 @@ main (int argc, char **argv)
   int *t = test_pr105736 (&val3);
   if (__builtin_dynamic_object_size (t, 0) != -1)
     FAIL ();
+  const char *str = "hello world";
+  if (test_strdup (str) != __builtin_strlen (str) + 1)
+    FAIL ();
+  if (test_strndup (str, 4) != 5)
+    FAIL ();
+  if (test_strdup_min (str) != __builtin_strlen (str) + 1)
+    FAIL ();
+  if (test_strndup_min (str, 4) != 0)
+    FAIL ();

   if (nfails > 0)
     __builtin_abort ();
diff --git a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-1.c b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-1.c
index 7cc8b1c9488..8f17c8edcaf 100644
--- a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-1.c
+++ b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-1.c
@@ -1,5 +1,5 @@
 /* { dg-do run } */
-/* { dg-options "-O2" } */
+/* { dg-options "-O2 -Wno-stringop-overread" } */
 /* { dg-require-effective-target alloca } */

 #define __builtin_object_size __builtin_dynamic_object_size
diff --git a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-2.c b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-2.c
index 267dbf48ca7..3677782ff1c 100644
--- a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-2.c
+++ b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-2.c
@@ -1,5 +1,5 @@
 /* { dg-do run } */
-/* { dg-options "-O2" } */
+/* { dg-options "-O2 -Wno-stringop-overread" } */
 /* { dg-require-effective-target alloca } */

 #define __builtin_object_size __builtin_dynamic_object_size
diff --git a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-3.c b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-3.c
index fb9dc56da7e..5b6987b7773 100644
--- a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-3.c
+++ b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-3.c
@@ -1,5 +1,5 @@
 /* { dg-do run } */
-/* { dg-options "-O2" } */
+/* { dg-options "-O2 -Wno-stringop-overread" } */
 /* { dg-require-effective-target alloca } */

 #define __builtin_object_size __builtin_dynamic_object_size
diff --git a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-4.c b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-4.c
index 870548b4206..9d796224e96 100644
--- a/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-4.c
+++ b/gcc/testsuite/gcc.dg/builtin-dynamic-object-size-4.c
@@ -1,5 +1,5 @@
 /* { dg-do run } */
-/* { dg-options "-O2" } */
+/* { dg-options "-O2 -Wno-stringop-overread" } */
 /* { dg-require-effective-target alloca } */

 #define __builtin_object_size __builtin_dynamic_object_size
diff --git a/gcc/testsuite/gcc.dg/builtin-object-size-1.c b/gcc/testsuite/gcc.dg/builtin-object-size-1.c
index b772e2da9b9..4fbd372d97a 100644
--- a/gcc/testsuite/gcc.dg/builtin-object-size-1.c
+++ b/gcc/testsuite/gcc.dg/builtin-object-size-1.c
@@ -1,5 +1,5 @@
 /* { dg-do run } */
-/* { dg-options "-O2" } */
+/* { dg-options "-O2 -Wno-stringop-overread" } */
 /* { dg-require-effective-target alloca } */

 typedef __SIZE_TYPE__ size_t;
@@ -7,10 +7,13 @@ extern void abort (void);
 extern void exit (int);
 extern void *malloc (size_t);
 extern void *calloc (size_t, size_t);
+extern void free (void *);
 extern void *alloca (size_t);
 extern void *memcpy (void *, const void *, size_t);
 extern void *memset (void *, int, size_t);
 extern char *strcpy (char *, const char *);
+extern char *strdup (const char *);
+extern char *strndup (const char *, size_t);

 struct A
 {
@@ -629,6 +632,64 @@ test10 (void)
     }
 }

+/* Tests for strdup/strndup.  */
+size_t
+__attribute__ ((noinline))
+test11 (void)
+{
+  int i = 0;
+  const char *ptr = "abcdefghijklmnopqrstuvwxyz";
+  char *res = strndup (ptr, 21);
+  if (__builtin_object_size (res, 0) != 22)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr, 32);
+  if (__builtin_object_size (res, 0) != 27)
+    abort ();
+
+  free (res);
+
+  res = strdup (ptr);
+  if (__builtin_object_size (res, 0) != 27)
+    abort ();
+
+  free (res);
+
+  char *ptr2 = malloc (64);
+  strcpy (ptr2, ptr);
+
+  res = strndup (ptr2, 21);
+  if (__builtin_object_size (res, 0) != 22)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr2, 32);
+  if (__builtin_object_size (res, 0) != 33)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr2, 128);
+  if (__builtin_object_size (res, 0) != 64)
+    abort ();
+
+  free (res);
+
+  res = strdup (ptr2);
+#ifdef __builtin_object_size
+  if (__builtin_object_size (res, 0) != 27)
+#else
+  if (__builtin_object_size (res, 0) != 64)
+#endif
+    abort ();
+
+  free (res);
+  free (ptr2);
+}
+
 int
 main (void)
 {
@@ -644,5 +705,6 @@ main (void)
   test8 ();
   test9 (1);
   test10 ();
+  test11 ();
   exit (0);
 }
diff --git a/gcc/testsuite/gcc.dg/builtin-object-size-2.c b/gcc/testsuite/gcc.dg/builtin-object-size-2.c
index 2729538da17..beb271c5afc 100644
--- a/gcc/testsuite/gcc.dg/builtin-object-size-2.c
+++ b/gcc/testsuite/gcc.dg/builtin-object-size-2.c
@@ -1,5 +1,5 @@
 /* { dg-do run } */
-/* { dg-options "-O2" } */
+/* { dg-options "-O2 -Wno-stringop-overread" } */
 /* { dg-require-effective-target alloca } */

 typedef __SIZE_TYPE__ size_t;
@@ -7,10 +7,13 @@ extern void abort (void);
 extern void exit (int);
 extern void *malloc (size_t);
 extern void *calloc (size_t, size_t);
+extern void free (void *);
 extern void *alloca (size_t);
 extern void *memcpy (void *, const void *, size_t);
 extern void *memset (void *, int, size_t);
 extern char *strcpy (char *, const char *);
+extern char *strdup (const char *);
+extern char *strndup (const char *, size_t);

 struct A
 {
@@ -544,6 +547,63 @@ test8 (unsigned cond)
 #endif
 }

+/* Tests for strdup/strndup.  */
+size_t
+__attribute__ ((noinline))
+test9 (void)
+{
+  const char *ptr = "abcdefghijklmnopqrstuvwxyz";
+  char *res = strndup (ptr, 21);
+  if (__builtin_object_size (res, 1) != 22)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr, 32);
+  if (__builtin_object_size (res, 1) != 27)
+    abort ();
+
+  free (res);
+
+  res = strdup (ptr);
+  if (__builtin_object_size (res, 1) != 27)
+    abort ();
+
+  free (res);
+
+  char *ptr2 = malloc (64);
+  strcpy (ptr2, ptr);
+
+  res = strndup (ptr2, 21);
+  if (__builtin_object_size (res, 1) != 22)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr2, 32);
+  if (__builtin_object_size (res, 1) != 33)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr2, 128);
+  if (__builtin_object_size (res, 1) != 64)
+    abort ();
+
+  free (res);
+
+  res = strdup (ptr2);
+#ifdef __builtin_object_size
+  if (__builtin_object_size (res, 1) != 27)
+#else
+  if (__builtin_object_size (res, 1) != 64)
+#endif
+    abort ();
+
+  free (res);
+  free (ptr2);
+}
+
 int
 main (void)
 {
@@ -557,5 +617,6 @@ main (void)
   test6 ();
   test7 ();
   test8 (1);
+  test9 ();
   exit (0);
 }
diff --git a/gcc/testsuite/gcc.dg/builtin-object-size-3.c b/gcc/testsuite/gcc.dg/builtin-object-size-3.c
index 44a99189776..5c878a14647 100644
--- a/gcc/testsuite/gcc.dg/builtin-object-size-3.c
+++ b/gcc/testsuite/gcc.dg/builtin-object-size-3.c
@@ -1,5 +1,5 @@
 /* { dg-do run } */
-/* { dg-options "-O2" } */
+/* { dg-options "-O2 -Wno-stringop-overread" } */
 /* { dg-require-effective-target alloca } */

 typedef __SIZE_TYPE__ size_t;
@@ -7,10 +7,13 @@ extern void abort (void);
 extern void exit (int);
 extern void *malloc (size_t);
 extern void *calloc (size_t, size_t);
+extern void free (void *);
 extern void *alloca (size_t);
 extern void *memcpy (void *, const void *, size_t);
 extern void *memset (void *, int, size_t);
 extern char *strcpy (char *, const char *);
+extern char *strdup (const char *);
+extern char *strndup (const char *, size_t);

 struct A
 {
@@ -636,6 +639,63 @@ test10 (void)
     }
 }

+/* Tests for strdup/strndup.  */
+size_t
+__attribute__ ((noinline))
+test11 (void)
+{
+  const char *ptr = "abcdefghijklmnopqrstuvwxyz";
+  char *res = strndup (ptr, 21);
+  if (__builtin_object_size (res, 2) != 22)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr, 32);
+  if (__builtin_object_size (res, 2) != 27)
+    abort ();
+
+  free (res);
+
+  res = strdup (ptr);
+  if (__builtin_object_size (res, 2) != 27)
+    abort ();
+
+  free (res);
+
+  char *ptr2 = malloc (64);
+  strcpy (ptr2, ptr);
+
+  res = strndup (ptr2, 21);
+  if (__builtin_object_size (res, 2) != 0)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr2, 32);
+  if (__builtin_object_size (res, 2) != 0)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr2, 128);
+  if (__builtin_object_size (res, 2) != 0)
+    abort ();
+
+  free (res);
+
+  res = strdup (ptr2);
+#ifdef __builtin_object_size
+  if (__builtin_object_size (res, 2) != 27)
+#else
+  if (__builtin_object_size (res, 2) != 0)
+#endif
+    abort ();
+
+  free (res);
+  free (ptr2);
+}
+
 int
 main (void)
 {
@@ -651,5 +711,6 @@ main (void)
   test8 ();
   test9 (1);
   test10 ();
+  test11 ();
   exit (0);
 }
diff --git a/gcc/testsuite/gcc.dg/builtin-object-size-4.c b/gcc/testsuite/gcc.dg/builtin-object-size-4.c
index b9fddfed036..0b1cb1e528a 100644
--- a/gcc/testsuite/gcc.dg/builtin-object-size-4.c
+++ b/gcc/testsuite/gcc.dg/builtin-object-size-4.c
@@ -1,5 +1,5 @@
 /* { dg-do run } */
-/* { dg-options "-O2" } */
+/* { dg-options "-O2 -Wno-stringop-overread" } */
 /* { dg-require-effective-target alloca } */

 typedef __SIZE_TYPE__ size_t;
@@ -7,10 +7,13 @@ extern void abort (void);
 extern void exit (int);
 extern void *malloc (size_t);
 extern void *calloc (size_t, size_t);
+extern void free (void *);
 extern void *alloca (size_t);
 extern void *memcpy (void *, const void *, size_t);
 extern void *memset (void *, int, size_t);
 extern char *strcpy (char *, const char *);
+extern char *strdup (const char *);
+extern char *strndup (const char *, size_t);

 struct A
 {
@@ -517,6 +520,63 @@ test8 (unsigned cond)
 #endif
 }

+/* Tests for strdup/strndup.  */
+size_t
+__attribute__ ((noinline))
+test9 (void)
+{
+  const char *ptr = "abcdefghijklmnopqrstuvwxyz";
+  char *res = strndup (ptr, 21);
+  if (__builtin_object_size (res, 3) != 22)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr, 32);
+  if (__builtin_object_size (res, 3) != 27)
+    abort ();
+
+  free (res);
+
+  res = strdup (ptr);
+  if (__builtin_object_size (res, 3) != 27)
+    abort ();
+
+  free (res);
+
+  char *ptr2 = malloc (64);
+  strcpy (ptr2, ptr);
+
+  res = strndup (ptr2, 21);
+  if (__builtin_object_size (res, 3) != 0)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr2, 32);
+  if (__builtin_object_size (res, 3) != 0)
+    abort ();
+
+  free (res);
+
+  res = strndup (ptr2, 128);
+  if (__builtin_object_size (res, 3) != 0)
+    abort ();
+
+  free (res);
+
+  res = strdup (ptr2);
+#ifdef __builtin_object_size
+  if (__builtin_object_size (res, 3) != 27)
+#else
+  if (__builtin_object_size (res, 3) != 0)
+#endif
+    abort ();
+
+  free (res);
+  free (ptr2);
+}
+
 int
 main (void)
 {
@@ -530,5 +590,6 @@ main (void)
   test6 ();
   test7 ();
   test8 (1);
+  test9 ();
   exit (0);
 }
diff --git a/gcc/tree-object-size.cc b/gcc/tree-object-size.cc
index 4eb454a4a33..c075b71db56 100644
--- a/gcc/tree-object-size.cc
+++ b/gcc/tree-object-size.cc
@@ -495,6 +495,18 @@ decl_init_size (tree decl, bool min)
   return size;
 }

+/* Get the outermost object that PTR may point into.  */
+
+static tree
+get_whole_object (const_tree ptr)
+{
+  tree pt_var = TREE_OPERAND (ptr, 0);
+  while (handled_component_p (pt_var))
+    pt_var = TREE_OPERAND (pt_var, 0);
+
+  return pt_var;
+}
+
 /* Compute __builtin_object_size for PTR, which is a ADDR_EXPR.
    OBJECT_SIZE_TYPE is the second argument from __builtin_object_size.
    If unknown, return size_unknown (object_size_type).  */
@@ -514,9 +526,7 @@ addr_object_size (struct object_size_info *osi, const_tree ptr,
   if (pwholesize)
     *pwholesize = size_unknown (object_size_type);

-  pt_var = TREE_OPERAND (ptr, 0);
-  while (handled_component_p (pt_var))
-    pt_var = TREE_OPERAND (pt_var, 0);
+  pt_var = get_whole_object (ptr);

   if (!pt_var)
     return false;
@@ -789,6 +799,53 @@ alloc_object_size (const gcall *call, int object_size_type)
   return bytes ? bytes : size_unknown (object_size_type);
 }

+/* Compute __builtin_object_size for CALL, which is a call to either
+   BUILT_IN_STRDUP or BUILT_IN_STRNDUP; IS_STRNDUP indicates which it is.
+   OBJECT_SIZE_TYPE is the second argument from __builtin_object_size.
+   If unknown, return size_unknown (object_size_type).  */
+
+static tree
+strdup_object_size (const gcall *call, int object_size_type, bool is_strndup)
+{
+  tree src = gimple_call_arg (call, 0);
+  tree sz = size_unknown (object_size_type);
+  tree n = is_strndup ? gimple_call_arg (call, 1) : NULL_TREE;
+
+  /* For strdup, simply emit strlen (SRC) + 1 and let the optimizer fold it the
+     way it likes.  */
+  if (!is_strndup)
+    {
+      tree strlen_fn = builtin_decl_implicit (BUILT_IN_STRLEN);
+      if (strlen_fn)
+	sz = fold_build2 (PLUS_EXPR, sizetype, size_one_node,
+			  build_call_expr (strlen_fn, 1, src));
+    }
+
+  /* In all other cases, return the size of SRC since the object size cannot
+     exceed that.  We cannot do this for OST_MINIMUM unless SRC points into a
+     string constant since otherwise the object size could go all the way down
+     to zero.  */
+  if (!size_valid_p (sz, object_size_type)
+       || size_unknown_p (sz, object_size_type))
+    {
+      tree wholesrc = NULL_TREE;
+      if (TREE_CODE (src) == ADDR_EXPR)
+	wholesrc = get_whole_object (src);
+
+      if (!(object_size_type & OST_MINIMUM)
+	  || (wholesrc && TREE_CODE (wholesrc) == STRING_CST))
+	compute_builtin_object_size (src, object_size_type, &sz);
+    }
+
+  if (!n)
+    return sz;
+
+  /* Factor in the N.  Note that with OST_MINIMUM, even if N is known we return
+     0 since the size could be less than N.  */
+  return fold_build2 (MIN_EXPR, sizetype,
+		      fold_build2 (PLUS_EXPR, sizetype, size_one_node, n),
+		      sz);
+}

 /* If object size is propagated from one of function's arguments directly
    to its return value, return that argument for GIMPLE_CALL statement CALL.
@@ -1235,12 +1292,19 @@ call_object_size (struct object_size_info *osi, tree ptr, gcall *call)
 {
   int object_size_type = osi->object_size_type;
   unsigned int varno = SSA_NAME_VERSION (ptr);
+  tree bytes = NULL_TREE;

   gcc_assert (is_gimple_call (call));

   gcc_assert (!object_sizes_unknown_p (object_size_type, varno));
   gcc_assert (osi->pass == 0);
-  tree bytes = alloc_object_size (call, object_size_type);
+
+  bool is_strdup = gimple_call_builtin_p (call, BUILT_IN_STRDUP);
+  bool is_strndup = gimple_call_builtin_p (call, BUILT_IN_STRNDUP);
+  if (is_strdup || is_strndup)
+    bytes = strdup_object_size (call, object_size_type, is_strndup);
+  else
+    bytes = alloc_object_size (call, object_size_type);

   if (!size_valid_p (bytes, object_size_type))
     bytes = size_unknown (object_size_type);
@@ -2113,7 +2177,7 @@ const pass_data pass_data_object_sizes =
   PROP_objsz, /* properties_provided */
   0, /* properties_destroyed */
   0, /* todo_flags_start */
-  0, /* todo_flags_finish */
+  TODO_update_ssa_no_phi, /* todo_flags_finish */
 };

 class pass_object_sizes : public gimple_opt_pass
@@ -2153,7 +2217,7 @@ const pass_data pass_data_early_object_sizes =
   0, /* properties_provided */
   0, /* properties_destroyed */
   0, /* todo_flags_start */
-  0, /* todo_flags_finish */
+  TODO_update_ssa_no_phi, /* todo_flags_finish */
 };

 class pass_early_object_sizes : public gimple_opt_pass
--
2.37.1
