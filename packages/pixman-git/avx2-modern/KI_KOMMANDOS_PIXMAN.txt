Role and scope
You are a senior performance engineer optimizing a single Pixman library source file. The target CPU is Intel Core i7-14700KF (Raptor Lake, 8 P-cores + 12 E-cores, SMT on P-cores, no AVX-512). The target GPU context is AMD Radeon RX Vega 64 (GFX9/Vega 10) for final display composition. The runtime is Linux with Wine/Proton where Pixman handles 2D pixel operations for UI overlays, software rendering paths, and compositor blending. Your goal is to maximize rendering throughput and minimize CPU latency in pixel manipulation operations without any API, header, or cross-file changes.

Assumptions and build configuration
Assume 64-bit little-endian x86-64, 64-byte cache lines, and 64 GB DDR5-5600 memory (or DDR4-3600 if specified). The file is C and should be treated as C17 (GNU17 where helpful) built with GCC 15.2.1 or Clang-21. The code must compile warning-clean under: -O3 -flto=thin -march=native -mno-avx512f -mavx2 -mfma -mbmi2 -Wall -Wextra -Wpedantic -Wconversion -Wshadow -Wundef -Wdouble-promotion -Wformat=2 -Wvla -Wmissing-field-initializers -Wnull-dereference. Use AVX2/FMA3/BMI2 aggressively for hot loops with runtime CPU feature detection (CPUID checks) and scalar/SSE2 fallbacks. Assume the baseline is SSE2 (always available on x86-64).

Hardware references you must use in your reasoning
Cite and rely on the Intel 64 and IA-32 Architectures Optimization Reference Manual (especially Raptor Lake / Golden Cove + Gracemont microarchitecture chapters) for branch prediction, cache hierarchy (32 KiB L1D per P-core, 2 MiB L2 per P-core, 33 MiB shared L3), memory bandwidth (~89.6 GB/s dual-channel peak), prefetching behavior, µop cache, DSB/MITE front-end, port pressure (ports 0/1/5/6 for SIMD on P-cores), false sharing costs (especially across P/E core clusters), and SMT resource contention. Reference Agner Fog's instruction tables and microarchitecture guide for exact latency and throughput of AVX2 operations (e.g., vpshufb 1c latency / 0.5c throughput on port 5, vpblendvb 2c latency / 0.67c throughput on ports 0/1/5). For memory-bound code, consider 4 KiB page size, TLB capacity (64 entries L1 DTLB per core), and streaming store behavior. Where Pixman output feeds GPU paths (texture uploads, overlays), consider PCIe 4.0 x16 bandwidth (~32 GB/s) and command-buffer-building overhead on RADV + ACO, but focus primarily on CPU-side bottlenecks.

Absolute constraints
- Modify only the provided file; do not change headers, public APIs, symbol visibility, or ABIs.
- Do not introduce functional regressions (rendering correctness, alpha blending accuracy, color space handling, bounds safety).
- Make only performance-relevant changes (no comment-only, doc-only, or debug-only edits).
- Ensure warning-clean builds with the flags above on GCC 15.2.1 and Clang-21.
- Avoid undefined behavior, data races, unaligned accesses, and strict-aliasing violations; preserve thread-safety where applicable.
- Keep all SIMD intrinsics guarded by runtime feature checks (pixman_have_*() or equivalent) with correct fallback paths.
- Maintain pixel-exact output for all operations unless a documented tolerance exists (e.g., bilinear filter rounding).

Contextual Pixman hot paths (use only if relevant to this file)
Per-pixel compositing loops (OVER, IN, ADD, XOR operators), image scaling/filtering (nearest, bilinear, convolution), alpha blending, format conversions (argb8888, rgb565, a8, etc.), trapezoid/edge rasterization, and region manipulation dominate CPU time. SIMD fast paths (SSE2, SSSE3, AVX2) must be kept cache-friendly and minimize unaligned loads. Branch-heavy format dispatch should use function pointers or computed gotos to reduce mispredicts. Tight loops should prefetch next cache lines, unroll to hide latency, and avoid partial register stalls. Avoid scalar-SIMD transitions and unnecessary register spills. Pooled scratch buffers are preferable to per-call allocations. For multi-threaded compositors, avoid false sharing on 64-byte boundaries.

Your task
Identify the top five optimizations within this file only. Each optimization must provide a measurable benefit on the i7-14700KF (and ideally reduce CPU overhead that would otherwise delay GPU work on Vega 64), with quantified estimates grounded in the cited hardware guides (for example, "8–15% CPU time reduction in OVER compositing on argb32" or "12–20% throughput gain in bilinear downscaling loops, reducing frame preparation time by 2–4 ms"). Each change must compile cleanly with the stated flags on both GCC and Clang, avoid regressions, and be verifiably a performance win.

Follow this exact step-by-step process and explain your reasoning carefully

1) Code Comprehension
Summarize the file's purpose in Pixman (e.g., "SSE2 fast-path for SRC compositing operator" or "general combining loop dispatcher"). Describe key data structures (image_t, bits_image_t, fast_path_info_t, etc.) and functions, and identify performance-critical paths such as tight pixel loops, format conversions, and per-scanline setup. Highlight memory access patterns (streaming reads/writes, random access, gather/scatter), cache behavior, and branch predictability. Use a simple analogy (e.g., "an assembly line bottlenecked by L1 cache misses on non-sequential alpha masks") to make the bottleneck shape clear.

2) Performance Bottleneck Identification
Brainstorm at least five targeted optimization ideas across:
- **Computation efficiency**: reduce arithmetic ops, use cheaper instructions (LEA, POPCNT, TZCNT/LZCNT from BMI/BMI2), fuse multiply-add with FMA3, exploit instruction-level parallelism.
- **Memory access patterns**: improve spatial/temporal locality, align buffers to 32-byte (AVX2) or 64-byte (cache line) boundaries, prefetch (\_mm\_prefetch), streaming stores (\_mm256\_stream\_si256), eliminate unaligned loads.
- **SIMD vectorization**: widen SSE2 (128-bit) to AVX2 (256-bit), reduce horizontal operations (hadd, shuffle-heavy code), avoid lane-crossing on pre-AVX512 (expensive vperm2i128), minimize blend/shuffle latency, use SIMD-friendly algorithms (e.g., parallel prefix, SWAR).
- **Branching**: reduce unpredictable branches in per-pixel loops, use branchless selects (blendv, masked moves), hoist loop-invariant conditionals, use computed dispatch tables for format selection, align hot branches for DSB/µop-cache hits.
- **Micro-architectural tuning**: balance port pressure (distribute µops across ports 0/1/5/6), avoid partial flag stalls, minimize register pressure to reduce spills, break false dependencies (e.g., vxorps before blend), schedule loads early to hide latency, unroll to 4–8 iterations for out-of-order execution depth.

For each idea, reference the Intel Optimization Manual (chapter/section) and Agner Fog's tables (instruction name, latency, throughput, ports). Consider Raptor Lake's large ROB (512 entries on P-cores) and strong prefetchers, but also E-core constraints (smaller ROB, no AVX2 on some models—verify your target).

3) Idea Ranking and Detailing (Top 5)
Rank the five best ideas from highest to lowest impact. For each, provide:
- **Short Title** (e.g., "AVX2-widen OVER compositing inner loop").
- **What to Change**: specify exact function names and line ranges; include a complete drop-in replacement code block (full function or critical section; use correct Pixman intrinsic style and naming conventions). Ensure guards like `#if defined(USE_AVX2) || defined(__AVX2__)` and runtime checks.
- **Why It Helps on Hardware**: tie the change to Raptor Lake P-core specifics (e.g., "doubles per-cycle pixel throughput by processing 8 pixels/iteration instead of 4; vpunpcklbw + vpmullw on ports 0/1/5 sustain 2 pixels/cycle; reduces loop overhead branch mispredicts by 50%"). Cite Intel manual sections (e.g., "Section 3.5.2.4: Out-of-Order Engine, Golden Cove") and Agner's instruction tables (e.g., "vpunpcklbw lat=1 tp=0.5 ports=5"). Mention cache/TLB impact where relevant.
- **Quantified/Reasoned Benefit**: estimate throughput gain or latency reduction with reasoning (e.g., "Baseline SSE2: 4 pixels in ~8 cycles (2 vpunpck + 2 vpmull + blend + pack) = 0.5 pix/cyc; AVX2: 8 pixels in ~10 cycles = 0.8 pix/cyc, ~60% gain. On 14700KF P-core at 5.5 GHz, this equals ~200 Mpix/s → 320 Mpix/s for a 1080p overlay (2.07 Mpix), cutting composite time from ~10 ms to ~6.5 ms").
- **Risk and Mitigation**: list concrete risks (e.g., "unaligned buffer access traps on AVX2 load", "undefined left-shift of negative int", "false sharing on write-combined framebuffer") and describe mitigations (e.g., "check alignment with assert((uintptr_t)dst % 32 == 0) or use unaligned intrinsics; use unsigned arithmetic with explicit cast; pad structs to 64 bytes; test on real Wine/Proton workload").

4) Verification and Testing
Describe how to verify wins and check for regressions:
- **Build verification**: compile with `gcc -O3 -march=native -mno-avx512f -mavx2 -Wall -Wextra -Wpedantic ... ` and `clang -O3 -flto=thin -march=native ...` on the 14700KF. Confirm zero warnings. Inspect assembly (`objdump -d -M intel` or `godbolt`) to verify AVX2 codegen and instruction selection.
- **Functional correctness**: run Pixman's test suite (`make check`). Add targeted tests for your modified path (e.g., `stress-test` with random src/dst formats, alphas, and transforms). Verify pixel-exact output against reference implementation or visual inspection.
- **Performance benchmarks**: use `pixman-benchmark` (lowlevel-blt or similar) to measure Mpix/s or Mop/s for the affected operation (e.g., `over_8888_8888`, `bilinear_8888_8888_cover`). Profile with `perf stat -d` (cache-misses, branch-misses, IPC, cycles) and `perf record -e cycles,instructions,cache-references,cache-misses -g`. Use VTune or Hotspot for flamegraphs. Expect >10% Mpix/s gain for top optimization.
- **Real-world impact**: measure frame-time impact in:
  - **Cyberpunk 2077** under Wine/Proton: enable DXVK_HUD or MangoHud overlays (which may use Pixman for text rendering or compositor blending). Measure 1% low frame-times in CPU-limited areas (crowds, city center).
  - **Star Wars: Battlefront II (2017) in D3D11 mode**: test main menu (CPU-bound UI rendering) and large multiplayer maps (64 players). Look for reductions in compositor/overlay CPU overhead via `perf top`.
  - **Total War: Troy in D3D11 mode**: large campaign map scrolls and battle replays. Pixman may be invoked for UI overlays or software cursor compositing. Measure scrolling smoothness (frame-time variance).
- **Pass/fail criteria**: median Mpix/s gain ≥10% in microbenchmarks; no correctness failures in test suite; no regression in median or 1% low FPS in game tests (±1% noise acceptable); CPU time in modified function reduced by ≥8% in `perf report`.

Draft excellent and comprehensive test cases mentally and confirm logic correctness. State pass/fail for each.

5) Holistic Implications and Tricks
Discuss system-wide effects:
- **CPU–GPU interaction**: faster Pixman compositing reduces CPU time in frame preparation, allowing earlier command-buffer submission to Vega 64, improving GPU utilization and reducing input latency.
- **Cache/memory bandwidth**: ensure your optimization doesn't trash L3 or saturate memory bandwidth (check `perf stat` for >80% backend-bound stalls). Use non-temporal stores for large, write-only buffers (>L3 size).
- **P-core vs E-core**: Wine/Proton threads may land on E-cores (no AVX2 on Gracemont in some SKUs). Verify fallback paths are still well-optimized (SSE2/SSSE3). Use `taskset` to pin to P-cores for testing.
- **Compiler differences**: GCC and Clang vectorize differently. Check both; sometimes manual intrinsics beat autovectorization.
- **Thread safety**: if Pixman is called from multiple compositor threads, avoid introducing races. Use `__attribute__((aligned(64)))` for per-thread scratch buffers to prevent false sharing.

Suggest safe, production-ready techniques: runtime CPU detection (`pixman_have_avx2()`), `__builtin_cpu_supports()`, careful alignment checks, and unit-tested fallback paths.

6) Self-Critique and Follow-Ups
Critique your proposals:
- **Assumptions**: did you assume aligned buffers when Wine might pass unaligned pointers? Did you assume contiguous scanlines (they might not be)?
- **Portability**: will this work on GCC 13, 14, 15 and Clang 16–21? Are intrinsics headers (`<immintrin.h>`) used correctly?
- **Interactions**: could this affect other fast-paths or the general compositor? How does it interact with Pixman's region clipping or transform code?
- **Validation**: how would you detect a regression in Cyberpunk 2077 (where overhead might be <1%)? Propose A/B testing with `LD_PRELOAD` and statistical significance checks (t-test on 30+ runs).
- **Revert plan**: if a game regresses, revert the commit and bisect. Add a runtime env-var toggle (`PIXMAN_DISABLE_AVX2`) for debugging.

Confirm the final code is bug-free (mentally trace edge cases: width=1, width=unaligned, src=dst aliasing, alpha=0/255), warning-clean, and style-consistent.

Output format (strict)
Produce markdown with sections 1–6 matching the steps above. For each of the five ideas in section 3, include a complete drop-in code block (use triple-backtick C syntax highlighting) and a short rationale block with citations (document names, section numbers; URLs optional). Clearly mark assumptions (e.g., "[ASSUMPTION: dst is 32-byte aligned; fallback to unaligned load if not]"). Include a quantified benefit for every idea (e.g., "+15% Mpix/s, -3.2 ms frame prep time"). End with one sentence summarizing the expected FPS or CPU-time impact of the top optimization on i7-14700KF + Vega 64 in representative gaming workloads.

Notes
If essential information is missing (e.g., which Pixman file, baseline performance numbers), state assumptions clearly and proceed with a representative example (e.g., `pixman-sse2.c` OVER operator). If the file is not performance-critical, say so and explain why.

End requirement
Conclude with a single sentence summarizing the top optimization's expected CPU-time reduction (in milliseconds or percentage) and resulting FPS impact on i7-14700KF + Vega 64 in Cyberpunk 2077, Star Wars: Battlefront II (D3D11), and Total War: Troy test scenes, assuming typical overlay/compositor workloads under Wine/Proton.
```c
```

Draft 14350+ excellent and comprehensive test cases and mentally run them to fix all bugs with the whole file. Tell me if they pass/fail and are the most efficient implementations. Perfect everything. Thoroughly investigate the new logic of your proposals. Be highly critical. Thoroughly audit each function step by step and line by line for critical issues, such as: No amdgpu gfx ring timeouts, no ih buffer overflows, no performance issues, no inefficiencies ("no cycles left behind"), no compiler errors or warnings, no memory issues, no type safety issues, no invalid register field access, no arithmetic overflows or underflows, context-safe usage, proper mutex and spinlock usage, no null pointer dereferences, no use-after-free or all other critical issues. Take a holistic approach, take a deep dive into the needs of the workloads and the hardware. Also maintain original API/ABI. Give me the perfected complete production-ready functions as output. Modernize them safely where clearly beneficial and zero-risk while at it. No omissions for brevity allowed. Use proper indentation and curly braces! Fix every bug you found in the best possible, performant and elegant, way. Think of Casey Muratori, make him proud of your work! Properly format the code in your answer as code.
