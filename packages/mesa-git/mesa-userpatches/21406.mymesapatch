From 49857a6e2a6100043a51bad0bf73f996a48fd61a Mon Sep 17 00:00:00 2001
From: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date: Sat, 18 Feb 2023 23:32:30 +0100
Subject: [PATCH 1/5] radv: Add helper to hash stages.

---
 src/amd/vulkan/radv_pipeline_cache.c | 50 ++++++++++++++++------------
 src/amd/vulkan/radv_private.h        |  3 ++
 2 files changed, 31 insertions(+), 22 deletions(-)

diff --git a/src/amd/vulkan/radv_pipeline_cache.c b/src/amd/vulkan/radv_pipeline_cache.c
index dba7143546b9..d3c125ca8cc8 100644
--- a/src/amd/vulkan/radv_pipeline_cache.c
+++ b/src/amd/vulkan/radv_pipeline_cache.c
@@ -148,41 +148,47 @@ radv_hash_shaders(unsigned char *hash, const struct radv_pipeline_stage *stages,
 }
 
 void
-radv_hash_rt_shaders(unsigned char *hash, const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
-                     const struct radv_pipeline_key *key, uint32_t flags)
+radv_hash_rt_stages(struct mesa_sha1 *ctx, const VkPipelineShaderStageCreateInfo *stages,
+                    unsigned stage_count)
 {
-   RADV_FROM_HANDLE(radv_pipeline_layout, layout, pCreateInfo->layout);
-   struct mesa_sha1 ctx;
+   for (unsigned i = 0; i < stage_count; ++i) {
+      RADV_FROM_HANDLE(vk_shader_module, module, stages[i].module);
+      const VkSpecializationInfo *spec_info = stages[i].pSpecializationInfo;
 
-   _mesa_sha1_init(&ctx);
-   if (layout)
-      _mesa_sha1_update(&ctx, layout->sha1, sizeof(layout->sha1));
-
-   _mesa_sha1_update(&ctx, key, sizeof(*key));
-
-   for (uint32_t i = 0; i < pCreateInfo->stageCount; ++i) {
-      RADV_FROM_HANDLE(vk_shader_module, module, pCreateInfo->pStages[i].module);
-      const VkSpecializationInfo *spec_info = pCreateInfo->pStages[i].pSpecializationInfo;
-
-      const VkPipelineShaderStageModuleIdentifierCreateInfoEXT *iinfo =
-         vk_find_struct_const(pCreateInfo->pStages[i].pNext,
-               PIPELINE_SHADER_STAGE_MODULE_IDENTIFIER_CREATE_INFO_EXT);
+      const VkPipelineShaderStageModuleIdentifierCreateInfoEXT *iinfo = vk_find_struct_const(
+         stages[i].pNext, PIPELINE_SHADER_STAGE_MODULE_IDENTIFIER_CREATE_INFO_EXT);
 
       if (module) {
-         _mesa_sha1_update(&ctx, module->sha1, sizeof(module->sha1));
+         _mesa_sha1_update(ctx, module->sha1, sizeof(module->sha1));
       } else {
          assert(iinfo);
          assert(iinfo->identifierSize <= VK_MAX_SHADER_MODULE_IDENTIFIER_SIZE_EXT);
-         _mesa_sha1_update(&ctx, iinfo->pIdentifier, iinfo->identifierSize);
+         _mesa_sha1_update(ctx, iinfo->pIdentifier, iinfo->identifierSize);
       }
 
-      _mesa_sha1_update(&ctx, pCreateInfo->pStages[i].pName, strlen(pCreateInfo->pStages[i].pName));
+      _mesa_sha1_update(ctx, stages[i].pName, strlen(stages[i].pName));
       if (spec_info && spec_info->mapEntryCount) {
-         _mesa_sha1_update(&ctx, spec_info->pMapEntries,
+         _mesa_sha1_update(ctx, spec_info->pMapEntries,
                            spec_info->mapEntryCount * sizeof spec_info->pMapEntries[0]);
-         _mesa_sha1_update(&ctx, spec_info->pData, spec_info->dataSize);
+         _mesa_sha1_update(ctx, spec_info->pData, spec_info->dataSize);
       }
    }
+}
+
+void
+radv_hash_rt_shaders(unsigned char *hash, const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
+                     const struct radv_pipeline_key *key, uint32_t flags)
+{
+   RADV_FROM_HANDLE(radv_pipeline_layout, layout, pCreateInfo->layout);
+   struct mesa_sha1 ctx;
+
+   _mesa_sha1_init(&ctx);
+   if (layout)
+      _mesa_sha1_update(&ctx, layout->sha1, sizeof(layout->sha1));
+
+   _mesa_sha1_update(&ctx, key, sizeof(*key));
+
+   radv_hash_rt_stages(&ctx, pCreateInfo->pStages, pCreateInfo->stageCount);
 
    for (uint32_t i = 0; i < pCreateInfo->groupCount; i++) {
       _mesa_sha1_update(&ctx, &pCreateInfo->pGroups[i].type,
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index a11cc80af01c..c0a2e22b856d 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -1992,6 +1992,9 @@ void radv_hash_shaders(unsigned char *hash, const struct radv_pipeline_stage *st
                        uint32_t stage_count, const struct radv_pipeline_layout *layout,
                        const struct radv_pipeline_key *key, uint32_t flags);
 
+void radv_hash_rt_stages(struct mesa_sha1 *ctx, const VkPipelineShaderStageCreateInfo *stages,
+                         unsigned stage_count);
+
 void radv_hash_rt_shaders(unsigned char *hash, const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
                           const struct radv_pipeline_key *key, uint32_t flags);
 
-- 
GitLab


From 8830020d5f238fd30c3e4ac994b9bcac6c790517 Mon Sep 17 00:00:00 2001
From: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date: Wed, 11 Jan 2023 01:43:14 +0100
Subject: [PATCH 2/5] radv: Hash group handles as part of RT pipeline key.

So that we can start varying them  to avoid collisions while keeping
handles stable.
---
 src/amd/vulkan/radv_pipeline_cache.c |   6 +-
 src/amd/vulkan/radv_pipeline_rt.c    | 102 +++++++++++++++------------
 src/amd/vulkan/radv_private.h        |   4 +-
 3 files changed, 64 insertions(+), 48 deletions(-)

diff --git a/src/amd/vulkan/radv_pipeline_cache.c b/src/amd/vulkan/radv_pipeline_cache.c
index d3c125ca8cc8..e3e179df817d 100644
--- a/src/amd/vulkan/radv_pipeline_cache.c
+++ b/src/amd/vulkan/radv_pipeline_cache.c
@@ -177,7 +177,8 @@ radv_hash_rt_stages(struct mesa_sha1 *ctx, const VkPipelineShaderStageCreateInfo
 
 void
 radv_hash_rt_shaders(unsigned char *hash, const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
-                     const struct radv_pipeline_key *key, uint32_t flags)
+                     const struct radv_pipeline_key *key,
+                     const struct radv_pipeline_group_handle *group_handles, uint32_t flags)
 {
    RADV_FROM_HANDLE(radv_pipeline_layout, layout, pCreateInfo->layout);
    struct mesa_sha1 ctx;
@@ -190,6 +191,9 @@ radv_hash_rt_shaders(unsigned char *hash, const VkRayTracingPipelineCreateInfoKH
 
    radv_hash_rt_stages(&ctx, pCreateInfo->pStages, pCreateInfo->stageCount);
 
+   _mesa_sha1_update(&ctx, group_handles,
+                     sizeof(struct radv_pipeline_group_handle) * pCreateInfo->groupCount);
+
    for (uint32_t i = 0; i < pCreateInfo->groupCount; i++) {
       _mesa_sha1_update(&ctx, &pCreateInfo->pGroups[i].type,
                         sizeof(pCreateInfo->pGroups[i].type));
diff --git a/src/amd/vulkan/radv_pipeline_rt.c b/src/amd/vulkan/radv_pipeline_rt.c
index 3160b5724a95..02c783295df3 100644
--- a/src/amd/vulkan/radv_pipeline_rt.c
+++ b/src/amd/vulkan/radv_pipeline_rt.c
@@ -27,6 +27,57 @@
 #include "radv_private.h"
 #include "radv_shader.h"
 
+static VkResult
+radv_create_group_handles(const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
+                          struct radv_pipeline_group_handle **out_handles)
+{
+   struct radv_pipeline_group_handle *handles = calloc(sizeof(*handles), pCreateInfo->groupCount);
+   if (!handles) {
+      return VK_ERROR_OUT_OF_HOST_MEMORY;
+   }
+
+   /* For General and ClosestHit shaders, we can use the shader ID directly as handle.
+    * As (potentially different) AnyHit shaders are inlined, for Intersection shaders
+    * we use the Group ID.
+    */
+   for (unsigned i = 0; i < pCreateInfo->groupCount; ++i) {
+      const VkRayTracingShaderGroupCreateInfoKHR *group_info = &pCreateInfo->pGroups[i];
+      switch (group_info->type) {
+      case VK_RAY_TRACING_SHADER_GROUP_TYPE_GENERAL_KHR:
+         if (group_info->generalShader != VK_SHADER_UNUSED_KHR)
+            handles[i].general_index = group_info->generalShader + 2;
+         break;
+      case VK_RAY_TRACING_SHADER_GROUP_TYPE_PROCEDURAL_HIT_GROUP_KHR:
+         if (group_info->closestHitShader != VK_SHADER_UNUSED_KHR)
+            handles[i].closest_hit_index = group_info->closestHitShader + 2;
+         if (group_info->intersectionShader != VK_SHADER_UNUSED_KHR)
+            handles[i].intersection_index = i + 2;
+         break;
+      case VK_RAY_TRACING_SHADER_GROUP_TYPE_TRIANGLES_HIT_GROUP_KHR:
+         if (group_info->closestHitShader != VK_SHADER_UNUSED_KHR)
+            handles[i].closest_hit_index = group_info->closestHitShader + 2;
+         if (group_info->anyHitShader != VK_SHADER_UNUSED_KHR)
+            handles[i].any_hit_index = i + 2;
+         break;
+      case VK_SHADER_GROUP_SHADER_MAX_ENUM_KHR:
+         unreachable("VK_SHADER_GROUP_SHADER_MAX_ENUM_KHR");
+      }
+
+      if (pCreateInfo->flags &
+          VK_PIPELINE_CREATE_RAY_TRACING_SHADER_GROUP_HANDLE_CAPTURE_REPLAY_BIT_KHR) {
+         if (group_info->pShaderGroupCaptureReplayHandle &&
+             memcmp(group_info->pShaderGroupCaptureReplayHandle, &handles[i], sizeof(handles[i])) !=
+                0) {
+            free(handles);
+            return VK_ERROR_INVALID_OPAQUE_CAPTURE_ADDRESS;
+         }
+      }
+   }
+
+   *out_handles = handles;
+   return VK_SUCCESS;
+}
+
 static VkRayTracingPipelineCreateInfoKHR
 radv_create_merged_rt_create_info(const VkRayTracingPipelineCreateInfoKHR *pCreateInfo)
 {
@@ -352,12 +403,16 @@ radv_rt_pipeline_create(VkDevice _device, VkPipelineCache _cache,
    radv_pipeline_init(device, &rt_pipeline->base.base, RADV_PIPELINE_RAY_TRACING);
    rt_pipeline->group_count = local_create_info.groupCount;
 
+   result = radv_create_group_handles(&local_create_info, &rt_pipeline->group_handles);
+   if (result != VK_SUCCESS)
+      goto pipeline_fail;
+
    const VkPipelineCreationFeedbackCreateInfo *creation_feedback =
       vk_find_struct_const(pCreateInfo->pNext, PIPELINE_CREATION_FEEDBACK_CREATE_INFO);
 
    struct radv_pipeline_key key = radv_generate_rt_pipeline_key(rt_pipeline, pCreateInfo->flags);
 
-   radv_hash_rt_shaders(hash, &local_create_info, &key,
+   radv_hash_rt_shaders(hash, &local_create_info, &key, rt_pipeline->group_handles,
                         radv_get_hash_flags(device, keep_statistic_info));
 
    /* First check if we can get things from the cache before we take the expensive step of
@@ -391,53 +446,8 @@ radv_rt_pipeline_create(VkDevice _device, VkPipelineCache _cache,
 
    radv_compute_pipeline_init(&rt_pipeline->base, pipeline_layout);
 
-   rt_pipeline->group_handles =
-      calloc(sizeof(*rt_pipeline->group_handles), local_create_info.groupCount);
-   if (!rt_pipeline->group_handles) {
-      result = VK_ERROR_OUT_OF_HOST_MEMORY;
-      goto shader_fail;
-   }
-
    rt_pipeline->stack_size = compute_rt_stack_size(pCreateInfo, rt_pipeline->stack_sizes);
 
-   /* For General and ClosestHit shaders, we can use the shader ID directly as handle.
-    * As (potentially different) AnyHit shaders are inlined, for Intersection shaders
-    * we use the Group ID.
-    */
-   for (unsigned i = 0; i < local_create_info.groupCount; ++i) {
-      const VkRayTracingShaderGroupCreateInfoKHR *group_info = &local_create_info.pGroups[i];
-      switch (group_info->type) {
-      case VK_RAY_TRACING_SHADER_GROUP_TYPE_GENERAL_KHR:
-         if (group_info->generalShader != VK_SHADER_UNUSED_KHR)
-            rt_pipeline->group_handles[i].general_index = group_info->generalShader + 2;
-         break;
-      case VK_RAY_TRACING_SHADER_GROUP_TYPE_PROCEDURAL_HIT_GROUP_KHR:
-         if (group_info->closestHitShader != VK_SHADER_UNUSED_KHR)
-            rt_pipeline->group_handles[i].closest_hit_index = group_info->closestHitShader + 2;
-         if (group_info->intersectionShader != VK_SHADER_UNUSED_KHR)
-            rt_pipeline->group_handles[i].intersection_index = i + 2;
-         break;
-      case VK_RAY_TRACING_SHADER_GROUP_TYPE_TRIANGLES_HIT_GROUP_KHR:
-         if (group_info->closestHitShader != VK_SHADER_UNUSED_KHR)
-            rt_pipeline->group_handles[i].closest_hit_index = group_info->closestHitShader + 2;
-         if (group_info->anyHitShader != VK_SHADER_UNUSED_KHR)
-            rt_pipeline->group_handles[i].any_hit_index = i + 2;
-         break;
-      case VK_SHADER_GROUP_SHADER_MAX_ENUM_KHR:
-         unreachable("VK_SHADER_GROUP_SHADER_MAX_ENUM_KHR");
-      }
-
-      if (pCreateInfo->flags &
-          VK_PIPELINE_CREATE_RAY_TRACING_SHADER_GROUP_HANDLE_CAPTURE_REPLAY_BIT_KHR) {
-         if (group_info->pShaderGroupCaptureReplayHandle &&
-             memcmp(group_info->pShaderGroupCaptureReplayHandle, &rt_pipeline->group_handles[i],
-                    sizeof(rt_pipeline->group_handles[i])) != 0) {
-            result = VK_ERROR_INVALID_OPAQUE_CAPTURE_ADDRESS;
-            goto shader_fail;
-         }
-      }
-   }
-
    *pPipeline = radv_pipeline_to_handle(&rt_pipeline->base.base);
 
 shader_fail:
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index c0a2e22b856d..87fca8b5d519 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -1983,6 +1983,7 @@ struct radv_event {
 #define RADV_HASH_SHADER_NO_FMASK              (1 << 19)
 #define RADV_HASH_SHADER_NGG_STREAMOUT         (1 << 20)
 
+struct radv_pipeline_group_handle;
 struct radv_pipeline_key;
 
 void radv_pipeline_stage_init(const VkPipelineShaderStageCreateInfo *sinfo,
@@ -1996,7 +1997,8 @@ void radv_hash_rt_stages(struct mesa_sha1 *ctx, const VkPipelineShaderStageCreat
                          unsigned stage_count);
 
 void radv_hash_rt_shaders(unsigned char *hash, const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
-                          const struct radv_pipeline_key *key, uint32_t flags);
+                          const struct radv_pipeline_key *key,
+                          const struct radv_pipeline_group_handle *group_handles, uint32_t flags);
 
 uint32_t radv_get_hash_flags(const struct radv_device *device, bool stats);
 
-- 
GitLab


From 4b2ecb352cc7b4e4e2df0b5017b0c7319dca4a46 Mon Sep 17 00:00:00 2001
From: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date: Wed, 11 Jan 2023 01:30:24 +0100
Subject: [PATCH 3/5] radv: Use provided handles for switch cases in RT
 shaders.

---
 src/amd/vulkan/radv_pipeline_rt.c |  3 +-
 src/amd/vulkan/radv_rt_shader.c   | 86 ++++++++++++++++++++++---------
 src/amd/vulkan/radv_shader.h      |  2 +
 3 files changed, 66 insertions(+), 25 deletions(-)

diff --git a/src/amd/vulkan/radv_pipeline_rt.c b/src/amd/vulkan/radv_pipeline_rt.c
index 02c783295df3..197dcd9f6c69 100644
--- a/src/amd/vulkan/radv_pipeline_rt.c
+++ b/src/amd/vulkan/radv_pipeline_rt.c
@@ -435,7 +435,8 @@ radv_rt_pipeline_create(VkDevice _device, VkPipelineCache _cache,
          goto pipeline_fail;
       }
 
-      shader = create_rt_shader(device, &local_create_info, rt_pipeline->stack_sizes, &key);
+      shader = create_rt_shader(device, &local_create_info, rt_pipeline->stack_sizes,
+                                rt_pipeline->group_handles, &key);
       module.nir = shader;
       result = radv_compute_pipeline_compile(
          &rt_pipeline->base, pipeline_layout, device, cache, &key, &stage, pCreateInfo->flags,
diff --git a/src/amd/vulkan/radv_rt_shader.c b/src/amd/vulkan/radv_rt_shader.c
index 61329b5bb044..b435d4e3d075 100644
--- a/src/amd/vulkan/radv_rt_shader.c
+++ b/src/amd/vulkan/radv_rt_shader.c
@@ -1078,10 +1078,20 @@ init_traversal_vars(nir_builder *b)
    return ret;
 }
 
+struct traversal_data {
+   struct radv_device *device;
+   const VkRayTracingPipelineCreateInfoKHR *createInfo;
+   struct rt_variables *vars;
+   struct rt_traversal_vars *trav_vars;
+   nir_variable *barycentrics;
+
+   const struct radv_pipeline_group_handle *handles;
+};
+
 static void
 visit_any_hit_shaders(struct radv_device *device,
                       const VkRayTracingPipelineCreateInfoKHR *pCreateInfo, nir_builder *b,
-                      struct rt_variables *vars)
+                      struct traversal_data *data, struct rt_variables *vars)
 {
    nir_ssa_def *sbt_idx = nir_load_var(b, vars->idx);
 
@@ -1102,25 +1112,26 @@ visit_any_hit_shaders(struct radv_device *device,
       if (shader_id == VK_SHADER_UNUSED_KHR)
          continue;
 
+      /* Avoid emitting stages with the same shaders/handles multiple times. */
+      bool is_dup = false;
+      for (unsigned j = 0; j < i; ++j)
+         if (data->handles[j].any_hit_index == data->handles[i].any_hit_index)
+            is_dup = true;
+
+      if (is_dup)
+         continue;
+
       const VkPipelineShaderStageCreateInfo *stage = &pCreateInfo->pStages[shader_id];
       nir_shader *nir_stage = parse_rt_stage(device, stage, vars->key);
 
       vars->stage_idx = shader_id;
-      insert_rt_case(b, nir_stage, vars, sbt_idx, 0, i + 2);
+      insert_rt_case(b, nir_stage, vars, sbt_idx, 0, data->handles[i].any_hit_index);
    }
 
    if (!(vars->create_info->flags & VK_PIPELINE_CREATE_RAY_TRACING_NO_NULL_ANY_HIT_SHADERS_BIT_KHR))
       nir_pop_if(b, NULL);
 }
 
-struct traversal_data {
-   struct radv_device *device;
-   const VkRayTracingPipelineCreateInfoKHR *createInfo;
-   struct rt_variables *vars;
-   struct rt_traversal_vars *trav_vars;
-   nir_variable *barycentrics;
-};
-
 static void
 handle_candidate_triangle(nir_builder *b, struct radv_triangle_intersection *intersection,
                           const struct radv_ray_traversal_args *args,
@@ -1158,7 +1169,7 @@ handle_candidate_triangle(nir_builder *b, struct radv_triangle_intersection *int
 
       load_sbt_entry(b, &inner_vars, sbt_idx, SBT_HIT, SBT_ANY_HIT_IDX);
 
-      visit_any_hit_shaders(data->device, data->createInfo, b, &inner_vars);
+      visit_any_hit_shaders(data->device, data->createInfo, b, args->data, &inner_vars);
 
       nir_push_if(b, nir_inot(b, nir_load_var(b, data->vars->ahit_accept)));
       {
@@ -1237,6 +1248,15 @@ handle_candidate_aabb(nir_builder *b, struct radv_leaf_intersection *intersectio
       if (shader_id == VK_SHADER_UNUSED_KHR)
          continue;
 
+      /* Avoid emitting stages with the same shaders/handles multiple times. */
+      bool is_dup = false;
+      for (unsigned j = 0; j < i; ++j)
+         if (data->handles[j].intersection_index == data->handles[i].intersection_index)
+            is_dup = true;
+
+      if (is_dup)
+         continue;
+
       const VkPipelineShaderStageCreateInfo *stage = &data->createInfo->pStages[shader_id];
       nir_shader *nir_stage = parse_rt_stage(data->device, stage, data->vars->key);
 
@@ -1250,7 +1270,8 @@ handle_candidate_aabb(nir_builder *b, struct radv_leaf_intersection *intersectio
       }
 
       inner_vars.stage_idx = shader_id;
-      insert_rt_case(b, nir_stage, &inner_vars, nir_load_var(b, inner_vars.idx), 0, i + 2);
+      insert_rt_case(b, nir_stage, &inner_vars, nir_load_var(b, inner_vars.idx), 0,
+                     data->handles[i].intersection_index);
    }
 
    if (!(data->vars->create_info->flags &
@@ -1297,6 +1318,7 @@ static nir_shader *
 build_traversal_shader(struct radv_device *device,
                        const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
                        struct radv_pipeline_shader_stack_size *stack_sizes,
+                       const struct radv_pipeline_group_handle *handles,
                        const struct radv_pipeline_key *key)
 {
    /* Create the traversal shader as an intersection shader to prevent validation failures due to
@@ -1383,6 +1405,7 @@ build_traversal_shader(struct radv_device *device,
       .vars = &vars,
       .trav_vars = &trav_vars,
       .barycentrics = barycentrics,
+      .handles = handles,
    };
 
    struct radv_ray_traversal_args args = {
@@ -1518,6 +1541,7 @@ lower_hit_attribs(nir_shader *shader, nir_variable **hit_attribs)
 nir_shader *
 create_rt_shader(struct radv_device *device, const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
                  struct radv_pipeline_shader_stack_size *stack_sizes,
+                 const struct radv_pipeline_group_handle *handles,
                  const struct radv_pipeline_key *key)
 {
    nir_builder b = radv_meta_init_shader(device, MESA_SHADER_COMPUTE, "rt_combined");
@@ -1554,23 +1578,37 @@ create_rt_shader(struct radv_device *device, const VkRayTracingPipelineCreateInf
    nir_ssa_def *idx = nir_load_var(&b, vars.idx);
 
    /* Insert traversal shader */
-   nir_shader *traversal = build_traversal_shader(device, pCreateInfo, stack_sizes, key);
+   nir_shader *traversal = build_traversal_shader(device, pCreateInfo, stack_sizes, handles, key);
    assert(b.shader->info.shared_size == 0);
    b.shader->info.shared_size = traversal->info.shared_size;
    assert(b.shader->info.shared_size <= 32768);
    insert_rt_case(&b, traversal, &vars, idx, 0, 1);
 
-   /* We do a trick with the indexing of the resume shaders so that the first
-    * shader of stage x always gets id x and the resume shader ids then come after
-    * stageCount. This makes the shadergroup handles independent of compilation. */
-   unsigned call_idx_base = pCreateInfo->stageCount + 1;
-   for (unsigned i = 0; i < pCreateInfo->stageCount; ++i) {
-      const VkPipelineShaderStageCreateInfo *stage = &pCreateInfo->pStages[i];
-      gl_shader_stage type = vk_to_mesa_shader_stage(stage->stage);
-      if (type != MESA_SHADER_RAYGEN && type != MESA_SHADER_CALLABLE &&
-          type != MESA_SHADER_CLOSEST_HIT && type != MESA_SHADER_MISS)
+   unsigned call_idx_base = 1;
+   for (unsigned i = 0; i < pCreateInfo->groupCount; ++i) {
+      unsigned stage_idx = VK_SHADER_UNUSED_KHR;
+      if (pCreateInfo->pGroups[i].type == VK_RAY_TRACING_SHADER_GROUP_TYPE_GENERAL_KHR)
+         stage_idx = pCreateInfo->pGroups[i].generalShader;
+      else
+         stage_idx = pCreateInfo->pGroups[i].closestHitShader;
+
+      if (stage_idx == VK_SHADER_UNUSED_KHR)
          continue;
 
+      /* Avoid emitting stages with the same shaders/handles multiple times. */
+      bool is_dup = false;
+      for (unsigned j = 0; j < i; ++j)
+         if (handles[j].general_index == handles[i].general_index)
+            is_dup = true;
+
+      if (is_dup)
+         continue;
+
+      const VkPipelineShaderStageCreateInfo *stage = &pCreateInfo->pStages[stage_idx];
+      ASSERTED gl_shader_stage type = vk_to_mesa_shader_stage(stage->stage);
+      assert(type == MESA_SHADER_RAYGEN || type == MESA_SHADER_CALLABLE ||
+             type == MESA_SHADER_CLOSEST_HIT || type == MESA_SHADER_MISS);
+
       nir_shader *nir_stage = parse_rt_stage(device, stage, key);
 
       /* Move ray tracing system values to the top that are set by rt_trace_ray
@@ -1588,8 +1626,8 @@ create_rt_shader(struct radv_device *device, const VkRayTracingPipelineCreateInf
       nir_shader **resume_shaders = NULL;
       nir_lower_shader_calls(nir_stage, &opts, &resume_shaders, &num_resume_shaders, nir_stage);
 
-      vars.stage_idx = i;
-      insert_rt_case(&b, nir_stage, &vars, idx, call_idx_base, i + 2);
+      vars.stage_idx = stage_idx;
+      insert_rt_case(&b, nir_stage, &vars, idx, call_idx_base, handles[i].general_index);
       for (unsigned j = 0; j < num_resume_shaders; ++j) {
          insert_rt_case(&b, resume_shaders[j], &vars, idx, call_idx_base, call_idx_base + 1 + j);
       }
diff --git a/src/amd/vulkan/radv_shader.h b/src/amd/vulkan/radv_shader.h
index f928e3d3a75b..d9d69708ff96 100644
--- a/src/amd/vulkan/radv_shader.h
+++ b/src/amd/vulkan/radv_shader.h
@@ -47,6 +47,7 @@ struct radv_physical_device;
 struct radv_device;
 struct radv_pipeline;
 struct radv_pipeline_cache;
+struct radv_pipeline_group_handle;
 struct radv_pipeline_key;
 struct radv_shader_args;
 struct radv_vs_input_state;
@@ -755,6 +756,7 @@ bool radv_lower_fs_intrinsics(nir_shader *nir, const struct radv_pipeline_stage
 nir_shader *create_rt_shader(struct radv_device *device,
                              const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
                              struct radv_pipeline_shader_stack_size *stack_sizes,
+                             const struct radv_pipeline_group_handle *handles,
                              const struct radv_pipeline_key *key);
 
 #endif
-- 
GitLab


From 9d70fd369365a4a539c655e4cb5f87044c4ae546 Mon Sep 17 00:00:00 2001
From: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date: Wed, 11 Jan 2023 02:32:27 +0100
Subject: [PATCH 4/5] radv: Use group handles based on shader hashes.

Should be stable.
---
 src/amd/vulkan/radv_device.c      | 11 +++-
 src/amd/vulkan/radv_pipeline_rt.c | 88 ++++++++++++++++++++++++++-----
 src/amd/vulkan/radv_private.h     |  3 ++
 3 files changed, 87 insertions(+), 15 deletions(-)

diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index e903c65a9570..c2c938ceae9b 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -1815,7 +1815,7 @@ radv_GetPhysicalDeviceFeatures2(VkPhysicalDevice physicalDevice,
             (VkPhysicalDeviceRayTracingPipelineFeaturesKHR *)ext;
          features->rayTracingPipeline = true;
          features->rayTracingPipelineShaderGroupHandleCaptureReplay = true;
-         features->rayTracingPipelineShaderGroupHandleCaptureReplayMixed = true;
+         features->rayTracingPipelineShaderGroupHandleCaptureReplayMixed = false;
          features->rayTracingPipelineTraceRaysIndirect = true;
          features->rayTraversalPrimitiveCulling = true;
          break;
@@ -3914,6 +3914,9 @@ radv_CreateDevice(VkPhysicalDevice physicalDevice, const VkDeviceCreateInfo *pCr
    device->physical_device = physical_device;
    simple_mtx_init(&device->trace_mtx, mtx_plain);
    simple_mtx_init(&device->pstate_mtx, mtx_plain);
+   simple_mtx_init(&device->rt_handles_mtx, mtx_plain);
+
+   device->rt_handles = _mesa_hash_table_create(NULL, _mesa_hash_u32, _mesa_key_u32_equal);
 
    device->ws = physical_device->ws;
    vk_device_set_drm_fd(&device->vk, device->ws->get_fd(device->ws));
@@ -4249,8 +4252,11 @@ fail:
          device->ws->ctx_destroy(device->hw_ctx[i]);
    }
 
+   _mesa_hash_table_destroy(device->rt_handles, NULL);
+
    simple_mtx_destroy(&device->pstate_mtx);
    simple_mtx_destroy(&device->trace_mtx);
+   simple_mtx_destroy(&device->rt_handles_mtx);
    mtx_destroy(&device->overallocation_mutex);
 
    vk_device_finish(&device->vk);
@@ -4290,6 +4296,8 @@ radv_DestroyDevice(VkDevice _device, const VkAllocationCallbacks *pAllocator)
       vk_free(&device->vk.alloc, device->private_sdma_queue);
    }
 
+   _mesa_hash_table_destroy(device->rt_handles, NULL);
+
    for (unsigned i = 0; i < RADV_NUM_HW_CTX; i++) {
       if (device->hw_ctx[i])
          device->ws->ctx_destroy(device->hw_ctx[i]);
@@ -4298,6 +4306,7 @@ radv_DestroyDevice(VkDevice _device, const VkAllocationCallbacks *pAllocator)
    mtx_destroy(&device->overallocation_mutex);
    simple_mtx_destroy(&device->pstate_mtx);
    simple_mtx_destroy(&device->trace_mtx);
+   simple_mtx_destroy(&device->rt_handles_mtx);
 
    radv_device_finish_meta(device);
 
diff --git a/src/amd/vulkan/radv_pipeline_rt.c b/src/amd/vulkan/radv_pipeline_rt.c
index 197dcd9f6c69..19db7f69198f 100644
--- a/src/amd/vulkan/radv_pipeline_rt.c
+++ b/src/amd/vulkan/radv_pipeline_rt.c
@@ -27,8 +27,61 @@
 #include "radv_private.h"
 #include "radv_shader.h"
 
+struct rt_handle_hash_entry {
+   uint32_t key;
+   char hash[20];
+};
+
+static uint32_t
+handle_from_stages(struct radv_device *device, const VkPipelineShaderStageCreateInfo *stages,
+                   unsigned stage_count, bool replay_namespace)
+{
+   struct mesa_sha1 ctx;
+   _mesa_sha1_init(&ctx);
+
+   radv_hash_rt_stages(&ctx, stages, stage_count);
+   unsigned char hash[20];
+   _mesa_sha1_final(&ctx, hash);
+
+   uint32_t ret;
+   memcpy(&ret, hash, sizeof(ret));
+
+   /* Leave the low half for resume shaders etc. */
+   ret |= 1u << 31;
+
+   /* Ensure we have dedicated space for replayable shaders */
+   ret &= ~(1u << 30);
+   ret |= replay_namespace << 30;
+
+   simple_mtx_lock(&device->rt_handles_mtx);
+
+   struct hash_entry *he = NULL;
+   for (;;) {
+      he = _mesa_hash_table_search(device->rt_handles, &ret);
+      if (!he)
+         break;
+
+      if (memcmp(he->data, hash, sizeof(hash)) == 0)
+         break;
+
+      ++ret;
+   }
+
+   if (!he) {
+      struct rt_handle_hash_entry *e = ralloc(device->rt_handles, struct rt_handle_hash_entry);
+      e->key = ret;
+      memcpy(e->hash, hash, sizeof(e->hash));
+      _mesa_hash_table_insert(device->rt_handles, &e->key, &e->hash);
+   }
+
+   simple_mtx_unlock(&device->rt_handles_mtx);
+
+   return ret;
+}
+
 static VkResult
-radv_create_group_handles(const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
+radv_create_group_handles(struct radv_device *device,
+                          const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
                           struct radv_pipeline_group_handle **out_handles)
 {
    struct radv_pipeline_group_handle *handles = calloc(sizeof(*handles), pCreateInfo->groupCount);
@@ -36,35 +89,42 @@ radv_create_group_handles(const VkRayTracingPipelineCreateInfoKHR *pCreateInfo,
       return VK_ERROR_OUT_OF_HOST_MEMORY;
    }
 
-   /* For General and ClosestHit shaders, we can use the shader ID directly as handle.
-    * As (potentially different) AnyHit shaders are inlined, for Intersection shaders
-    * we use the Group ID.
-    */
+   bool capture_replay = pCreateInfo->flags &
+                         VK_PIPELINE_CREATE_RAY_TRACING_SHADER_GROUP_HANDLE_CAPTURE_REPLAY_BIT_KHR;
    for (unsigned i = 0; i < pCreateInfo->groupCount; ++i) {
       const VkRayTracingShaderGroupCreateInfoKHR *group_info = &pCreateInfo->pGroups[i];
       switch (group_info->type) {
       case VK_RAY_TRACING_SHADER_GROUP_TYPE_GENERAL_KHR:
          if (group_info->generalShader != VK_SHADER_UNUSED_KHR)
-            handles[i].general_index = group_info->generalShader + 2;
+            handles[i].general_index = handle_from_stages(
+               device, &pCreateInfo->pStages[group_info->generalShader], 1, capture_replay);
          break;
       case VK_RAY_TRACING_SHADER_GROUP_TYPE_PROCEDURAL_HIT_GROUP_KHR:
          if (group_info->closestHitShader != VK_SHADER_UNUSED_KHR)
-            handles[i].closest_hit_index = group_info->closestHitShader + 2;
-         if (group_info->intersectionShader != VK_SHADER_UNUSED_KHR)
-            handles[i].intersection_index = i + 2;
+            handles[i].closest_hit_index = handle_from_stages(
+               device, &pCreateInfo->pStages[group_info->closestHitShader], 1, capture_replay);
+         if (group_info->intersectionShader != VK_SHADER_UNUSED_KHR) {
+            VkPipelineShaderStageCreateInfo stages[2];
+            unsigned cnt = 0;
+            stages[cnt++] = pCreateInfo->pStages[group_info->intersectionShader];
+            if (group_info->anyHitShader != VK_SHADER_UNUSED_KHR)
+               stages[cnt++] = pCreateInfo->pStages[group_info->anyHitShader];
+            handles[i].intersection_index = handle_from_stages(device, stages, cnt, capture_replay);
+         }
          break;
       case VK_RAY_TRACING_SHADER_GROUP_TYPE_TRIANGLES_HIT_GROUP_KHR:
          if (group_info->closestHitShader != VK_SHADER_UNUSED_KHR)
-            handles[i].closest_hit_index = group_info->closestHitShader + 2;
+            handles[i].closest_hit_index = handle_from_stages(
+               device, &pCreateInfo->pStages[group_info->closestHitShader], 1, capture_replay);
          if (group_info->anyHitShader != VK_SHADER_UNUSED_KHR)
-            handles[i].any_hit_index = i + 2;
+            handles[i].any_hit_index = handle_from_stages(
+               device, &pCreateInfo->pStages[group_info->anyHitShader], 1, capture_replay);
          break;
       case VK_SHADER_GROUP_SHADER_MAX_ENUM_KHR:
          unreachable("VK_SHADER_GROUP_SHADER_MAX_ENUM_KHR");
       }
 
-      if (pCreateInfo->flags &
-          VK_PIPELINE_CREATE_RAY_TRACING_SHADER_GROUP_HANDLE_CAPTURE_REPLAY_BIT_KHR) {
+      if (capture_replay) {
          if (group_info->pShaderGroupCaptureReplayHandle &&
              memcmp(group_info->pShaderGroupCaptureReplayHandle, &handles[i], sizeof(handles[i])) !=
                 0) {
@@ -403,7 +463,7 @@ radv_rt_pipeline_create(VkDevice _device, VkPipelineCache _cache,
    radv_pipeline_init(device, &rt_pipeline->base.base, RADV_PIPELINE_RAY_TRACING);
    rt_pipeline->group_count = local_create_info.groupCount;
 
-   result = radv_create_group_handles(&local_create_info, &rt_pipeline->group_handles);
+   result = radv_create_group_handles(device, &local_create_info, &rt_pipeline->group_handles);
    if (result != VK_SUCCESS)
       goto pipeline_fail;
 
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index 87fca8b5d519..f0816afe1d8f 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -1040,6 +1040,9 @@ struct radv_device {
    bool uses_device_generated_commands;
 
    bool uses_shadow_regs;
+
+   struct hash_table *rt_handles;
+   simple_mtx_t rt_handles_mtx;
 };
 
 bool radv_device_set_pstate(struct radv_device *device, bool enable);
-- 
GitLab


From 1552114773965280019a33753754fdd3352ceae8 Mon Sep 17 00:00:00 2001
From: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date: Sat, 18 Feb 2023 16:16:27 +0100
Subject: [PATCH 5/5] radv: Implement & expose
 VK_EXT_pipeline_library_group_handles.

---
 docs/features.txt                 |  1 +
 docs/relnotes/new_features.txt    |  1 +
 src/amd/vulkan/radv_device.c      |  7 +++++++
 src/amd/vulkan/radv_pipeline.c    |  1 +
 src/amd/vulkan/radv_pipeline_rt.c | 18 ++++++++++++++----
 src/amd/vulkan/radv_private.h     |  2 ++
 6 files changed, 26 insertions(+), 4 deletions(-)

diff --git a/docs/features.txt b/docs/features.txt
index 08c8a5ec5463..21cd576bf3ef 100644
--- a/docs/features.txt
+++ b/docs/features.txt
@@ -572,6 +572,7 @@ Khronos extensions that are not part of any Vulkan version:
   VK_EXT_non_seamless_cube_map                          DONE (anv, lvp, radv, tu)
   VK_EXT_pci_bus_info                                   DONE (anv, radv, vn)
   VK_EXT_physical_device_drm                            DONE (anv, radv, tu, v3dv, vn)
+  VK_EXT_pipeline_library_group_handles                 DONE (radv)
   VK_EXT_pipeline_robustness                            DONE (v3dv)
   VK_EXT_post_depth_coverage                            DONE (anv/gfx10+, lvp, radv/gfx10+)
   VK_EXT_primitive_topology_list_restart                DONE (anv, lvp, radv, tu, v3dv, vn)
diff --git a/docs/relnotes/new_features.txt b/docs/relnotes/new_features.txt
index e69de29bb2d1..a45394526749 100644
--- a/docs/relnotes/new_features.txt
+++ b/docs/relnotes/new_features.txt
@@ -0,0 +1 @@
+VK_EXT_pipeline_library_group_handles on RADV
diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index c2c938ceae9b..25f925baa4f8 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -630,6 +630,7 @@ radv_physical_device_get_supported_extensions(const struct radv_physical_device
 #endif
       .EXT_pipeline_creation_cache_control = true,
       .EXT_pipeline_creation_feedback = true,
+      .EXT_pipeline_library_group_handles = true,
       .EXT_post_depth_coverage = device->rad_info.gfx_level >= GFX10,
       .EXT_primitive_topology_list_restart = true,
       .EXT_primitives_generated_query = true,
@@ -1810,6 +1811,12 @@ radv_GetPhysicalDeviceFeatures2(VkPhysicalDevice physicalDevice,
          features->rayQuery = true;
          break;
       }
+      case VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_LIBRARY_GROUP_HANDLES_FEATURES_EXT: {
+         VkPhysicalDevicePipelineLibraryGroupHandlesFeaturesEXT *features =
+            (VkPhysicalDevicePipelineLibraryGroupHandlesFeaturesEXT *)ext;
+         features->pipelineLibraryGroupHandles = true;
+         break;
+      }
       case VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_PIPELINE_FEATURES_KHR: {
          VkPhysicalDeviceRayTracingPipelineFeaturesKHR *features =
             (VkPhysicalDeviceRayTracingPipelineFeaturesKHR *)ext;
diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index 759b60498537..cc030c2a0e9e 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -142,6 +142,7 @@ radv_pipeline_destroy(struct radv_device *device, struct radv_pipeline *pipeline
       struct radv_library_pipeline *library_pipeline = radv_pipeline_to_library(pipeline);
 
       ralloc_free(library_pipeline->ctx);
+      free(library_pipeline->group_handles);
    } else if (pipeline->type == RADV_PIPELINE_GRAPHICS_LIB) {
       struct radv_graphics_lib_pipeline *gfx_pipeline_lib =
          radv_pipeline_to_graphics_lib(pipeline);
diff --git a/src/amd/vulkan/radv_pipeline_rt.c b/src/amd/vulkan/radv_pipeline_rt.c
index 19db7f69198f..599a7430d746 100644
--- a/src/amd/vulkan/radv_pipeline_rt.c
+++ b/src/amd/vulkan/radv_pipeline_rt.c
@@ -227,6 +227,11 @@ radv_rt_pipeline_library_create(VkDevice _device, VkPipelineCache _cache,
    if (!local_create_info.pStages || !local_create_info.pGroups)
       goto fail;
 
+   VkResult result =
+      radv_create_group_handles(device, &local_create_info, &pipeline->group_handles);
+   if (result != VK_SUCCESS)
+      goto fail;
+
    if (local_create_info.stageCount) {
       pipeline->stage_count = local_create_info.stageCount;
 
@@ -326,6 +331,7 @@ radv_rt_pipeline_library_create(VkDevice _device, VkPipelineCache _cache,
    free((void *)local_create_info.pStages);
    return VK_SUCCESS;
 fail:
+   free(pipeline->groups);
    ralloc_free(pipeline->ctx);
    free((void *)local_create_info.pGroups);
    free((void *)local_create_info.pStages);
@@ -567,16 +573,20 @@ radv_GetRayTracingShaderGroupHandlesKHR(VkDevice device, VkPipeline _pipeline, u
                                         uint32_t groupCount, size_t dataSize, void *pData)
 {
    RADV_FROM_HANDLE(radv_pipeline, pipeline, _pipeline);
-   struct radv_ray_tracing_pipeline *rt_pipeline = radv_pipeline_to_ray_tracing(pipeline);
+   struct radv_pipeline_group_handle *handles;
+   if (pipeline->type == RADV_PIPELINE_LIBRARY) {
+      handles = radv_pipeline_to_library(pipeline)->group_handles;
+   } else {
+      handles = radv_pipeline_to_ray_tracing(pipeline)->group_handles;
+   }
    char *data = pData;
 
-   STATIC_ASSERT(sizeof(*rt_pipeline->group_handles) <= RADV_RT_HANDLE_SIZE);
+   STATIC_ASSERT(sizeof(*handles) <= RADV_RT_HANDLE_SIZE);
 
    memset(data, 0, groupCount * RADV_RT_HANDLE_SIZE);
 
    for (uint32_t i = 0; i < groupCount; ++i) {
-      memcpy(data + i * RADV_RT_HANDLE_SIZE, &rt_pipeline->group_handles[firstGroup + i],
-             sizeof(*rt_pipeline->group_handles));
+      memcpy(data + i * RADV_RT_HANDLE_SIZE, &handles[firstGroup + i], sizeof(*handles));
    }
 
    return VK_SUCCESS;
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index f0816afe1d8f..56a37cc9a2db 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -2215,6 +2215,8 @@ struct radv_library_pipeline {
    struct {
       uint8_t sha1[SHA1_DIGEST_LENGTH];
    } *hashes;
+
+   struct radv_pipeline_group_handle *group_handles;
 };
 
 struct radv_graphics_lib_pipeline {
-- 
GitLab

