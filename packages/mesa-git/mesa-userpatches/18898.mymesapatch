From e021cb93629a554aa39dd989f78f96e1d4f3dd06 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Tue, 22 Nov 2022 14:25:52 +0800
Subject: [PATCH 1/8] ac/nir: legacy vs/gs use nir_xfb_info to replace
 pipe_stream_output_info

pipe_stream_output_info is built from nir_xfb_info, why not just use
nir_xfb_info directly.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir.c | 76 ++++++++++++++++++++++-------------------
 src/amd/common/ac_nir.h | 12 +++----
 2 files changed, 46 insertions(+), 42 deletions(-)

diff --git a/src/amd/common/ac_nir.c b/src/amd/common/ac_nir.c
index 9c4051bc07ab..6e86babf3d16 100644
--- a/src/amd/common/ac_nir.c
+++ b/src/amd/common/ac_nir.c
@@ -23,6 +23,7 @@
 
 #include "ac_nir.h"
 #include "nir_builder.h"
+#include "nir_xfb_info.h"
 
 nir_ssa_def *
 ac_nir_load_arg(nir_builder *b, const struct ac_shader_args *ac_args, struct ac_arg arg)
@@ -110,7 +111,7 @@ ac_nir_lower_indirect_derefs(nir_shader *shader,
 }
 
 static void
-emit_streamout(nir_builder *b, const struct pipe_stream_output_info *info, unsigned stream,
+emit_streamout(nir_builder *b, unsigned stream, nir_xfb_info *info,
                nir_ssa_def *const outputs[64][4])
 {
    nir_ssa_def *so_vtx_count = nir_ubfe_imm(b, nir_load_streamout_config_amd(b), 16, 7);
@@ -119,44 +120,43 @@ emit_streamout(nir_builder *b, const struct pipe_stream_output_info *info, unsig
    nir_push_if(b, nir_ilt(b, tid, so_vtx_count));
    nir_ssa_def *so_write_index = nir_load_streamout_write_index_amd(b);
 
-   nir_ssa_def *so_buffers[PIPE_MAX_SO_BUFFERS];
-   nir_ssa_def *so_write_offset[PIPE_MAX_SO_BUFFERS];
-   for (unsigned i = 0; i < PIPE_MAX_SO_BUFFERS; i++) {
-      uint16_t stride = info->stride[i];
-      if (!stride)
-         continue;
-
+   nir_ssa_def *so_buffers[NIR_MAX_XFB_BUFFERS];
+   nir_ssa_def *so_write_offset[NIR_MAX_XFB_BUFFERS];
+   u_foreach_bit(i, info->buffers_written) {
       so_buffers[i] = nir_load_streamout_buffer_amd(b, i);
 
+      unsigned stride = info->buffers[i].stride;
       nir_ssa_def *offset = nir_load_streamout_offset_amd(b, i);
-      offset = nir_iadd(b, nir_imul_imm(b, nir_iadd(b, so_write_index, tid), stride * 4),
+      offset = nir_iadd(b, nir_imul_imm(b, nir_iadd(b, so_write_index, tid), stride),
                         nir_imul_imm(b, offset, 4));
       so_write_offset[i] = offset;
    }
 
    nir_ssa_def *undef = nir_ssa_undef(b, 1, 32);
-   for (unsigned i = 0; i < info->num_outputs; i++) {
-      const struct pipe_stream_output *output = &info->output[i];
-      if (stream != output->stream)
+   for (unsigned i = 0; i < info->output_count; i++) {
+      const nir_xfb_output_info *output = info->outputs + i;
+      if (stream != info->buffer_to_stream[output->buffer])
          continue;
 
       nir_ssa_def *vec[4] = {undef, undef, undef, undef};
       uint8_t mask = 0;
-      for (unsigned j = 0; j < output->num_components; j++) {
-         if (outputs[output->register_index][output->start_component + j]) {
-            vec[j] = outputs[output->register_index][output->start_component + j];
-            mask |= 1 << j;
+      u_foreach_bit(j, output->component_mask) {
+         nir_ssa_def *src = outputs[output->location][j];
+         if (src) {
+            unsigned comp = j - output->component_offset;
+            vec[comp] = src;
+            mask |= 1 << comp;
          }
       }
 
       if (!mask)
          continue;
 
-      unsigned buffer = output->output_buffer;
-      nir_ssa_def *data = nir_vec(b, vec, output->num_components);
+      unsigned buffer = output->buffer;
+      nir_ssa_def *data = nir_vec(b, vec, util_last_bit(mask));
       nir_ssa_def *zero = nir_imm_int(b, 0);
       nir_store_buffer_amd(b, data, so_buffers[buffer], so_write_offset[buffer], zero, zero,
-                           .base = output->dst_offset * 4, .slc_amd = true, .write_mask = mask,
+                           .base = output->offset, .slc_amd = true, .write_mask = mask,
                            .access = ACCESS_COHERENT);
    }
 
@@ -165,10 +165,11 @@ emit_streamout(nir_builder *b, const struct pipe_stream_output_info *info, unsig
 
 nir_shader *
 ac_nir_create_gs_copy_shader(const nir_shader *gs_nir,
-                             const struct pipe_stream_output_info *so_info, size_t num_outputs,
-                             const uint8_t *output_usage_mask, const uint8_t *output_streams,
-                             const uint8_t *output_semantics,
-                             const uint8_t num_stream_output_components[4])
+                             bool disable_streamout,
+                             size_t num_outputs,
+                             const uint8_t *output_usage_mask,
+                             const uint8_t *output_streams,
+                             const uint8_t *output_semantics)
 {
    assert(num_outputs <= 64);
 
@@ -180,15 +181,16 @@ ac_nir_create_gs_copy_shader(const nir_shader *gs_nir,
 
    nir_ssa_def *gsvs_ring = nir_load_ring_gsvs_amd(&b);
 
+   nir_xfb_info *info = gs_nir->xfb_info;
    nir_ssa_def *stream_id = NULL;
-   if (so_info->num_outputs)
+   if (!disable_streamout && info)
       stream_id = nir_ubfe_imm(&b, nir_load_streamout_config_amd(&b), 24, 2);
 
    nir_ssa_def *vtx_offset = nir_imul_imm(&b, nir_load_vertex_id_zero_base(&b), 4);
    nir_ssa_def *zero = nir_imm_zero(&b, 1, 32);
 
    for (unsigned stream = 0; stream < 4; stream++) {
-      if (stream > 0 && (!stream_id || !num_stream_output_components[stream]))
+      if (stream > 0 && (!stream_id || !(info->streams_written & BITFIELD_BIT(stream))))
          continue;
 
       if (stream_id)
@@ -202,13 +204,16 @@ ac_nir_create_gs_copy_shader(const nir_shader *gs_nir,
          if (!mask)
             continue;
 
+         gl_varying_slot location = output_semantics ? output_semantics[i] : i;
+
          u_foreach_bit (j, mask) {
             if (((output_streams[i] >> (j * 2)) & 0x3) != stream)
                continue;
 
-            outputs[i][j] = nir_load_buffer_amd(&b, 1, 32, gsvs_ring, vtx_offset, zero, zero,
-                                                .base = offset, .is_swizzled = false,
-                                                .slc_amd = true, .access = ACCESS_COHERENT);
+            outputs[location][j] =
+               nir_load_buffer_amd(&b, 1, 32, gsvs_ring, vtx_offset, zero, zero,
+                                   .base = offset, .is_swizzled = false,
+                                   .slc_amd = true, .access = ACCESS_COHERENT);
 
             offset += gs_nir->info.gs.vertices_out * 16 * 4;
          }
@@ -217,15 +222,15 @@ ac_nir_create_gs_copy_shader(const nir_shader *gs_nir,
       }
 
       if (stream_id)
-         emit_streamout(&b, so_info, stream, outputs);
+         emit_streamout(&b, stream, info, outputs);
 
       if (stream == 0) {
          u_foreach_bit64 (i, output_mask) {
             gl_varying_slot location = output_semantics ? output_semantics[i] : i;
 
             for (unsigned j = 0; j < 4; j++) {
-               if (outputs[i][j]) {
-                  nir_store_output(&b, outputs[i][j], zero,
+               if (outputs[location][j]) {
+                  nir_store_output(&b, outputs[location][j], zero,
                                    .base = i,
                                    .component = j,
                                    .write_mask = 1,
@@ -267,7 +272,7 @@ gather_outputs(nir_builder *b, nir_function_impl *impl, nir_ssa_def *outputs[64]
 
          assert(nir_src_is_const(intrin->src[1]) && !nir_src_as_uint(intrin->src[1]));
 
-         unsigned slot = nir_intrinsic_base(intrin);
+         unsigned slot = nir_intrinsic_io_semantics(intrin).location;
          u_foreach_bit (i, nir_intrinsic_write_mask(intrin)) {
             unsigned comp = nir_intrinsic_component(intrin) + i;
             outputs[slot][comp] = nir_channel(b, intrin->src[0].ssa, i);
@@ -277,8 +282,7 @@ gather_outputs(nir_builder *b, nir_function_impl *impl, nir_ssa_def *outputs[64]
 }
 
 void
-ac_nir_lower_legacy_vs(nir_shader *nir, int primitive_id_location,
-                       const struct pipe_stream_output_info *so_info)
+ac_nir_lower_legacy_vs(nir_shader *nir, int primitive_id_location, bool disable_streamout)
 {
    nir_function_impl *impl = nir_shader_get_entrypoint(nir);
    nir_metadata preserved = nir_metadata_block_index | nir_metadata_dominance;
@@ -306,7 +310,7 @@ ac_nir_lower_legacy_vs(nir_shader *nir, int primitive_id_location,
       nir->info.outputs_written |= BITFIELD64_BIT(VARYING_SLOT_PRIMITIVE_ID);
    }
 
-   if (so_info && so_info->num_outputs) {
+   if (!disable_streamout && nir->xfb_info) {
       /* 26.1. Transform Feedback of Vulkan 1.3.229 spec:
        * > The size of each component of an output variable must be at least 32-bits.
        * We lower 64-bit outputs.
@@ -314,7 +318,7 @@ ac_nir_lower_legacy_vs(nir_shader *nir, int primitive_id_location,
       nir_ssa_def *outputs[64][4] = {{0}};
       gather_outputs(&b, impl, outputs);
 
-      emit_streamout(&b, so_info, 0, outputs);
+      emit_streamout(&b, 0, nir->xfb_info, outputs);
       preserved = nir_metadata_none;
    }
 
diff --git a/src/amd/common/ac_nir.h b/src/amd/common/ac_nir.h
index 86aaf55b0266..798bb552aeb2 100644
--- a/src/amd/common/ac_nir.h
+++ b/src/amd/common/ac_nir.h
@@ -185,14 +185,14 @@ bool ac_nir_lower_resinfo(nir_shader *nir, enum amd_gfx_level gfx_level);
 
 nir_shader *
 ac_nir_create_gs_copy_shader(const nir_shader *gs_nir,
-                             const struct pipe_stream_output_info *so_info, size_t num_outputs,
-                             const uint8_t *output_usage_mask, const uint8_t *output_streams,
-                             const uint8_t *output_semantics,
-                             const uint8_t num_stream_output_components[4]);
+                             bool disable_streamout,
+                             size_t num_outputs,
+                             const uint8_t *output_usage_mask,
+                             const uint8_t *output_streams,
+                             const uint8_t *output_semantics);
 
 void
-ac_nir_lower_legacy_vs(nir_shader *nir, int primitive_id_location,
-                       const struct pipe_stream_output_info *so_info);
+ac_nir_lower_legacy_vs(nir_shader *nir, int primitive_id_location, bool disable_streamout);
 
 #ifdef __cplusplus
 }
-- 
GitLab


From 1d985729c0306a140937033148f9660c3375c620 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Tue, 27 Sep 2022 19:26:11 +0100
Subject: [PATCH 2/8] radv,aco: export legacy vertex outputs in NIR

This new behaviour will let us insert exports in GS copy shader control
flow.

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 .../compiler/aco_instruction_selection.cpp    |  5 +-
 src/amd/vulkan/radv_nir_to_llvm.c             | 24 ++------
 src/amd/vulkan/radv_pipeline.c                | 56 ++-----------------
 src/amd/vulkan/radv_shader_info.c             |  2 +-
 4 files changed, 11 insertions(+), 76 deletions(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 2de6e9a6debd..d1b57b15d20a 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -9191,7 +9191,6 @@ visit_intrinsic(isel_context* ctx, nir_intrinsic_instr* instr)
       break;
    }
    case nir_intrinsic_export_vertex_amd: {
-      ctx->block->kind |= block_kind_export_end;
       create_vs_exports(ctx);
       break;
    }
@@ -12099,9 +12098,7 @@ select_program(Program* program, unsigned shader_count, struct nir_shader* const
       if (ctx.program->info.so.num_outputs && ctx.stage.hw == HWStage::VS)
          emit_streamout(&ctx, 0);
 
-      if (ctx.stage.hw == HWStage::VS) {
-         create_vs_exports(&ctx);
-      } else if (nir->info.stage == MESA_SHADER_GEOMETRY && !ngg_gs) {
+      if (nir->info.stage == MESA_SHADER_GEOMETRY && !ngg_gs) {
          Builder bld(ctx.program, ctx.block);
          bld.barrier(aco_opcode::p_barrier,
                      memory_sync_info(storage_vmem_output, semantic_release, scope_device));
diff --git a/src/amd/vulkan/radv_nir_to_llvm.c b/src/amd/vulkan/radv_nir_to_llvm.c
index 1ca2a31f0684..85dbe2a4638e 100644
--- a/src/amd/vulkan/radv_nir_to_llvm.c
+++ b/src/amd/vulkan/radv_nir_to_llvm.c
@@ -1144,15 +1144,9 @@ handle_shader_outputs_post(struct ac_shader_abi *abi)
 
    switch (ctx->stage) {
    case MESA_SHADER_VERTEX:
-      if (ctx->shader_info->vs.as_ls)
-         break; /* Lowered in NIR */
-      else if (ctx->shader_info->vs.as_es)
-         break; /* Lowered in NIR */
-      else if (ctx->shader_info->is_ngg)
-         break; /* Lowered in NIR */
-      else
-         handle_vs_outputs_post(ctx);
-      break;
+   case MESA_SHADER_TESS_CTRL:
+   case MESA_SHADER_TESS_EVAL:
+      break; /* Lowered in NIR */
    case MESA_SHADER_FRAGMENT:
       handle_fs_outputs_post(ctx);
       break;
@@ -1162,16 +1156,6 @@ handle_shader_outputs_post(struct ac_shader_abi *abi)
       else
          emit_gs_epilogue(ctx);
       break;
-   case MESA_SHADER_TESS_CTRL:
-      break; /* Lowered in NIR */
-   case MESA_SHADER_TESS_EVAL:
-      if (ctx->shader_info->tes.as_es)
-         break; /* Lowered in NIR */
-      else if (ctx->shader_info->is_ngg)
-         break; /* Lowered in NIR */
-      else
-         handle_vs_outputs_post(ctx);
-      break;
    default:
       break;
    }
@@ -1445,7 +1429,9 @@ ac_translate_nir_to_llvm(struct ac_llvm_compiler *ac_llvm,
          ctx.abi.emit_vertex_with_counter = visit_emit_vertex_with_counter;
          ctx.abi.emit_primitive = visit_end_primitive;
       } else if (shaders[shader_idx]->info.stage == MESA_SHADER_TESS_EVAL) {
+         ctx.abi.export_vertex = radv_llvm_visit_export_vertex;
       } else if (shaders[shader_idx]->info.stage == MESA_SHADER_VERTEX) {
+         ctx.abi.export_vertex = radv_llvm_visit_export_vertex;
          ctx.abi.load_inputs = radv_load_vs_inputs;
       }
 
diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index 57e2b1311374..a6a37036e19a 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -2193,50 +2193,6 @@ radv_export_multiview(nir_shader *nir)
    return progress;
 }
 
-static bool
-radv_should_export_implicit_primitive_id(const struct radv_pipeline_stage *producer,
-                                         const struct radv_pipeline_stage *consumer)
-{
-   /* When the primitive ID is read by FS, we must ensure that it's exported by the previous vertex
-    * stage because it's implicit for VS or TES (but required by the Vulkan spec for GS or MS).
-    *
-    * There is two situations to handle:
-    *  - when the next stage is unknown (with graphics pipeline library), the primitive ID is
-    *  exported unconditionally
-    *  - when the pipeline uses NGG, the primitive ID is exported during NGG lowering
-    */
-   assert(producer->stage == MESA_SHADER_VERTEX || producer->stage == MESA_SHADER_TESS_EVAL);
-
-   if ((producer->nir->info.outputs_written & VARYING_BIT_PRIMITIVE_ID) || producer->info.is_ngg)
-      return false;
-
-   return !consumer || (consumer->stage == MESA_SHADER_FRAGMENT &&
-          (consumer->nir->info.inputs_read & VARYING_BIT_PRIMITIVE_ID));
-}
-
-static bool
-radv_export_implicit_primitive_id(nir_shader *nir)
-{
-   nir_function_impl *impl = nir_shader_get_entrypoint(nir);
-   nir_builder b;
-   nir_builder_init(&b, impl);
-
-   b.cursor = nir_after_cf_list(&impl->body);
-
-   nir_variable *var = nir_variable_create(nir, nir_var_shader_out, glsl_int_type(), NULL);
-   var->data.location = VARYING_SLOT_PRIMITIVE_ID;
-   var->data.interpolation = INTERP_MODE_NONE;
-
-   nir_store_var(&b, var, nir_load_primitive_id(&b), 1);
-
-   /* Update outputs_written to reflect that the pass added a new output. */
-   nir->info.outputs_written |= BITFIELD64_BIT(VARYING_SLOT_PRIMITIVE_ID);
-
-   nir_metadata_preserve(impl, nir_metadata_block_index | nir_metadata_dominance);
-
-   return true;
-}
-
 static void
 radv_remove_point_size(const struct radv_pipeline_key *pipeline_key,
                        nir_shader *producer, nir_shader *consumer)
@@ -2523,10 +2479,6 @@ radv_pipeline_link_vs(const struct radv_device *device, struct radv_pipeline_sta
 {
    assert(vs_stage->nir->info.stage == MESA_SHADER_VERTEX);
 
-   if (radv_should_export_implicit_primitive_id(vs_stage, next_stage)) {
-      NIR_PASS(_, vs_stage->nir, radv_export_implicit_primitive_id);
-   }
-
    if (radv_should_export_multiview(vs_stage, next_stage, pipeline_key)) {
       NIR_PASS(_, vs_stage->nir, radv_export_multiview);
    }
@@ -2593,10 +2545,6 @@ radv_pipeline_link_tes(const struct radv_device *device, struct radv_pipeline_st
 {
    assert(tes_stage->nir->info.stage == MESA_SHADER_TESS_EVAL);
 
-   if (radv_should_export_implicit_primitive_id(tes_stage, next_stage)) {
-      NIR_PASS(_, tes_stage->nir, radv_export_implicit_primitive_id);
-   }
-
    if (radv_should_export_multiview(tes_stage, next_stage, pipeline_key)) {
       NIR_PASS(_, tes_stage->nir, radv_export_multiview);
    }
@@ -3912,6 +3860,10 @@ radv_postprocess_nir(struct radv_pipeline *pipeline,
    if (lowered_ngg)
       radv_lower_ngg(device, stage, pipeline_key);
 
+   if (stage->stage == last_vgt_api_stage && stage->stage != MESA_SHADER_GEOMETRY && !lowered_ngg)
+      NIR_PASS_V(stage->nir, ac_nir_lower_legacy_vs,
+                 stage->info.outinfo.export_prim_id ? VARYING_SLOT_PRIMITIVE_ID : -1, true);
+
    NIR_PASS(_, stage->nir, nir_opt_idiv_const, 8);
 
    NIR_PASS(_, stage->nir, nir_lower_idiv,
diff --git a/src/amd/vulkan/radv_shader_info.c b/src/amd/vulkan/radv_shader_info.c
index 3625fe2a2e7d..525a1e90722e 100644
--- a/src/amd/vulkan/radv_shader_info.c
+++ b/src/amd/vulkan/radv_shader_info.c
@@ -1278,7 +1278,7 @@ radv_link_shaders_info(struct radv_device *device,
 
       if (ps_prim_id_in &&
           (producer->stage == MESA_SHADER_VERTEX || producer->stage == MESA_SHADER_TESS_EVAL)) {
-         /* Mark the primitive ID as output when it's implicitly exported by VS or TES with NGG. */
+         /* Mark the primitive ID as output when it's implicitly exported by VS or TES. */
          if (outinfo->vs_output_param_offset[VARYING_SLOT_PRIMITIVE_ID] == AC_EXP_PARAM_UNDEFINED)
             outinfo->vs_output_param_offset[VARYING_SLOT_PRIMITIVE_ID] = outinfo->param_exports++;
 
-- 
GitLab


From 5d02875657660387034723fa2fe42cdbff0a3e56 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 28 Sep 2022 17:17:35 +0100
Subject: [PATCH 3/8] radv: lower streamout in NIR

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/aco_instruction_selection.cpp | 3 ---
 src/amd/vulkan/radv_nir_to_llvm.c              | 6 ------
 src/amd/vulkan/radv_pipeline.c                 | 2 +-
 3 files changed, 1 insertion(+), 10 deletions(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index d1b57b15d20a..a9a63aa0506a 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -12095,9 +12095,6 @@ select_program(Program* program, unsigned shader_count, struct nir_shader* const
 
       visit_cf_list(&ctx, &func->body);
 
-      if (ctx.program->info.so.num_outputs && ctx.stage.hw == HWStage::VS)
-         emit_streamout(&ctx, 0);
-
       if (nir->info.stage == MESA_SHADER_GEOMETRY && !ngg_gs) {
          Builder bld(ctx.program, ctx.block);
          bld.barrier(aco_opcode::p_barrier,
diff --git a/src/amd/vulkan/radv_nir_to_llvm.c b/src/amd/vulkan/radv_nir_to_llvm.c
index 85dbe2a4638e..b9943bfdac5b 100644
--- a/src/amd/vulkan/radv_nir_to_llvm.c
+++ b/src/amd/vulkan/radv_nir_to_llvm.c
@@ -1001,12 +1001,6 @@ handle_vs_outputs_post(struct radv_shader_context *ctx)
    struct radv_shader_output_values *outputs;
    unsigned noutput = 0;
 
-   if (ctx->shader_info->so.num_outputs && !ctx->args->is_gs_copy_shader &&
-       ctx->stage != MESA_SHADER_GEOMETRY && !ctx->shader_info->is_ngg) {
-      /* The GS copy shader emission already emits streamout. */
-      radv_emit_streamout(ctx, 0);
-   }
-
    /* Allocate a temporary array for the output values. */
    unsigned num_outputs = util_bitcount64(ctx->output_mask);
    outputs = malloc(num_outputs * sizeof(outputs[0]));
diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index a6a37036e19a..ac78b6887e3e 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -3862,7 +3862,7 @@ radv_postprocess_nir(struct radv_pipeline *pipeline,
 
    if (stage->stage == last_vgt_api_stage && stage->stage != MESA_SHADER_GEOMETRY && !lowered_ngg)
       NIR_PASS_V(stage->nir, ac_nir_lower_legacy_vs,
-                 stage->info.outinfo.export_prim_id ? VARYING_SLOT_PRIMITIVE_ID : -1, true);
+                 stage->info.outinfo.export_prim_id ? VARYING_SLOT_PRIMITIVE_ID : -1, false);
 
    NIR_PASS(_, stage->nir, nir_opt_idiv_const, 8);
 
-- 
GitLab


From 1c257bde018ca14379de47f00839fecc345fe15a Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Fri, 30 Sep 2022 11:40:18 +0100
Subject: [PATCH 4/8] radv: make radv_use_llvm_for_stage device parameter const

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/vulkan/radv_private.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index c4d493c218a5..734c4dd6e107 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -3173,7 +3173,7 @@ radv_queue_ring(struct radv_queue *queue)
  * specific shader stage (developers only).
  */
 static inline bool
-radv_use_llvm_for_stage(struct radv_device *device, UNUSED gl_shader_stage stage)
+radv_use_llvm_for_stage(const struct radv_device *device, UNUSED gl_shader_stage stage)
 {
    return device->physical_device->use_llvm;
 }
-- 
GitLab


From 3cf7a18c9887130c0db79361fd05004839fca473 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Thu, 29 Sep 2022 12:43:05 +0100
Subject: [PATCH 5/8] radv,aco: implement GS copy shaders using NIR

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 .../compiler/aco_instruction_selection.cpp    |  7 +++---
 src/amd/compiler/aco_interface.cpp            |  4 +---
 src/amd/vulkan/radv_nir_to_llvm.c             | 16 ++++++-------
 src/amd/vulkan/radv_pipeline.c                | 24 +++++++++++++------
 src/amd/vulkan/radv_shader.c                  | 16 ++++++-------
 src/amd/vulkan/radv_shader_info.c             |  2 +-
 6 files changed, 37 insertions(+), 32 deletions(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index a9a63aa0506a..7f079209d09a 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -7810,10 +7810,9 @@ visit_emit_vertex_with_counter(isel_context* ctx, nir_intrinsic_instr* instr)
 
    unsigned offset = 0;
    for (unsigned i = 0; i <= VARYING_SLOT_VAR31; i++) {
-      if (ctx->program->info.gs.output_streams[i] != stream)
-         continue;
-
       for (unsigned j = 0; j < 4; j++) {
+         if (((ctx->program->info.gs.output_streams[i] >> (j * 2)) & 0x3) != stream)
+            continue;
          if (!(ctx->program->info.gs.output_usage_mask[i] & (1 << j)))
             continue;
 
@@ -12179,7 +12178,7 @@ select_gs_copy_shader(Program* program, struct nir_shader* gs_shader, ac_shader_
 
       unsigned offset = 0;
       for (unsigned i = 0; i <= VARYING_SLOT_VAR31; ++i) {
-         if (program->info.gs.output_streams[i] != stream)
+         if ((program->info.gs.output_streams[i] & 0x3) != stream)
             continue;
 
          unsigned output_usage_mask = program->info.gs.output_usage_mask[i];
diff --git a/src/amd/compiler/aco_interface.cpp b/src/amd/compiler/aco_interface.cpp
index 57271308f32d..eebad656a972 100644
--- a/src/amd/compiler/aco_interface.cpp
+++ b/src/amd/compiler/aco_interface.cpp
@@ -230,9 +230,7 @@ aco_compile_shader(const struct aco_compiler_options* options,
    program->debug.private_data = options->debug.private_data;
 
    /* Instruction Selection */
-   if (args->is_gs_copy_shader)
-      aco::select_gs_copy_shader(program.get(), shaders[0], &config, options, info, args);
-   else if (args->is_trap_handler_shader)
+   if (args->is_trap_handler_shader)
       aco::select_trap_handler_shader(program.get(), shaders[0], &config, options, info, args);
    else
       aco::select_program(program.get(), shader_count, shaders, &config, options, info, args);
diff --git a/src/amd/vulkan/radv_nir_to_llvm.c b/src/amd/vulkan/radv_nir_to_llvm.c
index b9943bfdac5b..28ae633963df 100644
--- a/src/amd/vulkan/radv_nir_to_llvm.c
+++ b/src/amd/vulkan/radv_nir_to_llvm.c
@@ -205,10 +205,12 @@ visit_emit_vertex_with_counter(struct ac_shader_abi *abi, unsigned stream, LLVMV
       bool *is_16bit_ptr = &abi->is_16bit[i * 4];
       int length = util_last_bit(output_usage_mask);
 
-      if (!(ctx->output_mask & (1ull << i)) || output_stream != stream)
+      if (!(ctx->output_mask & (1ull << i)))
          continue;
 
       for (unsigned j = 0; j < length; j++) {
+         if (((output_stream >> (j * 2)) & 0x3) != stream)
+            continue;
          if (!(output_usage_mask & (1 << j)))
             continue;
 
@@ -1012,11 +1014,11 @@ handle_vs_outputs_post(struct radv_shader_context *ctx)
       outputs[noutput].slot_name = i;
       outputs[noutput].slot_index = i == VARYING_SLOT_CLIP_DIST1;
 
-      if (ctx->stage == MESA_SHADER_VERTEX && !ctx->args->is_gs_copy_shader) {
+      if (ctx->stage == MESA_SHADER_VERTEX) {
          outputs[noutput].usage_mask = ctx->shader_info->vs.output_usage_mask[i];
       } else if (ctx->stage == MESA_SHADER_TESS_EVAL) {
          outputs[noutput].usage_mask = ctx->shader_info->tes.output_usage_mask[i];
-      } else if (ctx->args->is_gs_copy_shader|| ctx->stage == MESA_SHADER_GEOMETRY) {
+      } else if (ctx->stage == MESA_SHADER_GEOMETRY) {
          outputs[noutput].usage_mask = ctx->shader_info->gs.output_usage_mask[i];
       }
 
@@ -1644,7 +1646,7 @@ ac_gs_copy_shader_emit(struct radv_shader_context *ctx)
       offset = 0;
       for (unsigned i = 0; i < AC_LLVM_MAX_OUTPUTS; ++i) {
          unsigned output_usage_mask = ctx->shader_info->gs.output_usage_mask[i];
-         unsigned output_stream = ctx->shader_info->gs.output_streams[i];
+         unsigned output_stream = ctx->shader_info->gs.output_streams[i] & 0x3;
          int length = util_last_bit(output_usage_mask);
 
          if (!(ctx->output_mask & (1ull << i)) || output_stream != stream)
@@ -1747,9 +1749,5 @@ llvm_compile_shader(const struct radv_nir_compiler_options *options,
 
    radv_init_llvm_compiler(&ac_llvm, options->family, tm_options, info->wave_size);
 
-   if (args->is_gs_copy_shader) {
-      radv_compile_gs_copy_shader(&ac_llvm, options, info, *shaders, binary, args);
-   } else {
-      radv_compile_nir_shader(&ac_llvm, options, info, binary, args, shaders, shader_count);
-   }
+   radv_compile_nir_shader(&ac_llvm, options, info, binary, args, shaders, shader_count);
 }
diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index ac78b6887e3e..939add4bf791 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -3609,15 +3609,21 @@ radv_pipeline_create_gs_copy_shader(struct radv_pipeline *pipeline,
                                     struct radv_shader_binary **gs_copy_binary)
 {
    struct radv_device *device = pipeline->device;
-   struct radv_shader_info info = {0};
 
-   radv_nir_shader_info_pass(device, stages[MESA_SHADER_GEOMETRY].nir, pipeline_layout, pipeline_key,
-                             &info);
+   const struct radv_shader_info *gs_info = &stages[MESA_SHADER_GEOMETRY].info;
+   nir_shader *nir =
+      ac_nir_create_gs_copy_shader(stages[MESA_SHADER_GEOMETRY].nir, false, VARYING_SLOT_MAX,
+                                   gs_info->gs.output_usage_mask, gs_info->gs.output_streams, NULL);
+   nir_validate_shader(nir, "after ac_nir_create_gs_copy_shader");
+   nir_shader_gather_info(nir, nir_shader_get_entrypoint(nir));
+
+   struct radv_shader_info info = {0};
+   radv_nir_shader_info_pass(device, nir, pipeline_layout, pipeline_key, &info);
    info.wave_size = 64; /* Wave32 not supported. */
    info.workgroup_size = 64; /* HW VS: separate waves, no workgroups */
-   info.ballot_bit_size = 64;
+   info.so = gs_info->so;
 
-   if (stages[MESA_SHADER_GEOMETRY].info.outinfo.export_clip_dists) {
+   if (gs_info->outinfo.export_clip_dists) {
       if (stages[MESA_SHADER_GEOMETRY].nir->info.outputs_written & VARYING_BIT_CLIP_DIST0)
          info.outinfo.vs_output_param_offset[VARYING_SLOT_CLIP_DIST0] = info.outinfo.param_exports++;
       if (stages[MESA_SHADER_GEOMETRY].nir->info.outputs_written & VARYING_BIT_CLIP_DIST1)
@@ -3634,8 +3640,12 @@ radv_pipeline_create_gs_copy_shader(struct radv_pipeline *pipeline,
    info.user_sgprs_locs = gs_copy_args.user_sgprs_locs;
    info.inline_push_constant_mask = gs_copy_args.ac.inline_push_const_mask;
 
-   return radv_create_gs_copy_shader(device, stages[MESA_SHADER_GEOMETRY].nir, &info, &gs_copy_args,
-                                     gs_copy_binary, keep_executable_info, keep_statistic_info,
+   NIR_PASS_V(nir, radv_nir_lower_abi, device->physical_device->rad_info.gfx_level, &info,
+              &gs_copy_args, pipeline_key, radv_use_llvm_for_stage(device, MESA_SHADER_VERTEX),
+              device->physical_device->rad_info.address32_hi);
+
+   return radv_create_gs_copy_shader(device, nir, &info, &gs_copy_args, gs_copy_binary,
+                                     keep_executable_info, keep_statistic_info,
                                      pipeline_key->optimisations_disabled);
 }
 
diff --git a/src/amd/vulkan/radv_shader.c b/src/amd/vulkan/radv_shader.c
index e633afe92ed9..58ee3deb3ccc 100644
--- a/src/amd/vulkan/radv_shader.c
+++ b/src/amd/vulkan/radv_shader.c
@@ -2380,14 +2380,14 @@ static struct radv_shader *
 shader_compile(struct radv_device *device, struct nir_shader *const *shaders, int shader_count,
                gl_shader_stage stage, const struct radv_shader_info *info,
                const struct radv_shader_args *args, const struct radv_pipeline_key *key,
-               bool gs_copy_shader, bool trap_handler_shader, bool keep_shader_info,
-               bool keep_statistic_info, struct radv_shader_binary **binary_out)
+               bool trap_handler_shader, bool keep_shader_info, bool keep_statistic_info,
+               struct radv_shader_binary **binary_out)
 {
    struct radv_nir_compiler_options options = {0};
    radv_fill_nir_compiler_options(
       &options, device, key, radv_should_use_wgp_mode(device, stage, info),
-      radv_can_dump_shader(device, shaders[0], gs_copy_shader || trap_handler_shader),
-      is_meta_shader(shaders[0]), keep_shader_info, keep_statistic_info);
+      radv_can_dump_shader(device, shaders[0], trap_handler_shader), is_meta_shader(shaders[0]),
+      keep_shader_info, keep_statistic_info);
 
    struct radv_shader_debug_data debug_data = {
       .device = device,
@@ -2451,7 +2451,7 @@ radv_shader_nir_to_asm(struct radv_device *device, struct radv_pipeline_stage *p
    gl_shader_stage stage = shaders[shader_count - 1]->info.stage;
 
    return shader_compile(device, shaders, shader_count, stage, &pl_stage->info, &pl_stage->args,
-                         key, false, false, keep_shader_info, keep_statistic_info, binary_out);
+                         key, false, keep_shader_info, keep_statistic_info, binary_out);
 }
 
 struct radv_shader *
@@ -2466,7 +2466,7 @@ radv_create_gs_copy_shader(struct radv_device *device, struct nir_shader *shader
       .optimisations_disabled = disable_optimizations,
    };
 
-   return shader_compile(device, &shader, 1, stage, info, args, &key, true, false, keep_shader_info,
+   return shader_compile(device, &shader, 1, stage, info, args, &key, false, keep_shader_info,
                          keep_statistic_info, binary_out);
 }
 
@@ -2494,8 +2494,8 @@ radv_create_trap_handler_shader(struct radv_device *device)
    radv_declare_shader_args(device->physical_device->rad_info.gfx_level, &key, &info, stage, false,
                             MESA_SHADER_VERTEX, &args);
 
-   shader = shader_compile(device, &b.shader, 1, stage, &info, &args, &key, false, true, false,
-                           false, &binary);
+   shader =
+      shader_compile(device, &b.shader, 1, stage, &info, &args, &key, true, false, false, &binary);
 
    trap->alloc = radv_alloc_shader_memory(device, shader->code_size, NULL);
 
diff --git a/src/amd/vulkan/radv_shader_info.c b/src/amd/vulkan/radv_shader_info.c
index 525a1e90722e..5a44e0264026 100644
--- a/src/amd/vulkan/radv_shader_info.c
+++ b/src/amd/vulkan/radv_shader_info.c
@@ -463,7 +463,7 @@ gather_shader_info_gs(const nir_shader *nir, struct radv_shader_info *info)
       assert(stream < 4);
 
       info->gs.num_stream_output_components[stream] += num_components;
-      info->gs.output_streams[idx] = stream;
+      info->gs.output_streams[idx] = stream | (stream << 2) | (stream << 4) | (stream << 6);
    }
 }
 
-- 
GitLab


From b6197e390a5d70b0b4f7d5e678839622838d3eff Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Mon, 17 Oct 2022 20:26:51 +0100
Subject: [PATCH 6/8] radv,aco: remove old GS copy shader code

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 .../compiler/aco_instruction_selection.cpp    | 103 +------------
 src/amd/compiler/aco_instruction_selection.h  |   3 +-
 .../aco_instruction_selection_setup.cpp       |  28 ++--
 src/amd/compiler/aco_interface.cpp            |   1 -
 src/amd/compiler/aco_interface.h              |   1 -
 src/amd/compiler/aco_ir.h                     |   6 -
 src/amd/compiler/aco_print_ir.cpp             |   2 -
 src/amd/vulkan/radv_nir_to_llvm.c             | 139 +-----------------
 src/amd/vulkan/radv_shader.c                  |   5 +-
 src/amd/vulkan/radv_shader.h                  |   1 -
 10 files changed, 15 insertions(+), 274 deletions(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 7f079209d09a..ec45c1a6d36c 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -12012,7 +12012,7 @@ select_program(Program* program, unsigned shader_count, struct nir_shader* const
                const struct aco_shader_info* info,
                const struct radv_shader_args* args)
 {
-   isel_context ctx = setup_isel_context(program, shader_count, shaders, config, options, info, args, false, false);
+   isel_context ctx = setup_isel_context(program, shader_count, shaders, config, options, info, args, false);
    if_context ic_merged_wave_info;
    bool ngg_gs = ctx.stage.hw == HWStage::NGG && ctx.stage.has(SWStage::GS);
 
@@ -12130,105 +12130,6 @@ select_program(Program* program, unsigned shader_count, struct nir_shader* const
    cleanup_cfg(program);
 }
 
-void
-select_gs_copy_shader(Program* program, struct nir_shader* gs_shader, ac_shader_config* config,
-                      const struct aco_compiler_options* options,
-                      const struct aco_shader_info* info,
-                      const struct radv_shader_args* args)
-{
-   isel_context ctx = setup_isel_context(program, 1, &gs_shader, config, options, info, args, true, false);
-
-   ctx.block->fp_mode = program->next_fp_mode;
-
-   add_startpgm(&ctx);
-   append_logical_start(ctx.block);
-
-   Builder bld(ctx.program, ctx.block);
-
-   Temp gsvs_ring = bld.smem(aco_opcode::s_load_dwordx4, bld.def(s4),
-                             program->private_segment_buffer, Operand::c32(RING_GSVS_VS * 16u));
-
-   Operand stream_id = Operand::zero();
-   if (program->info.so.num_outputs)
-      stream_id = bld.sop2(aco_opcode::s_bfe_u32, bld.def(s1), bld.def(s1, scc),
-                           get_arg(&ctx, ctx.args->ac.streamout_config), Operand::c32(0x20018u));
-
-   Temp vtx_offset = bld.vop2(aco_opcode::v_lshlrev_b32, bld.def(v1), Operand::c32(2u),
-                              get_arg(&ctx, ctx.args->ac.vertex_id));
-
-   std::stack<if_context, std::vector<if_context>> if_contexts;
-
-   for (unsigned stream = 0; stream < 4; stream++) {
-      if (stream_id.isConstant() && stream != stream_id.constantValue())
-         continue;
-
-      unsigned num_components = program->info.gs.num_stream_output_components[stream];
-      if (stream > 0 && (!num_components || !program->info.so.num_outputs))
-         continue;
-
-      memset(ctx.outputs.mask, 0, sizeof(ctx.outputs.mask));
-
-      if (!stream_id.isConstant()) {
-         Temp cond =
-            bld.sopc(aco_opcode::s_cmp_eq_u32, bld.def(s1, scc), stream_id, Operand::c32(stream));
-         if_contexts.emplace();
-         begin_uniform_if_then(&ctx, &if_contexts.top(), cond);
-         bld.reset(ctx.block);
-      }
-
-      unsigned offset = 0;
-      for (unsigned i = 0; i <= VARYING_SLOT_VAR31; ++i) {
-         if ((program->info.gs.output_streams[i] & 0x3) != stream)
-            continue;
-
-         unsigned output_usage_mask = program->info.gs.output_usage_mask[i];
-         unsigned length = util_last_bit(output_usage_mask);
-         for (unsigned j = 0; j < length; ++j) {
-            if (!(output_usage_mask & (1 << j)))
-               continue;
-
-            Temp val = bld.tmp(v1);
-            unsigned const_offset = offset * program->info.gs.vertices_out * 16 * 4;
-            load_vmem_mubuf(&ctx, val, gsvs_ring, vtx_offset, Temp(), Temp(), const_offset, 4, 1, 0, true,
-                            true, memory_sync_info());
-
-            ctx.outputs.mask[i] |= 1 << j;
-            ctx.outputs.temps[i * 4u + j] = val;
-
-            offset++;
-         }
-      }
-
-      if (program->info.so.num_outputs) {
-         emit_streamout(&ctx, stream);
-         bld.reset(ctx.block);
-      }
-
-      if (stream == 0) {
-         create_vs_exports(&ctx);
-      }
-
-      if (!stream_id.isConstant()) {
-         begin_uniform_if_else(&ctx, &if_contexts.top());
-         bld.reset(ctx.block);
-      }
-   }
-
-   while (!if_contexts.empty()) {
-      end_uniform_if(&ctx, &if_contexts.top());
-      if_contexts.pop();
-   }
-
-   program->config->float_mode = program->blocks[0].fp_mode.val;
-
-   append_logical_end(ctx.block);
-   ctx.block->kind |= block_kind_uniform;
-   bld.reset(ctx.block);
-   bld.sopp(aco_opcode::s_endpgm);
-
-   cleanup_cfg(program);
-}
-
 void
 select_trap_handler_shader(Program* program, struct nir_shader* shader, ac_shader_config* config,
                            const struct aco_compiler_options* options,
@@ -12645,7 +12546,7 @@ select_ps_epilog(Program* program, const struct aco_ps_epilog_key* key, ac_shade
                  const struct aco_shader_info* info,
                  const struct radv_shader_args* args)
 {
-   isel_context ctx = setup_isel_context(program, 0, NULL, config, options, info, args, false, true);
+   isel_context ctx = setup_isel_context(program, 0, NULL, config, options, info, args, true);
 
    ctx.block->fp_mode = program->next_fp_mode;
 
diff --git a/src/amd/compiler/aco_instruction_selection.h b/src/amd/compiler/aco_instruction_selection.h
index 5370034303c4..bc2ff89a4130 100644
--- a/src/amd/compiler/aco_instruction_selection.h
+++ b/src/amd/compiler/aco_instruction_selection.h
@@ -128,8 +128,7 @@ isel_context setup_isel_context(Program* program, unsigned shader_count,
                                 struct nir_shader* const* shaders, ac_shader_config* config,
                                 const struct aco_compiler_options* options,
                                 const struct aco_shader_info* info,
-                                const struct radv_shader_args* args,
-                                bool is_gs_copy_shader, bool is_ps_epilog);
+                                const struct radv_shader_args* args, bool is_ps_epilog);
 
 } // namespace aco
 
diff --git a/src/amd/compiler/aco_instruction_selection_setup.cpp b/src/amd/compiler/aco_instruction_selection_setup.cpp
index 61064622988f..c7356e452e3d 100644
--- a/src/amd/compiler/aco_instruction_selection_setup.cpp
+++ b/src/amd/compiler/aco_instruction_selection_setup.cpp
@@ -435,7 +435,7 @@ init_context(isel_context* ctx, nir_shader* shader)
    /* we'll need these for isel */
    nir_metadata_require(impl, nir_metadata_block_index);
 
-   if (!ctx->stage.has(SWStage::GSCopy) && ctx->options->dump_preoptir) {
+   if (ctx->options->dump_preoptir) {
       fprintf(stderr, "NIR shader before instruction selection:\n");
       nir_print_shader(shader, stderr);
    }
@@ -805,8 +805,7 @@ isel_context
 setup_isel_context(Program* program, unsigned shader_count, struct nir_shader* const* shaders,
                    ac_shader_config* config, const struct aco_compiler_options* options,
                    const struct aco_shader_info* info,
-                   const struct radv_shader_args* args, bool is_gs_copy_shader,
-                   bool is_ps_epilog)
+                   const struct radv_shader_args* args, bool is_ps_epilog)
 {
    SWStage sw_stage = SWStage::None;
    for (unsigned i = 0; i < shader_count; i++) {
@@ -814,9 +813,7 @@ setup_isel_context(Program* program, unsigned shader_count, struct nir_shader* c
       case MESA_SHADER_VERTEX: sw_stage = sw_stage | SWStage::VS; break;
       case MESA_SHADER_TESS_CTRL: sw_stage = sw_stage | SWStage::TCS; break;
       case MESA_SHADER_TESS_EVAL: sw_stage = sw_stage | SWStage::TES; break;
-      case MESA_SHADER_GEOMETRY:
-         sw_stage = sw_stage | (is_gs_copy_shader ? SWStage::GSCopy : SWStage::GS);
-         break;
+      case MESA_SHADER_GEOMETRY: sw_stage = sw_stage | SWStage::GS; break;
       case MESA_SHADER_FRAGMENT: sw_stage = sw_stage | SWStage::FS; break;
       case MESA_SHADER_COMPUTE: sw_stage = sw_stage | SWStage::CS; break;
       case MESA_SHADER_TASK: sw_stage = sw_stage | SWStage::TS; break;
@@ -845,8 +842,6 @@ setup_isel_context(Program* program, unsigned shader_count, struct nir_shader* c
       hw_stage = HWStage::FS;
    else if (sw_stage == SWStage::CS)
       hw_stage = HWStage::CS;
-   else if (sw_stage == SWStage::GSCopy)
-      hw_stage = HWStage::VS;
    else if (sw_stage == SWStage::TS)
       hw_stage = HWStage::CS; /* Task shaders are implemented with compute shaders. */
    else if (sw_stage == SWStage::MS)
@@ -898,19 +893,14 @@ setup_isel_context(Program* program, unsigned shader_count, struct nir_shader* c
    calc_min_waves(program);
 
    unsigned scratch_size = 0;
-   if (program->stage == gs_copy_vs) {
-      assert(shader_count == 1);
-      setup_vs_output_info(&ctx, shaders[0]);
-   } else {
-      for (unsigned i = 0; i < shader_count; i++) {
-         nir_shader* nir = shaders[i];
-         setup_nir(&ctx, nir);
-      }
-
-      for (unsigned i = 0; i < shader_count; i++)
-         scratch_size = std::max(scratch_size, shaders[i]->scratch_size);
+   for (unsigned i = 0; i < shader_count; i++) {
+      nir_shader* nir = shaders[i];
+      setup_nir(&ctx, nir);
    }
 
+   for (unsigned i = 0; i < shader_count; i++)
+      scratch_size = std::max(scratch_size, shaders[i]->scratch_size);
+
    ctx.program->config->scratch_bytes_per_wave = align(scratch_size * ctx.program->wave_size, 1024);
 
    unsigned nir_num_blocks = 0;
diff --git a/src/amd/compiler/aco_interface.cpp b/src/amd/compiler/aco_interface.cpp
index eebad656a972..7b55151f768d 100644
--- a/src/amd/compiler/aco_interface.cpp
+++ b/src/amd/compiler/aco_interface.cpp
@@ -256,7 +256,6 @@ aco_compile_shader(const struct aco_compiler_options* options,
 
    (*build_binary)(binary,
                    shaders[shader_count - 1]->info.stage,
-                   args->is_gs_copy_shader,
                    &config,
                    llvm_ir.c_str(),
                    llvm_ir.size(),
diff --git a/src/amd/compiler/aco_interface.h b/src/amd/compiler/aco_interface.h
index 7bef7727cf5b..b894da8945cc 100644
--- a/src/amd/compiler/aco_interface.h
+++ b/src/amd/compiler/aco_interface.h
@@ -46,7 +46,6 @@ struct aco_compiler_statistic_info {
 
 typedef void (aco_callback)(void **priv_ptr,
                             gl_shader_stage stage,
-                            bool is_gs_copy_shader,
                             const struct ac_shader_config *config,
                             const char *llvm_ir_str,
                             unsigned llvm_ir_size,
diff --git a/src/amd/compiler/aco_ir.h b/src/amd/compiler/aco_ir.h
index 18ed836c4370..0b08ccf07dae 100644
--- a/src/amd/compiler/aco_ir.h
+++ b/src/amd/compiler/aco_ir.h
@@ -2025,7 +2025,6 @@ enum class SWStage : uint16_t {
    CS = 1 << 5,     /* Compute Shader */
    TS = 1 << 6,     /* Task Shader */
    MS = 1 << 7,     /* Mesh Shader */
-   GSCopy = 1 << 8, /* GS Copy Shader (internal) */
 
    /* Stage combinations merged to run on a single HWStage */
    VS_GS = VS | GS,
@@ -2090,7 +2089,6 @@ static constexpr Stage vertex_vs(HWStage::VS, SWStage::VS);
 static constexpr Stage fragment_fs(HWStage::FS, SWStage::FS);
 static constexpr Stage compute_cs(HWStage::CS, SWStage::CS);
 static constexpr Stage tess_eval_vs(HWStage::VS, SWStage::TES);
-static constexpr Stage gs_copy_vs(HWStage::VS, SWStage::GSCopy);
 /* Mesh shading pipeline */
 static constexpr Stage task_cs(HWStage::CS, SWStage::TS);
 static constexpr Stage mesh_ngg(HWStage::NGG, SWStage::MS);
@@ -2252,10 +2250,6 @@ void select_program(Program* program, unsigned shader_count, struct nir_shader*
                     ac_shader_config* config, const struct aco_compiler_options* options,
                     const struct aco_shader_info* info,
                     const struct radv_shader_args* args);
-void select_gs_copy_shader(Program* program, struct nir_shader* gs_shader, ac_shader_config* config,
-                           const struct aco_compiler_options* options,
-                           const struct aco_shader_info* info,
-                           const struct radv_shader_args* args);
 void select_trap_handler_shader(Program* program, struct nir_shader* shader,
                                 ac_shader_config* config,
                                 const struct aco_compiler_options* options,
diff --git a/src/amd/compiler/aco_print_ir.cpp b/src/amd/compiler/aco_print_ir.cpp
index 2dcf088a7013..b0f4ae471c12 100644
--- a/src/amd/compiler/aco_print_ir.cpp
+++ b/src/amd/compiler/aco_print_ir.cpp
@@ -869,8 +869,6 @@ print_stage(Stage stage, FILE* output)
       fprintf(output, "compute_cs");
    else if (stage == fragment_fs)
       fprintf(output, "fragment_fs");
-   else if (stage == gs_copy_vs)
-      fprintf(output, "gs_copy_vs");
    else if (stage == vertex_ls)
       fprintf(output, "vertex_ls");
    else if (stage == vertex_es)
diff --git a/src/amd/vulkan/radv_nir_to_llvm.c b/src/amd/vulkan/radv_nir_to_llvm.c
index 28ae633963df..42acbd7554d7 100644
--- a/src/amd/vulkan/radv_nir_to_llvm.c
+++ b/src/amd/vulkan/radv_nir_to_llvm.c
@@ -996,8 +996,9 @@ radv_llvm_export_vs(struct radv_shader_context *ctx, struct radv_shader_output_v
 }
 
 static void
-handle_vs_outputs_post(struct radv_shader_context *ctx)
+radv_llvm_visit_export_vertex(struct ac_shader_abi *abi)
 {
+   struct radv_shader_context *ctx = radv_shader_context_from_abi(abi);
    const struct radv_vs_output_info *outinfo = &ctx->shader_info->outinfo;
    const bool export_clip_dists = outinfo->export_clip_dists;
    struct radv_shader_output_values *outputs;
@@ -1166,14 +1167,6 @@ ac_llvm_finalize_module(struct radv_shader_context *ctx, LLVMPassManagerRef pass
    ac_llvm_context_dispose(&ctx->ac);
 }
 
-static void
-radv_llvm_visit_export_vertex(struct ac_shader_abi *abi)
-{
-   struct radv_shader_context *ctx = radv_shader_context_from_abi(abi);
-
-   handle_vs_outputs_post(ctx);
-}
-
 static void
 ac_setup_rings(struct radv_shader_context *ctx)
 {
@@ -1606,134 +1599,6 @@ radv_compile_nir_shader(struct ac_llvm_compiler *ac_llvm,
                           options);
 }
 
-static void
-ac_gs_copy_shader_emit(struct radv_shader_context *ctx)
-{
-   LLVMValueRef vtx_offset =
-      LLVMBuildMul(ctx->ac.builder, ac_get_arg(&ctx->ac, ctx->args->ac.vertex_id),
-                   LLVMConstInt(ctx->ac.i32, 4, false), "");
-   LLVMValueRef stream_id;
-
-   /* Fetch the vertex stream ID. */
-   if (ctx->shader_info->so.num_outputs) {
-      stream_id =
-         ac_unpack_param(&ctx->ac, ac_get_arg(&ctx->ac, ctx->args->ac.streamout_config), 24, 2);
-   } else {
-      stream_id = ctx->ac.i32_0;
-   }
-
-   LLVMBasicBlockRef end_bb;
-   LLVMValueRef switch_inst;
-
-   end_bb = LLVMAppendBasicBlockInContext(ctx->ac.context, ctx->main_function.value, "end");
-   switch_inst = LLVMBuildSwitch(ctx->ac.builder, stream_id, end_bb, 4);
-
-   for (unsigned stream = 0; stream < 4; stream++) {
-      unsigned num_components = ctx->shader_info->gs.num_stream_output_components[stream];
-      LLVMBasicBlockRef bb;
-      unsigned offset;
-
-      if (stream > 0 && !num_components)
-         continue;
-
-      if (stream > 0 && !ctx->shader_info->so.num_outputs)
-         continue;
-
-      bb = LLVMInsertBasicBlockInContext(ctx->ac.context, end_bb, "out");
-      LLVMAddCase(switch_inst, LLVMConstInt(ctx->ac.i32, stream, 0), bb);
-      LLVMPositionBuilderAtEnd(ctx->ac.builder, bb);
-
-      offset = 0;
-      for (unsigned i = 0; i < AC_LLVM_MAX_OUTPUTS; ++i) {
-         unsigned output_usage_mask = ctx->shader_info->gs.output_usage_mask[i];
-         unsigned output_stream = ctx->shader_info->gs.output_streams[i] & 0x3;
-         int length = util_last_bit(output_usage_mask);
-
-         if (!(ctx->output_mask & (1ull << i)) || output_stream != stream)
-            continue;
-
-         for (unsigned j = 0; j < length; j++) {
-            LLVMValueRef value, soffset;
-
-            if (!(output_usage_mask & (1 << j)))
-               continue;
-
-            soffset = LLVMConstInt(ctx->ac.i32, offset * ctx->shader->info.gs.vertices_out * 16 * 4,
-                                   false);
-
-            offset++;
-
-            value = ac_build_buffer_load(&ctx->ac, ctx->gsvs_ring[0], 1, ctx->ac.i32_0, vtx_offset,
-                                         soffset, ctx->ac.f32, ac_glc | ac_slc, true, false);
-
-            LLVMTypeRef type = LLVMGetAllocatedType(ctx->abi.outputs[ac_llvm_reg_index_soa(i, j)]);
-            if (ac_get_type_size(type) == 2) {
-               value = LLVMBuildBitCast(ctx->ac.builder, value, ctx->ac.i32, "");
-               value = LLVMBuildTrunc(ctx->ac.builder, value, ctx->ac.i16, "");
-            }
-
-            LLVMBuildStore(ctx->ac.builder, ac_to_float(&ctx->ac, value),
-                           ctx->abi.outputs[ac_llvm_reg_index_soa(i, j)]);
-         }
-      }
-
-      if (ctx->shader_info->so.num_outputs)
-         radv_emit_streamout(ctx, stream);
-
-      if (stream == 0) {
-         handle_vs_outputs_post(ctx);
-      }
-
-      LLVMBuildBr(ctx->ac.builder, end_bb);
-   }
-
-   LLVMPositionBuilderAtEnd(ctx->ac.builder, end_bb);
-}
-
-static void
-radv_compile_gs_copy_shader(struct ac_llvm_compiler *ac_llvm,
-                            const struct radv_nir_compiler_options *options,
-                            const struct radv_shader_info *info,
-                            struct nir_shader *geom_shader,
-                            struct radv_shader_binary **rbinary,
-                            const struct radv_shader_args *args)
-{
-   struct radv_shader_context ctx = {0};
-   ctx.args = args;
-   ctx.options = options;
-   ctx.shader_info = info;
-
-   assert(args->is_gs_copy_shader);
-
-   ac_llvm_context_init(&ctx.ac, ac_llvm, options->gfx_level, options->family,
-                        options->has_3d_cube_border_color_mipmap,
-                        AC_FLOAT_MODE_DEFAULT, 64, 64);
-   ctx.context = ctx.ac.context;
-
-   ctx.stage = MESA_SHADER_VERTEX;
-   ctx.shader = geom_shader;
-
-   create_function(&ctx, MESA_SHADER_VERTEX, false);
-
-   ac_setup_rings(&ctx);
-
-   nir_foreach_shader_out_variable(variable, geom_shader)
-   {
-      scan_shader_output_decl(&ctx, variable, geom_shader, MESA_SHADER_VERTEX);
-      ac_handle_shader_output_decl(&ctx.ac, &ctx.abi, geom_shader, variable, MESA_SHADER_VERTEX);
-   }
-
-   ac_gs_copy_shader_emit(&ctx);
-
-   LLVMBuildRetVoid(ctx.ac.builder);
-
-   ac_llvm_finalize_module(&ctx, ac_llvm->passmgr);
-
-   ac_compile_llvm_module(ac_llvm, ctx.ac.module, rbinary, MESA_SHADER_VERTEX, "GS Copy Shader",
-                          options);
-   (*rbinary)->is_gs_copy_shader = true;
-}
-
 void
 llvm_compile_shader(const struct radv_nir_compiler_options *options,
                     const struct radv_shader_info *info, unsigned shader_count,
diff --git a/src/amd/vulkan/radv_shader.c b/src/amd/vulkan/radv_shader.c
index 58ee3deb3ccc..300fe904c15f 100644
--- a/src/amd/vulkan/radv_shader.c
+++ b/src/amd/vulkan/radv_shader.c
@@ -2045,8 +2045,7 @@ radv_open_rtld_binary(struct radv_device *device, const struct radv_shader *shad
    unsigned num_lds_symbols = 0;
 
    if (device->physical_device->rad_info.gfx_level >= GFX9 &&
-       (binary->stage == MESA_SHADER_GEOMETRY || binary->info.is_ngg) &&
-       !binary->is_gs_copy_shader) {
+       (binary->stage == MESA_SHADER_GEOMETRY || binary->info.is_ngg)) {
       struct ac_rtld_symbol *sym = &lds_symbols[num_lds_symbols++];
       sym->name = "esgs_ring";
       sym->size = binary->info.ngg_info.esgs_ring_size;
@@ -2295,7 +2294,6 @@ radv_dump_nir_shaders(struct nir_shader *const *shaders, int shader_count)
 static void
 radv_aco_build_shader_binary(void **bin,
                              gl_shader_stage stage,
-                             bool is_gs_copy_shader,
                              const struct ac_shader_config *config,
                              const char *llvm_ir_str,
                              unsigned llvm_ir_size,
@@ -2322,7 +2320,6 @@ radv_aco_build_shader_binary(void **bin,
    struct radv_shader_binary_legacy *legacy_binary = (struct radv_shader_binary_legacy *)calloc(size, 1);
    legacy_binary->base.type = RADV_BINARY_TYPE_LEGACY;
    legacy_binary->base.stage = stage;
-   legacy_binary->base.is_gs_copy_shader = is_gs_copy_shader;
    legacy_binary->base.total_size = size;
    legacy_binary->base.config = *config;
 
diff --git a/src/amd/vulkan/radv_shader.h b/src/amd/vulkan/radv_shader.h
index 0efe7e32b5f7..f9a5ed50f2b0 100644
--- a/src/amd/vulkan/radv_shader.h
+++ b/src/amd/vulkan/radv_shader.h
@@ -429,7 +429,6 @@ enum radv_shader_binary_type { RADV_BINARY_TYPE_LEGACY, RADV_BINARY_TYPE_RTLD };
 struct radv_shader_binary {
    enum radv_shader_binary_type type;
    gl_shader_stage stage;
-   bool is_gs_copy_shader;
 
    struct ac_shader_config config;
    struct radv_shader_info info;
-- 
GitLab


From 56bc5cd3e32d413b6110308c79be2166c4ca7d3a Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Fri, 30 Sep 2022 19:49:56 +0100
Subject: [PATCH 7/8] radv,aco: remove old streamout code

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 .../compiler/aco_instruction_selection.cpp    | 113 -----------------
 src/amd/compiler/aco_shader_info.h            |  15 ---
 src/amd/vulkan/radv_aco_shader_info.h         |  11 --
 src/amd/vulkan/radv_nir_to_llvm.c             | 120 ------------------
 src/amd/vulkan/radv_shader.h                  |   9 --
 src/amd/vulkan/radv_shader_info.c             |  12 +-
 6 files changed, 3 insertions(+), 277 deletions(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index ec45c1a6d36c..c7f58a39c0a2 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -11553,119 +11553,6 @@ create_fs_exports(isel_context* ctx)
    ctx->block->kind |= block_kind_export_end;
 }
 
-static void
-emit_stream_output(isel_context* ctx, Temp const* so_buffers, Temp const* so_write_offset,
-                   const struct aco_stream_output* output)
-{
-   assert(ctx->stage.hw == HWStage::VS);
-
-   unsigned loc = output->location;
-   unsigned buf = output->buffer;
-
-   unsigned writemask = output->component_mask & ctx->outputs.mask[loc];
-   while (writemask) {
-      int start, count;
-      u_bit_scan_consecutive_range(&writemask, &start, &count);
-      if (count == 3 && ctx->options->gfx_level == GFX6) {
-         /* GFX6 doesn't support storing vec3, split it. */
-         writemask |= 1u << (start + 2);
-         count = 2;
-      }
-
-      unsigned offset = output->offset + (start - (ffs(output->component_mask) - 1)) * 4;
-
-      Temp write_data = ctx->program->allocateTmp(RegClass(RegType::vgpr, count));
-      aco_ptr<Pseudo_instruction> vec{create_instruction<Pseudo_instruction>(
-         aco_opcode::p_create_vector, Format::PSEUDO, count, 1)};
-      for (int i = 0; i < count; ++i)
-         vec->operands[i] = Operand(ctx->outputs.temps[loc * 4 + start + i]);
-      vec->definitions[0] = Definition(write_data);
-      ctx->block->instructions.emplace_back(std::move(vec));
-
-      aco_opcode opcode = get_buffer_store_op(count * 4);
-      aco_ptr<MUBUF_instruction> store{
-         create_instruction<MUBUF_instruction>(opcode, Format::MUBUF, 4, 0)};
-      store->operands[0] = Operand(so_buffers[buf]);
-      store->operands[1] = Operand(so_write_offset[buf]);
-      store->operands[2] = Operand::c32(0);
-      store->operands[3] = Operand(write_data);
-      if (offset > 4095) {
-         /* Don't think this can happen in RADV, but maybe GL? It's easy to do this anyway. */
-         Builder bld(ctx->program, ctx->block);
-         store->operands[1] =
-            bld.vadd32(bld.def(v1), Operand::c32(offset), Operand(so_write_offset[buf]));
-      } else {
-         store->offset = offset;
-      }
-      store->offen = true;
-      store->glc = ctx->program->gfx_level < GFX11;
-      store->dlc = false;
-      store->slc = true;
-      ctx->block->instructions.emplace_back(std::move(store));
-   }
-}
-
-static void
-emit_streamout(isel_context* ctx, unsigned stream)
-{
-   Builder bld(ctx->program, ctx->block);
-
-   Temp so_vtx_count =
-      bld.sop2(aco_opcode::s_bfe_u32, bld.def(s1), bld.def(s1, scc),
-               get_arg(ctx, ctx->args->ac.streamout_config), Operand::c32(0x70010u));
-
-   Temp tid = emit_mbcnt(ctx, bld.tmp(v1));
-
-   Temp can_emit = bld.vopc(aco_opcode::v_cmp_gt_i32, bld.def(bld.lm), so_vtx_count, tid);
-
-   if_context ic;
-   begin_divergent_if_then(ctx, &ic, can_emit);
-
-   bld.reset(ctx->block);
-
-   Temp so_write_index =
-      bld.vadd32(bld.def(v1), get_arg(ctx, ctx->args->ac.streamout_write_index), tid);
-
-   Temp so_buffers[4];
-   Temp so_write_offset[4];
-   Temp buf_ptr = convert_pointer_to_64_bit(ctx, get_arg(ctx, ctx->args->streamout_buffers));
-
-   for (unsigned i = 0; i < 4; i++) {
-      unsigned stride = ctx->program->info.so.strides[i];
-      if (!stride)
-         continue;
-
-      so_buffers[i] = bld.smem(aco_opcode::s_load_dwordx4, bld.def(s4), buf_ptr,
-                               bld.copy(bld.def(s1), Operand::c32(i * 16u)));
-
-      if (stride == 1) {
-         Temp offset = bld.sop2(aco_opcode::s_add_i32, bld.def(s1), bld.def(s1, scc),
-                                get_arg(ctx, ctx->args->ac.streamout_write_index),
-                                get_arg(ctx, ctx->args->ac.streamout_offset[i]));
-         Temp new_offset = bld.vadd32(bld.def(v1), offset, tid);
-
-         so_write_offset[i] =
-            bld.vop2(aco_opcode::v_lshlrev_b32, bld.def(v1), Operand::c32(2u), new_offset);
-      } else {
-         Temp offset = bld.v_mul_imm(bld.def(v1), so_write_index, stride * 4u);
-         Temp offset2 = bld.sop2(aco_opcode::s_mul_i32, bld.def(s1), Operand::c32(4u),
-                                 get_arg(ctx, ctx->args->ac.streamout_offset[i]));
-         so_write_offset[i] = bld.vadd32(bld.def(v1), offset, offset2);
-      }
-   }
-
-   for (unsigned i = 0; i < ctx->program->info.so.num_outputs; i++) {
-      const struct aco_stream_output* output = &ctx->program->info.so.outputs[i];
-      if (stream != output->stream)
-         continue;
-
-      emit_stream_output(ctx, so_buffers, so_write_offset, output);
-   }
-
-   begin_divergent_if_else(ctx, &ic);
-   end_divergent_if(ctx, &ic);
-}
-
 Pseudo_instruction*
 add_startpgm(struct isel_context* ctx)
 {
diff --git a/src/amd/compiler/aco_shader_info.h b/src/amd/compiler/aco_shader_info.h
index a36e204315cb..826aee6918c3 100644
--- a/src/amd/compiler/aco_shader_info.h
+++ b/src/amd/compiler/aco_shader_info.h
@@ -88,20 +88,6 @@ struct aco_vp_output_info {
    bool export_clip_dists;
 };
 
-struct aco_stream_output {
-   uint8_t location;
-   uint8_t buffer;
-   uint16_t offset;
-   uint8_t component_mask;
-   uint8_t stream;
-};
-
-struct aco_streamout_info {
-   uint16_t num_outputs;
-   struct aco_stream_output outputs[ACO_MAX_SO_OUTPUTS];
-   uint16_t strides[ACO_MAX_SO_BUFFERS];
-};
-
 struct aco_shader_info {
    uint8_t wave_size;
    bool is_ngg;
@@ -143,7 +129,6 @@ struct aco_shader_info {
    struct {
       uint8_t subgroup_size;
    } cs;
-   struct aco_streamout_info so;
 
    uint32_t gfx9_gs_ring_lds_size;
 };
diff --git a/src/amd/vulkan/radv_aco_shader_info.h b/src/amd/vulkan/radv_aco_shader_info.h
index 795973898851..2381feadc81a 100644
--- a/src/amd/vulkan/radv_aco_shader_info.h
+++ b/src/amd/vulkan/radv_aco_shader_info.h
@@ -34,16 +34,6 @@
 #define ASSIGN_FIELD(x) aco_info->x = radv->x
 #define ASSIGN_FIELD_CP(x) memcpy(&aco_info->x, &radv->x, sizeof(radv->x))
 
-static inline void
-radv_aco_convert_shader_so_info(struct aco_shader_info *aco_info,
-                       const struct radv_shader_info *radv)
-{
-   ASSIGN_FIELD(so.num_outputs);
-   ASSIGN_FIELD_CP(so.outputs);
-   ASSIGN_FIELD_CP(so.strides);
-   /* enabled_stream_buffers_mask unused */
-}
-
 static inline void
 radv_aco_convert_shader_vp_info(struct aco_vp_output_info *aco_info,
 				const struct radv_vs_output_info *radv)
@@ -97,7 +87,6 @@ radv_aco_convert_shader_info(struct aco_shader_info *aco_info,
    ASSIGN_FIELD(ps.num_interp);
    ASSIGN_FIELD(ps.spi_ps_input);
    ASSIGN_FIELD(cs.subgroup_size);
-   radv_aco_convert_shader_so_info(aco_info, radv);
    aco_info->gfx9_gs_ring_lds_size = radv->gs_ring_info.lds_size;
 }
 
diff --git a/src/amd/vulkan/radv_nir_to_llvm.c b/src/amd/vulkan/radv_nir_to_llvm.c
index 42acbd7554d7..6de8bec96a17 100644
--- a/src/amd/vulkan/radv_nir_to_llvm.c
+++ b/src/amd/vulkan/radv_nir_to_llvm.c
@@ -727,126 +727,6 @@ radv_load_output(struct radv_shader_context *ctx, unsigned index, unsigned chan)
    return LLVMBuildLoad2(ctx->ac.builder, type, output, "");
 }
 
-static void
-radv_emit_stream_output(struct radv_shader_context *ctx, LLVMValueRef const *so_buffers,
-                        LLVMValueRef const *so_write_offsets,
-                        const struct radv_stream_output *output,
-                        struct radv_shader_output_values *shader_out)
-{
-   unsigned num_comps = util_bitcount(output->component_mask);
-   unsigned buf = output->buffer;
-   unsigned offset = output->offset;
-   unsigned start;
-   LLVMValueRef out[4];
-
-   assert(num_comps && num_comps <= 4);
-   if (!num_comps || num_comps > 4)
-      return;
-
-   /* Get the first component. */
-   start = ffs(output->component_mask) - 1;
-
-   /* Load the output as int. */
-   for (int i = 0; i < num_comps; i++) {
-      out[i] = ac_to_integer(&ctx->ac, shader_out->values[start + i]);
-   }
-
-   /* Pack the output. */
-   LLVMValueRef vdata = NULL;
-
-   switch (num_comps) {
-   case 1: /* as i32 */
-      vdata = out[0];
-      break;
-   case 2: /* as v2i32 */
-   case 3: /* as v3i32 */
-   case 4: /* as v4i32 */
-      vdata = ac_build_gather_values(&ctx->ac, out, num_comps);
-      break;
-   }
-
-   LLVMValueRef voffset = LLVMBuildAdd(ctx->ac.builder, so_write_offsets[buf],
-                                       LLVMConstInt(ctx->ac.i32, offset, 0), "");
-   ac_build_buffer_store_dword(&ctx->ac, so_buffers[buf], vdata, NULL, voffset, ctx->ac.i32_0,
-                               ac_glc | ac_slc);
-}
-
-static void
-radv_emit_streamout(struct radv_shader_context *ctx, unsigned stream)
-{
-   int i;
-
-   /* Get bits [22:16], i.e. (so_param >> 16) & 127; */
-   assert(ctx->args->ac.streamout_config.used);
-   LLVMValueRef so_vtx_count = ac_build_bfe(
-      &ctx->ac, ac_get_arg(&ctx->ac, ctx->args->ac.streamout_config),
-      LLVMConstInt(ctx->ac.i32, 16, false), LLVMConstInt(ctx->ac.i32, 7, false), false);
-
-   LLVMValueRef tid = ac_get_thread_id(&ctx->ac);
-
-   /* can_emit = tid < so_vtx_count; */
-   LLVMValueRef can_emit = LLVMBuildICmp(ctx->ac.builder, LLVMIntULT, tid, so_vtx_count, "");
-
-   /* Emit the streamout code conditionally. This actually avoids
-    * out-of-bounds buffer access. The hw tells us via the SGPR
-    * (so_vtx_count) which threads are allowed to emit streamout data.
-    */
-   ac_build_ifcc(&ctx->ac, can_emit, 6501);
-   {
-      /* The buffer offset is computed as follows:
-       *   ByteOffset = streamout_offset[buffer_id]*4 +
-       *                (streamout_write_index + thread_id)*stride[buffer_id] +
-       *                attrib_offset
-       */
-      LLVMValueRef so_write_index = ac_get_arg(&ctx->ac, ctx->args->ac.streamout_write_index);
-
-      /* Compute (streamout_write_index + thread_id). */
-      so_write_index = LLVMBuildAdd(ctx->ac.builder, so_write_index, tid, "");
-
-      /* Load the descriptor and compute the write offset for each
-       * enabled buffer.
-       */
-      LLVMValueRef so_write_offset[4] = {0};
-      LLVMValueRef so_buffers[4] = {0};
-      struct ac_llvm_pointer buf_ptr = ac_get_ptr_arg(&ctx->ac, &ctx->args->ac, ctx->args->streamout_buffers);
-
-      for (i = 0; i < 4; i++) {
-         uint16_t stride = ctx->shader_info->so.strides[i];
-
-         if (!stride)
-            continue;
-
-         LLVMValueRef offset = LLVMConstInt(ctx->ac.i32, i, false);
-
-         so_buffers[i] = ac_build_load_to_sgpr(&ctx->ac, buf_ptr, offset);
-
-         LLVMValueRef so_offset = ac_get_arg(&ctx->ac, ctx->args->ac.streamout_offset[i]);
-
-         so_offset =
-            LLVMBuildMul(ctx->ac.builder, so_offset, LLVMConstInt(ctx->ac.i32, 4, false), "");
-
-         so_write_offset[i] = ac_build_imad(
-            &ctx->ac, so_write_index, LLVMConstInt(ctx->ac.i32, stride * 4, false), so_offset);
-      }
-
-      /* Write streamout data. */
-      for (i = 0; i < ctx->shader_info->so.num_outputs; i++) {
-         struct radv_shader_output_values shader_out = {0};
-         const struct radv_stream_output *output = &ctx->shader_info->so.outputs[i];
-
-         if (stream != output->stream)
-            continue;
-
-         for (int j = 0; j < 4; j++) {
-            shader_out.values[j] = radv_load_output(ctx, output->location, j);
-         }
-
-         radv_emit_stream_output(ctx, so_buffers, so_write_offset, output, &shader_out);
-      }
-   }
-   ac_build_endif(&ctx->ac, 6501);
-}
-
 static void
 radv_build_param_exports(struct radv_shader_context *ctx, struct radv_shader_output_values *outputs,
                          unsigned noutput, const struct radv_vs_output_info *outinfo,
diff --git a/src/amd/vulkan/radv_shader.h b/src/amd/vulkan/radv_shader.h
index f9a5ed50f2b0..06086942deda 100644
--- a/src/amd/vulkan/radv_shader.h
+++ b/src/amd/vulkan/radv_shader.h
@@ -171,17 +171,8 @@ enum radv_ud_index {
    AC_UD_MAX_UD = AC_UD_CS_MAX_UD,
 };
 
-struct radv_stream_output {
-   uint8_t location;
-   uint8_t buffer;
-   uint16_t offset;
-   uint8_t component_mask;
-   uint8_t stream;
-};
-
 struct radv_streamout_info {
    uint16_t num_outputs;
-   struct radv_stream_output outputs[MAX_SO_OUTPUTS];
    uint16_t strides[MAX_SO_BUFFERS];
    uint32_t enabled_stream_buffers_mask;
 };
diff --git a/src/amd/vulkan/radv_shader_info.c b/src/amd/vulkan/radv_shader_info.c
index 5a44e0264026..c5fef4443727 100644
--- a/src/amd/vulkan/radv_shader_info.c
+++ b/src/amd/vulkan/radv_shader_info.c
@@ -287,15 +287,9 @@ gather_xfb_info(const nir_shader *nir, struct radv_shader_info *info)
    so->num_outputs = xfb->output_count;
 
    for (unsigned i = 0; i < xfb->output_count; i++) {
-      struct radv_stream_output *output = &so->outputs[i];
-
-      output->buffer = xfb->outputs[i].buffer;
-      output->stream = xfb->buffer_to_stream[xfb->outputs[i].buffer];
-      output->offset = xfb->outputs[i].offset;
-      output->location = xfb->outputs[i].location;
-      output->component_mask = xfb->outputs[i].component_mask;
-
-      so->enabled_stream_buffers_mask |= (1 << output->buffer) << (output->stream * 4);
+      unsigned output_buffer = xfb->outputs[i].buffer;
+      unsigned stream = xfb->buffer_to_stream[xfb->outputs[i].buffer];
+      so->enabled_stream_buffers_mask |= (1 << output_buffer) << (stream * 4);
    }
 
    for (unsigned i = 0; i < NIR_MAX_XFB_BUFFERS; i++) {
-- 
GitLab


From 7c1b0227726e1758ee810d00883125bd1d4df67d Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 28 Sep 2022 20:24:14 +0100
Subject: [PATCH 8/8] radv: compile GS copy shader after geometry shader

This affects the pipeline feedback durations: GS copy shader compilation
is now included in the GS compilation duration.

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/vulkan/radv_pipeline.c | 13 ++++++-------
 1 file changed, 6 insertions(+), 7 deletions(-)

diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index 939add4bf791..68483d91f8a8 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -3669,13 +3669,6 @@ radv_pipeline_nir_to_asm(struct radv_pipeline *pipeline, struct radv_pipeline_st
    bool pipeline_has_ngg = last_vgt_api_stage != MESA_SHADER_NONE &&
                            stages[last_vgt_api_stage].info.is_ngg;
 
-   if (stages[MESA_SHADER_GEOMETRY].nir && !pipeline_has_ngg) {
-      pipeline->gs_copy_shader =
-         radv_pipeline_create_gs_copy_shader(pipeline, stages, pipeline_key, pipeline_layout,
-                                             keep_executable_info, keep_statistic_info,
-                                             gs_copy_binary);
-   }
-
    for (int s = MESA_VULKAN_SHADER_STAGES - 1; s >= 0; s--) {
       if (!(active_stages & (1 << s)) || pipeline->shaders[s])
          continue;
@@ -3705,6 +3698,12 @@ radv_pipeline_nir_to_asm(struct radv_pipeline *pipeline, struct radv_pipeline_st
                                                     pipeline_key, keep_executable_info,
                                                     keep_statistic_info, &binaries[s]);
 
+      if (s == MESA_SHADER_GEOMETRY && !pipeline_has_ngg) {
+         pipeline->gs_copy_shader = radv_pipeline_create_gs_copy_shader(
+            pipeline, stages, pipeline_key, pipeline_layout, keep_executable_info,
+            keep_statistic_info, gs_copy_binary);
+      }
+
       stages[s].feedback.duration += os_time_get_nano() - stage_start;
 
       active_stages &= ~(1 << shaders[0]->info.stage);
-- 
GitLab

