From 5a03418b4dcfea2f3cd359c1caca38aa4098e4c4 Mon Sep 17 00:00:00 2001
From: Mike Blumenkrantz <michael.blumenkrantz@gmail.com>
Date: Mon, 12 Sep 2022 13:55:44 -0400
Subject: [PATCH 03/13] radv: hoist indirect check up from
 radv_emit_index_buffer()

avoid calling the function entirely when possible, as info->indirect
should be possible to inline as a nullable stack value
---
 src/amd/vulkan/radv_cmd_buffer.c | 13 +++++--------
 1 file changed, 5 insertions(+), 8 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index dc8f34b9521d..f6fd231cc97a 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -2786,7 +2786,7 @@ radv_emit_guardband_state(struct radv_cmd_buffer *cmd_buffer)
 }

 static void
-radv_emit_index_buffer(struct radv_cmd_buffer *cmd_buffer, bool indirect)
+radv_emit_index_buffer(struct radv_cmd_buffer *cmd_buffer)
 {
    struct radeon_cmdbuf *cs = cmd_buffer->cs;
    struct radv_cmd_state *state = &cmd_buffer->state;
@@ -2796,11 +2796,6 @@ radv_emit_index_buffer(struct radv_cmd_buffer *cmd_buffer, bool indirect)
    if (state->index_type < 0)
       return;

-   /* For the direct indexed draws we use DRAW_INDEX_2, which includes
-    * the index_va and max_index_count already. */
-   if (!indirect)
-      return;
-
    if (state->max_index_count ||
        !cmd_buffer->device->physical_device->rad_info.has_zero_index_buffer_bug) {
       radeon_emit(cs, PKT3(PKT3_INDEX_BASE, 1, 0));
@@ -7294,8 +7289,10 @@ radv_emit_all_graphics_states(struct radv_cmd_buffer *cmd_buffer, const struct r
       radv_emit_guardband_state(cmd_buffer);

    if (info->indexed) {
-      if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_INDEX_BUFFER)
-         radv_emit_index_buffer(cmd_buffer, info->indirect);
+      /* For the direct indexed draws we use DRAW_INDEX_2, which includes
+       * the index_va and max_index_count already. */
+      if (info->indirect && cmd_buffer->state.dirty & RADV_CMD_DIRTY_INDEX_BUFFER)
+         radv_emit_index_buffer(cmd_buffer);
    } else {
       /* On GFX7 and later, non-indexed draws overwrite VGT_INDEX_TYPE,
        * so the state must be re-emitted before the next indexed
--
GitLab


From cd84801f47e00c2fd1d36b1389070ac90e46b951 Mon Sep 17 00:00:00 2001
From: Mike Blumenkrantz <michael.blumenkrantz@gmail.com>
Date: Mon, 12 Sep 2022 15:01:37 -0400
Subject: [PATCH 05/13] radv: unset all dynamic state flags after
 radv_cmd_buffer_flush_dynamic_state()

it's irrelevant whether the states are actually updated here, as unused states
will be flagged again when a new pipeline is bound
---
 src/amd/vulkan/radv_cmd_buffer.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index 1b68a059b7cc..7dff9974a98c 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -3292,7 +3292,7 @@ radv_cmd_buffer_flush_dynamic_state(struct radv_cmd_buffer *cmd_buffer, bool pip
    if (states & RADV_CMD_DIRTY_DYNAMIC_PATCH_CONTROL_POINTS)
       radv_emit_patch_control_points(cmd_buffer);

-   cmd_buffer->state.dirty &= ~states;
+   cmd_buffer->state.dirty &= ~RADV_CMD_DIRTY_DYNAMIC_ALL;
 }

 static void
--
GitLab


From aca59253acdb504c8af72a58a7e1f08453e65105 Mon Sep 17 00:00:00 2001
From: Mike Blumenkrantz <michael.blumenkrantz@gmail.com>
Date: Wed, 14 Sep 2022 16:40:33 -0400
Subject: [PATCH 12/13] radv: consolidate indexed draw paths

this reworks the existing code to behave identically, but with less code
by forcing inlined values
---
 src/amd/vulkan/radv_cmd_buffer.c | 184 +++++++++++++------------------
 1 file changed, 74 insertions(+), 110 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index 49b2d9696396..b174edfc1b99 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -6613,82 +6613,21 @@ radv_emit_userdata_task(struct radv_cmd_buffer *cmd_buffer, uint32_t x, uint32_t
 }

 ALWAYS_INLINE static void
-radv_emit_draw_packets_indexed(struct radv_cmd_buffer *cmd_buffer,
-                               const struct radv_draw_info *info,
-                               uint32_t drawCount, const VkMultiDrawIndexedInfoEXT *minfo,
-                               uint32_t stride,
-                               const int32_t *vertexOffset)
-
+radv_emit_draw_packets_indexed_internal(struct radv_cmd_buffer *cmd_buffer,
+                                        const struct radv_draw_info *info,
+                                        uint32_t drawCount, const VkMultiDrawIndexedInfoEXT *minfo,
+                                        uint32_t stride,
+                                        const int32_t *vertexOffset,
+                                        const bool uses_drawid,
+                                        const bool can_eop)
 {
    struct radv_cmd_state *state = &cmd_buffer->state;
    struct radeon_cmdbuf *cs = cmd_buffer->cs;
    const int index_size = radv_get_vgt_index_size(state->index_type);
    unsigned i = 0;
-   const bool uses_drawid = state->graphics_pipeline->uses_drawid;
-   const bool can_eop =
-      !uses_drawid && cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX10;
-
-   if (uses_drawid) {
-      if (vertexOffset) {
-         radv_emit_userdata_vertex(cmd_buffer, info, *vertexOffset);
-         vk_foreach_multi_draw_indexed(draw, i, minfo, drawCount, stride) {
-            const uint32_t remaining_indexes = MAX2(state->max_index_count, draw->firstIndex) - draw->firstIndex;
-
-            /* Skip draw calls with 0-sized index buffers if the GPU can't handle them */
-            if (!remaining_indexes &&
-                cmd_buffer->device->physical_device->rad_info.has_zero_index_buffer_bug)
-               continue;
-
-            if (i > 0)
-               radeon_set_sh_reg(cs, state->graphics_pipeline->vtx_base_sgpr + sizeof(uint32_t), i);
-
-            const uint64_t index_va = state->index_va + draw->firstIndex * index_size;
-
-            if (!state->render.view_mask) {
-               radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, false);
-            } else {
-               u_foreach_bit(view, state->render.view_mask) {
-                  radv_emit_view_index(cmd_buffer, view);
-
-                  radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, false);
-               }
-            }
-         }
-      } else {
-         vk_foreach_multi_draw_indexed(draw, i, minfo, drawCount, stride) {
-            const uint32_t remaining_indexes = MAX2(state->max_index_count, draw->firstIndex) - draw->firstIndex;
-
-            /* Skip draw calls with 0-sized index buffers if the GPU can't handle them */
-            if (!remaining_indexes &&
-                cmd_buffer->device->physical_device->rad_info.has_zero_index_buffer_bug)
-               continue;
-
-            if (i > 0) {
-               if (state->last_vertex_offset != draw->vertexOffset)
-                  radv_emit_userdata_vertex_drawid(cmd_buffer, draw->vertexOffset, i);
-               else
-                  radeon_set_sh_reg(cs, state->graphics_pipeline->vtx_base_sgpr + sizeof(uint32_t), i);
-            } else
-               radv_emit_userdata_vertex(cmd_buffer, info, draw->vertexOffset);
-
-            const uint64_t index_va = state->index_va + draw->firstIndex * index_size;

-            if (!state->render.view_mask) {
-               radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, false);
-            } else {
-               u_foreach_bit(view, state->render.view_mask) {
-                  radv_emit_view_index(cmd_buffer, view);
-
-                  radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, false);
-               }
-            }
-         }
-      }
-      if (drawCount > 1) {
-         state->last_drawid = drawCount - 1;
-      }
-   } else {
-      if (vertexOffset) {
+   if (vertexOffset) {
+      if (!uses_drawid) {
          if (cmd_buffer->device->physical_device->rad_info.gfx_level == GFX10) {
             /* GFX10 has a bug that consecutive draw packets with NOT_EOP must not have
              * count == 0 for the last draw that doesn't have NOT_EOP.
@@ -6701,56 +6640,81 @@ radv_emit_draw_packets_indexed(struct radv_cmd_buffer *cmd_buffer,
             }
          }

-         radv_emit_userdata_vertex(cmd_buffer, info, *vertexOffset);
-         vk_foreach_multi_draw_indexed(draw, i, minfo, drawCount, stride) {
-            const uint32_t remaining_indexes = MAX2(state->max_index_count, draw->firstIndex) - draw->firstIndex;
-
-            /* Skip draw calls with 0-sized index buffers if the GPU can't handle them */
-            if (!remaining_indexes &&
-                cmd_buffer->device->physical_device->rad_info.has_zero_index_buffer_bug)
-               continue;
-
-            const uint64_t index_va = state->index_va + draw->firstIndex * index_size;
+      }
+      radv_emit_userdata_vertex(cmd_buffer, info, *vertexOffset);
+   }

-            if (!state->render.view_mask) {
-               radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, can_eop && i < drawCount - 1);
-            } else {
-               u_foreach_bit(view, state->render.view_mask) {
-                  radv_emit_view_index(cmd_buffer, view);
+   vk_foreach_multi_draw_indexed(draw, i, minfo, drawCount, stride) {
+      const uint32_t remaining_indexes = MAX2(state->max_index_count, draw->firstIndex) - draw->firstIndex;
+      bool offset_changes = false;

-                  radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, false);
-               }
-            }
-         }
-      } else {
-         vk_foreach_multi_draw_indexed(draw, i, minfo, drawCount, stride) {
-            const uint32_t remaining_indexes = MAX2(state->max_index_count, draw->firstIndex) - draw->firstIndex;
-
-            /* Skip draw calls with 0-sized index buffers if the GPU can't handle them */
-            if (!remaining_indexes &&
-                cmd_buffer->device->physical_device->rad_info.has_zero_index_buffer_bug)
-               continue;
+      /* Skip draw calls with 0-sized index buffers if the GPU can't handle them */
+      if (!remaining_indexes &&
+          cmd_buffer->device->physical_device->rad_info.has_zero_index_buffer_bug)
+         continue;

+      if (!vertexOffset) {
+         if (uses_drawid) {
+            if (i > 0) {
+               if (state->last_vertex_offset != draw->vertexOffset)
+                  radv_emit_userdata_vertex_drawid(cmd_buffer, draw->vertexOffset, i);
+               else
+                  radeon_set_sh_reg(cs, state->graphics_pipeline->vtx_base_sgpr + sizeof(uint32_t), i);
+            } else
+               radv_emit_userdata_vertex(cmd_buffer, info, draw->vertexOffset);
+         } else {
             const VkMultiDrawIndexedInfoEXT *next = (const VkMultiDrawIndexedInfoEXT*)(i < drawCount - 1 ? ((uint8_t*)draw + stride) : NULL);
-            const bool offset_changes = next && next->vertexOffset != draw->vertexOffset;
+            offset_changes = next && next->vertexOffset != draw->vertexOffset;
             radv_emit_userdata_vertex(cmd_buffer, info, draw->vertexOffset);
+         }
+      }

-            const uint64_t index_va = state->index_va + draw->firstIndex * index_size;
+      if (vertexOffset && uses_drawid) {
+         if (i > 0)
+            radeon_set_sh_reg(cs, state->graphics_pipeline->vtx_base_sgpr + sizeof(uint32_t), i);
+      }

-            if (!state->render.view_mask) {
-               radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, can_eop && !offset_changes && i < drawCount - 1);
-            } else {
-               u_foreach_bit(view, state->render.view_mask) {
-                  radv_emit_view_index(cmd_buffer, view);
+      const uint64_t index_va = state->index_va + draw->firstIndex * index_size;

-                  radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, false);
-               }
-            }
+      if (!state->render.view_mask) {
+         radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, can_eop && !offset_changes && i < drawCount - 1);
+      } else {
+         u_foreach_bit(view, state->render.view_mask) {
+            radv_emit_view_index(cmd_buffer, view);
+
+            radv_cs_emit_draw_indexed_packet(cmd_buffer, index_va, remaining_indexes, draw->indexCount, false);
          }
       }
-      if (drawCount > 1) {
-         state->last_drawid = drawCount - 1;
-      }
+   }
+
+   if (drawCount > 1) {
+      state->last_drawid = drawCount - 1;
+   }
+}
+
+ALWAYS_INLINE static void
+radv_emit_draw_packets_indexed(struct radv_cmd_buffer *cmd_buffer,
+                               const struct radv_draw_info *info,
+                               uint32_t drawCount, const VkMultiDrawIndexedInfoEXT *minfo,
+                               uint32_t stride,
+                               const int32_t *vertexOffset)
+
+{
+   struct radv_cmd_state *state = &cmd_buffer->state;
+   const bool uses_drawid = state->graphics_pipeline->uses_drawid;
+   const bool can_eop =
+      !uses_drawid && cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX10;
+
+   if (uses_drawid) {
+      if (vertexOffset)
+         radv_emit_draw_packets_indexed_internal(cmd_buffer, info, drawCount, minfo, stride, vertexOffset, true, can_eop);
+      else
+         radv_emit_draw_packets_indexed_internal(cmd_buffer, info, drawCount, minfo, stride, NULL, true, can_eop);
+   } else {
+      if (vertexOffset)
+         radv_emit_draw_packets_indexed_internal(cmd_buffer, info, drawCount, minfo, stride, vertexOffset, false, can_eop);
+      else
+         radv_emit_draw_packets_indexed_internal(cmd_buffer, info, drawCount, minfo, stride, NULL, false, can_eop);
    }
 }

--
GitLab


From d34d971ab006352ceaf4327f01d34f7ccd54ee5f Mon Sep 17 00:00:00 2001
From: Mike Blumenkrantz <michael.blumenkrantz@gmail.com>
Date: Wed, 14 Sep 2022 21:00:15 -0400
Subject: [PATCH 13/13] radv: use the vertexOffset path for indexed draws

this is slightly (~1%) faster
---
 src/amd/vulkan/radv_cmd_buffer.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index b174edfc1b99..a554db421a5a 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -7728,7 +7728,7 @@ radv_CmdDrawIndexed(VkCommandBuffer commandBuffer, uint32_t indexCount, uint32_t
    if (!radv_before_draw(cmd_buffer, &info, 1))
       return;
    const VkMultiDrawIndexedInfoEXT minfo = { firstIndex, indexCount, vertexOffset };
-   radv_emit_draw_packets_indexed(cmd_buffer, &info, 1, &minfo, 0, NULL);
+   radv_emit_draw_packets_indexed(cmd_buffer, &info, 1, &minfo, 0, &vertexOffset);
    radv_after_draw(cmd_buffer);
 }

--
GitLab
