--- a/src/amd/compiler/aco_optimizer.cpp	2025-05-31 22:57:26.003334290 +0200
+++ b/src/amd/compiler/aco_optimizer.cpp	2025-06-01 00:30:01.222104109 +0200
@@ -43,36 +43,35 @@ struct mad_info {
 };
 
 enum Label {
-   label_constant_32bit = 1 << 1,
-   /* label_{abs,neg,mul,omod2,omod4,omod5,clamp} are used for both 16 and
-    * 32-bit operations but this shouldn't cause any issues because we don't
-    * look through any conversions */
-   label_abs = 1 << 2,
-   label_neg = 1 << 3,
-   label_temp = 1 << 5,
-   label_literal = 1 << 6,
-   label_mad = 1 << 7,
-   label_omod2 = 1 << 8,
-   label_omod4 = 1 << 9,
-   label_omod5 = 1 << 10,
-   label_clamp = 1 << 12,
-   label_b2f = 1 << 16,
-   label_uniform_bool = 1 << 21,
-   label_constant_64bit = 1 << 22,
-   label_uniform_bitwise = 1 << 23,
-   label_scc_invert = 1 << 24,
-   label_scc_needed = 1 << 26,
-   label_b2i = 1 << 27,
-   label_fcanonicalize = 1 << 28,
-   label_constant_16bit = 1 << 29,
-   label_canonicalized = 1ull << 32, /* 1ull to prevent sign extension */
-   label_extract = 1ull << 33,
-   label_insert = 1ull << 34,
-   label_f2f16 = 1ull << 38,
+    label_constant_32bit = 1 << 1,
+    label_abs = 1 << 2,
+    label_neg = 1 << 3,
+    label_temp = 1 << 5,
+    label_literal = 1 << 6,
+    label_mad = 1 << 7,
+    label_omod2 = 1 << 8,
+    label_omod4 = 1 << 9,
+    label_omod5 = 1 << 10,
+    label_clamp = 1 << 12,
+    label_b2f = 1 << 16,
+    label_uniform_bool = 1 << 21,
+    label_constant_64bit = 1 << 22,
+    label_uniform_bitwise = 1 << 23,
+    label_scc_invert = 1 << 24,
+    label_scc_needed = 1 << 26,
+    label_b2i = 1 << 27,
+    label_fcanonicalize = 1 << 28,
+    label_constant_16bit = 1 << 29,
+    label_canonicalized = 1ull << 32,
+    label_extract = 1ull << 33,
+    label_insert = 1ull << 34,
+    label_precise = 1ull << 35,
+    label_f2f16 = 1ull << 38,
 };
 
 static constexpr uint64_t instr_mod_labels =
-   label_omod2 | label_omod4 | label_omod5 | label_clamp | label_insert | label_f2f16;
+label_omod2 | label_omod4 | label_omod5 | label_clamp | label_insert | label_f2f16 |
+label_canonicalized | label_precise;
 
 static constexpr uint64_t temp_labels = label_abs | label_neg | label_temp | label_b2f |
                                         label_uniform_bool | label_scc_invert | label_b2i |
@@ -85,40 +84,40 @@ static_assert((instr_mod_labels & val_la
 static_assert((temp_labels & val_labels) == 0, "labels cannot intersect");
 
 struct ssa_info {
-   uint64_t label;
-   union {
-      uint32_t val;
-      Temp temp;
-      Instruction* mod_instr;
-   };
-   Instruction* parent_instr;
+    uint64_t label;
+    union {
+        uint32_t val;
+        Temp temp;
+        Instruction* mod_instr;
+    };
+    Instruction* parent_instr;
+
+    ssa_info() : label(0) {}
+
+    void add_label(Label new_label)
+    {
+        if (new_label & instr_mod_labels) {
+            label &= ~instr_mod_labels;
+            label &= ~(temp_labels | val_labels); /* instr, temp and val alias */
+        }
+
+        if (new_label & temp_labels) {
+            label &= ~temp_labels;
+            label &= ~(instr_mod_labels | val_labels); /* instr, temp and val alias */
+        }
+
+        uint32_t const_labels =
+        label_literal | label_constant_32bit | label_constant_64bit | label_constant_16bit;
+        if (new_label & const_labels) {
+            label &= ~val_labels | const_labels;
+            label &= ~(instr_mod_labels | temp_labels); /* instr, temp and val alias */
+        } else if (new_label & val_labels) {
+            label &= ~val_labels;
+            label &= ~(instr_mod_labels | temp_labels); /* instr, temp and val alias */
+        }
 
-   ssa_info() : label(0) {}
-
-   void add_label(Label new_label)
-   {
-      if (new_label & instr_mod_labels) {
-         label &= ~instr_mod_labels;
-         label &= ~(temp_labels | val_labels); /* instr, temp and val alias */
-      }
-
-      if (new_label & temp_labels) {
-         label &= ~temp_labels;
-         label &= ~(instr_mod_labels | val_labels); /* instr, temp and val alias */
-      }
-
-      uint32_t const_labels =
-         label_literal | label_constant_32bit | label_constant_64bit | label_constant_16bit;
-      if (new_label & const_labels) {
-         label &= ~val_labels | const_labels;
-         label &= ~(instr_mod_labels | temp_labels); /* instr, temp and val alias */
-      } else if (new_label & val_labels) {
-         label &= ~val_labels;
-         label &= ~(instr_mod_labels | temp_labels); /* instr, temp and val alias */
-      }
-
-      label |= new_label;
-   }
+        label |= new_label;
+    }
 
    void set_constant(amd_gfx_level gfx_level, uint64_t constant)
    {
@@ -3297,190 +3296,464 @@ propagate_swizzles(VALU_instruction* ins
    }
 }
 
-void
-combine_vop3p(opt_ctx& ctx, aco_ptr<Instruction>& instr)
+template <typename GfxEnum>
+static inline bool can_use_inline_constant(GfxEnum /*gfx_level*/,
+                                           uint32_t literal)
+{
+    /* 1.a  Small signed / unsigned integers that map to the 8-bit “iconst”
+     *      encoding used by all GFX generations.
+     */
+    if (literal <= 64u)               /* 0 … 64                              */
+        return true;
+    if (literal >= 0xfffffff0u)       /* −16 … −1  (two-complement, 32-bit)  */
+        return true;
+
+    /* 1.b  Canonical 32-bit float immediates that the assembler always
+     *      encodes as inline constants.
+     */
+    switch (literal) {
+        case 0x3f000000u: /*  0.5f */ case 0xbf000000u: /* -0.5f */
+        case 0x3f800000u: /*  1.0f */ case 0xbf800000u: /* -1.0f */
+        case 0x40000000u: /*  2.0f */ case 0xc0000000u: /* -2.0f */
+        case 0x40800000u: /*  4.0f */ case 0xc0800000u: /* -4.0f */
+            return true;
+
+        default:
+            return false;
+    }
+}
+
+bool is_literal_valid_for_vop3p_vega(aco_opcode     op,
+                                     const Operand& lit)
 {
-   VALU_instruction* vop3p = &instr->valu();
+    switch (op) {
+        case aco_opcode::v_pk_mad_i16:
+            /* GFX9: instruction does **not** support any literal at all */
+            return false;
 
-   /* apply clamp */
-   if (instr->opcode == aco_opcode::v_pk_mul_f16 && instr->operands[1].constantEquals(0x3C00) &&
-       vop3p->clamp && instr->operands[0].isTemp() && ctx.uses[instr->operands[0].tempId()] == 1 &&
-       !vop3p->opsel_lo[1] && !vop3p->opsel_hi[1]) {
-
-      Instruction* op_instr = ctx.info[instr->operands[0].tempId()].parent_instr;
-      if (op_instr->isVOP3P() &&
-          instr_info.alu_opcode_infos[(int)op_instr->opcode].output_modifiers) {
-         op_instr->valu().clamp = true;
-         propagate_swizzles(&op_instr->valu(), vop3p->opsel_lo[0], vop3p->opsel_hi[0]);
-         instr->definitions[0].swapTemp(op_instr->definitions[0]);
-         ctx.info[op_instr->definitions[0].tempId()].parent_instr = op_instr;
-         ctx.info[instr->definitions[0].tempId()].parent_instr = instr.get();
-         ctx.uses[instr->definitions[0].tempId()]--;
-         return;
-      }
-   }
+        case aco_opcode::v_pk_fma_f16:
+        case aco_opcode::v_pk_mad_u16:
+            /* Only inline constants, never a full 32-bit literal slot   */
+            return lit.isConstant() &&
+            can_use_inline_constant(GFX9, lit.constantValue());
+
+        default:
+            return true;
+    }
+}
+
+void propagate_swizzles_vega(VALU_instruction* instr,
+                             bool              opsel_lo,
+                             bool              opsel_hi)
+{
+    constexpr unsigned N = 3;  /* VOP3P has up to three src operands */
+
+    /* Fast path – both halves come from the ‘hi’ 16 bits: flip everything */
+    if (opsel_lo && opsel_hi) {
+        for (unsigned i = 0; i < N; ++i) {
+            bool tmp;
+
+            tmp = instr->opsel_lo[i];
+            instr->opsel_lo[i] = instr->opsel_hi[i];
+            instr->opsel_hi[i] = tmp;
+
+            tmp = instr->neg_lo[i];
+            instr->neg_lo[i]  = instr->neg_hi[i];
+            instr->neg_hi[i]  = tmp;
+        }
+        return;
+    }
+
+    /* Cache old state so we can shuffle safely */
+    bool old_opsel_lo[N], old_opsel_hi[N];
+    bool old_neg_lo  [N], old_neg_hi  [N];
+    for (unsigned i = 0; i < N; ++i) {
+        old_opsel_lo[i] = instr->opsel_lo[i];
+        old_opsel_hi[i] = instr->opsel_hi[i];
+        old_neg_lo  [i] = instr->neg_lo  [i];
+        old_neg_hi  [i] = instr->neg_hi  [i];
+    }
+
+    /* If the former *hi* half is now consumed as *lo* … */
+    if (opsel_lo) {
+        for (unsigned i = 0; i < N; ++i) {
+            instr->opsel_lo[i] = old_opsel_hi[i];
+            instr->neg_lo  [i] = old_neg_hi[i];
+        }
+    }
+
+    /* If the former *lo* half is now consumed as *hi* … */
+    if (!opsel_hi) {
+        for (unsigned i = 0; i < N; ++i) {
+            instr->opsel_hi[i] = old_opsel_lo[i];
+            instr->neg_hi  [i] = old_neg_lo[i];
+        }
+    }
+}
+
+void combine_vop3p(opt_ctx& ctx, aco_ptr<Instruction>& instr)
+{
+    if (!instr || !instr->isVOP3P())
+        return;
+
+    VALU_instruction* vop3p = &instr->valu();
+
+    // 1. Clamp propagation with full safety
+    if (instr->opcode == aco_opcode::v_pk_mul_f16 &&
+        instr->operands.size() >= 2 &&
+        instr->operands[1].isConstant() &&
+        instr->operands[1].constantEquals(0x3C00) &&
+        vop3p->clamp &&
+        instr->operands[0].isTemp()) {
+
+        Temp src_temp = instr->operands[0].getTemp();
+
+    // Safe bounds check
+    if (src_temp.id() >= ctx.uses.size() ||
+        ctx.uses[src_temp.id()] != 1)
+        return;
+
+    // Safe info access
+    if (src_temp.id() >= ctx.info.size())
+        return;
+
+        Instruction* mul_src = ctx.info[src_temp.id()].parent_instr;
+    if (!mul_src || !mul_src->isVOP3P() || mul_src->valu().clamp)
+        return;
+
+        // Check if instruction supports output modifiers
+        if (!instr_info.alu_opcode_infos[(int)mul_src->opcode].output_modifiers)
+            return;
+
+        // Apply optimization
+        mul_src->valu().clamp = true;
+    propagate_swizzles_vega(&mul_src->valu(),
+                            vop3p->opsel_lo[0],
+                            vop3p->opsel_hi[0]);
+
+    // Create p_parallelcopy
+    Definition def = instr->definitions[0];
+    aco_ptr<Instruction> pc(create_instruction(
+        aco_opcode::p_parallelcopy, Format::PSEUDO, 1, 1));
+    pc->operands[0] = Operand(mul_src->definitions[0].getTemp());
+    pc->definitions[0] = def;
+
+    // Update metadata
+    if (def.tempId() < ctx.info.size()) {
+        ctx.info[def.tempId()].parent_instr = pc.get();
+        ctx.info[def.tempId()].set_temp(pc->operands[0].getTemp());
+    }
+
+    // Update use count
+    if (mul_src->definitions[0].tempId() < ctx.uses.size())
+        ctx.uses[mul_src->definitions[0].tempId()]++;
+
+        instr = std::move(pc);
+    return;
+        }
+
+        // 2. Fneg folding - optimized for Vega
+        for (unsigned i = 0; i < instr->operands.size(); i++) {
+            if (!can_use_input_modifiers(ctx.program->gfx_level, instr->opcode, i))
+                continue;
 
-   /* check for fneg modifiers */
-   for (unsigned i = 0; i < instr->operands.size(); i++) {
-      if (!can_use_input_modifiers(ctx.program->gfx_level, instr->opcode, i))
-         continue;
-      Operand& op = instr->operands[i];
-      if (!op.isTemp())
-         continue;
+            Operand& op = instr->operands[i];
+            if (!op.isTemp())
+                continue;
 
-      ssa_info& info = ctx.info[op.tempId()];
-      if (info.parent_instr->opcode == aco_opcode::v_pk_mul_f16 &&
-          (info.parent_instr->operands[0].constantEquals(0x3C00) ||
-           info.parent_instr->operands[1].constantEquals(0x3C00) ||
-           info.parent_instr->operands[0].constantEquals(0xBC00) ||
-           info.parent_instr->operands[1].constantEquals(0xBC00))) {
+            // Safe bounds checks
+            if (op.tempId() >= ctx.info.size() || op.tempId() >= ctx.uses.size())
+                continue;
 
-         VALU_instruction* fneg = &info.parent_instr->valu();
+            if (ctx.uses[op.tempId()] != 1)
+                continue;
 
-         unsigned fneg_src =
-            fneg->operands[0].constantEquals(0x3C00) || fneg->operands[0].constantEquals(0xBC00);
+            ssa_info& info = ctx.info[op.tempId()];
+            Instruction* fneg = info.parent_instr;
 
-         if (fneg->opsel_lo[1 - fneg_src] || fneg->opsel_hi[1 - fneg_src])
-            continue;
+            if (!fneg || fneg->opcode != aco_opcode::v_pk_mul_f16)
+                continue;
 
-         Operand ops[3];
-         for (unsigned j = 0; j < instr->operands.size(); j++)
-            ops[j] = instr->operands[j];
-         ops[i] = fneg->operands[fneg_src];
-         if (!check_vop3_operands(ctx, instr->operands.size(), ops))
-            continue;
+            // Check for multiply by -1.0
+            unsigned const_idx = 2;
+            if (fneg->operands[0].constantEquals(0xBC00))
+                const_idx = 0;
+            else if (fneg->operands[1].constantEquals(0xBC00))
+                const_idx = 1;
+
+            if (const_idx > 1)
+                continue;
+
+            unsigned src_idx = 1 - const_idx;
+            VALU_instruction& fneg_valu = fneg->valu();
+
+            // Check modifiers on constant operand
+            if (fneg_valu.clamp ||
+                fneg_valu.opsel_lo[const_idx] || fneg_valu.opsel_hi[const_idx] ||
+                fneg_valu.neg_lo[const_idx] || fneg_valu.neg_hi[const_idx])
+                continue;
+
+            // Check if we can use the source operand
+            Operand new_op = fneg->operands[src_idx];
+            Operand ops[3];
+            for (unsigned j = 0; j < instr->operands.size(); j++)
+                ops[j] = (j == i) ? new_op : instr->operands[j];
+
+            if (!check_vop3_operands(ctx, instr->operands.size(), ops))
+                continue;
+
+            // Apply the optimization
+            bool opsel_lo = vop3p->opsel_lo[i];
+            bool opsel_hi = vop3p->opsel_hi[i];
+
+            vop3p->opsel_lo[i] = opsel_lo ? fneg_valu.opsel_hi[src_idx]
+            : fneg_valu.opsel_lo[src_idx];
+            vop3p->opsel_hi[i] = opsel_hi ? fneg_valu.opsel_hi[src_idx]
+            : fneg_valu.opsel_lo[src_idx];
+
+            bool neg_lo = opsel_lo ? fneg_valu.neg_hi[src_idx]
+            : fneg_valu.neg_lo[src_idx];
+            bool neg_hi = opsel_hi ? fneg_valu.neg_hi[src_idx]
+            : fneg_valu.neg_lo[src_idx];
+
+            vop3p->neg_lo[i] ^= neg_lo ^ 1;  // XOR with 1 for negation
+            vop3p->neg_hi[i] ^= neg_hi ^ 1;
+
+            instr->operands[i] = copy_operand(ctx, new_op);
+            decrease_uses(ctx, fneg);
+        }
 
-         if (fneg->clamp)
+        // 3. MAD formation - optimized for Vega
+        bool is_fadd = instr->opcode == aco_opcode::v_pk_add_f16;
+        bool is_uadd = instr->opcode == aco_opcode::v_pk_add_u16;
+        bool is_iadd = ctx.program->gfx_level >= GFX9 &&
+        instr->opcode == aco_opcode::v_pk_add_i16;
+
+        if (!is_fadd && !is_uadd && !is_iadd)
+            return;
+
+    if (is_fadd && instr->definitions[0].isPrecise())
+        return;
+
+    // Find best multiply instruction to fuse
+    Instruction* best_mul = nullptr;
+    unsigned best_mul_idx = 0;
+    unsigned best_add_idx = 0;
+    uint32_t best_uses = UINT32_MAX;
+
+    for (unsigned i = 0; i < 2; i++) {
+        if (i >= instr->operands.size())
             continue;
-         instr->operands[i] = fneg->operands[fneg_src];
 
-         /* opsel_lo/hi is either 0 or 1:
-          * if 0 - pick selection from fneg->lo
-          * if 1 - pick selection from fneg->hi
-          */
-         bool opsel_lo = vop3p->opsel_lo[i];
-         bool opsel_hi = vop3p->opsel_hi[i];
-         bool neg_lo = fneg->neg_lo[0] ^ fneg->neg_lo[1];
-         bool neg_hi = fneg->neg_hi[0] ^ fneg->neg_hi[1];
-         bool neg_const = fneg->operands[1 - fneg_src].constantEquals(0xBC00);
-         /* Avoid ternary xor as it causes CI fails that can't be reproduced on other systems. */
-         neg_lo ^= neg_const;
-         neg_hi ^= neg_const;
-         vop3p->neg_lo[i] ^= opsel_lo ? neg_hi : neg_lo;
-         vop3p->neg_hi[i] ^= opsel_hi ? neg_hi : neg_lo;
-         vop3p->opsel_lo[i] ^= opsel_lo ? !fneg->opsel_hi[fneg_src] : fneg->opsel_lo[fneg_src];
-         vop3p->opsel_hi[i] ^= opsel_hi ? !fneg->opsel_hi[fneg_src] : fneg->opsel_lo[fneg_src];
-
-         if (--ctx.uses[fneg->definitions[0].tempId()])
-            ctx.uses[fneg->operands[fneg_src].tempId()]++;
-      }
-   }
+        Instruction* mul = follow_operand(ctx, instr->operands[i], true);
+        if (!mul)
+            continue;
 
-   if (instr->opcode == aco_opcode::v_pk_add_f16 || instr->opcode == aco_opcode::v_pk_add_u16) {
-      bool fadd = instr->opcode == aco_opcode::v_pk_add_f16;
-      if (fadd && instr->definitions[0].isPrecise())
-         return;
-      if (!fadd && instr->valu().clamp)
-         return;
+        // Check for valid multiply opcode
+        bool valid_mul = false;
+        if (is_fadd) {
+            valid_mul = mul->opcode == aco_opcode::v_pk_mul_f16;
+        } else if (is_uadd) {
+            valid_mul = (mul->isVOP3P() && mul->opcode == aco_opcode::v_pk_mul_lo_u16) ||
+            (mul->isVOP2() && mul->opcode == aco_opcode::v_mul_lo_u16);
+        } else if (is_iadd) {
+            // Special case: v_pk_mad_i16 with zero addend
+            valid_mul = mul->opcode == aco_opcode::v_pk_mad_i16 &&
+            mul->operands.size() == 3 &&
+            mul->operands[2].constantEquals(0) &&
+            !mul->valu().neg_lo[2] && !mul->valu().neg_hi[2] &&
+            !mul->valu().opsel_lo[2] && !mul->valu().opsel_hi[2];
+        }
 
-      Instruction* mul_instr = nullptr;
-      unsigned add_op_idx = 0;
-      bitarray8 mul_neg_lo = 0, mul_neg_hi = 0, mul_opsel_lo = 0, mul_opsel_hi = 0;
-      uint32_t uses = UINT32_MAX;
+        if (!valid_mul)
+            continue;
 
-      /* find the 'best' mul instruction to combine with the add */
-      for (unsigned i = 0; i < 2; i++) {
-         Instruction* op_instr = follow_operand(ctx, instr->operands[i], true);
-         if (!op_instr)
+        // Check precision
+        if (is_fadd && mul->definitions[0].isPrecise())
             continue;
 
-         if (op_instr->isVOP3P()) {
-            if (fadd) {
-               if (op_instr->opcode != aco_opcode::v_pk_mul_f16 ||
-                   op_instr->definitions[0].isPrecise())
-                  continue;
-            } else {
-               if (op_instr->opcode != aco_opcode::v_pk_mul_lo_u16)
-                  continue;
-            }
+        // Check modifiers
+        if (mul->valu().clamp || (is_fadd && mul->valu().omod))
+            continue;
 
-            Operand op[3] = {op_instr->operands[0], op_instr->operands[1], instr->operands[1 - i]};
-            if (ctx.uses[instr->operands[i].tempId()] >= uses || !check_vop3_operands(ctx, 3, op))
-               continue;
+        // Check DPP/SDWA
+        if (mul->isDPP())
+            continue;
 
-            /* no clamp allowed between mul and add */
-            if (op_instr->valu().clamp)
-               continue;
+        if (mul->isSDWA()) {
+            bool valid_sdwa = true;
+            for (unsigned j = 0; j < 2 && j < mul->operands.size(); j++) {
+                auto& sel = mul->sdwa().sel[j];
+                if (sel.size() != 2 || (sel.offset() & 1) != 0) {
+                    valid_sdwa = false;
+                    break;
+                }
+            }
+            if (!valid_sdwa)
+                continue;
+        }
+
+        // Check operand validity
+        Operand ops[3] = {mul->operands[0], mul->operands[1], instr->operands[1-i]};
+        if (!check_vop3_operands(ctx, 3, ops))
+            continue;
+
+        // Check literal restrictions for Vega
+        if (ctx.program->gfx_level == GFX9) {
+            aco_opcode mad_op = is_fadd ? aco_opcode::v_pk_fma_f16 :
+            is_uadd ? aco_opcode::v_pk_mad_u16 :
+            aco_opcode::v_pk_mad_i16;
+
+            if (mad_op == aco_opcode::v_pk_mad_i16) {
+                // v_pk_mad_i16 doesn't support literals on GFX9
+                bool has_literal = false;
+                for (unsigned j = 0; j < 3; j++) {
+                    if (ops[j].isLiteral()) {
+                        has_literal = true;
+                        break;
+                    }
+                }
+                if (has_literal)
+                    continue;
+            }
+        }
 
-            mul_instr = op_instr;
-            add_op_idx = 1 - i;
+        // Check use count with Vega-optimized threshold
+        uint32_t uses = UINT32_MAX;
+        if (instr->operands[i].tempId() < ctx.uses.size())
             uses = ctx.uses[instr->operands[i].tempId()];
-            mul_neg_lo = mul_instr->valu().neg_lo;
-            mul_neg_hi = mul_instr->valu().neg_hi;
-            mul_opsel_lo = mul_instr->valu().opsel_lo;
-            mul_opsel_hi = mul_instr->valu().opsel_hi;
-         } else if (instr->operands[i].bytes() == 2) {
-            if ((fadd && (op_instr->opcode != aco_opcode::v_mul_f16 ||
-                          op_instr->definitions[0].isPrecise())) ||
-                (!fadd && op_instr->opcode != aco_opcode::v_mul_lo_u16 &&
-                 op_instr->opcode != aco_opcode::v_mul_lo_u16_e64))
-               continue;
 
-            if (op_instr->valu().clamp || op_instr->valu().omod || op_instr->valu().abs)
-               continue;
+        // Vega optimization: more aggressive for FMA
+        uint32_t use_threshold = is_fadd ? 3 : 2;
+        if (uses > use_threshold)
+            continue;
 
-            if (op_instr->isDPP() || (op_instr->isSDWA() && (op_instr->sdwa().sel[0].size() < 2 ||
-                                                             op_instr->sdwa().sel[1].size() < 2)))
-               continue;
+        // Select best candidate
+        if (uses < best_uses ||
+            (uses == best_uses && best_mul &&
+            mul->definitions[0].tempId() < best_mul->definitions[0].tempId())) {
+            best_uses = uses;
+        best_mul = mul;
+        best_mul_idx = i;
+        best_add_idx = 1 - i;
+            }
+    }
 
-            Operand op[3] = {op_instr->operands[0], op_instr->operands[1], instr->operands[1 - i]};
-            if (ctx.uses[instr->operands[i].tempId()] >= uses || !check_vop3_operands(ctx, 3, op))
-               continue;
+    if (!best_mul)
+        return;
 
-            mul_instr = op_instr;
-            add_op_idx = 1 - i;
-            uses = ctx.uses[instr->operands[i].tempId()];
-            mul_neg_lo = mul_instr->valu().neg;
-            mul_neg_hi = mul_instr->valu().neg;
-            if (mul_instr->isSDWA()) {
-               for (unsigned j = 0; j < 2; j++)
-                  mul_opsel_lo[j] = mul_instr->sdwa().sel[j].offset();
+    // Create MAD instruction
+    aco_opcode mad_op = is_fadd ? aco_opcode::v_pk_fma_f16 :
+    is_uadd ? aco_opcode::v_pk_mad_u16 :
+    aco_opcode::v_pk_mad_i16;
+
+    aco_ptr<Instruction> mad{create_instruction(mad_op, Format::VOP3P, 3, 1)};
+
+    // Copy operands
+    mad->operands[0] = copy_operand(ctx, best_mul->operands[0]);
+    mad->operands[1] = copy_operand(ctx, best_mul->operands[1]);
+    mad->operands[2] = copy_operand(ctx, instr->operands[best_add_idx]);
+
+    // Set clamp (only for float operations)
+    mad->valu().clamp = is_fadd && vop3p->clamp;
+
+    // Copy modifiers from multiply
+    VALU_instruction& mul_valu = best_mul->valu();
+    if (best_mul->isVOP3P()) {
+        mad->valu().neg_lo = mul_valu.neg_lo;
+        mad->valu().neg_hi = mul_valu.neg_hi;
+        mad->valu().opsel_lo = mul_valu.opsel_lo;
+        mad->valu().opsel_hi = mul_valu.opsel_hi;
+    } else {
+        // VOP2 multiply - expand modifiers
+        for (unsigned j = 0; j < 2; j++) {
+            mad->valu().neg_lo[j] = mul_valu.neg[j];
+            mad->valu().neg_hi[j] = mul_valu.neg[j];
+
+            if (best_mul->isSDWA()) {
+                uint8_t offset = best_mul->sdwa().sel[j].offset();
+                mad->valu().opsel_lo[j] = offset >> 1;
+                mad->valu().opsel_hi[j] = offset >> 1;
             } else {
-               mul_opsel_lo = mul_instr->valu().opsel;
+                mad->valu().opsel_lo[j] = mul_valu.opsel[j];
+                mad->valu().opsel_hi[j] = mul_valu.opsel[j];
             }
-            mul_opsel_hi = mul_opsel_lo;
-         }
-      }
+        }
+    }
 
-      if (!mul_instr)
-         return;
+    // Propagate swizzles from add
+    propagate_swizzles_vega(&mad->valu(),
+                            vop3p->opsel_lo[best_mul_idx],
+                            vop3p->opsel_hi[best_mul_idx]);
+
+    // Set addend modifiers
+    mad->valu().opsel_lo[2] = vop3p->opsel_lo[best_add_idx];
+    mad->valu().opsel_hi[2] = vop3p->opsel_hi[best_add_idx];
+    mad->valu().neg_lo[2] = vop3p->neg_lo[best_add_idx];
+    mad->valu().neg_hi[2] = vop3p->neg_hi[best_add_idx];
+
+    // Handle product negation with INT16_MIN safety
+    bool neg_prod_lo = vop3p->neg_lo[best_mul_idx];
+    bool neg_prod_hi = vop3p->neg_hi[best_mul_idx];
+
+    bool safe_negate_src0 = true;
+    if (is_iadd && mad->operands[0].isConstant()) {
+        uint32_t val = mad->operands[0].constantValue();
+        uint16_t lo = val & 0xFFFF;
+        uint16_t hi = (val >> 16) & 0xFFFF;
+
+        // Check which half is actually used
+        uint16_t actual_lo = mad->valu().opsel_lo[0] ? hi : lo;
+        uint16_t actual_hi = mad->valu().opsel_hi[0] ? hi : lo;
+
+        // INT16_MIN negation is undefined
+        if ((neg_prod_lo && actual_lo == 0x8000) ||
+            (neg_prod_hi && actual_hi == 0x8000)) {
+            safe_negate_src0 = false;
+            }
+    }
 
-      /* turn mul + packed add into v_pk_fma_f16 */
-      aco_opcode mad = fadd ? aco_opcode::v_pk_fma_f16 : aco_opcode::v_pk_mad_u16;
-      aco_ptr<Instruction> fma{create_instruction(mad, Format::VOP3P, 3, 1)};
-      fma->operands[0] = copy_operand(ctx, mul_instr->operands[0]);
-      fma->operands[1] = copy_operand(ctx, mul_instr->operands[1]);
-      fma->operands[2] = instr->operands[add_op_idx];
-      fma->valu().clamp = vop3p->clamp;
-      fma->valu().neg_lo = mul_neg_lo;
-      fma->valu().neg_hi = mul_neg_hi;
-      fma->valu().opsel_lo = mul_opsel_lo;
-      fma->valu().opsel_hi = mul_opsel_hi;
-      propagate_swizzles(&fma->valu(), vop3p->opsel_lo[1 - add_op_idx],
-                         vop3p->opsel_hi[1 - add_op_idx]);
-      fma->valu().opsel_lo[2] = vop3p->opsel_lo[add_op_idx];
-      fma->valu().opsel_hi[2] = vop3p->opsel_hi[add_op_idx];
-      fma->valu().neg_lo[2] = vop3p->neg_lo[add_op_idx];
-      fma->valu().neg_hi[2] = vop3p->neg_hi[add_op_idx];
-      fma->valu().neg_lo[1] = fma->valu().neg_lo[1] ^ vop3p->neg_lo[1 - add_op_idx];
-      fma->valu().neg_hi[1] = fma->valu().neg_hi[1] ^ vop3p->neg_hi[1 - add_op_idx];
-      fma->definitions[0] = instr->definitions[0];
-      fma->pass_flags = instr->pass_flags;
-      instr = std::move(fma);
-      ctx.info[instr->definitions[0].tempId()].parent_instr = instr.get();
-      decrease_uses(ctx, mul_instr);
-      return;
-   }
+    if (safe_negate_src0) {
+        mad->valu().neg_lo[0] ^= neg_prod_lo;
+        mad->valu().neg_hi[0] ^= neg_prod_hi;
+    } else {
+        mad->valu().neg_lo[1] ^= neg_prod_lo;
+        mad->valu().neg_hi[1] ^= neg_prod_hi;
+    }
+
+    // Set definition and precision
+    mad->definitions[0] = instr->definitions[0];
+    bool precise = instr->definitions[0].isPrecise() ||
+    best_mul->definitions[0].isPrecise();
+    mad->definitions[0].setPrecise(precise);
+
+    // Update metadata
+    Temp def_temp = mad->definitions[0].getTemp();
+    if (def_temp.id() < ctx.info.size()) {
+        ssa_info& info = ctx.info[def_temp.id()];
+        info.parent_instr = mad.get();
+
+        if (precise)
+            info.label |= label_precise;
+
+        // Clear incompatible labels
+        info.label &= ~(label_omod2 | label_omod4 | label_omod5 | label_f2f16);
+        if (!is_fadd || !vop3p->clamp)
+            info.label &= ~label_clamp;
+
+        // Set MAD info
+        ctx.mad_infos.emplace_back(std::move(instr), best_mul->definitions[0].tempId());
+        info.set_mad(ctx.mad_infos.size() - 1);
+    }
+
+    // Copy pass flags
+    mad->pass_flags = instr->pass_flags;
+
+    // Replace instruction
+    instr = std::move(mad);
+
+    // Update use counts
+    decrease_uses(ctx, best_mul);
 }
 
 bool
