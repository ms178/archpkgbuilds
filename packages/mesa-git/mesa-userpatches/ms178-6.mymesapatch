--- a/src/amd/compiler/aco_ir.cpp	2025-05-31 22:57:26.003334290 +0200
+++ b/src/amd/compiler/aco_ir.cpp	2025-06-01 17:13:01.222104109 +0200
@@ -584,6 +584,21 @@ can_use_opsel(amd_gfx_level gfx_level, a
    case aco_opcode::v_interp_p10_rtz_f16_f32_inreg: return idx == 0 || idx == 2;
    case aco_opcode::v_interp_p2_f16_f32_inreg:
    case aco_opcode::v_interp_p2_rtz_f16_f32_inreg: return idx == -1 || idx == 0;
+   case aco_opcode::v_alignbyte_b32:
+   case aco_opcode::v_alignbit_b32: return idx == 0 || idx == 1;
+   case aco_opcode::v_cvt_pkrtz_f16_f32:
+   case aco_opcode::v_cvt_pknorm_i16_f32:
+   case aco_opcode::v_cvt_pknorm_u16_f32:
+   case aco_opcode::v_cvt_pk_i16_i32:
+   case aco_opcode::v_cvt_pk_u16_u32: return false;
+   case aco_opcode::v_interp_p1_f32:
+   case aco_opcode::v_interp_p2_f32: break;
+   case aco_opcode::v_interp_p2_f16: return (idx == 0 || idx == 2);
+   case aco_opcode::v_mad_legacy_f16:
+   case aco_opcode::v_mad_legacy_i16:
+   case aco_opcode::v_mad_legacy_u16:
+   case aco_opcode::v_fma_legacy_f16:
+   case aco_opcode::v_div_fixup_legacy_f16: return (idx >= 0 && idx < 3);
    default:
       return gfx_level >= GFX11 && (get_gfx11_true16_mask(op) & BITFIELD_BIT(idx == -1 ? 3 : idx));
    }



--- a/src/amd/compiler/aco_opcodes.py	2025-05-31 22:57:26.003334290 +0200
+++ b/src/amd/compiler/aco_opcodes.py	2025-06-01 00:30:01.222104109 +0200
@@ -986,7 +986,6 @@ VOP2 = {
    ("v_fmac_f16",          dst(F16),      src(F16, F16, F16), op(gfx10=0x36)),
    ("v_fmamk_f16",         dst(noMods(F16)), noMods(src(F16, F16, IMM)), op(gfx10=0x37)),
    ("v_fmaak_f16",         dst(noMods(F16)), noMods(src(F16, F16, IMM)), op(gfx10=0x38)),
-   ("v_pk_fmac_f16",       dst(noMods(PkF16)), noMods(src(PkF16, PkF16, PkF16)), op(gfx10=0x3c)),
    ("v_dot2c_f32_f16",     dst(noMods(F32)), noMods(src(PkF16, PkF16, F32)), op(gfx9=0x37, gfx10=0x02, gfx12=-1)), #v_dot2acc_f32_f16 in GFX11
    ("v_add_f64",           dst(F64),      src(F64, F64), op(gfx12=0x02), InstrClass.ValuDoubleAdd),
    ("v_mul_f64",           dst(F64),      src(F64, F64), op(gfx12=0x06), InstrClass.ValuDoubleAdd),
@@ -1199,15 +1198,16 @@ VOPP = {
    ("v_pk_max_u16",     dst(PkU16), src(PkU16, PkU16), op(gfx9=0x0c)),
    ("v_pk_min_u16",     dst(PkU16), src(PkU16, PkU16), op(gfx9=0x0d)),
    ("v_pk_fma_f16",     dst(PkF16), src(PkF16, PkF16, PkF16), op(gfx9=0x0e)),
+   ("v_pk_fmac_f16",    dst(PkF16), src(PkF16, PkF16, PkF16), op(gfx9=0x1ea, gfx10=0x3c), InstrClass.ValuFma),
    ("v_pk_add_f16",     dst(PkF16), src(PkF16, PkF16), op(gfx9=0x0f)),
    ("v_pk_mul_f16",     dst(PkF16), src(PkF16, PkF16), op(gfx9=0x10)),
    ("v_pk_min_f16",     dst(PkF16), src(PkF16, PkF16), op(gfx9=0x11, gfx12=0x1b)), # called v_pk_min_num_f16 in GFX12
    ("v_pk_max_f16",     dst(PkF16), src(PkF16, PkF16), op(gfx9=0x12, gfx12=0x1c)), # called v_pk_min_num_f16 in GFX12
    ("v_pk_minimum_f16", dst(PkF16), src(PkF16, PkF16), op(gfx12=0x1d)),
    ("v_pk_maximum_f16", dst(PkF16), src(PkF16, PkF16), op(gfx12=0x1e)),
-   ("v_fma_mix_f32",    dst(F32), src(F32, F32, F32), op(gfx9=0x20)), # v_mad_mix_f32 in VEGA ISA, v_fma_mix_f32 in RDNA ISA
-   ("v_fma_mixlo_f16",  dst(F16), src(F32, F32, F32), op(gfx9=0x21)), # v_mad_mixlo_f16 in VEGA ISA, v_fma_mixlo_f16 in RDNA ISA
-   ("v_fma_mixhi_f16",  dst(F16), src(F32, F32, F32), op(gfx9=0x22)), # v_mad_mixhi_f16 in VEGA ISA, v_fma_mixhi_f16 in RDNA ISA
+   ("v_fma_mix_f32",    dst(F32), src(F32, F32, F32), op(gfx9=0x20), InstrClass.ValuFma),
+   ("v_fma_mixlo_f16",  dst(F16), src(F32, F32, F32), op(gfx9=0x21), InstrClass.ValuFma),
+   ("v_fma_mixhi_f16",  dst(F16), src(F32, F32, F32), op(gfx9=0x22), InstrClass.ValuFma),
    ("v_dot2_i32_i16",      dst(U32), src(PkU16, PkU16, U32), op(gfx9=0x26, gfx10=0x14, gfx11=-1)),
    ("v_dot2_u32_u16",      dst(U32), src(PkU16, PkU16, U32), op(gfx9=0x27, gfx10=0x15, gfx11=-1)),
    ("v_dot4_i32_iu8",      dst(U32), src(PkU16, PkU16, U32), op(gfx11=0x16)),
@@ -1275,8 +1275,8 @@ for (name, defs, ops, num) in VINTERP:
 # VOP3 instructions: 3 inputs, 1 output
 # VOP3b instructions: have a unique scalar output, e.g. VOP2 with vcc out
 VOP3 = {
-   ("v_mad_legacy_f32",        dst(F32), src(F32, F32, F32), op(0x140, gfx8=0x1c0, gfx10=0x140, gfx11=-1)), # GFX6-GFX10
-   ("v_mad_f32",               dst(F32), src(F32, F32, F32), op(0x141, gfx8=0x1c1, gfx10=0x141, gfx11=-1)),
+   ("v_mad_legacy_f32",        dst(F32), src(mods(F32), mods(F32), mods(F32)), op(0x140, gfx8=0x1c0, gfx10=0x140, gfx11=-1)), # GFX6-GFX10
+   ("v_mad_f32",               dst(F32), src(mods(F32), mods(F32), mods(F32)), op(0x141, gfx8=0x1c1, gfx10=0x141, gfx11=-1)),
    ("v_mad_i32_i24",           dst(U32), src(U32, U32, U32), op(0x142, gfx8=0x1c2, gfx10=0x142, gfx11=0x20a)),
    ("v_mad_u32_u24",           dst(U32), src(U32, U32, U32), op(0x143, gfx8=0x1c3, gfx10=0x143, gfx11=0x20b)),
    ("v_cubeid_f32",            dst(F32), src(F32, F32, F32), op(0x144, gfx8=0x1c4, gfx10=0x144, gfx11=0x20c)),
@@ -1286,11 +1286,11 @@ VOP3 = {
    ("v_bfe_u32",               dst(U32), src(U32, U32, U32), op(0x148, gfx8=0x1c8, gfx10=0x148, gfx11=0x210)),
    ("v_bfe_i32",               dst(U32), src(U32, U32, U32), op(0x149, gfx8=0x1c9, gfx10=0x149, gfx11=0x211)),
    ("v_bfi_b32",               dst(U32), src(U32, U32, U32), op(0x14a, gfx8=0x1ca, gfx10=0x14a, gfx11=0x212)),
-   ("v_fma_f32",               dst(F32), src(F32, F32, F32), op(0x14b, gfx8=0x1cb, gfx10=0x14b, gfx11=0x213), InstrClass.ValuFma),
-   ("v_fma_f64",               dst(F64), src(F64, F64, F64), op(0x14c, gfx8=0x1cc, gfx10=0x14c, gfx11=0x214), InstrClass.ValuDouble),
+   ("v_fma_f32",               dst(F32), src(mods(F32), mods(F32), mods(F32)), op(0x14b, gfx8=0x1cb, gfx10=0x14b, gfx11=0x213), InstrClass.ValuFma),
+   ("v_fma_f64",               dst(F64), src(mods(F64), mods(F64), mods(F64)), op(0x14c, gfx8=0x1cc, gfx10=0x14c, gfx11=0x214), InstrClass.ValuDouble),
    ("v_lerp_u8",               dst(U32), src(U32, U32, U32), op(0x14d, gfx8=0x1cd, gfx10=0x14d, gfx11=0x215)),
-   ("v_alignbit_b32",          dst(U32), src(U32, U32, U16), op(0x14e, gfx8=0x1ce, gfx10=0x14e, gfx11=0x216)),
-   ("v_alignbyte_b32",         dst(U32), src(U32, U32, U16), op(0x14f, gfx8=0x1cf, gfx10=0x14f, gfx11=0x217)),
+   ("v_alignbit_b32",          dst(U32), src(mods(U32), mods(U32), noMods(U16)), op(0x14e, gfx8=0x1ce, gfx10=0x14e, gfx11=0x216)),
+   ("v_alignbyte_b32",         dst(U32), src(mods(U32), mods(U32), noMods(U16)), op(0x14f, gfx8=0x1cf, gfx10=0x14f, gfx11=0x217)),
    ("v_mullit_f32",            dst(F32), src(F32, F32, F32), op(0x150, gfx8=-1, gfx10=0x150, gfx11=0x218)),
    ("v_min3_f32",              dst(F32), src(F32, F32, F32), op(0x151, gfx8=0x1d0, gfx10=0x151, gfx11=0x219, gfx12=0x229)), # called v_min3_num_f32 in GFX12
    ("v_min3_i32",              dst(U32), src(U32, U32, U32), op(0x152, gfx8=0x1d1, gfx10=0x152, gfx11=0x21a)),
@@ -1332,12 +1332,12 @@ VOP3 = {
    ("v_mqsad_u32_u8",          dst(U128), src(U64, U32, U128), op(gfx7=0x175, gfx8=0x1e7, gfx10=0x175, gfx11=0x23d), InstrClass.ValuQuarterRate32),
    ("v_mad_u64_u32",           dst(U64, VCC), src(U32, U32, U64), op(gfx7=0x176, gfx8=0x1e8, gfx10=0x176, gfx11=0x2fe), InstrClass.Valu64), # called v_mad_co_u64_u32 in GFX12
    ("v_mad_i64_i32",           dst(I64, VCC), src(U32, U32, I64), op(gfx7=0x177, gfx8=0x1e9, gfx10=0x177, gfx11=0x2ff), InstrClass.Valu64), # called v_mad_co_i64_i32 in GFX12
-   ("v_mad_legacy_f16",        dst(F16), src(F16, F16, F16), op(gfx8=0x1ea, gfx10=-1)),
-   ("v_mad_legacy_u16",        dst(U16), src(U16, U16, U16), op(gfx8=0x1eb, gfx10=-1)),
-   ("v_mad_legacy_i16",        dst(U16), src(U16, U16, U16), op(gfx8=0x1ec, gfx10=-1)),
+   ("v_mad_legacy_f16",        dst(F16), src(mods(F16), mods(F16), mods(F16)), op(gfx8=0x1ea, gfx10=-1)),
+   ("v_mad_legacy_u16",        dst(U16), src(mods(U16), mods(U16), mods(U16)), op(gfx8=0x1eb, gfx10=-1)),
+   ("v_mad_legacy_i16",        dst(U16), src(mods(U16), mods(U16), mods(U16)), op(gfx8=0x1ec, gfx10=-1)),
    ("v_perm_b32",              dst(U32), src(U32, U32, U32), op(gfx8=0x1ed, gfx10=0x344, gfx11=0x244)),
-   ("v_fma_legacy_f16",        dst(F16), src(F16, F16, F16), op(gfx8=0x1ee, gfx10=-1), InstrClass.ValuFma),
-   ("v_div_fixup_legacy_f16",  dst(F16), src(F16, F16, F16), op(gfx8=0x1ef, gfx10=-1)),
+   ("v_fma_legacy_f16",        dst(F16), src(mods(F16), mods(F16), mods(F16)), op(gfx8=0x1ee, gfx10=-1), InstrClass.ValuFma),
+   ("v_div_fixup_legacy_f16",  dst(F16), src(mods(F16), mods(F16), mods(F16)), op(gfx8=0x1ef, gfx10=-1)),
    ("v_cvt_pkaccum_u8_f32",    dst(U32), src(F32, U32, U32), op(0x12c, gfx8=0x1f0, gfx10=-1)),
    ("v_mad_u32_u16",           dst(U32), src(U16, U16, U32), op(gfx9=0x1f1, gfx10=0x373, gfx11=0x259)),
    ("v_mad_i32_i16",           dst(U32), src(U16, U16, U32), op(gfx9=0x1f2, gfx10=0x375, gfx11=0x25a)),
@@ -1365,7 +1365,7 @@ VOP3 = {
    ("v_interp_p1ll_f16",       dst(F32), src(F32, M0), op(gfx8=0x274, gfx10=0x342, gfx11=-1)),
    ("v_interp_p1lv_f16",       dst(F32), src(F32, M0, F16), op(gfx8=0x275, gfx10=0x343, gfx11=-1)),
    ("v_interp_p2_legacy_f16",  dst(F16), src(F32, M0, F32), op(gfx8=0x276, gfx10=-1)),
-   ("v_interp_p2_f16",         dst(F16), src(F32, M0, F32), op(gfx9=0x277, gfx10=0x35a, gfx11=-1)),
+   ("v_interp_p2_f16",         dst(F16), src(mods(F32), noMods(M0), mods(F32)), op(gfx9=0x277, gfx10=0x35a, gfx11=-1)),
    ("v_interp_p2_hi_f16",      dst(F16), src(F32, M0, F32), op(gfx9=0x277, gfx10=0x35a, gfx11=-1)),
    ("v_ldexp_f32",             dst(F32), src(F32, U32), op(0x12b, gfx8=0x288, gfx10=0x362, gfx11=0x31c)),
    ("v_readlane_b32_e64",      dst(U32), src(U32, U32), op(gfx8=0x289, gfx10=0x360)),



--- a/src/amd/compiler/aco_optimizer.cpp	2025-05-31 22:57:26.003334290 +0200
+++ b/src/amd/compiler/aco_optimizer.cpp	2025-06-01 00:30:01.222104109 +0200
@@ -43,40 +43,38 @@ struct mad_info {
 };
 
 enum Label {
-   label_constant_32bit = 1 << 1,
-   /* label_{abs,neg,mul,omod2,omod4,omod5,clamp} are used for both 16 and
-    * 32-bit operations but this shouldn't cause any issues because we don't
-    * look through any conversions */
-   label_abs = 1 << 2,
-   label_neg = 1 << 3,
-   label_temp = 1 << 5,
-   label_literal = 1 << 6,
-   label_mad = 1 << 7,
-   label_omod2 = 1 << 8,
-   label_omod4 = 1 << 9,
-   label_omod5 = 1 << 10,
-   label_clamp = 1 << 12,
-   label_b2f = 1 << 16,
-   label_uniform_bool = 1 << 21,
-   label_constant_64bit = 1 << 22,
-   label_uniform_bitwise = 1 << 23,
-   label_scc_invert = 1 << 24,
-   label_scc_needed = 1 << 26,
-   label_b2i = 1 << 27,
-   label_fcanonicalize = 1 << 28,
-   label_constant_16bit = 1 << 29,
-   label_canonicalized = 1ull << 32, /* 1ull to prevent sign extension */
-   label_extract = 1ull << 33,
-   label_insert = 1ull << 34,
-   label_f2f16 = 1ull << 38,
+    label_constant_32bit = 1 << 1,
+    label_abs = 1 << 2,
+    label_neg = 1 << 3,
+    label_temp = 1 << 5,
+    label_literal = 1 << 6,
+    label_mad = 1 << 7,
+    label_omod2 = 1 << 8,
+    label_omod4 = 1 << 9,
+    label_omod5 = 1 << 10,
+    label_clamp = 1 << 12,
+    label_b2f = 1 << 16,
+    label_uniform_bool = 1 << 21,
+    label_constant_64bit = 1 << 22,
+    label_uniform_bitwise = 1 << 23,
+    label_scc_invert = 1 << 24,
+    label_scc_needed = 1 << 26,
+    label_b2i = 1 << 27,
+    label_fcanonicalize = 1 << 28,
+    label_constant_16bit = 1 << 29,
+    label_canonicalized = 1ull << 32,
+    label_extract = 1ull << 33,
+    label_insert = 1ull << 34,
+    label_precise = 1ull << 35,
+    label_f2f16 = 1ull << 38,
 };
 
 static constexpr uint64_t instr_mod_labels =
-   label_omod2 | label_omod4 | label_omod5 | label_clamp | label_insert | label_f2f16;
+label_omod2 | label_omod4 | label_omod5 | label_clamp | label_insert | label_f2f16;
 
 static constexpr uint64_t temp_labels = label_abs | label_neg | label_temp | label_b2f |
                                         label_uniform_bool | label_scc_invert | label_b2i |
-                                        label_fcanonicalize;
+                                        label_fcanonicalize | label_canonicalized | label_precise;
 static constexpr uint32_t val_labels =
    label_constant_32bit | label_constant_64bit | label_constant_16bit | label_literal | label_mad;
 
@@ -84,251 +82,174 @@ static_assert((instr_mod_labels & temp_l
 static_assert((instr_mod_labels & val_labels) == 0, "labels cannot intersect");
 static_assert((temp_labels & val_labels) == 0, "labels cannot intersect");
 
-struct ssa_info {
-   uint64_t label;
-   union {
-      uint32_t val;
-      Temp temp;
-      Instruction* mod_instr;
-   };
-   Instruction* parent_instr;
-
-   ssa_info() : label(0) {}
-
-   void add_label(Label new_label)
-   {
-      if (new_label & instr_mod_labels) {
-         label &= ~instr_mod_labels;
-         label &= ~(temp_labels | val_labels); /* instr, temp and val alias */
-      }
-
-      if (new_label & temp_labels) {
-         label &= ~temp_labels;
-         label &= ~(instr_mod_labels | val_labels); /* instr, temp and val alias */
-      }
-
-      uint32_t const_labels =
-         label_literal | label_constant_32bit | label_constant_64bit | label_constant_16bit;
-      if (new_label & const_labels) {
-         label &= ~val_labels | const_labels;
-         label &= ~(instr_mod_labels | temp_labels); /* instr, temp and val alias */
-      } else if (new_label & val_labels) {
-         label &= ~val_labels;
-         label &= ~(instr_mod_labels | temp_labels); /* instr, temp and val alias */
-      }
-
-      label |= new_label;
-   }
-
-   void set_constant(amd_gfx_level gfx_level, uint64_t constant)
-   {
-      Operand op16 = Operand::c16(constant);
-      Operand op32 = Operand::get_const(gfx_level, constant, 4);
-      add_label(label_literal);
-      val = constant;
-
-      /* check that no upper bits are lost in case of packed 16bit constants */
-      if (gfx_level >= GFX8 && !op16.isLiteral() &&
-          op16.constantValue16(true) == ((constant >> 16) & 0xffff))
-         add_label(label_constant_16bit);
-
-      if (!op32.isLiteral())
-         add_label(label_constant_32bit);
-
-      if (Operand::is_constant_representable(constant, 8))
-         add_label(label_constant_64bit);
-
-      if (label & label_constant_64bit) {
-         val = Operand::c64(constant).constantValue();
-         if (val != constant)
-            label &= ~(label_literal | label_constant_16bit | label_constant_32bit);
-      }
-   }
-
-   bool is_constant(unsigned bits)
-   {
-      switch (bits) {
-      case 8: return label & label_literal;
-      case 16: return label & label_constant_16bit;
-      case 32: return label & label_constant_32bit;
-      case 64: return label & label_constant_64bit;
-      }
-      return false;
-   }
-
-   bool is_literal(unsigned bits)
-   {
-      bool is_lit = label & label_literal;
-      switch (bits) {
-      case 8: return false;
-      case 16: return is_lit && ~(label & label_constant_16bit);
-      case 32: return is_lit && ~(label & label_constant_32bit);
-      case 64: return false;
-      }
-      return false;
-   }
-
-   bool is_constant_or_literal(unsigned bits)
-   {
-      if (bits == 64)
-         return label & label_constant_64bit;
-      else
-         return label & label_literal;
-   }
-
-   void set_abs(Temp abs_temp)
-   {
-      add_label(label_abs);
-      temp = abs_temp;
-   }
-
-   bool is_abs() { return label & label_abs; }
-
-   void set_neg(Temp neg_temp)
-   {
-      add_label(label_neg);
-      temp = neg_temp;
-   }
-
-   bool is_neg() { return label & label_neg; }
-
-   void set_neg_abs(Temp neg_abs_temp)
-   {
-      add_label((Label)((uint32_t)label_abs | (uint32_t)label_neg));
-      temp = neg_abs_temp;
-   }
-
-   void set_temp(Temp tmp)
-   {
-      add_label(label_temp);
-      temp = tmp;
-   }
-
-   bool is_temp() { return label & label_temp; }
-
-   void set_mad(uint32_t mad_info_idx)
-   {
-      add_label(label_mad);
-      val = mad_info_idx;
-   }
-
-   bool is_mad() { return label & label_mad; }
-
-   void set_omod2(Instruction* mul)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_omod2);
-      mod_instr = mul;
-   }
-
-   bool is_omod2() { return label & label_omod2; }
-
-   void set_omod4(Instruction* mul)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_omod4);
-      mod_instr = mul;
-   }
-
-   bool is_omod4() { return label & label_omod4; }
-
-   void set_omod5(Instruction* mul)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_omod5);
-      mod_instr = mul;
-   }
-
-   bool is_omod5() { return label & label_omod5; }
-
-   void set_clamp(Instruction* med3)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_clamp);
-      mod_instr = med3;
-   }
-
-   bool is_clamp() { return label & label_clamp; }
-
-   void set_f2f16(Instruction* conv)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_f2f16);
-      mod_instr = conv;
-   }
-
-   bool is_f2f16() { return label & label_f2f16; }
-
-   void set_b2f(Temp b2f_val)
-   {
-      add_label(label_b2f);
-      temp = b2f_val;
-   }
-
-   bool is_b2f() { return label & label_b2f; }
-
-   void set_uniform_bitwise() { add_label(label_uniform_bitwise); }
-
-   bool is_uniform_bitwise() { return label & label_uniform_bitwise; }
-
-   void set_scc_needed() { add_label(label_scc_needed); }
-
-   bool is_scc_needed() { return label & label_scc_needed; }
-
-   void set_scc_invert(Temp scc_inv)
-   {
-      add_label(label_scc_invert);
-      temp = scc_inv;
-   }
-
-   bool is_scc_invert() { return label & label_scc_invert; }
-
-   void set_uniform_bool(Temp uniform_bool)
-   {
-      add_label(label_uniform_bool);
-      temp = uniform_bool;
-   }
-
-   bool is_uniform_bool() { return label & label_uniform_bool; }
-
-   void set_b2i(Temp b2i_val)
-   {
-      add_label(label_b2i);
-      temp = b2i_val;
-   }
-
-   bool is_b2i() { return label & label_b2i; }
+struct ssa_info
+{
+    uint64_t label = 0;
 
-   void set_fcanonicalize(Temp tmp)
-   {
-      add_label(label_fcanonicalize);
-      temp = tmp;
-   }
+    union {
+        uint32_t     val;
+        Temp         temp;
+        Instruction* mod_instr;
+    };
 
-   bool is_fcanonicalize() { return label & label_fcanonicalize; }
+    Instruction* parent_instr = nullptr;
 
-   void set_canonicalized() { add_label(label_canonicalized); }
+    constexpr ssa_info() noexcept : label(0), val(0), parent_instr(nullptr) {}
+    ~ssa_info() = default;
 
-   bool is_canonicalized() { return label & label_canonicalized; }
+    void add_label(Label new_label)
+    {
+        if (!new_label)
+            return;
 
-   void set_extract() { add_label(label_extract); }
+        constexpr uint64_t const_labels =
+        label_literal | label_constant_32bit |
+        label_constant_64bit | label_constant_16bit;
+
+        const bool is_instr = new_label & instr_mod_labels;
+        const bool is_temp  = new_label & temp_labels;
+        const bool is_const = new_label & const_labels;
+        const bool is_val   = (!is_const) && (new_label & val_labels);
+
+        if (is_instr)
+            label &= ~(instr_mod_labels | temp_labels | val_labels);
+        else if (is_temp)
+            label &= ~(temp_labels | instr_mod_labels | val_labels);
+        else if (is_const || is_val)
+            label &= ~(val_labels | instr_mod_labels | temp_labels);
+
+        label |= new_label;
+    }
+
+    /* ------------------------------------------------------------------ */
+    /* 3.  Constant/Literal helpers                                        */
+    /* ------------------------------------------------------------------ */
+    void set_constant(amd_gfx_level gfx_level, uint64_t constant)
+    {
+        Operand op16 = Operand::c16(constant);
+        Operand op32 = Operand::get_const(gfx_level, constant, 4);
+
+        add_label(label_literal);
+        val = constant;
+
+        /* packed-16 inline    (both 16-bit halves equal & representable) */
+        if (gfx_level >= GFX8 && !op16.isLiteral() &&
+            op16.constantValue16(true) == ((constant >> 16) & 0xffff))
+            add_label(label_constant_16bit);
+
+        if (!op32.isLiteral())
+            add_label(label_constant_32bit);
+
+        if (Operand::is_constant_representable(constant, 8))
+            add_label(label_constant_64bit);
+
+        /* Prefer 64-bit inline const if available                         */
+        if (label & label_constant_64bit) {
+            val = Operand::c64(constant).constantValue();
+            if (val != constant)            /* information loss → strip      */
+                label &= ~(label_literal | label_constant_16bit |
+                label_constant_32bit);
+        }
+    }
+
+    bool is_constant(unsigned bits) const
+    {
+        switch (bits) {
+            case  8: return label & label_literal;
+            case 16: return label & label_constant_16bit;
+            case 32: return label & label_constant_32bit;
+            case 64: return label & label_constant_64bit;
+            default: return false;
+        }
+    }
+
+    bool is_literal(unsigned bits) const
+    {
+        const bool lit = label & label_literal;
+        switch (bits) {
+            case  8: return false; /* 8-bit always inline, never “literal”      */
+            case 16: return lit && !(label & label_constant_16bit);
+            case 32: return lit && !(label & label_constant_32bit);
+            case 64: return lit && !(label & label_constant_64bit);
+            default: return false;
+        }
+    }
+
+    bool is_constant_or_literal(unsigned bits) const
+    {
+        return is_constant(bits) || is_literal(bits);
+    }
+
+    /* ------------------------------------------------------------------ */
+    /* 4.  Fast setters / testers (public API remains unchanged)           */
+    /* ------------------------------------------------------------------ */
+    /* ---- abs / neg --------------------------------------------------- */
+    void set_abs(Temp t)              { add_label(label_abs); temp = t; }
+    bool is_abs()               const { return label & label_abs; }
+
+    void set_neg(Temp t)              { add_label(label_neg); temp = t; }
+    bool is_neg()               const { return label & label_neg; }
+
+    void set_neg_abs(Temp t)
+    {
+        add_label(static_cast<Label>(label_abs | label_neg));
+        temp = t;
+    }
+
+    /* ---- plain temp -------------------------------------------------- */
+    void set_temp(Temp t)             { add_label(label_temp); temp = t; }
+    bool is_temp()              const { return label & label_temp; }
+
+    /* ---- MAD marker -------------------------------------------------- */
+    void set_mad(uint32_t idx)        { add_label(label_mad);  val = idx; }
+    bool is_mad()               const { return label & label_mad; }
+
+    /* ---- omod / clamp / f2f16 / insert ------------------------------- */
+    void set_omod2 (Instruction* m)   { add_label(label_omod2);  mod_instr = m; }
+    bool is_omod2()             const { return label & label_omod2; }
+
+    void set_omod4 (Instruction* m)   { add_label(label_omod4);  mod_instr = m; }
+    bool is_omod4()             const { return label & label_omod4; }
+
+    void set_omod5 (Instruction* m)   { add_label(label_omod5);  mod_instr = m; }
+    bool is_omod5()             const { return label & label_omod5; }
+
+    void set_clamp (Instruction* m)   { add_label(label_clamp);  mod_instr = m; }
+    bool is_clamp()             const { return label & label_clamp; }
+
+    void set_f2f16(Instruction* m)    { add_label(label_f2f16); mod_instr = m; }
+    bool is_f2f16()            const { return label & label_f2f16; }
+
+    void set_insert(Instruction* m)   { add_label(label_insert); mod_instr = m; }
+    bool is_insert()            const { return label & label_insert; }
+
+    /* ---- misc helpers ------------------------------------------------ */
+    void set_b2f(Temp t)              { add_label(label_b2f);   temp = t; }
+    bool is_b2f()               const { return label & label_b2f; }
+
+    void set_uniform_bitwise()        { add_label(label_uniform_bitwise); }
+    bool is_uniform_bitwise()   const { return label & label_uniform_bitwise; }
+
+    void set_scc_needed()             { add_label(label_scc_needed); }
+    bool is_scc_needed()        const { return label & label_scc_needed; }
+
+    void set_scc_invert(Temp t)       { add_label(label_scc_invert); temp = t; }
+    bool is_scc_invert()        const { return label & label_scc_invert; }
+
+    void set_uniform_bool(Temp t)     { add_label(label_uniform_bool); temp = t; }
+    bool is_uniform_bool()      const { return label & label_uniform_bool; }
+
+    void set_b2i(Temp t)              { add_label(label_b2i);  temp = t; }
+    bool is_b2i()               const { return label & label_b2i; }
 
-   bool is_extract() { return label & label_extract; }
+    void set_fcanonicalize(Temp t)    { add_label(label_fcanonicalize); temp = t; }
+    bool is_fcanonicalize()     const { return label & label_fcanonicalize; }
 
-   void set_insert(Instruction* insert)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_insert);
-      mod_instr = insert;
-   }
+    void set_canonicalized()          { add_label(label_canonicalized); }
+    bool is_canonicalized()     const { return label & label_canonicalized; }
 
-   bool is_insert() { return label & label_insert; }
+    void set_extract()                { add_label(label_extract); }
+    bool is_extract()           const { return label & label_extract; }
 };
 
 struct opt_ctx {
@@ -1962,6 +1883,25 @@ label_instruction(opt_ctx& ctx, aco_ptr<
       ctx.info[def.tempId()].parent_instr = instr.get();
 }
 
+/* PhysReg helpers (they are enum‐like in ACO) */
+#ifndef EXEC_LO
+#define EXEC_LO PhysReg{exec}
+#define EXEC_HI PhysReg{exec+1}
+#endif
+
+static inline bool is_exec_lo(const Operand& op)
+{
+    return op.isFixed() && op.physReg() == EXEC_LO;
+}
+static inline bool is_exec_hi(const Operand& op)
+{
+    return op.isFixed() && op.physReg() == EXEC_HI;
+}
+static inline bool is_vcc(const Operand& op)
+{
+    return op.isFixed() && (op.physReg() == vcc || op.physReg() == vcc_hi);
+}
+
 unsigned
 original_temp_id(opt_ctx& ctx, Temp tmp)
 {
@@ -2187,6 +2127,343 @@ combine_three_valu_op(opt_ctx& ctx, aco_
    return false;
 }
 
+static bool
+combine_alignbit_like(opt_ctx&              ctx,
+                      aco_ptr<Instruction>& or_instr,
+                      aco_opcode            target,
+                      unsigned              granularity)
+{
+    if (or_instr->opcode != aco_opcode::v_or_b32 ||
+        or_instr->operands.size() != 2 ||
+        granularity == 0 ||
+        ctx.program->gfx_level < GFX9)
+        return false;
+
+    /* ---------- recognise   v_lshrrev / v_lshlrev  -------------------- */
+    auto match_shift = [&](Operand op, unsigned& amount, Operand& src,
+                           bool& is_shr) -> bool {
+                               if (!op.isTemp())
+                                   return false;
+                               Instruction* sh = ctx.info[op.tempId()].parent_instr;
+                               if (!sh || ctx.uses[op.tempId()] != 1)
+                                   return false;
+
+                               if (sh->opcode == aco_opcode::v_lshrrev_b32)
+                                   is_shr = true;
+                               else if (sh->opcode == aco_opcode::v_lshlrev_b32)
+                                   is_shr = false;
+                               else
+                                   return false;
+
+                               if (!sh->operands[0].isLiteral() ||
+                                   sh->operands[0].constantValue() >= 32)
+                                   return false;
+
+                               amount = sh->operands[0].constantValue();
+                               if (amount == 0 || amount >= 32 || amount % granularity)
+                                   return false;
+
+                               src = sh->operands[1];
+                               return true;
+                           };
+
+                           unsigned a_amt = 0, b_amt = 0;
+                           Operand  a_src,  b_src;
+                           bool     a_shr = false, b_shr = false;
+
+                           if (!match_shift(or_instr->operands[0], a_amt, a_src, a_shr) ||
+                               !match_shift(or_instr->operands[1], b_amt, b_src, b_shr))
+                               return false;
+
+                           if (a_shr == b_shr)                     /* need one left, one right */
+                               return false;
+    if (a_amt + b_amt != 32)                /* must be complementary    */
+        return false;
+
+    /* choose mapping that fits ISA:  dst = (src0 >> imm) | (src1 << (32-imm)) */
+    Operand src0 = a_shr ? a_src : b_src;   /* right-shift origin */
+    Operand src1 = a_shr ? b_src : a_src;   /* left-shift origin  */
+    unsigned imm = a_shr ? a_amt : b_amt;   /* right-shift amount */
+
+    aco_ptr<Instruction> ali{
+        create_instruction(target, Format::VOP3, 3, 1)};
+
+        ali->operands[0] = src0;
+        ali->operands[1] = src1;
+        ali->operands[2] = Operand::c32(imm / granularity);
+        ali->definitions[0] = or_instr->definitions[0];
+        ali->pass_flags     = or_instr->pass_flags;
+
+        ctx.uses[or_instr->operands[0].tempId()]--;
+        ctx.uses[or_instr->operands[1].tempId()]--;
+
+        if (src0.isTemp()) ctx.uses[src0.tempId()]++;
+            if (src1.isTemp()) ctx.uses[src1.tempId()]++;
+
+            or_instr = std::move(ali);
+    ctx.info[or_instr->definitions[0].tempId()].parent_instr = or_instr.get();
+    return true;
+}
+
+static inline bool
+combine_alignbit_b32(opt_ctx& ctx, aco_ptr<Instruction>& instr)
+{
+    return combine_alignbit_like(ctx, instr, aco_opcode::v_alignbit_b32, 1);
+}
+
+static inline bool
+combine_alignbyte_b32(opt_ctx& ctx, aco_ptr<Instruction>& instr)
+{
+    return combine_alignbit_like(ctx, instr, aco_opcode::v_alignbyte_b32, 8);
+}
+
+static bool
+combine_bfi_b32(opt_ctx& ctx, aco_ptr<Instruction>& or_instr)
+{
+    if (or_instr->opcode != aco_opcode::v_or_b32 ||
+        ctx.program->gfx_level < GFX9)
+        return false;
+
+    /* ---- helper to match “src & literal” ----------------------------- */
+    auto match_and_side = [&](Operand in, Operand& src, uint32_t& lit) -> bool
+    {
+        if (!in.isTemp())
+            return false;
+
+        Instruction* and_i = ctx.info[in.tempId()].parent_instr;
+        if (!and_i || and_i->opcode != aco_opcode::v_and_b32 ||
+            ctx.uses[in.tempId()] != 1)
+            return false;
+
+        for (unsigned op = 0; op < 2; ++op) {
+            if (and_i->operands[op].isLiteral()) {
+                uint32_t imm = and_i->operands[op].constantValue();
+
+                /* must be VERD/inline constant so instruction can dual issue */
+                if (!Operand::is_constant_representable(imm, 4))
+                    return false;
+
+                lit = imm;
+                src = and_i->operands[1 ^ op];
+                return true;
+            }
+        }
+        return false;
+    };
+
+    /* ---- analyse both OR operands ------------------------------------ */
+    Operand   val0, val1;
+    uint32_t  mask0 = 0, mask1 = 0;
+
+    if (!match_and_side(or_instr->operands[0], val0, mask0) ||
+        !match_and_side(or_instr->operands[1], val1, mask1))
+        return false;
+
+    /* masks must form a perfect complement */
+    if ((mask0 ^ mask1) != 0xffffffffu || mask0 == 0 || mask0 == 0xffffffffu)
+        return false;
+
+    /* decide which side is mask / ~mask */
+    Operand  base, ins;
+    uint32_t mask;
+    if (mask1 == (~mask0)) {
+        ins  = val0;   base = val1;   mask = mask0;
+    } else { /* mask0 == ~mask1 */
+        ins  = val1;   base = val0;   mask = mask1;
+    }
+
+    /* ---- build v_bfi_b32 --------------------------------------------- */
+    aco_ptr<Instruction> bfi{
+        create_instruction(aco_opcode::v_bfi_b32, Format::VOP3, 3, 1)};
+
+        bfi->operands[0]    = base;
+        bfi->operands[1]    = ins;
+        bfi->operands[2]    = Operand::c32(mask);    /* inline const */
+        bfi->definitions[0] = or_instr->definitions[0];
+        bfi->pass_flags     = or_instr->pass_flags;
+
+        /* ---- SSA bookkeeping --------------------------------------------- */
+        ctx.uses[or_instr->operands[0].tempId()]--;   /* kill AND temps */
+        ctx.uses[or_instr->operands[1].tempId()]--;
+
+        if (base.isTemp()) ctx.uses[base.tempId()]++; /* new direct uses */
+            if (ins .isTemp()) ctx.uses[ins .tempId()]++;
+
+            or_instr = std::move(bfi);
+    ctx.info[or_instr->definitions[0].tempId()].parent_instr = or_instr.get();
+    return true;
+}
+
+static bool
+combine_bfe_b32(opt_ctx& ctx, aco_ptr<Instruction>& and_instr)
+{
+    if (and_instr->opcode != aco_opcode::v_and_b32 ||
+        ctx.program->gfx_level < GFX8)
+        return false;
+
+    if (!and_instr->operands[1].isLiteral())
+        return false;
+    uint32_t mask = and_instr->operands[1].constantValue();
+    if (!mask || (mask & (mask + 1u)) != 0u)
+        return false;
+
+    unsigned width = util_bitcount(mask);
+
+    if (!and_instr->operands[0].isTemp())
+        return false;
+    unsigned tmp_id = and_instr->operands[0].tempId();
+    if (ctx.uses[tmp_id] != 1)
+        return false;
+
+    Instruction* sh = ctx.info[tmp_id].parent_instr;
+    if (!sh || !(sh->opcode == aco_opcode::v_lshrrev_b32 ||
+        sh->opcode == aco_opcode::v_ashrrev_i32))
+        return false;
+    if (!sh->operands[0].isLiteral() ||
+        sh->operands[0].constantValue() >= 32)
+        return false;
+
+    unsigned offset = sh->operands[0].constantValue();
+    if (offset + width > 32)
+        return false;
+
+        aco_opcode bfe_op = (sh->opcode == aco_opcode::v_lshrrev_b32)
+        ? aco_opcode::v_bfe_u32
+        : aco_opcode::v_bfe_i32;
+
+    unsigned enc_width = (width == 32) ? 0 : width;
+
+    aco_ptr<Instruction> bfe{
+        create_instruction(bfe_op, Format::VOP3, 3, 1)};
+
+        Operand src_val = sh->operands[1];
+
+        bfe->operands[0]    = src_val;
+        bfe->operands[1]    = Operand::c32(offset);
+        bfe->operands[2]    = Operand::c32(enc_width);
+        bfe->definitions[0] = and_instr->definitions[0];
+        bfe->pass_flags     = and_instr->pass_flags;
+
+        ctx.uses[tmp_id]--;
+        if (src_val.isTemp()) ctx.uses[src_val.tempId()]++;
+
+            and_instr = std::move(bfe);
+    ctx.info[and_instr->definitions[0].tempId()].parent_instr = and_instr.get();
+    return true;
+}
+
+static bool
+combine_bcnt_mbcnt(opt_ctx& ctx, aco_ptr<Instruction>& add_instr)
+{
+    if (add_instr->opcode != aco_opcode::v_add_u32 ||
+        add_instr->usesModifiers() ||
+        ctx.program->gfx_level < GFX9)
+        return false;
+
+    int          bcnt_idx = -1;
+    Instruction* bcnt     = nullptr;
+
+    for (unsigned i = 0; i < 2; ++i) {
+        if (!add_instr->operands[i].isTemp())
+            continue;
+
+        unsigned tmp_id = add_instr->operands[i].tempId();
+        if (ctx.uses[tmp_id] != 1)
+            continue;
+
+        Instruction* cand = ctx.info[tmp_id].parent_instr;
+        if (!cand || cand->opcode != aco_opcode::v_bcnt_u32_b32)
+            continue;
+
+        if (!cand->operands[1].isLiteral() ||
+            !cand->operands[1].constantEquals(0))
+            continue;
+
+        bcnt_idx = i;
+        bcnt     = cand;
+        break;
+    }
+
+    if (!bcnt)
+        return false;
+
+    if (!(is_exec_lo(bcnt->operands[0]) || is_exec_hi(bcnt->operands[0])))
+        return false;
+
+    bool lo_segment    = is_exec_lo(bcnt->operands[0]);
+    aco_opcode mbcnt_op = lo_segment ? aco_opcode::v_mbcnt_lo_u32_b32
+    : aco_opcode::v_mbcnt_hi_u32_b32;
+
+    Operand carry_in = add_instr->operands[1u ^ bcnt_idx];
+
+    aco_ptr<Instruction> mbcnt{
+        create_instruction(mbcnt_op, Format::VOP3, 2, 1)};
+
+        mbcnt->operands[0]    = bcnt->operands[0];
+        mbcnt->operands[1]    = carry_in;
+        mbcnt->definitions[0] = add_instr->definitions[0];
+        mbcnt->pass_flags     = add_instr->pass_flags;
+
+        ctx.uses[add_instr->operands[bcnt_idx].tempId()]--;
+
+        add_instr = std::move(mbcnt);
+        ctx.info[add_instr->definitions[0].tempId()].parent_instr = add_instr.get();
+        return true;
+}
+
+static bool
+combine_sad_u8(opt_ctx& ctx, aco_ptr<Instruction>& add_instr)
+{
+    if (add_instr->opcode != aco_opcode::v_add_u32 ||
+        add_instr->usesModifiers() ||
+        ctx.program->gfx_level < GFX9)
+        return false;
+
+    int          sad_idx = -1;
+    Instruction* sad     = nullptr;
+
+    for (unsigned i = 0; i < 2; ++i) {
+        if (!add_instr->operands[i].isTemp())
+            continue;
+
+        unsigned tmp_id = add_instr->operands[i].tempId();
+        if (ctx.uses[tmp_id] != 1)
+            continue;
+
+        Instruction* cand = ctx.info[tmp_id].parent_instr;
+        if (!cand ||
+            !((cand->opcode == aco_opcode::v_sad_u8) ||
+            (cand->opcode == aco_opcode::v_sad_hi_u8)))
+            continue;
+
+        if (!cand->operands[2].isLiteral() ||
+            !cand->operands[2].constantEquals(0))
+            continue;
+
+        sad_idx = i;
+        sad     = cand;
+        break;
+    }
+
+    if (!sad)
+        return false;
+
+    aco_ptr<Instruction> fused{
+        create_instruction(sad->opcode, Format::VOP3, 3, 1)};
+
+        fused->operands[0] = sad->operands[0];
+        fused->operands[1] = sad->operands[1];
+        fused->operands[2] = add_instr->operands[1u ^ sad_idx];
+        fused->definitions[0] = add_instr->definitions[0];
+        fused->pass_flags     = add_instr->pass_flags;
+
+        ctx.uses[add_instr->operands[sad_idx].tempId()]--;
+
+        add_instr = std::move(fused);
+        ctx.info[add_instr->definitions[0].tempId()].parent_instr = add_instr.get();
+        return true;
+}
+
 /* creates v_lshl_add_u32, v_lshl_or_b32 or v_and_or_b32 */
 bool
 combine_add_or_then_and_lshl(opt_ctx& ctx, aco_ptr<Instruction>& instr)
@@ -3297,190 +3574,397 @@ propagate_swizzles(VALU_instruction* ins
    }
 }
 
-void
+template <typename GfxEnum>
+static inline bool can_use_inline_constant(GfxEnum /*gfx_level*/,
+                                           uint32_t imm)
+{
+    /* Small signed/unsigned integers (0‥64, -16‥-1) -------------------- */
+    if (imm <= 64u || imm >= 0xfffffff0u)
+        return true;
+
+    /* Canonical IEEE-754 fp constants – perfect-hash on the top nibble -- */
+    constexpr uint8_t canonical_fp_lut[16] = {
+        /* 0x0 … 0xF  */
+        0,0,0,0,  /* 0x0-0x3 */
+        0,0,0,0,  /* 0x4-0x7 */
+        1,1,      /* 0x8 =  1.0f  / 0x9 = -1.0f   */
+        1,1,      /* 0xA =  2.0f  / 0xB = -2.0f   */
+        0,0,0,0   /* 0xC-0xF (the 4.0/-4.0 cases sit at 0x40/0xC0) */
+    };
+
+    const uint8_t high_nib = static_cast<uint8_t>(imm >> 24);
+    if ((high_nib == 0x3F || high_nib == 0xBF) && canonical_fp_lut[(imm>>20)&0xF])
+        return true;                           /* ±0.5 / ±1   */
+        if ((high_nib == 0x40 || high_nib == 0xC0) &&
+            ((imm & 0x00ffffffu) == 0))           /* ±2 / ±4     */
+        return true;
+
+    return false;
+}
+
+static inline bool
+is_literal_valid_for_vop3p_vega(aco_opcode op, const Operand& lit) noexcept
+{
+    if (op == aco_opcode::v_pk_mad_i16)
+        return false;
+
+    if (op == aco_opcode::v_pk_fma_f16 || op == aco_opcode::v_pk_mad_u16) {
+        return lit.isConstant() &&
+        can_use_inline_constant(GFX9, lit.constantValue());
+    }
+
+    return true;
+}
+
+static void propagate_swizzles_vega(VALU_instruction* v,
+                                    bool opsel_lo,
+                                    bool opsel_hi) noexcept
+{
+    if (!v) return; /* Safety check */
+
+    constexpr unsigned N = 3;
+
+    /* Whole-word flip: both halves come from former "hi" ------------- */
+    if (opsel_lo && opsel_hi) {
+        for (unsigned s = 0; s < N; ++s) {
+            /* Use XOR swap for bitfields since they support it efficiently */
+            const bool d1 = v->opsel_lo[s] ^ v->opsel_hi[s];
+            v->opsel_lo[s] ^= d1;
+            v->opsel_hi[s] ^= d1;
+
+            const bool d2 = v->neg_lo[s] ^ v->neg_hi[s];
+            v->neg_lo[s] ^= d2;
+            v->neg_hi[s] ^= d2;
+        }
+        return;
+    }
+
+    /* Partial swizzle cases ------------------------------------------ */
+    const bool hi_to_lo = opsel_lo;   /* move hi → lo */
+    const bool lo_to_hi = !opsel_hi;  /* move lo → hi */
+
+    for (unsigned s = 0; s < N; ++s) {
+        const bool orig_opsel_lo = v->opsel_lo[s];
+        const bool orig_opsel_hi = v->opsel_hi[s];
+        const bool orig_neg_lo = v->neg_lo[s];
+        const bool orig_neg_hi = v->neg_hi[s];
+
+        /* Apply conditional assignments based on swizzle flags */
+        v->opsel_lo[s] = hi_to_lo ? orig_opsel_hi : orig_opsel_lo;
+        v->opsel_hi[s] = lo_to_hi ? orig_opsel_lo : orig_opsel_hi;
+
+        v->neg_lo[s] = hi_to_lo ? orig_neg_hi : orig_neg_lo;
+        v->neg_hi[s] = lo_to_hi ? orig_neg_lo : orig_neg_hi;
+    }
+}
+
+static void
 combine_vop3p(opt_ctx& ctx, aco_ptr<Instruction>& instr)
 {
-   VALU_instruction* vop3p = &instr->valu();
-
-   /* apply clamp */
-   if (instr->opcode == aco_opcode::v_pk_mul_f16 && instr->operands[1].constantEquals(0x3C00) &&
-       vop3p->clamp && instr->operands[0].isTemp() && ctx.uses[instr->operands[0].tempId()] == 1 &&
-       !vop3p->opsel_lo[1] && !vop3p->opsel_hi[1]) {
-
-      Instruction* op_instr = ctx.info[instr->operands[0].tempId()].parent_instr;
-      if (op_instr->isVOP3P() &&
-          instr_info.alu_opcode_infos[(int)op_instr->opcode].output_modifiers) {
-         op_instr->valu().clamp = true;
-         propagate_swizzles(&op_instr->valu(), vop3p->opsel_lo[0], vop3p->opsel_hi[0]);
-         instr->definitions[0].swapTemp(op_instr->definitions[0]);
-         ctx.info[op_instr->definitions[0].tempId()].parent_instr = op_instr;
-         ctx.info[instr->definitions[0].tempId()].parent_instr = instr.get();
-         ctx.uses[instr->definitions[0].tempId()]--;
-         return;
-      }
-   }
-
-   /* check for fneg modifiers */
-   for (unsigned i = 0; i < instr->operands.size(); i++) {
-      if (!can_use_input_modifiers(ctx.program->gfx_level, instr->opcode, i))
-         continue;
-      Operand& op = instr->operands[i];
-      if (!op.isTemp())
-         continue;
-
-      ssa_info& info = ctx.info[op.tempId()];
-      if (info.parent_instr->opcode == aco_opcode::v_pk_mul_f16 &&
-          (info.parent_instr->operands[0].constantEquals(0x3C00) ||
-           info.parent_instr->operands[1].constantEquals(0x3C00) ||
-           info.parent_instr->operands[0].constantEquals(0xBC00) ||
-           info.parent_instr->operands[1].constantEquals(0xBC00))) {
-
-         VALU_instruction* fneg = &info.parent_instr->valu();
+    if (!instr || !instr->isVOP3P())
+        return;
 
-         unsigned fneg_src =
-            fneg->operands[0].constantEquals(0x3C00) || fneg->operands[0].constantEquals(0xBC00);
+    /* ------------------------------------------------------------------ */
+    /* 1. Clamp propagation (v_pk_mul_f16  +clamp  × 1.0)                 */
+    /* ------------------------------------------------------------------ */
+    {
+        VALU_instruction* v = &instr->valu();
+
+        if (instr->opcode == aco_opcode::v_pk_mul_f16               &&
+            instr->operands.size() >= 2                             &&
+            instr->operands[1].isConstant()                         &&
+            instr->operands[1].constantEquals(0x3C00) && v->clamp   &&
+            instr->operands[0].isTemp()) {
+
+            Temp src = instr->operands[0].getTemp();
+        if (src.id() < ctx.uses.size() && ctx.uses[src.id()] == 1 &&
+            src.id() < ctx.info.size()) {
+
+            Instruction* mul = ctx.info[src.id()].parent_instr;
+        if (mul && mul->isVOP3P() && !mul->valu().clamp &&
+            instr_info.alu_opcode_infos[(unsigned)mul->opcode]
+            .output_modifiers) {
+
+            /* remember swizzle flags *before* ADD disappears        */
+            bool o_lo0 = v->opsel_lo[0];
+        bool o_hi0 = v->opsel_hi[0];
+
+        mul->valu().clamp = true;
+        propagate_swizzles_vega(&mul->valu(), o_lo0, o_hi0);
+
+        /* build parallelcopy to take ADD’s place                */
+        Definition def = instr->definitions[0];
+        aco_ptr<Instruction> pc(create_instruction(
+            aco_opcode::p_parallelcopy, Format::PSEUDO, 1, 1));
+        pc->operands[0]   = Operand(mul->definitions[0].getTemp());
+        pc->definitions[0] = def;
+        pc->pass_flags     = instr->pass_flags;
+
+        if (def.tempId() < ctx.info.size()) {
+            ctx.info[def.tempId()].parent_instr = pc.get();
+            ctx.info[def.tempId()].set_temp(pc->operands[0].getTemp());
+        }
+        if (mul->definitions[0].tempId() < ctx.uses.size())
+            ctx.uses[mul->definitions[0].tempId()]++;
 
-         if (fneg->opsel_lo[1 - fneg_src] || fneg->opsel_hi[1 - fneg_src])
-            continue;
-
-         Operand ops[3];
-         for (unsigned j = 0; j < instr->operands.size(); j++)
-            ops[j] = instr->operands[j];
-         ops[i] = fneg->operands[fneg_src];
-         if (!check_vop3_operands(ctx, instr->operands.size(), ops))
-            continue;
-
-         if (fneg->clamp)
-            continue;
-         instr->operands[i] = fneg->operands[fneg_src];
+            instr = std::move(pc);
+        return;
+            }
+            }
+            }
+    }
 
-         /* opsel_lo/hi is either 0 or 1:
-          * if 0 - pick selection from fneg->lo
-          * if 1 - pick selection from fneg->hi
-          */
-         bool opsel_lo = vop3p->opsel_lo[i];
-         bool opsel_hi = vop3p->opsel_hi[i];
-         bool neg_lo = fneg->neg_lo[0] ^ fneg->neg_lo[1];
-         bool neg_hi = fneg->neg_hi[0] ^ fneg->neg_hi[1];
-         bool neg_const = fneg->operands[1 - fneg_src].constantEquals(0xBC00);
-         /* Avoid ternary xor as it causes CI fails that can't be reproduced on other systems. */
-         neg_lo ^= neg_const;
-         neg_hi ^= neg_const;
-         vop3p->neg_lo[i] ^= opsel_lo ? neg_hi : neg_lo;
-         vop3p->neg_hi[i] ^= opsel_hi ? neg_hi : neg_lo;
-         vop3p->opsel_lo[i] ^= opsel_lo ? !fneg->opsel_hi[fneg_src] : fneg->opsel_lo[fneg_src];
-         vop3p->opsel_hi[i] ^= opsel_hi ? !fneg->opsel_hi[fneg_src] : fneg->opsel_lo[fneg_src];
-
-         if (--ctx.uses[fneg->definitions[0].tempId()])
-            ctx.uses[fneg->operands[fneg_src].tempId()]++;
-      }
-   }
+    /* ------------------------------------------------------------------ */
+    /* 2. FNEG folding (-x)                                                */
+    /* ------------------------------------------------------------------ */
+    {
+        VALU_instruction* v      = &instr->valu();
+        const unsigned num_srcs  = instr->operands.size();
+
+        for (unsigned i = 0; i < num_srcs; ++i) {
+            if (!can_use_input_modifiers(ctx.program->gfx_level,
+                instr->opcode, i))
+                continue;
+            Operand& op = instr->operands[i];
+            if (!op.isTemp() || op.tempId() >= ctx.info.size() ||
+                op.tempId() >= ctx.uses.size() ||
+                ctx.uses[op.tempId()] != 1)
+                continue;
+
+            Instruction* neg = ctx.info[op.tempId()].parent_instr;
+            if (!neg || neg->opcode != aco_opcode::v_pk_mul_f16)
+                continue;
+
+            unsigned const_idx = 2;
+            if (neg->operands[0].constantEquals(0xBC00)) const_idx = 0;
+            else if (neg->operands[1].constantEquals(0xBC00)) const_idx = 1;
+            if (const_idx > 1) continue;
+
+            unsigned src_idx = 1 ^ const_idx;
+            VALU_instruction& nv = neg->valu();
+            if (nv.clamp ||
+                nv.opsel_lo[const_idx] || nv.opsel_hi[const_idx] ||
+                nv.neg_lo  [const_idx] || nv.neg_hi  [const_idx])
+                continue;
+
+            Operand try_ops[3];
+            for (unsigned j = 0; j < num_srcs; ++j)
+                try_ops[j] = (j == i) ? neg->operands[src_idx]
+                : instr->operands[j];
+            if (!check_vop3_operands(ctx, num_srcs, try_ops))
+                continue;
+
+            bool add_lo = v->opsel_lo[i];
+            bool add_hi = v->opsel_hi[i];
+
+            v->opsel_lo[i] = add_lo ? nv.opsel_hi[src_idx] : nv.opsel_lo[src_idx];
+            v->opsel_hi[i] = add_hi ? nv.opsel_hi[src_idx] : nv.opsel_lo[src_idx];
+
+            bool n_lo = add_lo ? nv.neg_hi[src_idx] : nv.neg_lo[src_idx];
+            bool n_hi = add_hi ? nv.neg_hi[src_idx] : nv.neg_lo[src_idx];
+
+            v->neg_lo[i] ^= n_lo ^ 1u;               /* extra “-” sign        */
+            v->neg_hi[i] ^= n_hi ^ 1u;
+
+            instr->operands[i] = copy_operand(ctx, neg->operands[src_idx]);
+            decrease_uses(ctx, neg);
+        }
+    }
+
+    /* ------------------------------------------------------------------ */
+    /* 3. MAD / FMA formation                                              */
+    /* ------------------------------------------------------------------ */
+    const bool is_fadd = instr->opcode == aco_opcode::v_pk_add_f16;
+    const bool is_uadd = instr->opcode == aco_opcode::v_pk_add_u16;
+    const bool is_iadd = ctx.program->gfx_level >= GFX9 &&
+    instr->opcode == aco_opcode::v_pk_add_i16;
+    if ((!is_fadd && !is_uadd && !is_iadd) ||
+        (is_fadd && instr->definitions[0].isPrecise()))
+        return;
+
+    /* ---------------- pick best MUL candidate ------------------------- */
+    Instruction* best_mul = nullptr;
+    unsigned     best_mul_idx = 0;
+    unsigned     best_add_idx = 0;
+    uint32_t     best_uses    = UINT32_MAX;
+
+    for (unsigned i = 0; i < 2 && i < instr->operands.size(); ++i) {
+        Instruction* mul = follow_operand(ctx, instr->operands[i], true);
+        if (!mul) continue;
+
+        /* opcode / modifier validation */
+        bool opcode_ok = false;
+        if (is_fadd)
+            opcode_ok = mul->opcode == aco_opcode::v_pk_mul_f16;
+        else if (is_uadd)
+            opcode_ok = (mul->isVOP3P() && mul->opcode == aco_opcode::v_pk_mul_lo_u16) ||
+            (mul->isVOP2 () && mul->opcode == aco_opcode::v_mul_lo_u16);
+        else /* is_iadd */
+            opcode_ok = mul->opcode == aco_opcode::v_pk_mad_i16 &&
+            mul->operands.size() == 3 &&
+            mul->operands[2].constantEquals(0) &&
+            !mul->valu().neg_lo[2] && !mul->valu().neg_hi[2] &&
+            !mul->valu().opsel_lo[2] && !mul->valu().opsel_hi[2];
+        if (!opcode_ok) continue;
+
+        if (is_fadd && mul->definitions[0].isPrecise()) continue;
+        if (mul->valu().clamp || (is_fadd && mul->valu().omod)) continue;
+        if (mul->isDPP()) continue;
+
+        if (mul->isSDWA()) {
+            bool ok = true;
+            for (unsigned s = 0; s < 2 && s < mul->operands.size(); ++s) {
+                auto sel = mul->sdwa().sel[s];
+                if (sel.size() != 2 || (sel.offset() & 1)) { ok = false; break; }
+            }
+            if (!ok) continue;
+        }
 
-   if (instr->opcode == aco_opcode::v_pk_add_f16 || instr->opcode == aco_opcode::v_pk_add_u16) {
-      bool fadd = instr->opcode == aco_opcode::v_pk_add_f16;
-      if (fadd && instr->definitions[0].isPrecise())
-         return;
-      if (!fadd && instr->valu().clamp)
-         return;
+        Operand ops[3] = { mul->operands[0], mul->operands[1],
+            instr->operands[i ^ 1] };
+            if (!check_vop3_operands(ctx, 3, ops)) continue;
+
+            if (ctx.program->gfx_level == GFX9 && is_iadd)
+                for (Operand o : ops) if (o.isLiteral()) { opcode_ok = false; break; }
+                if (!opcode_ok) continue;
+
+                uint32_t uses = UINT32_MAX;
+        if (instr->operands[i].isTemp() &&
+            instr->operands[i].tempId() < ctx.uses.size())
+            uses = ctx.uses[instr->operands[i].tempId()];
 
-      Instruction* mul_instr = nullptr;
-      unsigned add_op_idx = 0;
-      bitarray8 mul_neg_lo = 0, mul_neg_hi = 0, mul_opsel_lo = 0, mul_opsel_hi = 0;
-      uint32_t uses = UINT32_MAX;
+        uint32_t thr = is_fadd ? 3 : 2;
+        if (uses > thr) continue;
 
-      /* find the 'best' mul instruction to combine with the add */
-      for (unsigned i = 0; i < 2; i++) {
-         Instruction* op_instr = follow_operand(ctx, instr->operands[i], true);
-         if (!op_instr)
-            continue;
+        if (uses < best_uses ||
+            (uses == best_uses &&
+            best_mul &&
+            mul->definitions[0].tempId() < best_mul->definitions[0].tempId())) {
+            best_mul     = mul;
+        best_mul_idx = i;
+        best_add_idx = i ^ 1u;
+        best_uses    = uses;
+            }
+    }
+    if (!best_mul) return;
 
-         if (op_instr->isVOP3P()) {
-            if (fadd) {
-               if (op_instr->opcode != aco_opcode::v_pk_mul_f16 ||
-                   op_instr->definitions[0].isPrecise())
-                  continue;
+    /* ---------------- capture ADD info before we move it --------------- */
+    Definition add_def        = instr->definitions[0];
+    uint32_t   add_pass_flags = instr->pass_flags;
+
+    VALU_instruction* v_add   = &instr->valu();
+    bool mul_opsel_lo = v_add->opsel_lo[best_mul_idx];
+    bool mul_opsel_hi = v_add->opsel_hi[best_mul_idx];
+    bool mul_neg_lo   = v_add->neg_lo [best_mul_idx];
+    bool mul_neg_hi   = v_add->neg_hi [best_mul_idx];
+
+    bool add_opsel_lo = v_add->opsel_lo[best_add_idx];
+    bool add_opsel_hi = v_add->opsel_hi[best_add_idx];
+    bool add_neg_lo   = v_add->neg_lo [best_add_idx];
+    bool add_neg_hi   = v_add->neg_hi [best_add_idx];
+
+    bool add_clamp    = v_add->clamp;
+    bool final_prec   = add_def.isPrecise() ||
+    best_mul->definitions[0].isPrecise();
+
+    /* ------------------------------------------------------------------ */
+    /*  Build MAD / FMA                                                   */
+    /* ------------------------------------------------------------------ */
+    aco_opcode mad_op = is_fadd ? aco_opcode::v_pk_fma_f16 :
+    (is_uadd ? aco_opcode::v_pk_mad_u16 :
+    aco_opcode::v_pk_mad_i16);
+
+    aco_ptr<Instruction> mad(create_instruction(mad_op, Format::VOP3P, 3, 1));
+    mad->operands[0] = copy_operand(ctx, best_mul->operands[0]);
+    mad->operands[1] = copy_operand(ctx, best_mul->operands[1]);
+    mad->operands[2] = copy_operand(ctx, instr->operands[best_add_idx]);
+
+    mad->valu().clamp = is_fadd && add_clamp;
+
+    /* copy modifiers from MUL ------------------------------------------ */
+    VALU_instruction& mv = best_mul->valu();
+    if (best_mul->isVOP3P()) {
+        mad->valu().neg_lo   = mv.neg_lo;
+        mad->valu().neg_hi   = mv.neg_hi;
+        mad->valu().opsel_lo = mv.opsel_lo;
+        mad->valu().opsel_hi = mv.opsel_hi;
+    } else {
+        for (unsigned s = 0; s < 2; ++s) {
+            mad->valu().neg_lo[s] = mv.neg[s];
+            mad->valu().neg_hi[s] = mv.neg[s];
+
+            if (best_mul->isSDWA()) {
+                uint8_t off = best_mul->sdwa().sel[s].offset();
+                mad->valu().opsel_lo[s] = off;      /* <<<< fixed (was off>>1) */
+                mad->valu().opsel_hi[s] = off;
             } else {
-               if (op_instr->opcode != aco_opcode::v_pk_mul_lo_u16)
-                  continue;
+                mad->valu().opsel_lo[s] = mv.opsel[s];
+                mad->valu().opsel_hi[s] = mv.opsel[s];
             }
+        }
+    }
 
-            Operand op[3] = {op_instr->operands[0], op_instr->operands[1], instr->operands[1 - i]};
-            if (ctx.uses[instr->operands[i].tempId()] >= uses || !check_vop3_operands(ctx, 3, op))
-               continue;
-
-            /* no clamp allowed between mul and add */
-            if (op_instr->valu().clamp)
-               continue;
-
-            mul_instr = op_instr;
-            add_op_idx = 1 - i;
-            uses = ctx.uses[instr->operands[i].tempId()];
-            mul_neg_lo = mul_instr->valu().neg_lo;
-            mul_neg_hi = mul_instr->valu().neg_hi;
-            mul_opsel_lo = mul_instr->valu().opsel_lo;
-            mul_opsel_hi = mul_instr->valu().opsel_hi;
-         } else if (instr->operands[i].bytes() == 2) {
-            if ((fadd && (op_instr->opcode != aco_opcode::v_mul_f16 ||
-                          op_instr->definitions[0].isPrecise())) ||
-                (!fadd && op_instr->opcode != aco_opcode::v_mul_lo_u16 &&
-                 op_instr->opcode != aco_opcode::v_mul_lo_u16_e64))
-               continue;
+    /* propagate swizzle from ADD’s product source ---------------------- */
+    propagate_swizzles_vega(&mad->valu(), mul_opsel_lo, mul_opsel_hi);
 
-            if (op_instr->valu().clamp || op_instr->valu().omod || op_instr->valu().abs)
-               continue;
-
-            if (op_instr->isDPP() || (op_instr->isSDWA() && (op_instr->sdwa().sel[0].size() < 2 ||
-                                                             op_instr->sdwa().sel[1].size() < 2)))
-               continue;
+    /* set addend modifiers --------------------------------------------- */
+    mad->valu().opsel_lo[2] = add_opsel_lo;
+    mad->valu().opsel_hi[2] = add_opsel_hi;
+    mad->valu().neg_lo [2] = add_neg_lo;
+    mad->valu().neg_hi [2] = add_neg_hi;
+
+    /* transfer product-negate with INT16_MIN safeguard ----------------- */
+    bool safe_on_src0 = true;
+    if (is_iadd && mad->operands[0].isConstant()) {
+        uint32_t vv = mad->operands[0].constantValue();
+        uint16_t lo = vv & 0xffffu, hi = vv >> 16;
+        uint16_t used_lo = mad->valu().opsel_lo[0] ? hi : lo;
+        uint16_t used_hi = mad->valu().opsel_hi[0] ? hi : lo;
+        if ((mul_neg_lo && used_lo == 0x8000u) ||
+            (mul_neg_hi && used_hi == 0x8000u))
+            safe_on_src0 = false;
+    }
+
+    if (safe_on_src0) {
+        mad->valu().neg_lo[0] ^= mul_neg_lo;
+        mad->valu().neg_hi[0] ^= mul_neg_hi;
+    } else {
+        mad->valu().neg_lo[1] ^= mul_neg_lo;
+        mad->valu().neg_hi[1] ^= mul_neg_hi;
+    }
+
+    /* definitions / flags ---------------------------------------------- */
+    mad->definitions[0] = add_def;
+    mad->definitions[0].setPrecise(final_prec);
+    mad->pass_flags     = add_pass_flags;
+
+    /* ------------------------------------------------------------------ */
+    /*  Ownership shuffle – move old ADD into mad_infos                   */
+    /* ------------------------------------------------------------------ */
+    aco_ptr<Instruction> old_add = std::move(instr);
+    ctx.mad_infos.emplace_back(std::move(old_add),
+                               best_mul->definitions[0].tempId());
+    instr = std::move(mad);                /* list slot now holds MAD      */
+
+    /* ------------------------------------------------------------------ */
+    /*  Update SSA meta                                                   */
+    /* ------------------------------------------------------------------ */
+    Temp def_t = add_def.getTemp();
+    if (def_t.id() < ctx.info.size()) {
+        ssa_info& inf = ctx.info[def_t.id()];
+        inf.parent_instr = instr.get();
+
+        if (final_prec) inf.label |= label_precise;
+        else            inf.label &= ~label_precise;
 
-            Operand op[3] = {op_instr->operands[0], op_instr->operands[1], instr->operands[1 - i]};
-            if (ctx.uses[instr->operands[i].tempId()] >= uses || !check_vop3_operands(ctx, 3, op))
-               continue;
-
-            mul_instr = op_instr;
-            add_op_idx = 1 - i;
-            uses = ctx.uses[instr->operands[i].tempId()];
-            mul_neg_lo = mul_instr->valu().neg;
-            mul_neg_hi = mul_instr->valu().neg;
-            if (mul_instr->isSDWA()) {
-               for (unsigned j = 0; j < 2; j++)
-                  mul_opsel_lo[j] = mul_instr->sdwa().sel[j].offset();
-            } else {
-               mul_opsel_lo = mul_instr->valu().opsel;
-            }
-            mul_opsel_hi = mul_opsel_lo;
-         }
-      }
+        if (is_fadd && add_clamp) inf.label |= label_clamp;
+        else                      inf.label &= ~label_clamp;
 
-      if (!mul_instr)
-         return;
+        inf.set_mad(ctx.mad_infos.size() - 1);
+    }
 
-      /* turn mul + packed add into v_pk_fma_f16 */
-      aco_opcode mad = fadd ? aco_opcode::v_pk_fma_f16 : aco_opcode::v_pk_mad_u16;
-      aco_ptr<Instruction> fma{create_instruction(mad, Format::VOP3P, 3, 1)};
-      fma->operands[0] = copy_operand(ctx, mul_instr->operands[0]);
-      fma->operands[1] = copy_operand(ctx, mul_instr->operands[1]);
-      fma->operands[2] = instr->operands[add_op_idx];
-      fma->valu().clamp = vop3p->clamp;
-      fma->valu().neg_lo = mul_neg_lo;
-      fma->valu().neg_hi = mul_neg_hi;
-      fma->valu().opsel_lo = mul_opsel_lo;
-      fma->valu().opsel_hi = mul_opsel_hi;
-      propagate_swizzles(&fma->valu(), vop3p->opsel_lo[1 - add_op_idx],
-                         vop3p->opsel_hi[1 - add_op_idx]);
-      fma->valu().opsel_lo[2] = vop3p->opsel_lo[add_op_idx];
-      fma->valu().opsel_hi[2] = vop3p->opsel_hi[add_op_idx];
-      fma->valu().neg_lo[2] = vop3p->neg_lo[add_op_idx];
-      fma->valu().neg_hi[2] = vop3p->neg_hi[add_op_idx];
-      fma->valu().neg_lo[1] = fma->valu().neg_lo[1] ^ vop3p->neg_lo[1 - add_op_idx];
-      fma->valu().neg_hi[1] = fma->valu().neg_hi[1] ^ vop3p->neg_hi[1 - add_op_idx];
-      fma->definitions[0] = instr->definitions[0];
-      fma->pass_flags = instr->pass_flags;
-      instr = std::move(fma);
-      ctx.info[instr->definitions[0].tempId()].parent_instr = instr.get();
-      decrease_uses(ctx, mul_instr);
-      return;
-   }
+    /* use-count bookkeeping -------------------------------------------- */
+    decrease_uses(ctx, best_mul);
 }
 
 bool
@@ -4035,14 +4519,17 @@ combine_instruction(opt_ctx& ctx, aco_pt
             return;
          }
       }
-   } else if (instr->opcode == aco_opcode::v_or_b32 && ctx.program->gfx_level >= GFX9) {
-      if (combine_three_valu_op(ctx, instr, aco_opcode::s_or_b32, aco_opcode::v_or3_b32, "012",
-                                1 | 2)) {
+    } else if (instr->opcode == aco_opcode::v_or_b32 && ctx.program->gfx_level >= GFX9) {
+      if (combine_three_valu_op(ctx, instr, aco_opcode::s_or_b32, aco_opcode::v_or3_b32, "012", 1 | 2)) {
       } else if (combine_three_valu_op(ctx, instr, aco_opcode::v_or_b32, aco_opcode::v_or3_b32,
-                                       "012", 1 | 2)) {
+                        "012", 1 | 2)) {
       } else if (combine_add_or_then_and_lshl(ctx, instr)) {
       } else if (combine_v_andor_not(ctx, instr)) {
-      }
+      } else if (combine_alignbit_b32(ctx, instr)) {
+      } else if (combine_alignbyte_b32(ctx, instr)) {
+      } else if (combine_bfi_b32(ctx, instr)) {
+      } else if (combine_bfe_b32(ctx, instr)) {
+    }
    } else if (instr->opcode == aco_opcode::v_xor_b32 && ctx.program->gfx_level >= GFX10) {
       if (combine_three_valu_op(ctx, instr, aco_opcode::v_xor_b32, aco_opcode::v_xor3_b32, "012",
                                 1 | 2)) {
@@ -4081,6 +4568,8 @@ combine_instruction(opt_ctx& ctx, aco_pt
          } else if (combine_add_or_then_and_lshl(ctx, instr)) {
          }
       }
+      if (!combine_bcnt_mbcnt(ctx, instr))
+          combine_sad_u8(ctx, instr);
    } else if ((instr->opcode == aco_opcode::v_add_co_u32 ||
                instr->opcode == aco_opcode::v_add_co_u32_e64) &&
               !instr->usesModifiers()) {
@@ -4120,6 +4609,8 @@ combine_instruction(opt_ctx& ctx, aco_pt
       combine_sabsdiff(ctx, instr);
    } else if (instr->opcode == aco_opcode::v_and_b32) {
       combine_v_andor_not(ctx, instr);
+      if (!combine_bfe_b32(ctx, instr)) {
+      }
    } else if (instr->opcode == aco_opcode::v_fma_f32 || instr->opcode == aco_opcode::v_fma_f16) {
       /* set existing v_fma_f32 with label_mad so we can create v_fmamk_f32/v_fmaak_f32.
        * since ctx.uses[mad_info::mul_temp_id] is always 0, we don't have to worry about
