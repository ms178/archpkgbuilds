From 959464c169c8d81e23f588b981bf841b2d0830cc Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Iv=C3=A1n=20Briano?= <ivan.briano@intel.com>
Date: Fri, 15 Sep 2023 14:34:31 -0700
Subject: [PATCH 1/5] vulkan/runtime: add internal parameter to vk_spirv_to_nir

If used to compile internal shaders, it will lack the flag while running
through all the optimization passes it does.
---
 src/intel/vulkan/anv_internal_kernels.c | 5 ++---
 src/vulkan/runtime/vk_nir.c             | 3 +++
 src/vulkan/runtime/vk_nir.h             | 1 +
 src/vulkan/runtime/vk_pipeline.c        | 4 +++-
 4 files changed, 9 insertions(+), 4 deletions(-)

diff --git a/src/intel/vulkan/anv_internal_kernels.c b/src/intel/vulkan/anv_internal_kernels.c
index 343f6bcd7ff4f..19b7071f0c574 100644
--- a/src/intel/vulkan/anv_internal_kernels.c
+++ b/src/intel/vulkan/anv_internal_kernels.c
@@ -164,12 +164,11 @@ compile_upload_spirv(struct anv_device *device,
    nir_shader* nir =
       vk_spirv_to_nir(&device->vk, spirv_source, spirv_source_size * 4,
                       stage, "main", 0, NULL, &spirv_options,
-                      nir_options, NULL);
+                      nir_options, true /* internal */,
+                      NULL);
 
    assert(nir != NULL);
 
-   nir->info.internal = true;
-
    NIR_PASS_V(nir, nir_lower_vars_to_ssa);
    NIR_PASS_V(nir, nir_opt_cse);
    NIR_PASS_V(nir, nir_opt_gcm, true);
diff --git a/src/vulkan/runtime/vk_nir.c b/src/vulkan/runtime/vk_nir.c
index 7d48dc70f1ff7..c36d38b9634c7 100644
--- a/src/vulkan/runtime/vk_nir.c
+++ b/src/vulkan/runtime/vk_nir.c
@@ -120,6 +120,7 @@ vk_spirv_to_nir(struct vk_device *device,
                 const VkSpecializationInfo *spec_info,
                 const struct spirv_to_nir_options *spirv_options,
                 const struct nir_shader_compiler_options *nir_options,
+                bool internal,
                 void *mem_ctx)
 {
    assert(spirv_size_B >= 4 && spirv_size_B % 4 == 0);
@@ -149,6 +150,8 @@ vk_spirv_to_nir(struct vk_device *device,
    if (mem_ctx != NULL)
       ralloc_steal(mem_ctx, nir);
 
+   nir->info.internal = internal;
+
    /* We have to lower away local constant initializers right before we
     * inline functions.  That way they get properly initialized at the top
     * of the function and not at the top of its caller.
diff --git a/src/vulkan/runtime/vk_nir.h b/src/vulkan/runtime/vk_nir.h
index 7f8faf68c495d..48b1ba8915e20 100644
--- a/src/vulkan/runtime/vk_nir.h
+++ b/src/vulkan/runtime/vk_nir.h
@@ -47,6 +47,7 @@ vk_spirv_to_nir(struct vk_device *device,
                 const VkSpecializationInfo *spec_info,
                 const struct spirv_to_nir_options *spirv_options,
                 const struct nir_shader_compiler_options *nir_options,
+                bool internal,
                 void *mem_ctx);
 
 #ifdef __cplusplus
diff --git a/src/vulkan/runtime/vk_pipeline.c b/src/vulkan/runtime/vk_pipeline.c
index 9d3d6d4d65452..50a87e13a3c73 100644
--- a/src/vulkan/runtime/vk_pipeline.c
+++ b/src/vulkan/runtime/vk_pipeline.c
@@ -147,7 +147,9 @@ vk_pipeline_shader_stage_to_nir(struct vk_device *device,
    nir_shader *nir = vk_spirv_to_nir(device, spirv_data, spirv_size, stage,
                                      info->pName, subgroup_size,
                                      info->pSpecializationInfo,
-                                     spirv_options, nir_options, mem_ctx);
+                                     spirv_options, nir_options,
+                                     false /* internal */,
+                                     mem_ctx);
    if (nir == NULL)
       return vk_errorf(device, VK_ERROR_UNKNOWN, "spirv_to_nir failed");
 
-- 
GitLab


From 9e72081ba0200c14164fa41b39570106c01debda Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Iv=C3=A1n=20Briano?= <ivan.briano@intel.com>
Date: Thu, 14 Sep 2023 12:15:20 -0700
Subject: [PATCH 2/5] nir/lower_int64: respect rounding mode when casting to
 float
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Appendix A: Vulkan environemtn for SPIR-V says:
  Operations described as “correctly rounded” will return the infinitely
  precise result, x, rounded so as to be representable in
  floating-point. The rounding mode is not specified, unless the entry
  point is declared with the RoundingModeRTE or the RoundingModeRTZ
  Execution Mode.

Conversion between types are classified as correctly rounded, so let's
do rounding correctly.

Fixes upcoming Vulkan CTS tests:
dEQP-VK.spirv_assembly.instruction.compute.float_controls.fp32.input_args.rounding_rtz_conv_from_uint64_up
dEQP-VK.spirv_assembly.instruction.compute.float_controls.fp32.input_args.rounding_rtz_conv_from_int64_up
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp32.input_args.rounding_rtz_conv_from_uint64_up_vert
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp32.input_args.rounding_rtz_conv_from_int64_up_vert
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp32.input_args.rounding_rtz_conv_from_uint64_up_frag
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp32.input_args.rounding_rtz_conv_from_int64_up_frag
---
 src/compiler/nir/nir_lower_int64.c | 12 +++++++-----
 1 file changed, 7 insertions(+), 5 deletions(-)

diff --git a/src/compiler/nir/nir_lower_int64.c b/src/compiler/nir/nir_lower_int64.c
index 29c4060bc6f55..9ee7c221c7a11 100644
--- a/src/compiler/nir/nir_lower_int64.c
+++ b/src/compiler/nir/nir_lower_int64.c
@@ -772,11 +772,13 @@ lower_2f(nir_builder *b, nir_def *x, unsigned dest_bit_size,
                                     COND_LOWER_OP(b, iand, x, lsb_mask));
    nir_def *round_up = nir_ior(b, COND_LOWER_CMP(b, ilt, half, rem),
                                nir_iand(b, halfway, is_odd));
-   if (significand_bits >= 32)
-      significand = COND_LOWER_OP(b, iadd, significand,
-                                  COND_LOWER_CAST(b, b2i64, round_up));
-   else
-      significand = nir_iadd(b, significand, nir_b2i32(b, round_up));
+   if (!nir_has_any_rounding_mode_rtz(b->shader->info.float_controls_execution_mode)) {
+      if (significand_bits >= 32)
+         significand = COND_LOWER_OP(b, iadd, significand,
+                                     COND_LOWER_CAST(b, b2i64, round_up));
+      else
+         significand = nir_iadd(b, significand, nir_b2i32(b, round_up));
+   }
 
    nir_def *res;
 
-- 
GitLab


From 1eca38c8fa4aa5f6770d722216265efd9d4eae50 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Iv=C3=A1n=20Briano?= <ivan.briano@intel.com>
Date: Thu, 14 Sep 2023 18:09:07 -0700
Subject: [PATCH 3/5] intel/compiler: round f2f16 correctly for RTNE case

v2: bcsel -> b2i32 (Ian)

Fixes upcoming Vulkan CTS tests:
dEQP-VK.spirv_assembly.instruction.compute.float_controls.fp16.input_args.rounding_rte_conv_from_fp64_up
dEQP-VK.spirv_assembly.instruction.compute.float_controls.fp16.input_args.rounding_rte_conv_from_fp64_up_nostorage
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp16.input_args.rounding_rte_conv_from_fp64_up_vert
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp16.input_args.rounding_rte_conv_from_fp64_up_nostorage_vert
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp16.input_args.rounding_rte_conv_from_fp64_up_frag
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp16.input_args.rounding_rte_conv_from_fp64_up_nostorage_frag
---
 src/intel/compiler/brw_nir.c                  |  6 +-
 .../compiler/brw_nir_lower_conversions.c      | 60 ++++++++++++++++++-
 2 files changed, 62 insertions(+), 4 deletions(-)

diff --git a/src/intel/compiler/brw_nir.c b/src/intel/compiler/brw_nir.c
index 1f58b061e62e4..329bc7c09cc4c 100644
--- a/src/intel/compiler/brw_nir.c
+++ b/src/intel/compiler/brw_nir.c
@@ -1657,7 +1657,11 @@ brw_postprocess_nir(nir_shader *nir, const struct brw_compiler *compiler,
    } while (progress);
 
 
-   OPT(brw_nir_lower_conversions);
+   if (OPT(brw_nir_lower_conversions)) {
+      if (OPT(nir_lower_int64)) {
+         brw_nir_optimize(nir, compiler);
+      }
+   }
 
    if (is_scalar)
       OPT(nir_lower_alu_to_scalar, NULL, NULL);
diff --git a/src/intel/compiler/brw_nir_lower_conversions.c b/src/intel/compiler/brw_nir_lower_conversions.c
index 329aa9d9b74bf..68428ab0654d0 100644
--- a/src/intel/compiler/brw_nir_lower_conversions.c
+++ b/src/intel/compiler/brw_nir_lower_conversions.c
@@ -25,7 +25,8 @@
 #include "compiler/nir/nir_builder.h"
 
 static nir_rounding_mode
-get_opcode_rounding_mode(nir_op op)
+get_opcode_rounding_mode(nir_op op, nir_alu_type dst_type,
+                         unsigned execution_mode)
 {
    switch (op) {
    case nir_op_f2f16_rtz:
@@ -33,7 +34,8 @@ get_opcode_rounding_mode(nir_op op)
    case nir_op_f2f16_rtne:
       return nir_rounding_mode_rtne;
    default:
-      return nir_rounding_mode_undef;
+      return nir_get_rounding_mode_from_float_controls(execution_mode,
+                                                       dst_type);
    }
 }
 
@@ -45,6 +47,57 @@ split_conversion(nir_builder *b, nir_alu_instr *alu, nir_alu_type src_type,
    b->cursor = nir_before_instr(&alu->instr);
    nir_def *src = nir_ssa_for_alu_src(b, alu, 0);
    nir_def *tmp = nir_type_convert(b, src, src_type, tmp_type, nir_rounding_mode_undef);
+
+   if (dst_type == nir_type_float16 && rnd == nir_rounding_mode_rtne) {
+      /* We round down from double to half float by going through float in
+       * between, but this can give us inaccurate results in some cases. One
+       * such case is 0x40ee6a0000000001, which should round to 0x7b9b, but
+       * going through float first turns into 0x7b9a instead. This is because
+       * the first non-fitting bit is set, so we get a tie, but with the least
+       * significant bit of the original number set, the tie should break
+       * rounding up. The cast to float, however, turns into 0x47735000, which
+       * when going to half still ties, but now we lost the tie-up bit, and
+       * instead we round to the nearest even, which in this case is down.
+       *
+       * To fix this, we check if the original would have tied, and if the tie
+       * would have rounded up, and if both are true, set the least
+       * significant bit of the intermediate float to 1, so that a tie on the
+       * next cast rounds up as well. If the rounding already got rid of the
+       * tie, that set bit will just be truncated anyway and the end result
+       * doesn't change.
+       *
+       * Another failing case is 0x40effdffffffffff. This one doesn't have the
+       * tie from double to half, so it just rounds down to 0x7bff (65504.0),
+       * but going through float first, it turns into 0x477ff000, which does
+       * have the tie bit for half set, and when that one gets rounded it
+       * turns into 0x7c00 (Infinity).
+       * The fix for that one is to make sure the intermediate float does not
+       * have the tie bit set if the original didn't have it.
+       *
+       * For the RTZ case, we don't need to do anything, as the intermediate
+       * float should be ok already.
+       */
+      int significand_bits16 = 10;
+      int significand_bits32 = 23;
+      int significand_bits64 = 52;
+      int f64_to_16_tie_bit = significand_bits64 - significand_bits16 - 1;
+      int f32_to_16_tie_bit = significand_bits32 - significand_bits16 - 1;
+      uint64_t f64_rounds_up_mask = ((1ULL << f64_to_16_tie_bit) - 1);
+
+      nir_def *would_tie = nir_iand_imm(b, src, 1ULL << f64_to_16_tie_bit);
+      nir_def *would_rnd_up = nir_iand_imm(b, src, f64_rounds_up_mask);
+
+      nir_def *tie_up = nir_b2i32(b, nir_ine_imm(b, would_rnd_up, 0));
+
+      nir_def *break_tie = nir_bcsel(b,
+                                     nir_ine_imm(b, would_tie, 0),
+                                     nir_imm_int(b, ~0),
+                                     nir_imm_int(b, ~(1U << f32_to_16_tie_bit)));
+
+      tmp = nir_ior(b, tmp, tie_up);
+      tmp = nir_iand(b, tmp, break_tie);
+   }
+
    nir_def *res = nir_type_convert(b, tmp, tmp_type, dst_type, rnd);
    nir_def_rewrite_uses(&alu->def, res);
    nir_instr_remove(&alu->instr);
@@ -78,7 +131,8 @@ lower_alu_instr(nir_builder *b, nir_alu_instr *alu)
        (src_bit_size == 64 && dst_full_type == nir_type_float16)) {
       split_conversion(b, alu, src_type, nir_type_float | 32,
                        dst_type | dst_bit_size,
-                       get_opcode_rounding_mode(alu->op));
+                       get_opcode_rounding_mode(alu->op, dst_full_type,
+                                                b->shader->info.float_controls_execution_mode));
       return true;
    }
 
-- 
GitLab


From abf40f420bfb11f8c3082e531011ea63dc36d378 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Iv=C3=A1n=20Briano?= <ivan.briano@intel.com>
Date: Mon, 18 Sep 2023 17:27:56 -0700
Subject: [PATCH 4/5] util: add double_to_float16 helpers

We convert from doubles to half by going through float in between, but
as noted in the comment in this commit, that can give wrong results in
some cases.

Add some helpers to ensure correct results based on rounding mode that
will be used in the next commit.

v2: Use fi/di from u_math.h (Ian)
---
 src/util/double.h | 64 +++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 64 insertions(+)

diff --git a/src/util/double.h b/src/util/double.h
index 784aa3076eea0..b5f604b149b37 100644
--- a/src/util/double.h
+++ b/src/util/double.h
@@ -25,6 +25,8 @@
 #ifndef _DOUBLE_H_
 #define _DOUBLE_H_
 
+#include "half_float.h"
+#include "u_math.h"
 
 #ifdef __cplusplus
 extern "C" {
@@ -46,6 +48,68 @@ _mesa_double_to_float_rtne(double val)
    return _mesa_double_to_float(val);
 }
 
+/*
+ * We round down from double to half float by going through float in between,
+ * but this can give us inaccurate results in some cases.
+ * One such case is 0x40ee6a0000000001, which should round to 0x7b9b, but
+ * going through float first turns into 0x7b9a instead. This is because the
+ * first non-fitting bit is set, so we get a tie, but with the least
+ * significant bit of the original number set, the tie should break rounding
+ * up.
+ * The cast to float, however, turns into 0x47735000, which when going to half
+ * still ties, but now we lost the tie-up bit, and instead we round to the
+ * nearest even, which in this case is down.
+ *
+ * To fix this, we check if the original would have tied, and if the tie would
+ * have rounded up, and if both are true, set the least significant bit of the
+ * intermediate float to 1, so that a tie on the next cast rounds up as well.
+ * If the rounding already got rid of the tie, that set bit will just be
+ * truncated anyway and the end result doesn't change.
+ *
+ * Another failing case is 0x40effdffffffffff. This one doesn't have the tie
+ * from double to half, so it just rounds down to 0x7bff (65504.0), but going
+ * through float first, it turns into 0x477ff000, which does have the tie bit
+ * for half set, and when that one gets rounded it turns into 0x7c00
+ * (Infinity).
+ * The fix for that one is to make sure the intermediate float does not have
+ * the tie bit set if the original didn't have it.
+ */
+static inline uint16_t
+_mesa_double_to_float16_rtne(double val)
+{
+   int significand_bits16 = 10;
+   int significand_bits32 = 23;
+   int significand_bits64 = 52;
+   int f64_to_16_tie_bit = significand_bits64 - significand_bits16 - 1;
+   int f32_to_16_tie_bit = significand_bits32 - significand_bits16 - 1;
+   uint64_t f64_rounds_up_mask = ((1ULL << f64_to_16_tie_bit) - 1);
+
+   union di src;
+   union fi dst;
+
+   src.d = val;
+   dst.f = val;
+
+   bool f64_has_tie = (src.ui & (1ULL << f64_to_16_tie_bit)) != 0;
+   bool f64_rounds_up = (src.ui & f64_rounds_up_mask) != 0;
+
+   dst.ui |= (f64_has_tie && f64_rounds_up);
+   if (!f64_has_tie)
+      dst.ui &= ~(1U << f32_to_16_tie_bit);
+
+   return _mesa_float_to_float16_rtne(dst.f);
+}
+
+/*
+ * double -> float -> half with RTZ doesn't have as many complications as
+ * RTNE, but we do need to ensure that the double -> float cast also uses RTZ.
+ */
+static inline uint16_t
+_mesa_double_to_float16_rtz(double val)
+{
+   return _mesa_float_to_float16_rtz(_mesa_double_to_float_rtz(val));
+}
+
 #ifdef __cplusplus
 } /* extern C */
 #endif
-- 
GitLab


From 79695488d63356f867de87791a0a4c88192876f5 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Iv=C3=A1n=20Briano?= <ivan.briano@intel.com>
Date: Mon, 18 Sep 2023 17:39:40 -0700
Subject: [PATCH 5/5] nir: round f2f16{_rtne/_rtz} correctly for constant
 expressions

As noted in the previous commit, the intermediate cast to float from
double can produce wrong results.

Fixes upcoming Vulkan CTS tests:
dEQP-VK.spirv_assembly.instruction.compute.float_controls.fp16.input_args.rounding_rte_sconst_conv_from_fp64_up
dEQP-VK.spirv_assembly.instruction.compute.float_controls.fp16.input_args.rounding_rte_sconst_conv_from_fp64_up_nostorage
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp16.input_args.rounding_rte_sconst_conv_from_fp64_up_vert
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp16.input_args.rounding_rte_sconst_conv_from_fp64_up_nostorage_vert
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp16.input_args.rounding_rte_sconst_conv_from_fp64_up_frag
dEQP-VK.spirv_assembly.instruction.graphics.float_controls.fp16.input_args.rounding_rte_sconst_conv_from_fp64_up_nostorage_frag
---
 src/compiler/nir/nir_opcodes.py | 24 +++++++++++++++++++++---
 1 file changed, 21 insertions(+), 3 deletions(-)

diff --git a/src/compiler/nir/nir_opcodes.py b/src/compiler/nir/nir_opcodes.py
index cef3d2f641762..4e7283dcb25c2 100644
--- a/src/compiler/nir/nir_opcodes.py
+++ b/src/compiler/nir/nir_opcodes.py
@@ -251,7 +251,9 @@ for src_t in [tint, tuint, tfloat, tbool]:
               for rnd_mode in rnd_modes:
                   if rnd_mode == '_rtne':
                       conv_expr = """
-                      if (bit_size > 16) {
+                      if (bit_size > 32) {
+                         dst = _mesa_half_to_float(_mesa_double_to_float16_rtne(src0));
+                      } else if (bit_size > 16) {
                          dst = _mesa_half_to_float(_mesa_float_to_float16_rtne(src0));
                       } else {
                          dst = src0;
@@ -259,14 +261,30 @@ for src_t in [tint, tuint, tfloat, tbool]:
                       """
                   elif rnd_mode == '_rtz':
                       conv_expr = """
-                      if (bit_size > 16) {
+                      if (bit_size > 32) {
+                         dst = _mesa_half_to_float(_mesa_double_to_float16_rtz(src0));
+                      } else if (bit_size > 16) {
                          dst = _mesa_half_to_float(_mesa_float_to_float16_rtz(src0));
                       } else {
                          dst = src0;
                       }
                       """
                   else:
-                      conv_expr = "src0"
+                      conv_expr = """
+                      if (bit_size > 32) {
+                         if (nir_is_rounding_mode_rtz(execution_mode, 16))
+                            dst = _mesa_half_to_float(_mesa_double_to_float16_rtz(src0));
+                         else
+                            dst = _mesa_half_to_float(_mesa_double_to_float16_rtne(src0));
+                      } else if (bit_size > 16) {
+                         if (nir_is_rounding_mode_rtz(execution_mode, 16))
+                            dst = _mesa_half_to_float(_mesa_float_to_float16_rtz(src0));
+                         else
+                            dst = _mesa_half_to_float(_mesa_float_to_float16_rtne(src0));
+                      } else {
+                         dst = src0;
+                      }
+                      """
 
                   unop_numeric_convert("{0}2{1}{2}{3}".format(src_t[0],
                                                               dst_t[0],
-- 
GitLab

