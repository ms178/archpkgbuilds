From c746c0032e4741ec40e51ebedcb225cd78f1e3c7 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 5 Oct 2023 05:31:18 -0400
Subject: [PATCH 1/8] ac/gpu_info: split ib_alignment as ip[type].ib_alignment

No change in behavior. The previous overalignment is preserved.

It sets ib_pad_dw_mask sooner.

Reviewed-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/common/ac_gpu_info.c                  | 45 ++++++++++---------
 src/amd/common/ac_gpu_info.h                  |  2 +-
 .../vulkan/radv_device_generated_commands.c   | 20 +++++----
 src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c |  8 ++--
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.c     | 12 ++---
 .../winsys/radeon/drm/radeon_drm_winsys.c     |  4 +-
 6 files changed, 48 insertions(+), 43 deletions(-)

diff --git a/src/amd/common/ac_gpu_info.c b/src/amd/common/ac_gpu_info.c
index 4706edf7ece6d..60f04922403dc 100644
--- a/src/amd/common/ac_gpu_info.c
+++ b/src/amd/common/ac_gpu_info.c
@@ -647,6 +647,8 @@ bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
       return false;
    }
 
+   unsigned max_ib_alignment = 0;
+
    for (unsigned ip_type = 0; ip_type < AMD_NUM_IP_TYPES; ip_type++) {
       struct drm_amdgpu_info_hw_ip ip_info = {0};
 
@@ -677,10 +679,26 @@ bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
             info->ip[AMD_IP_GFX].ver_minor = info->ip[AMD_IP_COMPUTE].ver_minor = 3;
       }
       info->ip[ip_type].num_queues = util_bitcount(ip_info.available_rings);
-      info->ib_alignment = MAX3(info->ib_alignment, ip_info.ib_start_alignment,
-                                ip_info.ib_size_alignment);
+      info->ip[ip_type].ib_alignment = MAX2(ip_info.ib_start_alignment, ip_info.ib_size_alignment);
+      max_ib_alignment = MAX2(max_ib_alignment, info->ip[ip_type].ib_alignment);
+   }
+
+   /* TODO: Remove this. This hack mimics the previous behavior of global ib_alignment. */
+   for (unsigned ip_type = 0; ip_type < AMD_NUM_IP_TYPES; ip_type++) {
+      info->ip[ip_type].ib_alignment = MAX2(max_ib_alignment, 1024);
    }
 
+   /* This is "align_mask" copied from the kernel, maximums of all IP versions. */
+   info->ib_pad_dw_mask[AMD_IP_GFX] = 0xff;
+   info->ib_pad_dw_mask[AMD_IP_COMPUTE] = 0xff;
+   info->ib_pad_dw_mask[AMD_IP_SDMA] = 0xf;
+   info->ib_pad_dw_mask[AMD_IP_UVD] = 0xf;
+   info->ib_pad_dw_mask[AMD_IP_VCE] = 0x3f;
+   info->ib_pad_dw_mask[AMD_IP_UVD_ENC] = 0x3f;
+   info->ib_pad_dw_mask[AMD_IP_VCN_DEC] = 0xf;
+   info->ib_pad_dw_mask[AMD_IP_VCN_ENC] = 0x3f;
+   info->ib_pad_dw_mask[AMD_IP_VCN_JPEG] = 0xf;
+
    /* Only require gfx or compute. */
    if (!info->ip[AMD_IP_GFX].num_queues && !info->ip[AMD_IP_COMPUTE].num_queues) {
       fprintf(stderr, "amdgpu: failed to find gfx or compute.\n");
@@ -690,12 +708,6 @@ bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
    assert(util_is_power_of_two_or_zero(info->ip[AMD_IP_COMPUTE].num_queues));
    assert(util_is_power_of_two_or_zero(info->ip[AMD_IP_SDMA].num_queues));
 
-   /* The kernel pads gfx and compute IBs to 256 dwords since:
-    *   66f3b2d527154bd258a57c8815004b5964aa1cf5
-    * Do the same.
-    */
-   info->ib_alignment = MAX2(info->ib_alignment, 1024);
-
    r = amdgpu_query_firmware_version(dev, AMDGPU_INFO_FW_GFX_ME, 0, 0, &info->me_fw_version,
                                      &info->me_fw_feature);
    if (r) {
@@ -1132,17 +1144,6 @@ bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
    info->lds_encode_granularity = info->gfx_level >= GFX7 ? 128 * 4 : 64 * 4;
    info->lds_alloc_granularity = info->gfx_level >= GFX10_3 ? 256 * 4 : info->lds_encode_granularity;
 
-   /* This is "align_mask" copied from the kernel, maximums of all IP versions. */
-   info->ib_pad_dw_mask[AMD_IP_GFX] = 0xff;
-   info->ib_pad_dw_mask[AMD_IP_COMPUTE] = 0xff;
-   info->ib_pad_dw_mask[AMD_IP_SDMA] = 0xf;
-   info->ib_pad_dw_mask[AMD_IP_UVD] = 0xf;
-   info->ib_pad_dw_mask[AMD_IP_VCE] = 0x3f;
-   info->ib_pad_dw_mask[AMD_IP_UVD_ENC] = 0x3f;
-   info->ib_pad_dw_mask[AMD_IP_VCN_DEC] = 0xf;
-   info->ib_pad_dw_mask[AMD_IP_VCN_ENC] = 0x3f;
-   info->ib_pad_dw_mask[AMD_IP_VCN_JPEG] = 0xf;
-
    /* The mere presence of CLEAR_STATE in the IB causes random GPU hangs
     * on GFX6. Some CLEAR_STATE cause asic hang on radeon kernel, etc.
     * SPI_VS_OUT_CONFIG. So only enable GFX7 CLEAR_STATE on amdgpu kernel.
@@ -1681,8 +1682,9 @@ void ac_print_gpu_info(const struct radeon_info *info, FILE *f)
 
    for (unsigned i = 0; i < AMD_NUM_IP_TYPES; i++) {
       if (info->ip[i].num_queues) {
-         fprintf(f, "    IP %-7s %2u.%u \tqueues:%u\n", ip_string[i],
-                 info->ip[i].ver_major, info->ip[i].ver_minor, info->ip[i].num_queues);
+         fprintf(f, "    IP %-7s %2u.%u \tqueues:%u (align:%u, pad_dw:0x%x)\n", ip_string[i],
+                 info->ip[i].ver_major, info->ip[i].ver_minor, info->ip[i].num_queues,
+                 info->ip[i].ib_alignment, info->ib_pad_dw_mask[i]);
       }
    }
 
@@ -1756,7 +1758,6 @@ void ac_print_gpu_info(const struct radeon_info *info, FILE *f)
 
    fprintf(f, "CP info:\n");
    fprintf(f, "    gfx_ib_pad_with_type2 = %i\n", info->gfx_ib_pad_with_type2);
-   fprintf(f, "    ib_alignment = %u\n", info->ib_alignment);
    fprintf(f, "    me_fw_version = %i\n", info->me_fw_version);
    fprintf(f, "    me_fw_feature = %i\n", info->me_fw_feature);
    fprintf(f, "    mec_fw_version = %i\n", info->mec_fw_version);
diff --git a/src/amd/common/ac_gpu_info.h b/src/amd/common/ac_gpu_info.h
index 1e9e8717c9f94..384f71c7ccbc1 100644
--- a/src/amd/common/ac_gpu_info.h
+++ b/src/amd/common/ac_gpu_info.h
@@ -26,6 +26,7 @@ struct amd_ip_info {
    uint8_t ver_minor;
    uint8_t ver_rev;
    uint8_t num_queues;
+   uint32_t ib_alignment;
 };
 
 struct radeon_info {
@@ -160,7 +161,6 @@ struct radeon_info {
 
    /* CP info. */
    bool gfx_ib_pad_with_type2;
-   unsigned ib_alignment; /* both start and size alignment */
    uint32_t me_fw_version;
    uint32_t me_fw_feature;
    uint32_t mec_fw_version;
diff --git a/src/amd/vulkan/radv_device_generated_commands.c b/src/amd/vulkan/radv_device_generated_commands.c
index a711f0339e108..6078a9794db6b 100644
--- a/src/amd/vulkan/radv_device_generated_commands.c
+++ b/src/amd/vulkan/radv_device_generated_commands.c
@@ -140,9 +140,9 @@ radv_get_sequence_size(const struct radv_indirect_command_layout *layout, struct
 }
 
 static uint32_t
-radv_align_cmdbuf_size(const struct radv_device *device, uint32_t size)
+radv_align_cmdbuf_size(const struct radv_device *device, uint32_t size, enum amd_ip_type ip_type)
 {
-   const uint32_t ib_alignment = device->physical_device->rad_info.ib_alignment;
+   const uint32_t ib_alignment = device->physical_device->rad_info.ip[ip_type].ib_alignment;
 
    return align(size, ib_alignment);
 }
@@ -150,7 +150,7 @@ radv_align_cmdbuf_size(const struct radv_device *device, uint32_t size)
 static unsigned
 radv_dgc_preamble_cmdbuf_size(const struct radv_device *device)
 {
-   return radv_align_cmdbuf_size(device, 16);
+   return radv_align_cmdbuf_size(device, 16, AMD_IP_GFX);
 }
 
 static bool
@@ -173,7 +173,7 @@ radv_get_indirect_cmdbuf_size(const VkGeneratedCommandsInfoNV *cmd_info)
 
    uint32_t cmd_size, upload_size;
    radv_get_sequence_size(layout, pipeline, &cmd_size, &upload_size);
-   return radv_align_cmdbuf_size(device, cmd_size * cmd_info->sequencesCount);
+   return radv_align_cmdbuf_size(device, cmd_size * cmd_info->sequencesCount, AMD_IP_GFX);
 }
 
 struct radv_dgc_params {
@@ -474,7 +474,7 @@ dgc_cmd_buf_size(nir_builder *b, nir_def *sequence_count, const struct radv_devi
    nir_def *cmd_buf_size = load_param32(b, cmd_buf_size);
    nir_def *cmd_buf_stride = load_param32(b, cmd_buf_stride);
    nir_def *size = nir_imul(b, cmd_buf_stride, sequence_count);
-   unsigned align_mask = radv_align_cmdbuf_size(device, 1) - 1;
+   unsigned align_mask = radv_align_cmdbuf_size(device, 1, AMD_IP_GFX) - 1;
 
    size = nir_iand_imm(b, nir_iadd_imm(b, size, align_mask), ~align_mask);
 
@@ -1367,12 +1367,14 @@ radv_GetGeneratedCommandsMemoryRequirementsNV(VkDevice _device,
    uint32_t cmd_stride, upload_stride;
    radv_get_sequence_size(layout, pipeline, &cmd_stride, &upload_stride);
 
-   VkDeviceSize cmd_buf_size =
-      radv_align_cmdbuf_size(device, cmd_stride * pInfo->maxSequencesCount) + radv_dgc_preamble_cmdbuf_size(device);
+   VkDeviceSize cmd_buf_size = radv_align_cmdbuf_size(device, cmd_stride * pInfo->maxSequencesCount, AMD_IP_GFX) +
+                               radv_dgc_preamble_cmdbuf_size(device);
    VkDeviceSize upload_buf_size = upload_stride * pInfo->maxSequencesCount;
 
    pMemoryRequirements->memoryRequirements.memoryTypeBits = device->physical_device->memory_types_32bit;
-   pMemoryRequirements->memoryRequirements.alignment = device->physical_device->rad_info.ib_alignment;
+   pMemoryRequirements->memoryRequirements.alignment =
+      MAX2(device->physical_device->rad_info.ip[AMD_IP_GFX].ib_alignment,
+           device->physical_device->rad_info.ip[AMD_IP_COMPUTE].ib_alignment);
    pMemoryRequirements->memoryRequirements.size =
       align(cmd_buf_size + upload_buf_size, pMemoryRequirements->memoryRequirements.alignment);
 }
@@ -1506,7 +1508,7 @@ radv_prepare_dgc(struct radv_cmd_buffer *cmd_buffer, const VkGeneratedCommandsIn
    radv_get_sequence_size(layout, pipeline, &cmd_stride, &upload_stride);
 
    unsigned cmd_buf_size =
-      radv_align_cmdbuf_size(cmd_buffer->device, cmd_stride * pGeneratedCommandsInfo->sequencesCount);
+      radv_align_cmdbuf_size(cmd_buffer->device, cmd_stride * pGeneratedCommandsInfo->sequencesCount, AMD_IP_GFX);
 
    uint64_t upload_addr =
       radv_buffer_get_va(prep_buffer->bo) + prep_buffer->offset + pGeneratedCommandsInfo->preprocessOffset;
diff --git a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
index a637ff150678c..e95d5d37a39dd 100644
--- a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
+++ b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
@@ -248,7 +248,7 @@ radv_amdgpu_cs_bo_create(struct radv_amdgpu_cs *cs, uint32_t ib_size)
    const enum radeon_bo_flag flags =
       RADEON_FLAG_CPU_ACCESS | RADEON_FLAG_NO_INTERPROCESS_SHARING | RADEON_FLAG_READ_ONLY | gtt_wc_flag;
 
-   return ws->buffer_create(ws, ib_size, cs->ws->info.ib_alignment, domain, flags, RADV_BO_PRIORITY_CS, 0,
+   return ws->buffer_create(ws, ib_size, cs->ws->info.ip[cs->hw_ip].ib_alignment, domain, flags, RADV_BO_PRIORITY_CS, 0,
                             &cs->ib_buffer);
 }
 
@@ -287,7 +287,7 @@ radv_amdgpu_cs_get_new_ib(struct radeon_cmdbuf *_cs, uint32_t ib_size)
 static unsigned
 radv_amdgpu_cs_get_initial_size(struct radv_amdgpu_winsys *ws, enum amd_ip_type ip_type)
 {
-   const uint32_t ib_alignment = ws->info.ib_alignment;
+   const uint32_t ib_alignment = ws->info.ip[ip_type].ib_alignment;
    assert(util_is_power_of_two_nonzero(ib_alignment));
    return align(20 * 1024 * 4, ib_alignment);
 }
@@ -377,7 +377,7 @@ radv_amdgpu_cs_grow(struct radeon_cmdbuf *_cs, size_t min_size)
       return;
    }
 
-   const uint32_t ib_alignment = cs->ws->info.ib_alignment;
+   const uint32_t ib_alignment = cs->ws->info.ip[cs->hw_ip].ib_alignment;
 
    cs->ws->base.cs_finalize(_cs);
 
@@ -1669,7 +1669,7 @@ radv_amdgpu_cs_submit(struct radv_amdgpu_ctx *ctx, struct radv_amdgpu_cs_request
       chunks[i].chunk_data = (uint64_t)(uintptr_t)&chunk_data[i];
 
       ib = &request->ibs[i];
-      assert(ib->ib_mc_address && ib->ib_mc_address % ctx->ws->info.ib_alignment == 0);
+      assert(ib->ib_mc_address && ib->ib_mc_address % ctx->ws->info.ip[ib->ip_type].ib_alignment == 0);
       assert(ib->size);
 
       chunk_data[i].ib_data._pad = 0;
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
index c70c691843c57..886f3272705f3 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
@@ -951,11 +951,11 @@ static void amdgpu_set_ib_size(struct radeon_cmdbuf *rcs, struct amdgpu_ib *ib)
 }
 
 static void amdgpu_ib_finalize(struct amdgpu_winsys *ws, struct radeon_cmdbuf *rcs,
-                               struct amdgpu_ib *ib)
+                               struct amdgpu_ib *ib, enum amd_ip_type ip_type)
 {
    amdgpu_set_ib_size(rcs, ib);
    ib->used_ib_space += rcs->current.cdw * 4;
-   ib->used_ib_space = align(ib->used_ib_space, ws->info.ib_alignment);
+   ib->used_ib_space = align(ib->used_ib_space, ws->info.ip[ip_type].ib_alignment);
    ib->max_ib_size = MAX2(ib->max_ib_size, rcs->prev_dw + rcs->current.cdw);
 }
 
@@ -1145,12 +1145,12 @@ amdgpu_cs_setup_preemption(struct radeon_cmdbuf *rcs, const uint32_t *preamble_i
    struct amdgpu_cs *cs = amdgpu_cs(rcs);
    struct amdgpu_winsys *ws = cs->ws;
    struct amdgpu_cs_context *csc[2] = {&cs->csc1, &cs->csc2};
-   unsigned size = align(preamble_num_dw * 4, ws->info.ib_alignment);
+   unsigned size = align(preamble_num_dw * 4, ws->info.ip[AMD_IP_GFX].ib_alignment);
    struct pb_buffer *preamble_bo;
    uint32_t *map;
 
    /* Create the preamble IB buffer. */
-   preamble_bo = amdgpu_bo_create(ws, size, ws->info.ib_alignment,
+   preamble_bo = amdgpu_bo_create(ws, size, ws->info.ip[AMD_IP_GFX].ib_alignment,
                                   RADEON_DOMAIN_VRAM,
                                   RADEON_FLAG_NO_INTERPROCESS_SHARING |
                                   RADEON_FLAG_GTT_WC |
@@ -1708,7 +1708,7 @@ static void amdgpu_cs_submit_ib(void *job, void *gdata, int thread_index)
 
    if (noop && acs->ip_type == AMD_IP_GFX) {
       /* Reduce the IB size and fill it with NOP to make it like an empty IB. */
-      unsigned noop_size = MIN2(cs->ib[IB_MAIN].ib_bytes, ws->info.ib_alignment);
+      unsigned noop_size = MIN2(cs->ib[IB_MAIN].ib_bytes, ws->info.ip[AMD_IP_GFX].ib_alignment);
 
       cs->ib_main_addr[0] = PKT3(PKT3_NOP, noop_size / 4 - 2, 0);
       cs->ib[IB_MAIN].ib_bytes = noop_size;
@@ -1862,7 +1862,7 @@ static int amdgpu_cs_flush(struct radeon_cmdbuf *rcs,
       struct amdgpu_cs_context *cur = cs->csc;
 
       /* Set IB sizes. */
-      amdgpu_ib_finalize(ws, rcs, &cs->main);
+      amdgpu_ib_finalize(ws, rcs, &cs->main, cs->ip_type);
 
       /* Create a fence. */
       amdgpu_fence_reference(&cur->fence, NULL);
diff --git a/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c b/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c
index 18eb60b6ac270..ab62362210fe2 100644
--- a/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c
+++ b/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c
@@ -544,6 +544,9 @@ static bool do_winsys_init(struct radeon_drm_winsys *ws)
       }
    }
 
+   for (unsigned ip_type = 0; ip_type < AMD_NUM_IP_TYPES; ip_type++)
+      ws->info.ip[ip_type].ib_alignment = 4096;
+
    /* Hawaii with old firmware needs type2 nop packet.
     * accel_working2 with value 3 indicates the new firmware.
     */
@@ -551,7 +554,6 @@ static bool do_winsys_init(struct radeon_drm_winsys *ws)
                                     (ws->info.family == CHIP_HAWAII &&
                                      ws->accel_working2 < 3);
    ws->info.tcc_cache_line_size = 64; /* TC L2 line size on GCN */
-   ws->info.ib_alignment = 4096;
    ws->info.has_bo_metadata = false;
    ws->info.has_eqaa_surface_allocator = false;
    ws->info.has_sparse_vm_mappings = false;
-- 
GitLab


From 797e426475f983c3ff1c62c6a67f2c65d294f699 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 5 Oct 2023 05:37:44 -0400
Subject: [PATCH 2/8] ac/gpu_info: move ib_pad_dw_mask into ip[]

No change in behavior.

Reviewed-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/common/ac_gpu_info.c                  | 22 +++++++++----------
 src/amd/common/ac_gpu_info.h                  |  2 +-
 src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c |  2 +-
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.c     |  6 ++---
 4 files changed, 16 insertions(+), 16 deletions(-)

diff --git a/src/amd/common/ac_gpu_info.c b/src/amd/common/ac_gpu_info.c
index 60f04922403dc..b1383fd3505c0 100644
--- a/src/amd/common/ac_gpu_info.c
+++ b/src/amd/common/ac_gpu_info.c
@@ -689,15 +689,15 @@ bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
    }
 
    /* This is "align_mask" copied from the kernel, maximums of all IP versions. */
-   info->ib_pad_dw_mask[AMD_IP_GFX] = 0xff;
-   info->ib_pad_dw_mask[AMD_IP_COMPUTE] = 0xff;
-   info->ib_pad_dw_mask[AMD_IP_SDMA] = 0xf;
-   info->ib_pad_dw_mask[AMD_IP_UVD] = 0xf;
-   info->ib_pad_dw_mask[AMD_IP_VCE] = 0x3f;
-   info->ib_pad_dw_mask[AMD_IP_UVD_ENC] = 0x3f;
-   info->ib_pad_dw_mask[AMD_IP_VCN_DEC] = 0xf;
-   info->ib_pad_dw_mask[AMD_IP_VCN_ENC] = 0x3f;
-   info->ib_pad_dw_mask[AMD_IP_VCN_JPEG] = 0xf;
+   info->ip[AMD_IP_GFX].ib_pad_dw_mask = 0xff;
+   info->ip[AMD_IP_COMPUTE].ib_pad_dw_mask = 0xff;
+   info->ip[AMD_IP_SDMA].ib_pad_dw_mask = 0xf;
+   info->ip[AMD_IP_UVD].ib_pad_dw_mask = 0xf;
+   info->ip[AMD_IP_VCE].ib_pad_dw_mask = 0x3f;
+   info->ip[AMD_IP_UVD_ENC].ib_pad_dw_mask = 0x3f;
+   info->ip[AMD_IP_VCN_DEC].ib_pad_dw_mask = 0xf;
+   info->ip[AMD_IP_VCN_ENC].ib_pad_dw_mask = 0x3f;
+   info->ip[AMD_IP_VCN_JPEG].ib_pad_dw_mask = 0xf;
 
    /* Only require gfx or compute. */
    if (!info->ip[AMD_IP_GFX].num_queues && !info->ip[AMD_IP_COMPUTE].num_queues) {
@@ -1682,9 +1682,9 @@ void ac_print_gpu_info(const struct radeon_info *info, FILE *f)
 
    for (unsigned i = 0; i < AMD_NUM_IP_TYPES; i++) {
       if (info->ip[i].num_queues) {
-         fprintf(f, "    IP %-7s %2u.%u \tqueues:%u (align:%u, pad_dw:0x%x)\n", ip_string[i],
+         fprintf(f, "    IP %-7s %2u.%u \tqueues:%u \talign:%u \tpad_dw:0x%x\n", ip_string[i],
                  info->ip[i].ver_major, info->ip[i].ver_minor, info->ip[i].num_queues,
-                 info->ip[i].ib_alignment, info->ib_pad_dw_mask[i]);
+                 info->ip[i].ib_alignment, info->ip[i].ib_pad_dw_mask);
       }
    }
 
diff --git a/src/amd/common/ac_gpu_info.h b/src/amd/common/ac_gpu_info.h
index 384f71c7ccbc1..54ca2a6da9a21 100644
--- a/src/amd/common/ac_gpu_info.h
+++ b/src/amd/common/ac_gpu_info.h
@@ -27,6 +27,7 @@ struct amd_ip_info {
    uint8_t ver_rev;
    uint8_t num_queues;
    uint32_t ib_alignment;
+   uint32_t ib_pad_dw_mask;
 };
 
 struct radeon_info {
@@ -80,7 +81,6 @@ struct radeon_info {
    bool family_overridden; /* AMD_FORCE_FAMILY was used, skip command submission */
    bool is_pro_graphics;
    bool has_graphics; /* false if the chip is compute-only */
-   uint32_t ib_pad_dw_mask[AMD_NUM_IP_TYPES];
    bool has_clear_state;
    bool has_distributed_tess;
    bool has_dcc_constant_encode;
diff --git a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
index e95d5d37a39dd..9ecc7d4f01d6e 100644
--- a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
+++ b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
@@ -429,7 +429,7 @@ radv_amdgpu_cs_finalize(struct radeon_cmdbuf *_cs)
 
    assert(cs->base.cdw <= cs->base.reserved_dw);
 
-   uint32_t ib_pad_dw_mask = MAX2(3, cs->ws->info.ib_pad_dw_mask[ip_type]);
+   uint32_t ib_pad_dw_mask = MAX2(3, cs->ws->info.ip[ip_type].ib_pad_dw_mask);
    uint32_t nop_packet = get_nop_packet(cs);
 
    if (cs->use_ib) {
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
index 886f3272705f3..459a93bea1c83 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
@@ -1169,7 +1169,7 @@ amdgpu_cs_setup_preemption(struct radeon_cmdbuf *rcs, const uint32_t *preamble_i
    memcpy(map, preamble_ib, preamble_num_dw * 4);
 
    /* Pad the IB. */
-   uint32_t ib_pad_dw_mask = ws->info.ib_pad_dw_mask[cs->ip_type];
+   uint32_t ib_pad_dw_mask = ws->info.ip[cs->ip_type].ib_pad_dw_mask;
    while (preamble_num_dw & ib_pad_dw_mask)
       map[preamble_num_dw++] = PKT3_NOP_PAD;
    amdgpu_bo_unmap(&ws->dummy_ws.base, preamble_bo);
@@ -1245,7 +1245,7 @@ static bool amdgpu_cs_check_space(struct radeon_cmdbuf *rcs, unsigned dw)
    rcs->current.max_dw += cs_epilog_dw;
 
    /* Pad with NOPs but leave 4 dwords for INDIRECT_BUFFER. */
-   uint32_t ib_pad_dw_mask = cs->ws->info.ib_pad_dw_mask[cs->ip_type];
+   uint32_t ib_pad_dw_mask = cs->ws->info.ip[cs->ip_type].ib_pad_dw_mask;
    while ((rcs->current.cdw & ib_pad_dw_mask) != ib_pad_dw_mask - 3)
       radeon_emit(rcs, PKT3_NOP_PAD);
 
@@ -1803,7 +1803,7 @@ static int amdgpu_cs_flush(struct radeon_cmdbuf *rcs,
    struct amdgpu_cs *cs = amdgpu_cs(rcs);
    struct amdgpu_winsys *ws = cs->ws;
    int error_code = 0;
-   uint32_t ib_pad_dw_mask = ws->info.ib_pad_dw_mask[cs->ip_type];
+   uint32_t ib_pad_dw_mask = ws->info.ip[cs->ip_type].ib_pad_dw_mask;
 
    rcs->current.max_dw += amdgpu_cs_epilog_dws(cs);
 
-- 
GitLab


From 6c593e6bb0d3d1437df728b94b1693b5de1899ce Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 5 Oct 2023 06:06:15 -0400
Subject: [PATCH 3/8] ac/gpu_info: drop the hack unifying all IB alignments

We overalign it anyway, so there is no change in behavior.

Reviewed-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/common/ac_gpu_info.c | 11 ++---------
 1 file changed, 2 insertions(+), 9 deletions(-)

diff --git a/src/amd/common/ac_gpu_info.c b/src/amd/common/ac_gpu_info.c
index b1383fd3505c0..310df8145cd6f 100644
--- a/src/amd/common/ac_gpu_info.c
+++ b/src/amd/common/ac_gpu_info.c
@@ -647,8 +647,6 @@ bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
       return false;
    }
 
-   unsigned max_ib_alignment = 0;
-
    for (unsigned ip_type = 0; ip_type < AMD_NUM_IP_TYPES; ip_type++) {
       struct drm_amdgpu_info_hw_ip ip_info = {0};
 
@@ -679,13 +677,8 @@ bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
             info->ip[AMD_IP_GFX].ver_minor = info->ip[AMD_IP_COMPUTE].ver_minor = 3;
       }
       info->ip[ip_type].num_queues = util_bitcount(ip_info.available_rings);
-      info->ip[ip_type].ib_alignment = MAX2(ip_info.ib_start_alignment, ip_info.ib_size_alignment);
-      max_ib_alignment = MAX2(max_ib_alignment, info->ip[ip_type].ib_alignment);
-   }
-
-   /* TODO: Remove this. This hack mimics the previous behavior of global ib_alignment. */
-   for (unsigned ip_type = 0; ip_type < AMD_NUM_IP_TYPES; ip_type++) {
-      info->ip[ip_type].ib_alignment = MAX2(max_ib_alignment, 1024);
+      info->ip[ip_type].ib_alignment = MAX3(ip_info.ib_start_alignment,
+                                            ip_info.ib_size_alignment, 1024);
    }
 
    /* This is "align_mask" copied from the kernel, maximums of all IP versions. */
-- 
GitLab


From e576d520bb968739947b7e5342c64ee9997b969d Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 5 Oct 2023 06:07:32 -0400
Subject: [PATCH 4/8] ac/gpu_info: conservatively decrease IB alignment and
 padding to 256B

This should be large enough for all engines.

Reviewed-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/common/ac_gpu_info.c | 14 ++++++++++----
 1 file changed, 10 insertions(+), 4 deletions(-)

diff --git a/src/amd/common/ac_gpu_info.c b/src/amd/common/ac_gpu_info.c
index 310df8145cd6f..0d12d28ea3fec 100644
--- a/src/amd/common/ac_gpu_info.c
+++ b/src/amd/common/ac_gpu_info.c
@@ -677,13 +677,19 @@ bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
             info->ip[AMD_IP_GFX].ver_minor = info->ip[AMD_IP_COMPUTE].ver_minor = 3;
       }
       info->ip[ip_type].num_queues = util_bitcount(ip_info.available_rings);
+
+      /* According to the kernel, only SDMA and VPE require 256B alignment, but use it
+       * for all queues because the kernel reports wrong limits for some of the queues.
+       * This is only space allocation alignment, so it's OK to keep it like this even
+       * when it's greater than what the queues require.
+       */
       info->ip[ip_type].ib_alignment = MAX3(ip_info.ib_start_alignment,
-                                            ip_info.ib_size_alignment, 1024);
+                                            ip_info.ib_size_alignment, 256);
    }
 
-   /* This is "align_mask" copied from the kernel, maximums of all IP versions. */
-   info->ip[AMD_IP_GFX].ib_pad_dw_mask = 0xff;
-   info->ip[AMD_IP_COMPUTE].ib_pad_dw_mask = 0xff;
+   /* Set dword padding minus 1. */
+   info->ip[AMD_IP_GFX].ib_pad_dw_mask = 0x3f;
+   info->ip[AMD_IP_COMPUTE].ib_pad_dw_mask = 0x3f;
    info->ip[AMD_IP_SDMA].ib_pad_dw_mask = 0xf;
    info->ip[AMD_IP_UVD].ib_pad_dw_mask = 0xf;
    info->ip[AMD_IP_VCE].ib_pad_dw_mask = 0x3f;
-- 
GitLab


From 101ac3b1405da64bfa65d01bb9a175b433099afe Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 5 Oct 2023 06:37:22 -0400
Subject: [PATCH 5/8] ac/gpu_info: set gfx and compute IB padding to only 8
 dwords

This is what the kernel reports and what PAL seems to be doing.

Reviewed-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/common/ac_gpu_info.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/src/amd/common/ac_gpu_info.c b/src/amd/common/ac_gpu_info.c
index 0d12d28ea3fec..8029cfa71b20d 100644
--- a/src/amd/common/ac_gpu_info.c
+++ b/src/amd/common/ac_gpu_info.c
@@ -688,8 +688,8 @@ bool ac_query_gpu_info(int fd, void *dev_p, struct radeon_info *info,
    }
 
    /* Set dword padding minus 1. */
-   info->ip[AMD_IP_GFX].ib_pad_dw_mask = 0x3f;
-   info->ip[AMD_IP_COMPUTE].ib_pad_dw_mask = 0x3f;
+   info->ip[AMD_IP_GFX].ib_pad_dw_mask = 0x7;
+   info->ip[AMD_IP_COMPUTE].ib_pad_dw_mask = 0x7;
    info->ip[AMD_IP_SDMA].ib_pad_dw_mask = 0xf;
    info->ip[AMD_IP_UVD].ib_pad_dw_mask = 0xf;
    info->ip[AMD_IP_VCE].ib_pad_dw_mask = 0x3f;
-- 
GitLab


From 85864ab74f582b3f76903b098ea775ea8b9b8d7e Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 5 Oct 2023 06:43:43 -0400
Subject: [PATCH 6/8] winsys/amdgpu: properly pad the IB in
 amdgpu_submit_gfx_nop

---
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.c | 20 ++++++++++----------
 1 file changed, 10 insertions(+), 10 deletions(-)

diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
index 459a93bea1c83..ef63f04cf9b2d 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
@@ -328,7 +328,7 @@ static void amdgpu_ctx_destroy(struct radeon_winsys_ctx *rwctx)
    amdgpu_ctx_unref((struct amdgpu_ctx*)rwctx);
 }
 
-static int amdgpu_submit_gfx_nop(amdgpu_device_handle dev)
+static int amdgpu_submit_gfx_nop(struct amdgpu_ctx *ctx)
 {
    struct amdgpu_bo_alloc_request request = {0};
    struct drm_amdgpu_bo_list_in bo_list_in;
@@ -346,24 +346,24 @@ static int amdgpu_submit_gfx_nop(amdgpu_device_handle dev)
     * that the reset is not complete.
     */
    amdgpu_context_handle temp_ctx;
-   r = amdgpu_cs_ctx_create2(dev, AMDGPU_CTX_PRIORITY_NORMAL, &temp_ctx);
+   r = amdgpu_cs_ctx_create2(ctx->ws->dev, AMDGPU_CTX_PRIORITY_NORMAL, &temp_ctx);
    if (r)
       return r;
 
    request.preferred_heap = AMDGPU_GEM_DOMAIN_VRAM;
    request.alloc_size = 4096;
    request.phys_alignment = 4096;
-   r = amdgpu_bo_alloc(dev, &request, &buf_handle);
+   r = amdgpu_bo_alloc(ctx->ws->dev, &request, &buf_handle);
    if (r)
       goto destroy_ctx;
 
-   r = amdgpu_va_range_alloc(dev, amdgpu_gpu_va_range_general,
+   r = amdgpu_va_range_alloc(ctx->ws->dev, amdgpu_gpu_va_range_general,
                  request.alloc_size, request.phys_alignment,
                  0, &va, &va_handle,
                  AMDGPU_VA_RANGE_32_BIT | AMDGPU_VA_RANGE_HIGH);
    if (r)
       goto destroy_bo;
-   r = amdgpu_bo_va_op_raw(dev, buf_handle, 0, request.alloc_size, va,
+   r = amdgpu_bo_va_op_raw(ctx->ws->dev, buf_handle, 0, request.alloc_size, va,
                            AMDGPU_VM_PAGE_READABLE | AMDGPU_VM_PAGE_WRITEABLE | AMDGPU_VM_PAGE_EXECUTABLE,
                            AMDGPU_VA_OP_MAP);
    if (r)
@@ -373,8 +373,8 @@ static int amdgpu_submit_gfx_nop(amdgpu_device_handle dev)
    if (r)
       goto destroy_bo;
 
-   /* Use a single NOP. */
-   ((uint32_t*)cpu)[0] = PKT3_NOP_PAD;
+   unsigned noop_dw_size = ctx->ws->info.ip[AMD_IP_GFX].ib_pad_dw_mask + 1;
+   ((uint32_t*)cpu)[0] = PKT3(PKT3_NOP, noop_dw_size - 2, 0);
 
    amdgpu_bo_cpu_unmap(buf_handle);
 
@@ -388,7 +388,7 @@ static int amdgpu_submit_gfx_nop(amdgpu_device_handle dev)
    bo_list_in.bo_info_ptr = (uint64_t)(uintptr_t)&list;
 
    ib_in.ip_type = AMD_IP_GFX;
-   ib_in.ib_bytes = 4;
+   ib_in.ib_bytes = noop_dw_size * 4;
    ib_in.va_start = va;
 
    chunks[0].chunk_id = AMDGPU_CHUNK_ID_BO_HANDLES;
@@ -399,7 +399,7 @@ static int amdgpu_submit_gfx_nop(amdgpu_device_handle dev)
    chunks[1].length_dw = sizeof(struct drm_amdgpu_cs_chunk_ib) / 4;
    chunks[1].chunk_data = (uintptr_t)&ib_in;
 
-   r = amdgpu_cs_submit_raw2(dev, temp_ctx, 0, 2, chunks, &seq_no);
+   r = amdgpu_cs_submit_raw2(ctx->ws->dev, temp_ctx, 0, 2, chunks, &seq_no);
 
 destroy_bo:
    if (va_handle)
@@ -484,7 +484,7 @@ amdgpu_ctx_query_reset_status(struct radeon_winsys_ctx *rwctx, bool full_reset_o
                *reset_completed = true;
 
             if (ctx->ws->info.drm_minor < 54 && ctx->ws->info.has_graphics)
-               *reset_completed = amdgpu_submit_gfx_nop(ctx->ws->dev) == 0;
+               *reset_completed = amdgpu_submit_gfx_nop(ctx) == 0;
          }
 
          if (needs_reset)
-- 
GitLab


From 4c006860927f330afe4330957b6e22023b951dbd Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 5 Oct 2023 08:46:56 -0400
Subject: [PATCH 7/8] winsys/amdgpu: correctly pad noop IBs for RADEON_NOOP=1

We need to use ib_pad_dw_mask, not ib_alignment.
---
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.c | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
index ef63f04cf9b2d..b963a56bf0415 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
@@ -1708,10 +1708,11 @@ static void amdgpu_cs_submit_ib(void *job, void *gdata, int thread_index)
 
    if (noop && acs->ip_type == AMD_IP_GFX) {
       /* Reduce the IB size and fill it with NOP to make it like an empty IB. */
-      unsigned noop_size = MIN2(cs->ib[IB_MAIN].ib_bytes, ws->info.ip[AMD_IP_GFX].ib_alignment);
+      unsigned noop_dw_size = ws->info.ip[AMD_IP_GFX].ib_pad_dw_mask + 1;
+      assert(cs->ib[IB_MAIN].ib_bytes / 4 >= noop_dw_size);
 
-      cs->ib_main_addr[0] = PKT3(PKT3_NOP, noop_size / 4 - 2, 0);
-      cs->ib[IB_MAIN].ib_bytes = noop_size;
+      cs->ib_main_addr[0] = PKT3(PKT3_NOP, noop_dw_size - 2, 0);
+      cs->ib[IB_MAIN].ib_bytes = noop_dw_size * 4;
       noop = false;
    }
 
-- 
GitLab


From 1ee6335014f0fc2bef0611a1224c55d2ac14d510 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 5 Oct 2023 06:50:29 -0400
Subject: [PATCH 8/8] winsys/amdgpu: pad gfx and compute IBs with only 1 NOP

---
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.c | 44 +++++++++++++++--------
 1 file changed, 29 insertions(+), 15 deletions(-)

diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
index b963a56bf0415..fc7e3aa0e7246 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
@@ -328,6 +328,31 @@ static void amdgpu_ctx_destroy(struct radeon_winsys_ctx *rwctx)
    amdgpu_ctx_unref((struct amdgpu_ctx*)rwctx);
 }
 
+static void amdgpu_pad_gfx_compute_ib(struct amdgpu_winsys *ws, enum amd_ip_type ip_type,
+                                      uint32_t *ib, uint32_t *num_dw, unsigned leave_dw_space)
+{
+   unsigned pad_dw_mask = ws->info.ip[ip_type].ib_pad_dw_mask;
+   unsigned unaligned_dw = (*num_dw + leave_dw_space) & pad_dw_mask;
+
+   if (unaligned_dw) {
+      int remaining = pad_dw_mask + 1 - unaligned_dw;
+
+      /* Only pad by 1 dword with the type-2 NOP if necessary. */
+      if (remaining == 1 && ws->info.gfx_ib_pad_with_type2) {
+         ib[(*num_dw)++] = PKT2_NOP_PAD;
+      } else {
+         /* Pad with a single NOP packet to minimize CP overhead because NOP is a variable-sized
+          * packet. The size of the packet body after the header is always count + 1.
+          * If count == -1, there is no packet body. NOP is the only packet that can have
+          * count == -1, which is the definition of PKT3_NOP_PAD (count == 0x3fff means -1).
+          */
+         ib[(*num_dw)++] = PKT3(PKT3_NOP, remaining - 2, 0);
+         *num_dw += remaining - 1;
+      }
+   }
+   assert(((*num_dw + leave_dw_space) & pad_dw_mask) == 0);
+}
+
 static int amdgpu_submit_gfx_nop(struct amdgpu_ctx *ctx)
 {
    struct amdgpu_bo_alloc_request request = {0};
@@ -1169,9 +1194,7 @@ amdgpu_cs_setup_preemption(struct radeon_cmdbuf *rcs, const uint32_t *preamble_i
    memcpy(map, preamble_ib, preamble_num_dw * 4);
 
    /* Pad the IB. */
-   uint32_t ib_pad_dw_mask = ws->info.ip[cs->ip_type].ib_pad_dw_mask;
-   while (preamble_num_dw & ib_pad_dw_mask)
-      map[preamble_num_dw++] = PKT3_NOP_PAD;
+   amdgpu_pad_gfx_compute_ib(ws, cs->ip_type, map, &preamble_num_dw, 0);
    amdgpu_bo_unmap(&ws->dummy_ws.base, preamble_bo);
 
    for (unsigned i = 0; i < 2; i++) {
@@ -1245,17 +1268,14 @@ static bool amdgpu_cs_check_space(struct radeon_cmdbuf *rcs, unsigned dw)
    rcs->current.max_dw += cs_epilog_dw;
 
    /* Pad with NOPs but leave 4 dwords for INDIRECT_BUFFER. */
-   uint32_t ib_pad_dw_mask = cs->ws->info.ip[cs->ip_type].ib_pad_dw_mask;
-   while ((rcs->current.cdw & ib_pad_dw_mask) != ib_pad_dw_mask - 3)
-      radeon_emit(rcs, PKT3_NOP_PAD);
+   amdgpu_pad_gfx_compute_ib(cs->ws, cs->ip_type, rcs->current.buf, &rcs->current.cdw, 4);
 
    radeon_emit(rcs, PKT3(PKT3_INDIRECT_BUFFER, 2, 0));
    radeon_emit(rcs, va);
    radeon_emit(rcs, va >> 32);
    uint32_t *new_ptr_ib_size = &rcs->current.buf[rcs->current.cdw++];
-   assert((rcs->current.cdw & ib_pad_dw_mask) == 0);
 
-   assert((rcs->current.cdw & 7) == 0);
+   assert((rcs->current.cdw & cs->ws->info.ip[cs->ip_type].ib_pad_dw_mask) == 0);
    assert(rcs->current.cdw <= rcs->current.max_dw);
 
    amdgpu_set_ib_size(rcs, ib);
@@ -1821,13 +1841,7 @@ static int amdgpu_cs_flush(struct radeon_cmdbuf *rcs,
       break;
    case AMD_IP_GFX:
    case AMD_IP_COMPUTE:
-      if (ws->info.gfx_ib_pad_with_type2) {
-         while (rcs->current.cdw & ib_pad_dw_mask)
-            radeon_emit(rcs, PKT2_NOP_PAD);
-      } else {
-         while (rcs->current.cdw & ib_pad_dw_mask)
-            radeon_emit(rcs, PKT3_NOP_PAD);
-      }
+      amdgpu_pad_gfx_compute_ib(ws, cs->ip_type, rcs->current.buf, &rcs->current.cdw, 0);
       if (cs->ip_type == AMD_IP_GFX)
          ws->gfx_ib_size_counter += (rcs->prev_dw + rcs->current.cdw) * 4;
       break;
-- 
GitLab

