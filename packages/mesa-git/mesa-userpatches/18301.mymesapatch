From c7ecf4ba1d2f7d10e63da93600876983301824e5 Mon Sep 17 00:00:00 2001
From: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Date: Tue, 20 Sep 2022 23:55:53 +0530
Subject: [PATCH 1/8] ac,radeonsi: move shadow regs create ib preamble function
 to amd common
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

The si_create_shadowing_ib_preamble() function can be reused from radv also.
Hence it is moved.

Signed-off-by: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Reviewed-by: Marek Olšák <marek.olsak@amd.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
---
 src/amd/common/ac_shadowed_regs.c             | 144 +++++++++++++++
 src/amd/common/ac_shadowed_regs.h             |   6 +
 .../drivers/radeonsi/si_cp_reg_shadowing.c    | 168 ++----------------
 3 files changed, 163 insertions(+), 155 deletions(-)

diff --git a/src/amd/common/ac_shadowed_regs.c b/src/amd/common/ac_shadowed_regs.c
index b8abcb192321..a02d05cba4ae 100644
--- a/src/amd/common/ac_shadowed_regs.c
+++ b/src/amd/common/ac_shadowed_regs.c
@@ -4128,3 +4128,147 @@ void ac_print_shadowed_regs(const struct radeon_info *info)
       }
    }
 }
+
+static void ac_build_load_reg(const struct radeon_info *info,
+                              pm4_cmd_add_fn pm4_cmd_add, void *pm4_cmdbuf,
+                              enum ac_reg_range_type type,
+                              uint64_t gpu_address)
+{
+   unsigned packet, num_ranges, offset;
+   const struct ac_reg_range *ranges;
+
+   ac_get_reg_ranges(info->gfx_level, info->family,
+                     type, &num_ranges, &ranges);
+
+   switch (type) {
+   case SI_REG_RANGE_UCONFIG:
+      gpu_address += SI_SHADOWED_UCONFIG_REG_OFFSET;
+      offset = CIK_UCONFIG_REG_OFFSET;
+      packet = PKT3_LOAD_UCONFIG_REG;
+      break;
+   case SI_REG_RANGE_CONTEXT:
+      gpu_address += SI_SHADOWED_CONTEXT_REG_OFFSET;
+      offset = SI_CONTEXT_REG_OFFSET;
+      packet = PKT3_LOAD_CONTEXT_REG;
+      break;
+   default:
+      gpu_address += SI_SHADOWED_SH_REG_OFFSET;
+      offset = SI_SH_REG_OFFSET;
+      packet = PKT3_LOAD_SH_REG;
+      break;
+   }
+
+   pm4_cmd_add(pm4_cmdbuf, PKT3(packet, 1 + num_ranges * 2, 0));
+   pm4_cmd_add(pm4_cmdbuf, gpu_address);
+   pm4_cmd_add(pm4_cmdbuf, gpu_address >> 32);
+   for (unsigned i = 0; i < num_ranges; i++) {
+      pm4_cmd_add(pm4_cmdbuf, (ranges[i].offset - offset) / 4);
+      pm4_cmd_add(pm4_cmdbuf, ranges[i].size / 4);
+   }
+}
+
+void ac_create_shadowing_ib_preamble(const struct radeon_info *info,
+                                     pm4_cmd_add_fn pm4_cmd_add, void *pm4_cmdbuf,
+                                     uint64_t gpu_address,
+                                     bool dpbb_allowed)
+{
+   if (dpbb_allowed) {
+      pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_EVENT_WRITE, 0, 0));
+      pm4_cmd_add(pm4_cmdbuf, EVENT_TYPE(V_028A90_BREAK_BATCH) | EVENT_INDEX(0));
+   }
+
+   /* Wait for idle, because we'll update VGT ring pointers. */
+   pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_EVENT_WRITE, 0, 0));
+   pm4_cmd_add(pm4_cmdbuf, EVENT_TYPE(V_028A90_VS_PARTIAL_FLUSH) | EVENT_INDEX(4));
+
+   /* VGT_FLUSH is required even if VGT is idle. It resets VGT pointers. */
+   pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_EVENT_WRITE, 0, 0));
+   pm4_cmd_add(pm4_cmdbuf, EVENT_TYPE(V_028A90_VGT_FLUSH) | EVENT_INDEX(0));
+
+   if (info->gfx_level >= GFX11) {
+      /* We must wait for idle using an EOP event before changing the attribute ring registers.
+       * Use the bottom-of-pipe EOP event, but increment the PWS counter instead of writing memory.
+       */
+      pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_RELEASE_MEM, 6, 0));
+      pm4_cmd_add(pm4_cmdbuf, S_490_EVENT_TYPE(V_028A90_BOTTOM_OF_PIPE_TS) |
+                              S_490_EVENT_INDEX(5) |
+                              S_490_PWS_ENABLE(1));
+      pm4_cmd_add(pm4_cmdbuf, 0); /* DST_SEL, INT_SEL, DATA_SEL */
+      pm4_cmd_add(pm4_cmdbuf, 0); /* ADDRESS_LO */
+      pm4_cmd_add(pm4_cmdbuf, 0); /* ADDRESS_HI */
+      pm4_cmd_add(pm4_cmdbuf, 0); /* DATA_LO */
+      pm4_cmd_add(pm4_cmdbuf, 0); /* DATA_HI */
+      pm4_cmd_add(pm4_cmdbuf, 0); /* INT_CTXID */
+
+      unsigned gcr_cntl = S_586_GL2_INV(1) | S_586_GL2_WB(1) |
+                          S_586_GLM_INV(1) | S_586_GLM_WB(1) |
+                          S_586_GL1_INV(1) | S_586_GLV_INV(1) |
+                          S_586_GLK_INV(1) | S_586_GLI_INV(V_586_GLI_ALL);
+
+      /* Wait for the PWS counter. */
+      pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_ACQUIRE_MEM, 6, 0));
+      pm4_cmd_add(pm4_cmdbuf, S_580_PWS_STAGE_SEL(V_580_CP_PFP) |
+                              S_580_PWS_COUNTER_SEL(V_580_TS_SELECT) |
+                              S_580_PWS_ENA2(1) |
+                              S_580_PWS_COUNT(0));
+      pm4_cmd_add(pm4_cmdbuf, 0xffffffff); /* GCR_SIZE */
+      pm4_cmd_add(pm4_cmdbuf, 0x01ffffff); /* GCR_SIZE_HI */
+      pm4_cmd_add(pm4_cmdbuf, 0); /* GCR_BASE_LO */
+      pm4_cmd_add(pm4_cmdbuf, 0); /* GCR_BASE_HI */
+      pm4_cmd_add(pm4_cmdbuf, S_585_PWS_ENA(1));
+      pm4_cmd_add(pm4_cmdbuf, gcr_cntl); /* GCR_CNTL */
+   } else if (info->gfx_level >= GFX10) {
+      unsigned gcr_cntl = S_586_GL2_INV(1) | S_586_GL2_WB(1) |
+                          S_586_GLM_INV(1) | S_586_GLM_WB(1) |
+                          S_586_GL1_INV(1) | S_586_GLV_INV(1) |
+                          S_586_GLK_INV(1) | S_586_GLI_INV(V_586_GLI_ALL);
+
+      pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_ACQUIRE_MEM, 6, 0));
+      pm4_cmd_add(pm4_cmdbuf, 0);           /* CP_COHER_CNTL */
+      pm4_cmd_add(pm4_cmdbuf, 0xffffffff);  /* CP_COHER_SIZE */
+      pm4_cmd_add(pm4_cmdbuf, 0xffffff);    /* CP_COHER_SIZE_HI */
+      pm4_cmd_add(pm4_cmdbuf, 0);           /* CP_COHER_BASE */
+      pm4_cmd_add(pm4_cmdbuf, 0);           /* CP_COHER_BASE_HI */
+      pm4_cmd_add(pm4_cmdbuf, 0x0000000A);  /* POLL_INTERVAL */
+      pm4_cmd_add(pm4_cmdbuf, gcr_cntl);    /* GCR_CNTL */
+
+      pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_PFP_SYNC_ME, 0, 0));
+      pm4_cmd_add(pm4_cmdbuf, 0);
+   } else if (info->gfx_level == GFX9) {
+      unsigned cp_coher_cntl = S_0301F0_SH_ICACHE_ACTION_ENA(1) |
+                               S_0301F0_SH_KCACHE_ACTION_ENA(1) |
+                               S_0301F0_TC_ACTION_ENA(1) |
+                               S_0301F0_TCL1_ACTION_ENA(1) |
+                               S_0301F0_TC_WB_ACTION_ENA(1);
+
+      pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_ACQUIRE_MEM, 5, 0));
+      pm4_cmd_add(pm4_cmdbuf, cp_coher_cntl); /* CP_COHER_CNTL */
+      pm4_cmd_add(pm4_cmdbuf, 0xffffffff);    /* CP_COHER_SIZE */
+      pm4_cmd_add(pm4_cmdbuf, 0xffffff);      /* CP_COHER_SIZE_HI */
+      pm4_cmd_add(pm4_cmdbuf, 0);             /* CP_COHER_BASE */
+      pm4_cmd_add(pm4_cmdbuf, 0);             /* CP_COHER_BASE_HI */
+      pm4_cmd_add(pm4_cmdbuf, 0x0000000A);    /* POLL_INTERVAL */
+
+      pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_PFP_SYNC_ME, 0, 0));
+      pm4_cmd_add(pm4_cmdbuf, 0);
+   } else {
+      unreachable("invalid chip");
+   }
+
+   pm4_cmd_add(pm4_cmdbuf, PKT3(PKT3_CONTEXT_CONTROL, 1, 0));
+   pm4_cmd_add(pm4_cmdbuf,
+               CC0_UPDATE_LOAD_ENABLES(1) |
+               CC0_LOAD_PER_CONTEXT_STATE(1) |
+               CC0_LOAD_CS_SH_REGS(1) |
+               CC0_LOAD_GFX_SH_REGS(1) |
+               CC0_LOAD_GLOBAL_UCONFIG(1));
+   pm4_cmd_add(pm4_cmdbuf,
+               CC1_UPDATE_SHADOW_ENABLES(1) |
+               CC1_SHADOW_PER_CONTEXT_STATE(1) |
+               CC1_SHADOW_CS_SH_REGS(1) |
+               CC1_SHADOW_GFX_SH_REGS(1) |
+               CC1_SHADOW_GLOBAL_UCONFIG(1));
+
+   for (unsigned i = 0; i < SI_NUM_SHADOWED_REG_RANGES; i++)
+      ac_build_load_reg(info, pm4_cmd_add, pm4_cmdbuf, i, gpu_address);
+}
diff --git a/src/amd/common/ac_shadowed_regs.h b/src/amd/common/ac_shadowed_regs.h
index 8d2114452af1..92977f63bdc9 100644
--- a/src/amd/common/ac_shadowed_regs.h
+++ b/src/amd/common/ac_shadowed_regs.h
@@ -51,6 +51,8 @@ enum ac_reg_range_type
 extern "C" {
 #endif
 
+typedef void (*pm4_cmd_add_fn)(void *pm4_cmdbuf, uint32_t value);
+
 typedef void (*set_context_reg_seq_array_fn)(struct radeon_cmdbuf *cs, unsigned reg, unsigned num,
                                              const uint32_t *values);
 
@@ -63,6 +65,10 @@ void ac_check_shadowed_regs(enum amd_gfx_level gfx_level, enum radeon_family fam
                             unsigned reg_offset, unsigned count);
 void ac_print_shadowed_regs(const struct radeon_info *info);
 
+void ac_create_shadowing_ib_preamble(const struct radeon_info *info,
+                                     pm4_cmd_add_fn pm4_cmd_add, void *pm4_cmdbuf,
+                                     uint64_t gpu_address,
+                                     bool dpbb_allowed);
 #ifdef __cplusplus
 }
 #endif
diff --git a/src/gallium/drivers/radeonsi/si_cp_reg_shadowing.c b/src/gallium/drivers/radeonsi/si_cp_reg_shadowing.c
index d58b9a90bb95..9b5c15ab9633 100644
--- a/src/gallium/drivers/radeonsi/si_cp_reg_shadowing.c
+++ b/src/gallium/drivers/radeonsi/si_cp_reg_shadowing.c
@@ -27,159 +27,6 @@
 #include "ac_shadowed_regs.h"
 #include "util/u_memory.h"
 
-static void si_build_load_reg(struct si_screen *sscreen, struct si_pm4_state *pm4,
-                              enum ac_reg_range_type type,
-                              struct si_resource *shadow_regs)
-{
-   uint64_t gpu_address = shadow_regs->gpu_address;
-   unsigned packet, num_ranges, offset;
-   const struct ac_reg_range *ranges;
-
-   ac_get_reg_ranges(sscreen->info.gfx_level, sscreen->info.family,
-                     type, &num_ranges, &ranges);
-
-   switch (type) {
-   case SI_REG_RANGE_UCONFIG:
-      gpu_address += SI_SHADOWED_UCONFIG_REG_OFFSET;
-      offset = CIK_UCONFIG_REG_OFFSET;
-      packet = PKT3_LOAD_UCONFIG_REG;
-      break;
-   case SI_REG_RANGE_CONTEXT:
-      gpu_address += SI_SHADOWED_CONTEXT_REG_OFFSET;
-      offset = SI_CONTEXT_REG_OFFSET;
-      packet = PKT3_LOAD_CONTEXT_REG;
-      break;
-   default:
-      gpu_address += SI_SHADOWED_SH_REG_OFFSET;
-      offset = SI_SH_REG_OFFSET;
-      packet = PKT3_LOAD_SH_REG;
-      break;
-   }
-
-   si_pm4_cmd_add(pm4, PKT3(packet, 1 + num_ranges * 2, 0));
-   si_pm4_cmd_add(pm4, gpu_address);
-   si_pm4_cmd_add(pm4, gpu_address >> 32);
-   for (unsigned i = 0; i < num_ranges; i++) {
-      si_pm4_cmd_add(pm4, (ranges[i].offset - offset) / 4);
-      si_pm4_cmd_add(pm4, ranges[i].size / 4);
-   }
-}
-
-static struct si_pm4_state *
-si_create_shadowing_ib_preamble(struct si_context *sctx)
-{
-   struct si_shadow_preamble {
-      struct si_pm4_state pm4;
-      uint32_t more_pm4[150]; /* Add more space because the command buffer is large. */
-   };
-   struct si_pm4_state *pm4 = (struct si_pm4_state *)CALLOC_STRUCT(si_shadow_preamble);
-
-   /* Add all the space that we allocated. */
-   pm4->max_dw = (sizeof(struct si_shadow_preamble) - offsetof(struct si_shadow_preamble, pm4.pm4)) / 4;
-
-   if (sctx->screen->dpbb_allowed) {
-      si_pm4_cmd_add(pm4, PKT3(PKT3_EVENT_WRITE, 0, 0));
-      si_pm4_cmd_add(pm4, EVENT_TYPE(V_028A90_BREAK_BATCH) | EVENT_INDEX(0));
-   }
-
-   /* Wait for idle, because we'll update VGT ring pointers. */
-   si_pm4_cmd_add(pm4, PKT3(PKT3_EVENT_WRITE, 0, 0));
-   si_pm4_cmd_add(pm4, EVENT_TYPE(V_028A90_VS_PARTIAL_FLUSH) | EVENT_INDEX(4));
-
-   /* VGT_FLUSH is required even if VGT is idle. It resets VGT pointers. */
-   si_pm4_cmd_add(pm4, PKT3(PKT3_EVENT_WRITE, 0, 0));
-   si_pm4_cmd_add(pm4, EVENT_TYPE(V_028A90_VGT_FLUSH) | EVENT_INDEX(0));
-
-   if (sctx->gfx_level >= GFX11) {
-      /* We must wait for idle using an EOP event before changing the attribute ring registers.
-       * Use the bottom-of-pipe EOP event, but increment the PWS counter instead of writing memory.
-       */
-      si_pm4_cmd_add(pm4, PKT3(PKT3_RELEASE_MEM, 6, 0));
-      si_pm4_cmd_add(pm4, S_490_EVENT_TYPE(V_028A90_BOTTOM_OF_PIPE_TS) |
-                          S_490_EVENT_INDEX(5) |
-                          S_490_PWS_ENABLE(1));
-      si_pm4_cmd_add(pm4, 0); /* DST_SEL, INT_SEL, DATA_SEL */
-      si_pm4_cmd_add(pm4, 0); /* ADDRESS_LO */
-      si_pm4_cmd_add(pm4, 0); /* ADDRESS_HI */
-      si_pm4_cmd_add(pm4, 0); /* DATA_LO */
-      si_pm4_cmd_add(pm4, 0); /* DATA_HI */
-      si_pm4_cmd_add(pm4, 0); /* INT_CTXID */
-
-      unsigned gcr_cntl = S_586_GL2_INV(1) | S_586_GL2_WB(1) |
-                          S_586_GLM_INV(1) | S_586_GLM_WB(1) |
-                          S_586_GL1_INV(1) | S_586_GLV_INV(1) |
-                          S_586_GLK_INV(1) | S_586_GLI_INV(V_586_GLI_ALL);
-
-      /* Wait for the PWS counter. */
-      si_pm4_cmd_add(pm4, PKT3(PKT3_ACQUIRE_MEM, 6, 0));
-      si_pm4_cmd_add(pm4, S_580_PWS_STAGE_SEL(V_580_CP_PFP) |
-                          S_580_PWS_COUNTER_SEL(V_580_TS_SELECT) |
-                          S_580_PWS_ENA2(1) |
-                          S_580_PWS_COUNT(0));
-      si_pm4_cmd_add(pm4, 0xffffffff); /* GCR_SIZE */
-      si_pm4_cmd_add(pm4, 0x01ffffff); /* GCR_SIZE_HI */
-      si_pm4_cmd_add(pm4, 0); /* GCR_BASE_LO */
-      si_pm4_cmd_add(pm4, 0); /* GCR_BASE_HI */
-      si_pm4_cmd_add(pm4, S_585_PWS_ENA(1));
-      si_pm4_cmd_add(pm4, gcr_cntl); /* GCR_CNTL */
-   } else if (sctx->gfx_level >= GFX10) {
-      unsigned gcr_cntl = S_586_GL2_INV(1) | S_586_GL2_WB(1) |
-                          S_586_GLM_INV(1) | S_586_GLM_WB(1) |
-                          S_586_GL1_INV(1) | S_586_GLV_INV(1) |
-                          S_586_GLK_INV(1) | S_586_GLI_INV(V_586_GLI_ALL);
-
-      si_pm4_cmd_add(pm4, PKT3(PKT3_ACQUIRE_MEM, 6, 0));
-      si_pm4_cmd_add(pm4, 0);           /* CP_COHER_CNTL */
-      si_pm4_cmd_add(pm4, 0xffffffff);  /* CP_COHER_SIZE */
-      si_pm4_cmd_add(pm4, 0xffffff);    /* CP_COHER_SIZE_HI */
-      si_pm4_cmd_add(pm4, 0);           /* CP_COHER_BASE */
-      si_pm4_cmd_add(pm4, 0);           /* CP_COHER_BASE_HI */
-      si_pm4_cmd_add(pm4, 0x0000000A);  /* POLL_INTERVAL */
-      si_pm4_cmd_add(pm4, gcr_cntl);    /* GCR_CNTL */
-
-      si_pm4_cmd_add(pm4, PKT3(PKT3_PFP_SYNC_ME, 0, 0));
-      si_pm4_cmd_add(pm4, 0);
-   } else if (sctx->gfx_level == GFX9) {
-      unsigned cp_coher_cntl = S_0301F0_SH_ICACHE_ACTION_ENA(1) |
-                               S_0301F0_SH_KCACHE_ACTION_ENA(1) |
-                               S_0301F0_TC_ACTION_ENA(1) |
-                               S_0301F0_TCL1_ACTION_ENA(1) |
-                               S_0301F0_TC_WB_ACTION_ENA(1);
-
-      si_pm4_cmd_add(pm4, PKT3(PKT3_ACQUIRE_MEM, 5, 0));
-      si_pm4_cmd_add(pm4, cp_coher_cntl); /* CP_COHER_CNTL */
-      si_pm4_cmd_add(pm4, 0xffffffff);    /* CP_COHER_SIZE */
-      si_pm4_cmd_add(pm4, 0xffffff);      /* CP_COHER_SIZE_HI */
-      si_pm4_cmd_add(pm4, 0);             /* CP_COHER_BASE */
-      si_pm4_cmd_add(pm4, 0);             /* CP_COHER_BASE_HI */
-      si_pm4_cmd_add(pm4, 0x0000000A);    /* POLL_INTERVAL */
-
-      si_pm4_cmd_add(pm4, PKT3(PKT3_PFP_SYNC_ME, 0, 0));
-      si_pm4_cmd_add(pm4, 0);
-   } else {
-      unreachable("invalid chip");
-   }
-
-   si_pm4_cmd_add(pm4, PKT3(PKT3_CONTEXT_CONTROL, 1, 0));
-   si_pm4_cmd_add(pm4,
-                  CC0_UPDATE_LOAD_ENABLES(1) |
-                  CC0_LOAD_PER_CONTEXT_STATE(1) |
-                  CC0_LOAD_CS_SH_REGS(1) |
-                  CC0_LOAD_GFX_SH_REGS(1) |
-                  CC0_LOAD_GLOBAL_UCONFIG(1));
-   si_pm4_cmd_add(pm4,
-                  CC1_UPDATE_SHADOW_ENABLES(1) |
-                  CC1_SHADOW_PER_CONTEXT_STATE(1) |
-                  CC1_SHADOW_CS_SH_REGS(1) |
-                  CC1_SHADOW_GFX_SH_REGS(1) |
-                  CC1_SHADOW_GLOBAL_UCONFIG(1));
-
-   for (unsigned i = 0; i < SI_NUM_SHADOWED_REG_RANGES; i++)
-      si_build_load_reg(sctx->screen, pm4, i, sctx->shadowed_regs);
-
-   return pm4;
-}
-
 static void si_set_context_reg_array(struct radeon_cmdbuf *cs, unsigned reg, unsigned num,
                                      const uint32_t *values)
 {
@@ -212,8 +59,19 @@ void si_init_cp_reg_shadowing(struct si_context *sctx)
                              SI_COHERENCY_CP, L2_BYPASS);
 
       /* Create the shadowing preamble. */
-      struct si_pm4_state *shadowing_preamble =
-            si_create_shadowing_ib_preamble(sctx);
+      struct si_shadow_preamble {
+         struct si_pm4_state pm4;
+         uint32_t more_pm4[150]; /* Add more space because the command buffer is large. */
+      };
+      struct si_pm4_state *shadowing_preamble = (struct si_pm4_state *)CALLOC_STRUCT(si_shadow_preamble);
+
+      /* Add all the space that we allocated. */
+      shadowing_preamble->max_dw = (sizeof(struct si_shadow_preamble) -
+                                    offsetof(struct si_shadow_preamble, pm4.pm4)) / 4;
+
+      ac_create_shadowing_ib_preamble(&sctx->screen->info,
+                                      (pm4_cmd_add_fn)si_pm4_cmd_add, shadowing_preamble,
+                                      sctx->shadowed_regs->gpu_address, sctx->screen->dpbb_allowed);
 
       /* Initialize shadowed registers as follows. */
       radeon_add_to_buffer_list(sctx, &sctx->gfx_cs, sctx->shadowed_regs,
-- 
GitLab


From 3e2f56ea09a10349ee67f62233b85c4295cbd38e Mon Sep 17 00:00:00 2001
From: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Date: Mon, 29 Aug 2022 10:53:28 +0530
Subject: [PATCH 2/8] radv: add shadowregs variable to RADV_DEBUG environment
 variable
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Reviewed-by: Marek Olšák <marek.olsak@amd.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
---
 docs/envvars.rst             | 2 ++
 src/amd/vulkan/radv_debug.h  | 1 +
 src/amd/vulkan/radv_device.c | 1 +
 3 files changed, 4 insertions(+)

diff --git a/docs/envvars.rst b/docs/envvars.rst
index c27c3cad9717..f3a94f634d29 100644
--- a/docs/envvars.rst
+++ b/docs/envvars.rst
@@ -970,6 +970,8 @@ RADV driver environment variables
       dump shaders
    ``shaderstats``
       dump shader statistics
+   ``shadowregs``
+      enable register shadowing
    ``spirv``
       dump SPIR-V
    ``splitfma``
diff --git a/src/amd/vulkan/radv_debug.h b/src/amd/vulkan/radv_debug.h
index 8e062908ba09..3c5c1a209ca8 100644
--- a/src/amd/vulkan/radv_debug.h
+++ b/src/amd/vulkan/radv_debug.h
@@ -67,6 +67,7 @@ enum {
    RADV_DEBUG_SPLIT_FMA = 1ull << 36,
    RADV_DEBUG_DUMP_EPILOGS = 1ull << 37,
    RADV_DEBUG_NO_FMASK = 1ull << 38,
+   RADV_DEBUG_SHADOW_REGS = 1ull << 39,
 };
 
 enum {
diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index 21fa5200ca12..bbbb16e364d8 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -1074,6 +1074,7 @@ static const struct debug_control radv_debug_options[] = {
    {"nodma", RADV_DEBUG_NO_DMA_BLIT},
    {"epilogs", RADV_DEBUG_DUMP_EPILOGS},
    {"nofmask", RADV_DEBUG_NO_FMASK},
+   {"shadowregs", RADV_DEBUG_SHADOW_REGS},
    {NULL, 0}};
 
 const char *
-- 
GitLab


From 951d2745edff5b1d98b437c1c0accdc0db0990b5 Mon Sep 17 00:00:00 2001
From: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Date: Fri, 23 Sep 2022 00:22:42 +0530
Subject: [PATCH 3/8] radv: add support for register shadowing
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Reviewed-by: Marek Olšák <marek.olsak@amd.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
---
 src/amd/vulkan/meson.build             |   1 +
 src/amd/vulkan/radv_cp_reg_shadowing.c | 148 +++++++++++++++++++++++++
 src/amd/vulkan/radv_device.c           |  22 +++-
 src/amd/vulkan/radv_private.h          |  21 ++++
 src/amd/vulkan/si_cmd_buffer.c         |  14 ++-
 5 files changed, 199 insertions(+), 7 deletions(-)
 create mode 100644 src/amd/vulkan/radv_cp_reg_shadowing.c

diff --git a/src/amd/vulkan/meson.build b/src/amd/vulkan/meson.build
index 7f0bcfa102af..8a18f4292a1a 100644
--- a/src/amd/vulkan/meson.build
+++ b/src/amd/vulkan/meson.build
@@ -60,6 +60,7 @@ libradv_files = files(
   'radv_acceleration_structure.h',
   'radv_android.c',
   'radv_cmd_buffer.c',
+  'radv_cp_reg_shadowing.c',
   'radv_cs.h',
   'radv_debug.c',
   'radv_debug.h',
diff --git a/src/amd/vulkan/radv_cp_reg_shadowing.c b/src/amd/vulkan/radv_cp_reg_shadowing.c
new file mode 100644
index 000000000000..302b14521188
--- /dev/null
+++ b/src/amd/vulkan/radv_cp_reg_shadowing.c
@@ -0,0 +1,148 @@
+/*
+ * Copyright 2023 Advanced Micro Devices, Inc.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * on the rights to use, copy, modify, merge, publish, distribute, sub
+ * license, and/or sell copies of the Software, and to permit persons to whom
+ * the Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHOR(S) AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
+ * USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "ac_shadowed_regs.h"
+#include "radv_cs.h"
+#include "radv_debug.h"
+#include "radv_private.h"
+#include "sid.h"
+
+static void
+radv_set_context_reg_array(struct radeon_cmdbuf *cs, unsigned reg, unsigned num,
+                           const uint32_t *values)
+{
+   radeon_set_context_reg_seq(cs, reg, num);
+   radeon_emit_array(cs, values, num);
+}
+
+VkResult
+radv_create_shadow_regs_preamble(const struct radv_device *device,
+                                 struct radv_queue_state *queue_state)
+{
+   struct radeon_winsys *ws = device->ws;
+   struct radeon_info *info = &device->physical_device->rad_info;
+   VkResult result;
+
+   struct radeon_cmdbuf *cs = ws->cs_create(ws, AMD_IP_GFX);
+   if (!cs)
+      return VK_ERROR_OUT_OF_HOST_MEMORY;
+
+   /* allocate memory for queue_state->shadowed_regs where register states are saved */
+   result = ws->buffer_create(ws, SI_SHADOWED_REG_BUFFER_SIZE, 4096, RADEON_DOMAIN_VRAM,
+                              RADEON_FLAG_ZERO_VRAM | RADEON_FLAG_NO_INTERPROCESS_SHARING,
+                              RADV_BO_PRIORITY_SCRATCH, 0, &queue_state->shadowed_regs);
+   if (result != VK_SUCCESS)
+      goto fail;
+
+   /* fill the cs for shadow regs preamble ib that starts the register shadowing */
+   ac_create_shadowing_ib_preamble(info, (pm4_cmd_add_fn)&radeon_emit, cs,
+                                   queue_state->shadowed_regs->va, device->pbb_allowed);
+
+   while (cs->cdw & 7) {
+      if (info->gfx_ib_pad_with_type2)
+         radeon_emit(cs, PKT2_NOP_PAD);
+      else
+         radeon_emit(cs, PKT3_NOP_PAD);
+   }
+
+   result = ws->buffer_create(ws, cs->cdw * 4, 4096, ws->cs_domain(ws),
+                              RADEON_FLAG_CPU_ACCESS | RADEON_FLAG_NO_INTERPROCESS_SHARING |
+                                 RADEON_FLAG_READ_ONLY | RADEON_FLAG_GTT_WC,
+                              RADV_BO_PRIORITY_CS, 0, &queue_state->shadow_regs_ib);
+   if (result != VK_SUCCESS)
+      goto fail_ib_buffer;
+
+   /* copy the cs to queue_state->shadow_regs_ib. This will be the first preamble ib
+    * added in radv_update_preamble_cs.
+    */
+   void *map = ws->buffer_map(queue_state->shadow_regs_ib);
+   if (!map) {
+      result = VK_ERROR_MEMORY_MAP_FAILED;
+      goto fail_map;
+   }
+   memcpy(map, cs->buf, cs->cdw * 4);
+   queue_state->shadow_regs_ib_size_dw = cs->cdw;
+
+   ws->buffer_unmap(queue_state->shadow_regs_ib);
+   ws->cs_destroy(cs);
+   return VK_SUCCESS;
+fail_map:
+   ws->buffer_destroy(ws, queue_state->shadow_regs_ib);
+   queue_state->shadow_regs_ib = NULL;
+fail_ib_buffer:
+   ws->buffer_destroy(ws, queue_state->shadowed_regs);
+   queue_state->shadowed_regs = NULL;
+fail:
+   ws->cs_destroy(cs);
+   return result;
+}
+
+void
+radv_destroy_shadow_regs_preamble(struct radv_queue_state *queue_state, struct radeon_winsys *ws)
+{
+   if (queue_state->shadow_regs_ib)
+      ws->buffer_destroy(ws, queue_state->shadow_regs_ib);
+   if (queue_state->shadowed_regs)
+      ws->buffer_destroy(ws, queue_state->shadowed_regs);
+}
+
+void
+radv_emit_shadow_regs_preamble(struct radeon_cmdbuf *cs, const struct radv_device *device,
+                               struct radv_queue_state *queue_state)
+{
+   uint64_t va = radv_buffer_get_va(queue_state->shadow_regs_ib);
+   radeon_emit(cs, PKT3(PKT3_INDIRECT_BUFFER_CIK, 2, 0));
+   radeon_emit(cs, va);
+   radeon_emit(cs, va >> 32);
+   radeon_emit(cs, queue_state->shadow_regs_ib_size_dw & 0xffff);
+
+   radv_cs_add_buffer(device->ws, cs, queue_state->shadowed_regs);
+   radv_cs_add_buffer(device->ws, cs, queue_state->shadow_regs_ib);
+}
+
+/* radv_init_shadowed_regs_buffer_state() will be called once from radv_queue_init(). This
+ * initializes the shadowed_regs buffer to good state */
+VkResult
+radv_init_shadowed_regs_buffer_state(const struct radv_device *device, struct radv_queue *queue)
+{
+   struct radeon_info *info = &device->physical_device->rad_info;
+   struct radeon_winsys *ws = device->ws;
+   struct radeon_cmdbuf *cs;
+   VkResult result;
+
+   cs = ws->cs_create(ws, AMD_IP_GFX);
+   if (!cs)
+      return VK_ERROR_OUT_OF_HOST_MEMORY;
+   radv_emit_shadow_regs_preamble(cs, device, &queue->state);
+   ac_emulate_clear_state(info, cs, radv_set_context_reg_array);
+
+   result = ws->cs_finalize(cs);
+   if (result == VK_SUCCESS) {
+      if (!radv_queue_internal_submit(queue, cs))
+         result = VK_ERROR_UNKNOWN;
+   }
+
+   ws->cs_destroy(cs);
+   return result;
+}
diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index bbbb16e364d8..62d979e9d8a0 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -3111,14 +3111,28 @@ radv_queue_init(struct radv_device *device, struct radv_queue *queue, int idx,
    if (result != VK_SUCCESS)
       return result;
 
-   queue->vk.driver_submit = radv_queue_submit;
+   queue->state.uses_shadow_regs =
+      device->uses_shadow_regs && queue->state.qf == RADV_QUEUE_GENERAL;
+   if (queue->state.uses_shadow_regs) {
+      result = radv_create_shadow_regs_preamble(device, &queue->state);
+      if (result != VK_SUCCESS)
+         goto fail;
+      result = radv_init_shadowed_regs_buffer_state(device, queue);
+      if (result != VK_SUCCESS)
+         goto fail;
+   }
 
+   queue->vk.driver_submit = radv_queue_submit;
    return VK_SUCCESS;
+fail:
+   vk_queue_finish(&queue->vk);
+   return result;
 }
 
 static void
 radv_queue_state_finish(struct radv_queue_state *queue, struct radv_device *device)
 {
+   radv_destroy_shadow_regs_preamble(queue, device->ws);
    if (queue->initial_full_flush_preamble_cs)
       device->ws->cs_destroy(queue->initial_full_flush_preamble_cs);
    if (queue->initial_preamble_cs)
@@ -3855,6 +3869,10 @@ radv_CreateDevice(VkPhysicalDevice physicalDevice, const VkDeviceCreateInfo *pCr
    device->overallocation_disallowed = overallocation_disallowed;
    mtx_init(&device->overallocation_mutex, mtx_plain);
 
+   if (physical_device->rad_info.mid_command_buffer_preemption_enabled ||
+       device->instance->debug_flags & RADV_DEBUG_SHADOW_REGS)
+      device->uses_shadow_regs = true;
+
    /* Create one context per queue priority. */
    for (unsigned i = 0; i < pCreateInfo->queueCreateInfoCount; i++) {
       const VkDeviceQueueCreateInfo *queue_create = &pCreateInfo->pQueueCreateInfos[i];
@@ -5045,6 +5063,8 @@ radv_update_preamble_cs(struct radv_queue_state *queue, struct radv_device *devi
       /* Emit initial configuration. */
       switch (queue->qf) {
       case RADV_QUEUE_GENERAL:
+         if (queue->uses_shadow_regs)
+            radv_emit_shadow_regs_preamble(cs, device, queue);
          radv_init_graphics_state(cs, device);
 
          if (esgs_ring_bo || gsvs_ring_bo || tess_rings_bo || task_rings_bo) {
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index f545aba58583..d8702904c4b9 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -765,6 +765,16 @@ struct radv_queue_state {
    struct radeon_cmdbuf *continue_preamble_cs;
    struct radeon_cmdbuf *gang_wait_preamble_cs;
    struct radeon_cmdbuf *gang_wait_postamble_cs;
+
+   /* the uses_shadow_regs here will be set only for general queue */
+   bool uses_shadow_regs;
+   /* register state is saved in shadowed_regs buffer */
+   struct radeon_winsys_bo *shadowed_regs;
+   /* shadow regs preamble ib. This will be the first preamble ib.
+    * This ib has the packets to start register shadowing.
+    */
+   struct radeon_winsys_bo *shadow_regs_ib;
+   uint32_t shadow_regs_ib_size_dw;
 };
 
 struct radv_queue {
@@ -1005,6 +1015,8 @@ struct radv_device {
    struct radeon_cmdbuf **perf_counter_lock_cs;
 
    bool uses_device_generated_commands;
+
+   bool uses_shadow_regs;
 };
 
 bool radv_device_set_pstate(struct radv_device *device, bool enable);
@@ -1689,6 +1701,15 @@ void si_write_scissors(struct radeon_cmdbuf *cs, int count, const VkRect2D *scis
 void si_write_guardband(struct radeon_cmdbuf *cs, int count, const VkViewport *viewports,
                         unsigned rast_prim, unsigned polygon_mode, float line_width);
 
+VkResult radv_create_shadow_regs_preamble(const struct radv_device *device,
+                                          struct radv_queue_state *queue_state);
+void radv_destroy_shadow_regs_preamble(struct radv_queue_state *queue_state,
+                                       struct radeon_winsys *ws);
+void radv_emit_shadow_regs_preamble(struct radeon_cmdbuf *cs, const struct radv_device *device,
+                                    struct radv_queue_state *queue_state);
+VkResult radv_init_shadowed_regs_buffer_state(const struct radv_device *device,
+                                              struct radv_queue *queue);
+
 uint32_t si_get_ia_multi_vgt_param(struct radv_cmd_buffer *cmd_buffer, bool instanced_draw,
                                    bool indirect_draw, bool count_from_stream_output,
                                    uint32_t draw_vertex_count, unsigned topology,
diff --git a/src/amd/vulkan/si_cmd_buffer.c b/src/amd/vulkan/si_cmd_buffer.c
index 9d8724ab7e15..79318be5eb01 100644
--- a/src/amd/vulkan/si_cmd_buffer.c
+++ b/src/amd/vulkan/si_cmd_buffer.c
@@ -200,13 +200,15 @@ si_emit_graphics(struct radv_device *device, struct radeon_cmdbuf *cs)
    bool has_clear_state = physical_device->rad_info.has_clear_state;
    int i;
 
-   radeon_emit(cs, PKT3(PKT3_CONTEXT_CONTROL, 1, 0));
-   radeon_emit(cs, CC0_UPDATE_LOAD_ENABLES(1));
-   radeon_emit(cs, CC1_UPDATE_SHADOW_ENABLES(1));
+   if (!device->uses_shadow_regs) {
+      radeon_emit(cs, PKT3(PKT3_CONTEXT_CONTROL, 1, 0));
+      radeon_emit(cs, CC0_UPDATE_LOAD_ENABLES(1));
+      radeon_emit(cs, CC1_UPDATE_SHADOW_ENABLES(1));
 
-   if (has_clear_state) {
-      radeon_emit(cs, PKT3(PKT3_CLEAR_STATE, 0, 0));
-      radeon_emit(cs, 0);
+      if (has_clear_state) {
+         radeon_emit(cs, PKT3(PKT3_CLEAR_STATE, 0, 0));
+         radeon_emit(cs, 0);
+      }
    }
 
    if (physical_device->rad_info.gfx_level <= GFX8)
-- 
GitLab


From e6ee4087c98e0a5d1ecca0cf63fd76cc5fdae7fd Mon Sep 17 00:00:00 2001
From: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Date: Tue, 22 Nov 2022 13:42:17 +0530
Subject: [PATCH 4/8] radv: set preemp flag and pre_ena bit for shadowregs
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Reviewed-by: Marek Olšák <marek.olsak@amd.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
---
 src/amd/vulkan/radv_device.c                  |  1 +
 src/amd/vulkan/radv_radeon_winsys.h           |  1 +
 src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c | 27 ++++++++++++-------
 3 files changed, 20 insertions(+), 9 deletions(-)

diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index 62d979e9d8a0..784357337d86 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -5833,6 +5833,7 @@ radv_queue_submit_normal(struct radv_queue *queue, struct vk_queue_submit *submi
       .preamble_count = 1,
       .initial_preamble_cs = preambles,
       .continue_preamble_cs = queue->state.continue_preamble_cs,
+      .uses_shadow_regs = queue->state.uses_shadow_regs,
    };
 
    for (uint32_t j = 0, advance; j < cmd_buffer_count; j += advance) {
diff --git a/src/amd/vulkan/radv_radeon_winsys.h b/src/amd/vulkan/radv_radeon_winsys.h
index 47d194d62afd..dd644d22b64b 100644
--- a/src/amd/vulkan/radv_radeon_winsys.h
+++ b/src/amd/vulkan/radv_radeon_winsys.h
@@ -195,6 +195,7 @@ struct radv_winsys_submit_info {
    struct radeon_cmdbuf **cs_array;
    struct radeon_cmdbuf **initial_preamble_cs;
    struct radeon_cmdbuf *continue_preamble_cs;
+   bool uses_shadow_regs;
 };
 
 /* Kernel effectively allows 0-31. This sets some priorities for fixed
diff --git a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
index 04c66ee77098..bf34206d0dc0 100644
--- a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
+++ b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
@@ -884,7 +884,7 @@ radv_amdgpu_winsys_cs_submit_chained(struct radv_amdgpu_ctx *ctx, int queue_idx,
                                      struct radv_winsys_sem_info *sem_info,
                                      struct radeon_cmdbuf **cs_array, unsigned cs_count,
                                      struct radeon_cmdbuf **initial_preamble_cs,
-                                     unsigned preamble_count)
+                                     unsigned preamble_count, bool uses_shadow_regs)
 {
    struct radv_amdgpu_cs *cs0 = radv_amdgpu_cs(cs_array[0]);
    struct radv_amdgpu_winsys *aws = cs0->ws;
@@ -892,6 +892,7 @@ radv_amdgpu_winsys_cs_submit_chained(struct radv_amdgpu_ctx *ctx, int queue_idx,
    struct radv_amdgpu_cs_request request;
    struct radv_amdgpu_cs_ib_info ibs[1 + AMD_NUM_IP_TYPES];
    unsigned num_handles = 0;
+   uint32_t pre_ena = cs0->hw_ip == AMDGPU_HW_IP_GFX && uses_shadow_regs ? S_3F2_PRE_ENA(1) : 0;
    VkResult result;
 
    for (unsigned i = cs_count; i--;) {
@@ -918,7 +919,7 @@ radv_amdgpu_winsys_cs_submit_chained(struct radv_amdgpu_ctx *ctx, int queue_idx,
          cs->base.buf[cs->base.cdw - 4] = PKT3(PKT3_INDIRECT_BUFFER_CIK, 2, 0);
          cs->base.buf[cs->base.cdw - 3] = next->ib.ib_mc_address;
          cs->base.buf[cs->base.cdw - 2] = next->ib.ib_mc_address >> 32;
-         cs->base.buf[cs->base.cdw - 1] = S_3F2_CHAIN(1) | S_3F2_VALID(1) | next->ib.size;
+         cs->base.buf[cs->base.cdw - 1] = S_3F2_CHAIN(1) | S_3F2_VALID(1) | pre_ena | next->ib.size;
       }
    }
 
@@ -938,6 +939,8 @@ radv_amdgpu_winsys_cs_submit_chained(struct radv_amdgpu_ctx *ctx, int queue_idx,
    }
 
    ibs[preamble_count] = cs0->ib;
+   if (uses_shadow_regs && cs0->hw_ip == AMDGPU_HW_IP_GFX)
+      ibs[preamble_count].flags |= AMDGPU_IB_FLAG_PREEMPT;
 
    request.ip_type = cs0->hw_ip;
    request.ip_instance = 0;
@@ -967,7 +970,7 @@ radv_amdgpu_winsys_cs_submit_fallback(struct radv_amdgpu_ctx *ctx, int queue_idx
                                       struct radv_winsys_sem_info *sem_info,
                                       struct radeon_cmdbuf **cs_array, unsigned cs_count,
                                       struct radeon_cmdbuf **initial_preamble_cs,
-                                      unsigned preamble_count)
+                                      unsigned preamble_count, bool uses_shadow_regs)
 {
    const unsigned number_of_ibs = cs_count + preamble_count;
    struct drm_amdgpu_bo_list_entry *handles = NULL;
@@ -1020,6 +1023,9 @@ radv_amdgpu_winsys_cs_submit_fallback(struct radv_amdgpu_ctx *ctx, int queue_idx
          cs->base.buf[cs->base.cdw - 1] =  PKT3_NOP_PAD;
          cs->is_chained = false;
       }
+
+      if (uses_shadow_regs && cs->ib.ip_type == AMDGPU_HW_IP_GFX)
+         cs->ib.flags |= AMDGPU_IB_FLAG_PREEMPT;
    }
 
    request.ip_type = last_cs->hw_ip;
@@ -1051,7 +1057,8 @@ radv_amdgpu_winsys_cs_submit_sysmem(struct radv_amdgpu_ctx *ctx, int queue_idx,
                                     struct radv_winsys_sem_info *sem_info,
                                     struct radeon_cmdbuf **cs_array, unsigned cs_count,
                                     struct radeon_cmdbuf *initial_preamble_cs,
-                                    struct radeon_cmdbuf *continue_preamble_cs)
+                                    struct radeon_cmdbuf *continue_preamble_cs,
+                                    bool uses_shadow_regs)
 {
    struct radv_amdgpu_cs *cs0 = radv_amdgpu_cs(cs_array[0]);
    struct radeon_winsys *ws = (struct radeon_winsys *)cs0->ws;
@@ -1140,7 +1147,8 @@ radv_amdgpu_winsys_cs_submit_sysmem(struct radv_amdgpu_ctx *ctx, int queue_idx,
 
             ibs[j].size = size;
             ibs[j].ib_mc_address = radv_buffer_get_va(bos[j]);
-            ibs[j].flags = 0;
+            ibs[j].flags =
+               uses_shadow_regs && cs->hw_ip == AMDGPU_HW_IP_GFX ? AMDGPU_IB_FLAG_PREEMPT : 0;
             ibs[j].ip_type = cs->hw_ip;
          }
 
@@ -1187,7 +1195,8 @@ radv_amdgpu_winsys_cs_submit_sysmem(struct radv_amdgpu_ctx *ctx, int queue_idx,
 
          ibs[0].size = size;
          ibs[0].ib_mc_address = radv_buffer_get_va(bos[0]);
-         ibs[0].flags = 0;
+         ibs[0].flags =
+            uses_shadow_regs && cs->hw_ip == AMDGPU_HW_IP_GFX ? AMDGPU_IB_FLAG_PREEMPT : 0;
          ibs[0].ip_type = cs->hw_ip;
       }
 
@@ -1339,15 +1348,15 @@ radv_amdgpu_winsys_cs_submit_internal(struct radv_amdgpu_ctx *ctx,
       assert(submit->preamble_count <= 1);
       result = radv_amdgpu_winsys_cs_submit_sysmem(
          ctx, submit->queue_index, sem_info, submit->cs_array, submit->cs_count,
-         submit->initial_preamble_cs[0], submit->continue_preamble_cs);
+         submit->initial_preamble_cs[0], submit->continue_preamble_cs, submit->uses_shadow_regs);
    } else if (can_patch) {
       result = radv_amdgpu_winsys_cs_submit_chained(
          ctx, submit->queue_index, sem_info, submit->cs_array, submit->cs_count,
-         submit->initial_preamble_cs, submit->preamble_count);
+         submit->initial_preamble_cs, submit->preamble_count, submit->uses_shadow_regs);
    } else {
       result = radv_amdgpu_winsys_cs_submit_fallback(
          ctx, submit->queue_index, sem_info, submit->cs_array, submit->cs_count,
-         submit->initial_preamble_cs, submit->preamble_count);
+         submit->initial_preamble_cs, submit->preamble_count, submit->uses_shadow_regs);
    }
 
    return result;
-- 
GitLab


From a063d7b5667b13954784e6c292a5720ab37d074e Mon Sep 17 00:00:00 2001
From: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Date: Mon, 12 Sep 2022 23:31:11 +0530
Subject: [PATCH 5/8] radv: INDEX_TYPE and NUM_INSTANCES PKT3 are not shadowed
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

INDEX_TYPE and NUM_INSTANCES PKT3 should be always written
if shadowing is enabled since they are not shadowed.

Signed-off-by: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Reviewed-by: Marek Olšák <marek.olsak@amd.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
---
 src/amd/vulkan/radv_cmd_buffer.c | 6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index c79e633a62c2..8d3d8a39783b 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -5170,7 +5170,8 @@ radv_emit_draw_registers(struct radv_cmd_buffer *cmd_buffer, const struct radv_d
       disable_instance_packing = true;
    }
 
-   if ((draw_info->indexed && state->index_type != state->last_index_type) ||
+   if ((draw_info->indexed &&
+        (state->index_type != state->last_index_type || cmd_buffer->device->uses_shadow_regs)) ||
        (info->gfx_level == GFX10_3 &&
         (state->last_index_type == -1 ||
          disable_instance_packing != G_028A7C_DISABLE_INSTANCE_PACKING(state->last_index_type)))) {
@@ -8710,7 +8711,8 @@ radv_before_draw(struct radv_cmd_buffer *cmd_buffer, const struct radv_draw_info
       struct radv_cmd_state *state = &cmd_buffer->state;
       struct radeon_cmdbuf *cs = cmd_buffer->cs;
       assert(state->graphics_pipeline->vtx_base_sgpr);
-      if (state->last_num_instances != info->instance_count) {
+      if (state->last_num_instances != info->instance_count ||
+          cmd_buffer->device->uses_shadow_regs) {
          radeon_emit(cs, PKT3(PKT3_NUM_INSTANCES, 0, false));
          radeon_emit(cs, info->instance_count);
          state->last_num_instances = info->instance_count;
-- 
GitLab


From b67a86078e7606b62087a28581dcfae642672555 Mon Sep 17 00:00:00 2001
From: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Date: Tue, 18 Oct 2022 12:24:36 +0530
Subject: [PATCH 6/8] radv: fence complete struct is 4 qw size
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

also libdrm function amdgpu_cs_chunk_fence_info_to_data() has qw multiplier
and hence need not do it in radv_amdgpu_cs_submit().

Signed-off-by: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Reviewed-by: Marek Olšák <marek.olsak@amd.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
---
 src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c | 10 ++++++++--
 1 file changed, 8 insertions(+), 2 deletions(-)

diff --git a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
index bf34206d0dc0..5d4e661cab5c 100644
--- a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
+++ b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
@@ -1531,7 +1531,7 @@ radv_amdgpu_ctx_create(struct radeon_winsys *_ws, enum radeon_ctx_priority prior
    }
    ctx->ws = ws;
 
-   assert(AMDGPU_HW_IP_NUM * MAX_RINGS_PER_TYPE * sizeof(uint64_t) <= 4096);
+   assert(AMDGPU_HW_IP_NUM * MAX_RINGS_PER_TYPE * 4 * sizeof(uint64_t) <= 4096);
    result = ws->base.buffer_create(&ws->base, 4096, 8, RADEON_DOMAIN_GTT,
                                    RADEON_FLAG_CPU_ACCESS | RADEON_FLAG_NO_INTERPROCESS_SHARING,
                                    RADV_BO_PRIORITY_CS, 0, &ctx->fence_bo);
@@ -1757,7 +1757,13 @@ radv_amdgpu_cs_submit(struct radv_amdgpu_ctx *ctx, struct radv_amdgpu_cs_request
 
       struct amdgpu_cs_fence_info fence_info;
       fence_info.handle = radv_amdgpu_winsys_bo(ctx->fence_bo)->bo;
-      fence_info.offset = (request->ip_type * MAX_RINGS_PER_TYPE + request->ring) * sizeof(uint64_t);
+      /* Need to reserve 4 QWORD for user fence:
+       *   QWORD[0]: completed fence
+       *   QWORD[1]: preempted fence
+       *   QWORD[2]: reset fence
+       *   QWORD[3]: preempted then reset
+       */
+      fence_info.offset = (request->ip_type * MAX_RINGS_PER_TYPE + request->ring) * 4;
       amdgpu_cs_chunk_fence_info_to_data(&fence_info, &chunk_data[i]);
    }
 
-- 
GitLab


From c5aa63ecbbd7741f850c837697076e4fca4ed1d1 Mon Sep 17 00:00:00 2001
From: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Date: Thu, 12 Jan 2023 09:42:53 +0530
Subject: [PATCH 7/8] radv: allow NULL initial_preamble_cs in
 radv_amdgpu_winsys_cs_submit_sysmem()

In case of mcbp, shadowed_regs is initialized early in radv_queue_init()
function by submitting the command buffer. The command buffer is submitted in
radv_init_shadowed_regs_buffer_state() function. When RADV_DEBUG=noibs is used
radv_amdgpu_winsys_cs_submit_sysmem() function is used to submit command buffer.
radv_amdgpu_winsys_cs_submit_sysmem() crashes here because initial_preamble_cs
is NULL. This patch fixes the radv_amdgpu_winsys_cs_submit_sysmem() function
to support NULL initial_preamble_cs.

Signed-off-by: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
---
 src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
index 5d4e661cab5c..3e21fe55c30e 100644
--- a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
+++ b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c
@@ -1056,7 +1056,7 @@ static VkResult
 radv_amdgpu_winsys_cs_submit_sysmem(struct radv_amdgpu_ctx *ctx, int queue_idx,
                                     struct radv_winsys_sem_info *sem_info,
                                     struct radeon_cmdbuf **cs_array, unsigned cs_count,
-                                    struct radeon_cmdbuf *initial_preamble_cs,
+                                    struct radeon_cmdbuf **initial_preamble_cs,
                                     struct radeon_cmdbuf *continue_preamble_cs,
                                     bool uses_shadow_regs)
 {
@@ -1075,7 +1075,8 @@ radv_amdgpu_winsys_cs_submit_sysmem(struct radv_amdgpu_ctx *ctx, int queue_idx,
    for (unsigned i = 0; i < cs_count;) {
       struct radv_amdgpu_cs_ib_info *ibs;
       struct radeon_winsys_bo **bos;
-      struct radeon_cmdbuf *preamble_cs = i ? continue_preamble_cs : initial_preamble_cs;
+      struct radeon_cmdbuf *preamble_cs = i ? continue_preamble_cs :
+         initial_preamble_cs ? initial_preamble_cs[0] : NULL;
       struct radv_amdgpu_cs *cs = radv_amdgpu_cs(cs_array[i]);
       struct drm_amdgpu_bo_list_entry *handles = NULL;
       unsigned num_handles = 0;
@@ -1348,7 +1349,7 @@ radv_amdgpu_winsys_cs_submit_internal(struct radv_amdgpu_ctx *ctx,
       assert(submit->preamble_count <= 1);
       result = radv_amdgpu_winsys_cs_submit_sysmem(
          ctx, submit->queue_index, sem_info, submit->cs_array, submit->cs_count,
-         submit->initial_preamble_cs[0], submit->continue_preamble_cs, submit->uses_shadow_regs);
+         submit->initial_preamble_cs, submit->continue_preamble_cs, submit->uses_shadow_regs);
    } else if (can_patch) {
       result = radv_amdgpu_winsys_cs_submit_chained(
          ctx, submit->queue_index, sem_info, submit->cs_array, submit->cs_count,
-- 
GitLab


From 2ab1d2668795c051fb6f95ca182378dcfa1ece30 Mon Sep 17 00:00:00 2001
From: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Date: Fri, 20 Jan 2023 12:29:00 +0530
Subject: [PATCH 8/8] radeonsi: remove some shadow reg optimization for bf1
 game
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

This patch removes below shadow reg optimization. This is done for
Vega64 battlefield 1 crash when shadow regs enabled.

  + reset only dirty states with buffers in si_pm4_reset_emitted()
  + various draw states in si_begin_new_gfx_cs()

v2: remove first_cs parameter from si_pm4_reset_emitted() (Marek Olšák)
Signed-off-by: Yogesh Mohan Marimuthu <yogesh.mohanmarimuthu@amd.com>
Reviewed-by: Marek Olšák <marek.olsak@amd.com>
---
 src/gallium/drivers/radeonsi/si_gfx_cs.c | 42 +++++++++++-------------
 src/gallium/drivers/radeonsi/si_pm4.c    | 17 +---------
 src/gallium/drivers/radeonsi/si_pm4.h    |  2 +-
 3 files changed, 22 insertions(+), 39 deletions(-)

diff --git a/src/gallium/drivers/radeonsi/si_gfx_cs.c b/src/gallium/drivers/radeonsi/si_gfx_cs.c
index 0c48240a5f0e..0a48aee6cef7 100644
--- a/src/gallium/drivers/radeonsi/si_gfx_cs.c
+++ b/src/gallium/drivers/radeonsi/si_gfx_cs.c
@@ -415,10 +415,8 @@ void si_begin_new_gfx_cs(struct si_context *ctx, bool first_cs)
 
    si_add_all_descriptors_to_bo_list(ctx);
 
-   if (first_cs || !ctx->shadowed_regs) {
-      si_shader_pointers_mark_dirty(ctx);
-      ctx->cs_shader_state.initialized = false;
-   }
+   si_shader_pointers_mark_dirty(ctx);
+   ctx->cs_shader_state.initialized = false;
 
    if (!ctx->has_graphics) {
       ctx->initial_gfx_cs_size = ctx->gfx_cs.current.cdw;
@@ -434,7 +432,7 @@ void si_begin_new_gfx_cs(struct si_context *ctx, bool first_cs)
    /* set all valid group as dirty so they get reemited on
     * next draw command
     */
-   si_pm4_reset_emitted(ctx, first_cs);
+   si_pm4_reset_emitted(ctx);
 
    /* The CS initialization should be emitted before everything else. */
    if (ctx->cs_preamble_state) {
@@ -460,7 +458,7 @@ void si_begin_new_gfx_cs(struct si_context *ctx, bool first_cs)
 
    /* CLEAR_STATE disables all colorbuffers, so only enable bound ones. */
    bool has_clear_state = ctx->screen->info.has_clear_state;
-   if (has_clear_state || ctx->shadowed_regs) {
+   if (has_clear_state) {
       ctx->framebuffer.dirty_cbufs =
             u_bit_consecutive(0, ctx->framebuffer.state.nr_cbufs);
       /* CLEAR_STATE disables the zbuffer, so only enable it if it's bound. */
@@ -508,22 +506,6 @@ void si_begin_new_gfx_cs(struct si_context *ctx, bool first_cs)
       si_mark_atom_dirty(ctx, &ctx->atoms.s.scissors);
       si_mark_atom_dirty(ctx, &ctx->atoms.s.viewports);
 
-      /* Invalidate various draw states so that they are emitted before
-       * the first draw call. */
-      si_invalidate_draw_constants(ctx);
-      ctx->last_index_size = -1;
-      ctx->last_primitive_restart_en = -1;
-      ctx->last_restart_index = SI_RESTART_INDEX_UNKNOWN;
-      ctx->last_prim = -1;
-      ctx->last_multi_vgt_param = -1;
-      ctx->last_vs_state = ~0;
-      ctx->last_gs_state = ~0;
-      ctx->last_ls = NULL;
-      ctx->last_tcs = NULL;
-      ctx->last_tes_sh_base = -1;
-      ctx->last_num_tcs_input_cp = -1;
-      ctx->last_ls_hs_config = -1; /* impossible value */
-
       if (has_clear_state) {
          si_set_tracked_regs_to_clear_state(ctx);
       } else {
@@ -536,6 +518,22 @@ void si_begin_new_gfx_cs(struct si_context *ctx, bool first_cs)
       memset(ctx->tracked_regs.spi_ps_input_cntl, 0xff, sizeof(uint32_t) * 32);
    }
 
+   /* Invalidate various draw states so that they are emitted before
+    * the first draw call. */
+   si_invalidate_draw_constants(ctx);
+   ctx->last_index_size = -1;
+   ctx->last_primitive_restart_en = -1;
+   ctx->last_restart_index = SI_RESTART_INDEX_UNKNOWN;
+   ctx->last_prim = -1;
+   ctx->last_multi_vgt_param = -1;
+   ctx->last_vs_state = ~0;
+   ctx->last_gs_state = ~0;
+   ctx->last_ls = NULL;
+   ctx->last_tcs = NULL;
+   ctx->last_tes_sh_base = -1;
+   ctx->last_num_tcs_input_cp = -1;
+   ctx->last_ls_hs_config = -1; /* impossible value */
+
    if (ctx->scratch_buffer) {
       si_context_add_resource_size(ctx, &ctx->scratch_buffer->b.b);
       si_mark_atom_dirty(ctx, &ctx->atoms.s.scratch_state);
diff --git a/src/gallium/drivers/radeonsi/si_pm4.c b/src/gallium/drivers/radeonsi/si_pm4.c
index f8454cd302c2..280125b65118 100644
--- a/src/gallium/drivers/radeonsi/si_pm4.c
+++ b/src/gallium/drivers/radeonsi/si_pm4.c
@@ -151,23 +151,8 @@ void si_pm4_emit(struct si_context *sctx, struct si_pm4_state *state)
       state->atom.emit(sctx);
 }
 
-void si_pm4_reset_emitted(struct si_context *sctx, bool first_cs)
+void si_pm4_reset_emitted(struct si_context *sctx)
 {
-   if (!first_cs && sctx->shadowed_regs) {
-      /* Only dirty states that contain buffers, so that they are
-       * added to the buffer list on the next draw call.
-       */
-      for (unsigned i = 0; i < SI_NUM_STATES; i++) {
-         struct si_pm4_state *state = sctx->queued.array[i];
-
-         if (state && state->is_shader) {
-            sctx->emitted.array[i] = NULL;
-            sctx->dirty_states |= 1 << i;
-         }
-      }
-      return;
-   }
-
    memset(&sctx->emitted, 0, sizeof(sctx->emitted));
 
    for (unsigned i = 0; i < SI_NUM_STATES; i++) {
diff --git a/src/gallium/drivers/radeonsi/si_pm4.h b/src/gallium/drivers/radeonsi/si_pm4.h
index 4d1770a96d84..486b627d540a 100644
--- a/src/gallium/drivers/radeonsi/si_pm4.h
+++ b/src/gallium/drivers/radeonsi/si_pm4.h
@@ -70,7 +70,7 @@ void si_pm4_clear_state(struct si_pm4_state *state);
 void si_pm4_free_state(struct si_context *sctx, struct si_pm4_state *state, unsigned idx);
 
 void si_pm4_emit(struct si_context *sctx, struct si_pm4_state *state);
-void si_pm4_reset_emitted(struct si_context *sctx, bool first_cs);
+void si_pm4_reset_emitted(struct si_context *sctx);
 
 #ifdef __cplusplus
 }
-- 
GitLab

