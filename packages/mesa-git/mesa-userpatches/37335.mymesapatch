From bed0284154a7519953619457904855d2aa1fff17 Mon Sep 17 00:00:00 2001
From: David Rosca <david.rosca@amd.com>
Date: Mon, 15 Sep 2025 12:46:19 +0200
Subject: [PATCH 1/4] drm-uapi: Update amdgpu_drm.h for userq changes

---
 include/drm-uapi/amdgpu_drm.h               | 8 ++++++--
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp | 2 +-
 2 files changed, 7 insertions(+), 3 deletions(-)

diff --git a/include/drm-uapi/amdgpu_drm.h b/include/drm-uapi/amdgpu_drm.h
index 7c070bb3f1e81..ea81a090fea46 100644
--- a/include/drm-uapi/amdgpu_drm.h
+++ b/include/drm-uapi/amdgpu_drm.h
@@ -494,7 +494,11 @@ struct drm_amdgpu_userq_signal {
 	 * @bo_write_handles.
 	 */
 	__u32	num_bo_write_handles;
-
+	/**
+	 * @syncobj_points: The list of syncobj points submitted by the user queue job
+	 * for the corresponding @syncobj_handles.
+	 */
+	__u64	syncobj_points;
 };
 
 struct drm_amdgpu_userq_fence_info {
@@ -516,7 +520,7 @@ struct drm_amdgpu_userq_wait {
 	 * @waitq_id: Queue handle used by the userq wait IOCTL to retrieve the
 	 * wait queue and maintain the fence driver references in it.
 	 */
-	__u32	waitq_id;
+	__u32	queue_id;
 	__u32	pad;
 	/**
 	 * @syncobj_handles: The list of syncobj handles submitted by the user queue
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp
index 9ed2b41e30061..bdeb498750190 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp
@@ -1516,7 +1516,7 @@ static int amdgpu_cs_submit_ib_userq(struct amdgpu_userq *userq,
 
    struct drm_amdgpu_userq_fence_info *fence_info;
    struct drm_amdgpu_userq_wait userq_wait_data = {
-      .waitq_id = userq->userq_handle,
+      .queue_id = userq->userq_handle,
       .syncobj_handles = (uintptr_t)syncobj_dependencies_list,
       .syncobj_timeline_handles = (uintptr_t)&syncobj_timeline_dependency,
       .syncobj_timeline_points = (uintptr_t)&syncobj_timeline_dependency_point,
-- 
GitLab


From 6192585775054f90a281e08124456f2f7d283c3d Mon Sep 17 00:00:00 2001
From: David Rosca <david.rosca@amd.com>
Date: Fri, 12 Sep 2025 15:56:47 +0200
Subject: [PATCH 2/4] winsys/amdgpu: Support timeline syncobjs

---
 src/gallium/drivers/radeonsi/si_fence.c       |   4 +-
 src/gallium/include/winsys/radeon_winsys.h    |   4 +-
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp   | 159 ++++++++++++------
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.h     |   7 +-
 src/gallium/winsys/radeon/drm/radeon_drm_cs.c |   3 +-
 5 files changed, 115 insertions(+), 62 deletions(-)

diff --git a/src/gallium/drivers/radeonsi/si_fence.c b/src/gallium/drivers/radeonsi/si_fence.c
index 14eae33994f8c..5b13f4dc4189c 100644
--- a/src/gallium/drivers/radeonsi/si_fence.c
+++ b/src/gallium/drivers/radeonsi/si_fence.c
@@ -170,12 +170,12 @@ static void si_add_fence_dependency(struct si_context *sctx, struct pipe_fence_h
 {
    struct radeon_winsys *ws = sctx->ws;
 
-   ws->cs_add_fence_dependency(&sctx->gfx_cs, fence);
+   ws->cs_add_fence_dependency(&sctx->gfx_cs, fence, 0);
 }
 
 static void si_add_syncobj_signal(struct si_context *sctx, struct pipe_fence_handle *fence)
 {
-   sctx->ws->cs_add_syncobj_signal(&sctx->gfx_cs, fence);
+   sctx->ws->cs_add_syncobj_signal(&sctx->gfx_cs, fence, 0);
 }
 
 static void si_fence_reference(struct pipe_screen *screen, struct pipe_fence_handle **dst,
diff --git a/src/gallium/include/winsys/radeon_winsys.h b/src/gallium/include/winsys/radeon_winsys.h
index 781a993df9f71..9d83236912875 100644
--- a/src/gallium/include/winsys/radeon_winsys.h
+++ b/src/gallium/include/winsys/radeon_winsys.h
@@ -711,12 +711,12 @@ struct radeon_winsys {
     * Add a fence dependency to the CS, so that the CS will wait for
     * the fence before execution.
     */
-   void (*cs_add_fence_dependency)(struct radeon_cmdbuf *rcs, struct pipe_fence_handle *fence);
+   void (*cs_add_fence_dependency)(struct radeon_cmdbuf *rcs, struct pipe_fence_handle *fence, uint64_t value);
 
    /**
     * Signal a syncobj when the CS finishes execution.
     */
-   void (*cs_add_syncobj_signal)(struct radeon_cmdbuf *rcs, struct pipe_fence_handle *fence);
+   void (*cs_add_syncobj_signal)(struct radeon_cmdbuf *rcs, struct pipe_fence_handle *fence, uint64_t value);
 
    /**
     * Returns the amd_ip_type type of a CS.
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp
index bdeb498750190..70ce069e3a85d 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.cpp
@@ -848,7 +848,7 @@ static void amdgpu_init_cs_context(struct amdgpu_winsys *aws,
 static void cleanup_fence_list(struct amdgpu_fence_list *fences)
 {
    for (unsigned i = 0; i < fences->num; i++)
-      amdgpu_fence_drop_reference(fences->list[i]);
+      amdgpu_fence_drop_reference(fences->list[i].fence);
    fences->num = 0;
 }
 
@@ -1190,7 +1190,8 @@ static unsigned amdgpu_cs_get_buffer_list(struct radeon_cmdbuf *rcs,
 }
 
 static void add_fence_to_list(struct amdgpu_fence_list *fences,
-                              struct amdgpu_fence *fence)
+                              struct amdgpu_fence *fence,
+                              uint64_t value)
 {
    unsigned idx = fences->num++;
 
@@ -1200,13 +1201,15 @@ static void add_fence_to_list(struct amdgpu_fence_list *fences,
 
       fences->max = idx + increment;
       size = fences->max * sizeof(fences->list[0]);
-      fences->list = (struct pipe_fence_handle**)realloc(fences->list, size);
+      fences->list = (struct amdgpu_fence_entry*)realloc(fences->list, size);
    }
-   amdgpu_fence_set_reference(&fences->list[idx], (struct pipe_fence_handle*)fence);
+   amdgpu_fence_set_reference(&fences->list[idx].fence, (struct pipe_fence_handle*)fence);
+   fences->list[idx].value = value;
 }
 
 static void amdgpu_cs_add_fence_dependency(struct radeon_cmdbuf *rcs,
-                                           struct pipe_fence_handle *pfence)
+                                           struct pipe_fence_handle *pfence,
+                                           uint64_t value)
 {
    struct amdgpu_cs *acs = amdgpu_cs(rcs);
    struct amdgpu_winsys *aws = acs->aws;
@@ -1226,7 +1229,7 @@ static void amdgpu_cs_add_fence_dependency(struct radeon_cmdbuf *rcs,
          }
       }
    } else {
-      add_fence_to_list(&csc->syncobj_dependencies, fence);
+      add_fence_to_list(&csc->syncobj_dependencies, fence, value);
    }
 }
 
@@ -1244,7 +1247,7 @@ static void amdgpu_add_fences_to_dependencies(struct amdgpu_winsys *ws,
       }
 
       if (bo->alt_fence)
-         add_fence_to_list(&csc->syncobj_dependencies, (struct amdgpu_fence*)bo->alt_fence);
+         add_fence_to_list(&csc->syncobj_dependencies, (struct amdgpu_fence*)bo->alt_fence, 0);
    }
 }
 
@@ -1263,12 +1266,13 @@ static void amdgpu_add_to_kernel_bo_list(struct drm_amdgpu_bo_list_entry *bo_ent
 }
 
 static void amdgpu_cs_add_syncobj_signal(struct radeon_cmdbuf *rcs,
-                                         struct pipe_fence_handle *fence)
+                                         struct pipe_fence_handle *fence,
+                                         uint64_t value)
 {
    struct amdgpu_cs *acs = amdgpu_cs(rcs);
    struct amdgpu_cs_context *csc = amdgpu_csc_get_current(acs);
 
-   add_fence_to_list(&csc->syncobj_to_signal, (struct amdgpu_fence*)fence);
+   add_fence_to_list(&csc->syncobj_to_signal, (struct amdgpu_fence*)fence, value);
 }
 
 static int amdgpu_cs_submit_ib_kernelq(struct amdgpu_cs *acs,
@@ -1297,41 +1301,85 @@ static int amdgpu_cs_submit_ib_kernelq(struct amdgpu_cs *acs,
    /* Syncobj dependencies. */
    unsigned num_syncobj_dependencies = csc->syncobj_dependencies.num;
    if (num_syncobj_dependencies) {
-      struct drm_amdgpu_cs_chunk_sem *sem_chunk =
-         (struct drm_amdgpu_cs_chunk_sem *)
-         alloca(num_syncobj_dependencies * sizeof(sem_chunk[0]));
+      if (aws->info.has_timeline_syncobj) {
+         struct drm_amdgpu_cs_chunk_syncobj *sem_chunk =
+            (struct drm_amdgpu_cs_chunk_syncobj *)
+            alloca(num_syncobj_dependencies * sizeof(sem_chunk[0]));
+
+         for (unsigned i = 0; i < csc->syncobj_dependencies.num; i++) {
+            struct amdgpu_fence *fence =
+               (struct amdgpu_fence*)csc->syncobj_dependencies.list[i].fence;
+
+            assert(util_queue_fence_is_signalled(&fence->submitted));
+            sem_chunk[i].handle = fence->syncobj;
+            sem_chunk[i].flags = DRM_SYNCOBJ_WAIT_FLAGS_WAIT_FOR_SUBMIT;
+            sem_chunk[i].point = csc->syncobj_dependencies.list[i].value;
+         }
 
-      for (unsigned i = 0; i < num_syncobj_dependencies; i++) {
-         struct amdgpu_fence *fence =
-            (struct amdgpu_fence*)csc->syncobj_dependencies.list[i];
+         chunks[num_chunks].chunk_id = AMDGPU_CHUNK_ID_SYNCOBJ_TIMELINE_WAIT;
+         chunks[num_chunks].length_dw = sizeof(sem_chunk[0]) / 4 * num_syncobj_dependencies;
+         chunks[num_chunks].chunk_data = (uintptr_t)sem_chunk;
+      } else {
+         struct drm_amdgpu_cs_chunk_sem *sem_chunk =
+            (struct drm_amdgpu_cs_chunk_sem *)
+            alloca(num_syncobj_dependencies * sizeof(sem_chunk[0]));
 
-         assert(util_queue_fence_is_signalled(&fence->submitted));
-         sem_chunk[i].handle = fence->syncobj;
-      }
+         for (unsigned i = 0; i < csc->syncobj_dependencies.num; i++) {
+            struct amdgpu_fence *fence =
+               (struct amdgpu_fence*)csc->syncobj_dependencies.list[i].fence;
 
-      chunks[num_chunks].chunk_id = AMDGPU_CHUNK_ID_SYNCOBJ_IN;
-      chunks[num_chunks].length_dw = sizeof(sem_chunk[0]) / 4 * num_syncobj_dependencies;
-      chunks[num_chunks].chunk_data = (uintptr_t)sem_chunk;
+            assert(util_queue_fence_is_signalled(&fence->submitted));
+            sem_chunk[i].handle = fence->syncobj;
+         }
+
+         chunks[num_chunks].chunk_id = AMDGPU_CHUNK_ID_SYNCOBJ_IN;
+         chunks[num_chunks].length_dw = sizeof(sem_chunk[0]) / 4 * num_syncobj_dependencies;
+         chunks[num_chunks].chunk_data = (uintptr_t)sem_chunk;
+      }
       num_chunks++;
    }
 
    /* Syncobj signals. */
    unsigned num_syncobj_to_signal = 1 + csc->syncobj_to_signal.num;
-   struct drm_amdgpu_cs_chunk_sem *sem_chunk =
-      (struct drm_amdgpu_cs_chunk_sem *)
-      alloca(num_syncobj_to_signal * sizeof(sem_chunk[0]));
+   if (aws->info.has_timeline_syncobj) {
+      struct drm_amdgpu_cs_chunk_syncobj *sem_chunk =
+         (struct drm_amdgpu_cs_chunk_syncobj *)
+         alloca(num_syncobj_to_signal * sizeof(sem_chunk[0]));
 
-   for (unsigned i = 0; i < num_syncobj_to_signal - 1; i++) {
-      struct amdgpu_fence *fence =
-         (struct amdgpu_fence*)csc->syncobj_to_signal.list[i];
+      for (unsigned i = 0; i < csc->syncobj_to_signal.num; i++) {
+         struct amdgpu_fence *fence =
+            (struct amdgpu_fence*)csc->syncobj_to_signal.list[i].fence;
 
-      sem_chunk[i].handle = fence->syncobj;
-   }
-   sem_chunk[csc->syncobj_to_signal.num].handle = ((struct amdgpu_fence*)csc->fence)->syncobj;
+         sem_chunk[i].handle = fence->syncobj;
+         sem_chunk[i].flags = 0;
+         sem_chunk[i].point = csc->syncobj_to_signal.list[i].value;
+      }
+
+      sem_chunk[csc->syncobj_to_signal.num].handle = ((struct amdgpu_fence*)csc->fence)->syncobj;
+      sem_chunk[csc->syncobj_to_signal.num].flags = 0;
+      sem_chunk[csc->syncobj_to_signal.num].point = 0;
 
-   chunks[num_chunks].chunk_id = AMDGPU_CHUNK_ID_SYNCOBJ_OUT;
-   chunks[num_chunks].length_dw = sizeof(sem_chunk[0]) / 4 * num_syncobj_to_signal;
-   chunks[num_chunks].chunk_data = (uintptr_t)sem_chunk;
+      chunks[num_chunks].chunk_id = AMDGPU_CHUNK_ID_SYNCOBJ_TIMELINE_SIGNAL;
+      chunks[num_chunks].length_dw = sizeof(sem_chunk[0]) / 4 * num_syncobj_to_signal;
+      chunks[num_chunks].chunk_data = (uintptr_t)sem_chunk;
+   } else {
+      struct drm_amdgpu_cs_chunk_sem *sem_chunk =
+         (struct drm_amdgpu_cs_chunk_sem *)
+         alloca(num_syncobj_to_signal * sizeof(sem_chunk[0]));
+
+      for (unsigned i = 0; i < csc->syncobj_to_signal.num; i++) {
+         struct amdgpu_fence *fence =
+            (struct amdgpu_fence*)csc->syncobj_to_signal.list[i].fence;
+
+         sem_chunk[i].handle = fence->syncobj;
+      }
+
+      sem_chunk[csc->syncobj_to_signal.num].handle = ((struct amdgpu_fence*)csc->fence)->syncobj;
+
+      chunks[num_chunks].chunk_id = AMDGPU_CHUNK_ID_SYNCOBJ_TIMELINE_SIGNAL;
+      chunks[num_chunks].length_dw = sizeof(sem_chunk[0]) / 4 * num_syncobj_to_signal;
+      chunks[num_chunks].chunk_data = (uintptr_t)sem_chunk;
+   }
    num_chunks++;
 
    if (aws->info.has_fw_based_shadowing && acs->mcbp_fw_shadow_chunk.shadow_va) {
@@ -1479,54 +1527,52 @@ static int amdgpu_cs_submit_ib_userq(struct amdgpu_userq *userq,
    struct amdgpu_winsys *aws = acs->aws;
    struct amdgpu_cs_context *csc = amdgpu_csc_get_submitted(acs);
 
-   /* Syncobj dependencies. */
-   unsigned num_syncobj_dependencies = csc->syncobj_dependencies.num;
+   /* Syncobj dependencies. Adding 1 for vm timeline. */
+   unsigned num_syncobj_dependencies = csc->syncobj_dependencies.num + 1;
    uint32_t *syncobj_dependencies_list =
       (uint32_t*)alloca(num_syncobj_dependencies * sizeof(uint32_t));
+   uint64_t *syncobj_dependencies_points =
+      (uint64_t*)alloca(num_syncobj_dependencies * sizeof(uint64_t));
 
-   /* Currently only 1 vm timeline syncobj can be a dependency. */
-   uint16_t num_syncobj_timeline_dependencies = 1;
-   uint32_t syncobj_timeline_dependency;
-   uint64_t syncobj_timeline_dependency_point;
-
-   if (num_syncobj_dependencies) {
-      for (unsigned i = 0; i < num_syncobj_dependencies; i++) {
-         struct amdgpu_fence *fence =
-            (struct amdgpu_fence*)csc->syncobj_dependencies.list[i];
+   for (unsigned i = 0; i < csc->syncobj_dependencies.num; i++) {
+      struct amdgpu_fence *fence =
+         (struct amdgpu_fence*)csc->syncobj_dependencies.list[i].fence;
 
-         assert(util_queue_fence_is_signalled(&fence->submitted));
-         syncobj_dependencies_list[i] = fence->syncobj;
-      }
+      assert(util_queue_fence_is_signalled(&fence->submitted));
+      syncobj_dependencies_list[i] = fence->syncobj;
+      syncobj_dependencies_points[i] = csc->syncobj_dependencies.list[i].value;
    }
-   syncobj_timeline_dependency = aws->vm_timeline_syncobj;
-   syncobj_timeline_dependency_point = vm_timeline_point;
+   syncobj_dependencies_list[num_syncobj_dependencies - 1] = aws->vm_timeline_syncobj;
+   syncobj_dependencies_points[num_syncobj_dependencies - 1] = vm_timeline_point;
 
    /* Syncobj signals. Adding 1 for cs submission fence. */
    unsigned num_syncobj_to_signal = csc->syncobj_to_signal.num + 1;
    uint32_t *syncobj_signal_list =
       (uint32_t*)alloca(num_syncobj_to_signal * sizeof(uint32_t));
+   uint64_t *syncobj_signal_points =
+      (uint64_t*)alloca(num_syncobj_to_signal * sizeof(uint64_t));
 
    for (unsigned i = 0; i < csc->syncobj_to_signal.num; i++) {
       struct amdgpu_fence *fence =
-         (struct amdgpu_fence*)csc->syncobj_to_signal.list[i];
+         (struct amdgpu_fence*)csc->syncobj_to_signal.list[i].fence;
 
       syncobj_signal_list[i] = fence->syncobj;
+      syncobj_signal_points[i] = csc->syncobj_to_signal.list[i].value;
    }
    syncobj_signal_list[num_syncobj_to_signal - 1] = ((struct amdgpu_fence*)csc->fence)->syncobj;
+   syncobj_signal_points[num_syncobj_to_signal - 1] = 0;
 
    struct drm_amdgpu_userq_fence_info *fence_info;
    struct drm_amdgpu_userq_wait userq_wait_data = {
       .queue_id = userq->userq_handle,
-      .syncobj_handles = (uintptr_t)syncobj_dependencies_list,
-      .syncobj_timeline_handles = (uintptr_t)&syncobj_timeline_dependency,
-      .syncobj_timeline_points = (uintptr_t)&syncobj_timeline_dependency_point,
+      .syncobj_timeline_handles = (uintptr_t)syncobj_dependencies_list,
+      .syncobj_timeline_points = (uintptr_t)syncobj_dependencies_points,
       /* Wait for previous reads/writes to complete before writing to these BOs. */
       .bo_read_handles = (uintptr_t)shared_buf_kms_handles_write,
       /* Wait for previous writes to complete before reading from these BOs. */
       .bo_write_handles = (uintptr_t)shared_buf_kms_handles_read,
-      .num_syncobj_timeline_handles = num_syncobj_timeline_dependencies,
+      .num_syncobj_timeline_handles = (uint16_t)num_syncobj_dependencies,
       .num_fences = 0,
-      .num_syncobj_handles = num_syncobj_dependencies,
       .num_bo_read_handles = num_shared_buf_write,
       .num_bo_write_handles = num_shared_buf_read,
       .out_fences = (uintptr_t)NULL,
@@ -1561,6 +1607,7 @@ static int amdgpu_cs_submit_ib_userq(struct amdgpu_userq *userq,
       .bo_write_handles = (uintptr_t)shared_buf_kms_handles_write,
       .num_bo_read_handles = num_shared_buf_read,
       .num_bo_write_handles = num_shared_buf_write,
+      .syncobj_points = (uintptr_t)syncobj_signal_points,
    };
 
 #if DETECT_CC_GCC && (DETECT_ARCH_X86 || DETECT_ARCH_X86_64)
@@ -1914,7 +1961,7 @@ static void amdgpu_cs_submit_ib(void *job, void *gdata, int thread_index)
          if (amdgpu_fence_wait(*fence, 0, false))
             amdgpu_fence_reference(fence, NULL);
          else
-            add_fence_to_list(&csc->syncobj_dependencies, (struct amdgpu_fence*)*fence);
+            add_fence_to_list(&csc->syncobj_dependencies, (struct amdgpu_fence*)*fence, 0);
       }
    }
 
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.h b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.h
index 982ea0b5cb1b2..67ac6d995c839 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.h
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.h
@@ -69,8 +69,13 @@ struct amdgpu_ib {
    bool                    is_chained_ib;
 };
 
+struct amdgpu_fence_entry {
+   struct pipe_fence_handle    *fence;
+   uint64_t                    value;
+};
+
 struct amdgpu_fence_list {
-   struct pipe_fence_handle    **list;
+   struct amdgpu_fence_entry   *list;
    unsigned                    num;
    unsigned                    max;
 };
diff --git a/src/gallium/winsys/radeon/drm/radeon_drm_cs.c b/src/gallium/winsys/radeon/drm/radeon_drm_cs.c
index d6b7a8ff9edd7..225c69ed3cdf0 100644
--- a/src/gallium/winsys/radeon/drm/radeon_drm_cs.c
+++ b/src/gallium/winsys/radeon/drm/radeon_drm_cs.c
@@ -831,7 +831,8 @@ static struct pipe_fence_handle *radeon_drm_cs_get_next_fence(struct radeon_cmdb
 
 static void
 radeon_drm_cs_add_fence_dependency(struct radeon_cmdbuf *rcs,
-                                   struct pipe_fence_handle *fence)
+                                   struct pipe_fence_handle *fence,
+                                   uint64_t value)
 {
    /* TODO: Handle the following unlikely multi-threaded scenario:
     *
-- 
GitLab


From 638c5e70f9889c6bd7c46b25045367ce352e4af0 Mon Sep 17 00:00:00 2001
From: David Rosca <david.rosca@amd.com>
Date: Fri, 12 Sep 2025 15:58:37 +0200
Subject: [PATCH 3/4] radeonsi: Support NV_timeline_semaphore

---
 src/gallium/drivers/radeonsi/si_fence.c | 15 +++++++--------
 src/gallium/drivers/radeonsi/si_get.c   |  2 ++
 2 files changed, 9 insertions(+), 8 deletions(-)

diff --git a/src/gallium/drivers/radeonsi/si_fence.c b/src/gallium/drivers/radeonsi/si_fence.c
index 5b13f4dc4189c..822cf87a00f47 100644
--- a/src/gallium/drivers/radeonsi/si_fence.c
+++ b/src/gallium/drivers/radeonsi/si_fence.c
@@ -166,16 +166,16 @@ void si_cp_wait_mem(struct si_context *ctx, struct radeon_cmdbuf *cs, uint64_t v
    radeon_end();
 }
 
-static void si_add_fence_dependency(struct si_context *sctx, struct pipe_fence_handle *fence)
+static void si_add_fence_dependency(struct si_context *sctx, struct pipe_fence_handle *fence, uint64_t value)
 {
    struct radeon_winsys *ws = sctx->ws;
 
-   ws->cs_add_fence_dependency(&sctx->gfx_cs, fence, 0);
+   ws->cs_add_fence_dependency(&sctx->gfx_cs, fence, value);
 }
 
-static void si_add_syncobj_signal(struct si_context *sctx, struct pipe_fence_handle *fence)
+static void si_add_syncobj_signal(struct si_context *sctx, struct pipe_fence_handle *fence, uint64_t value)
 {
-   sctx->ws->cs_add_syncobj_signal(&sctx->gfx_cs, fence, 0);
+   sctx->ws->cs_add_syncobj_signal(&sctx->gfx_cs, fence, value);
 }
 
 static void si_fence_reference(struct pipe_screen *screen, struct pipe_fence_handle **dst,
@@ -392,6 +392,7 @@ static void si_create_fence_fd(struct pipe_context *ctx, struct pipe_fence_handl
       break;
 
    case PIPE_FD_TYPE_SYNCOBJ:
+   case PIPE_FD_TYPE_TIMELINE_SEMAPHORE_VK:
       if (!sscreen->info.has_syncobj)
          goto finish;
 
@@ -558,12 +559,11 @@ static void si_fence_server_signal(struct pipe_context *ctx, struct pipe_fence_h
 {
    struct si_context *sctx = (struct si_context *)ctx;
    struct si_fence *sfence = (struct si_fence *)fence;
-   assert(!value);
 
    assert(sfence->gfx);
 
    if (sfence->gfx)
-      si_add_syncobj_signal(sctx, sfence->gfx);
+      si_add_syncobj_signal(sctx, sfence->gfx, value);
 
    /**
     * The spec requires a flush here. We insert a flush
@@ -587,7 +587,6 @@ static void si_fence_server_sync(struct pipe_context *ctx, struct pipe_fence_han
 {
    struct si_context *sctx = (struct si_context *)ctx;
    struct si_fence *sfence = (struct si_fence *)fence;
-   assert(!value);
 
    util_queue_fence_wait(&sfence->ready);
 
@@ -606,7 +605,7 @@ static void si_fence_server_sync(struct pipe_context *ctx, struct pipe_fence_han
     * performance. Therefore, DO NOT FLUSH.
     */
    if (sfence->gfx)
-      si_add_fence_dependency(sctx, sfence->gfx);
+      si_add_fence_dependency(sctx, sfence->gfx, value);
 }
 
 void si_init_fence_functions(struct si_context *ctx)
diff --git a/src/gallium/drivers/radeonsi/si_get.c b/src/gallium/drivers/radeonsi/si_get.c
index 7c8ab6dd77b35..e2497d5a5d707 100644
--- a/src/gallium/drivers/radeonsi/si_get.c
+++ b/src/gallium/drivers/radeonsi/si_get.c
@@ -1276,6 +1276,8 @@ void si_init_screen_caps(struct si_screen *sscreen)
     */
    caps->max_texture_lod_bias = 16;
 
+   caps->max_timeline_semaphore_difference = sscreen->info.has_timeline_syncobj ? UINT64_MAX : 0;
+
    if (sscreen->ws->va_range)
       sscreen->ws->va_range(sscreen->ws, &caps->min_vma, &caps->max_vma);
 }
-- 
GitLab


From 05eefbb7e9cc183f635ce137d434432d5a13a64f Mon Sep 17 00:00:00 2001
From: David Rosca <david.rosca@amd.com>
Date: Tue, 23 Sep 2025 14:47:35 +0200
Subject: [PATCH 4/4] radeonsi: Add RADEON_FLUSH_FORCE and use it to force
 flush

Forcing flush by setting initial_gfx_cs_size to zero requires
there are always packets emitted on starting new gfx IB.
But this is not the case with userq, as there is no preamble.
Add a new flag to be used with si_flush_gfx_cs to force flush.
---
 src/gallium/drivers/radeonsi/si_fence.c           | 4 ++--
 src/gallium/drivers/radeonsi/si_gfx_cs.c          | 2 +-
 src/gallium/drivers/radeonsi/si_state_shaders.cpp | 3 +--
 src/gallium/include/winsys/radeon_winsys.h        | 3 +++
 4 files changed, 7 insertions(+), 5 deletions(-)

diff --git a/src/gallium/drivers/radeonsi/si_fence.c b/src/gallium/drivers/radeonsi/si_fence.c
index 822cf87a00f47..ba43fbb2a0dce 100644
--- a/src/gallium/drivers/radeonsi/si_fence.c
+++ b/src/gallium/drivers/radeonsi/si_fence.c
@@ -471,10 +471,10 @@ static void si_flush_all_queues(struct pipe_context *ctx,
    }
 
    if (force_flush) {
-      sctx->initial_gfx_cs_size = 0;
+      rflags |= RADEON_FLUSH_FORCE;
    }
 
-   if (!radeon_emitted(&sctx->gfx_cs, sctx->initial_gfx_cs_size)) {
+   if (!force_flush && !radeon_emitted(&sctx->gfx_cs, sctx->initial_gfx_cs_size)) {
       if (fence)
          ws->fence_reference(ws, &gfx_fence, sctx->last_gfx_fence);
       if (!(flags & PIPE_FLUSH_DEFERRED))
diff --git a/src/gallium/drivers/radeonsi/si_gfx_cs.c b/src/gallium/drivers/radeonsi/si_gfx_cs.c
index 082b449e71d35..e08e6f72ae28e 100644
--- a/src/gallium/drivers/radeonsi/si_gfx_cs.c
+++ b/src/gallium/drivers/radeonsi/si_gfx_cs.c
@@ -112,7 +112,7 @@ void si_flush_gfx_cs(struct si_context *ctx, unsigned flags, struct pipe_fence_h
    /* Drop this flush if it's a no-op. */
    if (!radeon_emitted(cs, ctx->initial_gfx_cs_size) &&
        (!wait_flags || !ctx->gfx_last_ib_is_busy) &&
-       !(flags & RADEON_FLUSH_TOGGLE_SECURE_SUBMISSION)) {
+       !(flags & (RADEON_FLUSH_TOGGLE_SECURE_SUBMISSION | RADEON_FLUSH_FORCE))) {
       tc_driver_internal_flush_notify(ctx->tc);
       return;
    }
diff --git a/src/gallium/drivers/radeonsi/si_state_shaders.cpp b/src/gallium/drivers/radeonsi/si_state_shaders.cpp
index 0bea02ec0cdcb..faecdde3f8df1 100644
--- a/src/gallium/drivers/radeonsi/si_state_shaders.cpp
+++ b/src/gallium/drivers/radeonsi/si_state_shaders.cpp
@@ -4267,8 +4267,7 @@ bool si_update_gs_ring_buffers(struct si_context *sctx)
    }
 
    /* Flush the context to re-emit both cs_preamble states. */
-   sctx->initial_gfx_cs_size = 0; /* force flush */
-   si_flush_gfx_cs(sctx, RADEON_FLUSH_ASYNC_START_NEXT_GFX_IB_NOW, NULL);
+   si_flush_gfx_cs(sctx, RADEON_FLUSH_ASYNC_START_NEXT_GFX_IB_NOW | RADEON_FLUSH_FORCE, NULL);
 
    return true;
 }
diff --git a/src/gallium/include/winsys/radeon_winsys.h b/src/gallium/include/winsys/radeon_winsys.h
index 9d83236912875..292aa91aa5d45 100644
--- a/src/gallium/include/winsys/radeon_winsys.h
+++ b/src/gallium/include/winsys/radeon_winsys.h
@@ -11,6 +11,9 @@
 
 /* The public winsys interface header for the radeon driver. */
 
+/* Force flush. */
+#define RADEON_FLUSH_FORCE                    (1u << 28)
+
 /* Skip command submission. Same as RADEON_NOOP=1. */
 #define RADEON_FLUSH_NOOP                     (1u << 29)
 
-- 
GitLab

