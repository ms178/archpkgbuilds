From 43b69cceeae346dba54f126efc81577b68238d04 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Fri, 5 Jan 2024 17:37:33 +0000
Subject: [PATCH 1/4] nir: add mqsad_4x8 and nir_opt_mqsad

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/compiler/nir/meson.build               |   1 +
 src/compiler/nir/nir.h                     |   2 +
 src/compiler/nir/nir_lower_alu_width.c     |   1 +
 src/compiler/nir/nir_opcodes.py            |   8 +
 src/compiler/nir/nir_opt_mqsad.c           | 187 +++++++++++++++++++++
 src/compiler/nir/tests/algebraic_tests.cpp |  67 +++++++-
 6 files changed, 260 insertions(+), 6 deletions(-)
 create mode 100644 src/compiler/nir/nir_opt_mqsad.c

diff --git a/src/compiler/nir/meson.build b/src/compiler/nir/meson.build
index 2edbc6bcfe6d0..3535ffff18d58 100644
--- a/src/compiler/nir/meson.build
+++ b/src/compiler/nir/meson.build
@@ -257,6 +257,7 @@ files_libnir = files(
   'nir_opt_memcpy.c',
   'nir_opt_move.c',
   'nir_opt_move_discards_to_top.c',
+  'nir_opt_mqsad.c',
   'nir_opt_non_uniform_access.c',
   'nir_opt_offsets.c',
   'nir_opt_peephole_select.c',
diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index 61c2b4bc884a5..a1bfd64f9fe3b 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -6303,6 +6303,8 @@ bool nir_opt_gcm(nir_shader *shader, bool value_number);
 
 bool nir_opt_idiv_const(nir_shader *shader, unsigned min_bit_size);
 
+bool nir_opt_mqsad(nir_shader *shader);
+
 typedef enum {
    nir_opt_if_optimize_phi_true_false = (1 << 0),
    nir_opt_if_avoid_64bit_phis = (1 << 1),
diff --git a/src/compiler/nir/nir_lower_alu_width.c b/src/compiler/nir/nir_lower_alu_width.c
index 0d3f4e9feb346..b8ee78a200582 100644
--- a/src/compiler/nir/nir_lower_alu_width.c
+++ b/src/compiler/nir/nir_lower_alu_width.c
@@ -232,6 +232,7 @@ lower_alu_instr_width(nir_builder *b, nir_instr *instr, void *_data)
    case nir_op_unpack_snorm_4x8:
    case nir_op_unpack_unorm_2x16:
    case nir_op_unpack_snorm_2x16:
+   case nir_op_mqsad_4x8:
       /* There is no scalar version of these ops, unless we were to break it
        * down to bitshifts and math (which is definitely not intended).
        */
diff --git a/src/compiler/nir/nir_opcodes.py b/src/compiler/nir/nir_opcodes.py
index 0770351c98821..b415575df06fa 100644
--- a/src/compiler/nir/nir_opcodes.py
+++ b/src/compiler/nir/nir_opcodes.py
@@ -1138,6 +1138,14 @@ then add them together. There is also a third source which is a 32-bit unsigned
 integer and added to the result.
 """)
 
+opcode("mqsad_4x8", 4, tuint32, [1, 2, 4], [tuint32, tuint32, tuint32], False, "", """
+uint64_t src = src1.x | ((uint64_t)src1.y << 32);
+dst.x = msad(src0.x, src, src2.x);
+dst.y = msad(src0.x, src >> 8, src2.y);
+dst.z = msad(src0.x, src >> 16, src2.z);
+dst.w = msad(src0.x, src >> 24, src2.w);
+""")
+
 # Combines the first component of each input to make a 3-component vector.
 
 triop_horiz("vec3", 3, 1, 1, 1, """
diff --git a/src/compiler/nir/nir_opt_mqsad.c b/src/compiler/nir/nir_opt_mqsad.c
new file mode 100644
index 0000000000000..e5ee5e757b40f
--- /dev/null
+++ b/src/compiler/nir/nir_opt_mqsad.c
@@ -0,0 +1,187 @@
+/*
+ * Copyright 2023 Valve Corporation
+ * SPDX-License-Identifier: MIT
+ */
+#include "nir.h"
+#include "nir_builder.h"
+#include "nir_worklist.h"
+
+/*
+ * This pass recognizes certain patterns of rotates and nir_op_msad_4x8 and replaces it
+ * with a single nir_op_mqsad_4x8 instruction.
+ */
+
+static bool
+parse_shift(nir_scalar *s, bool shl, unsigned amount)
+{
+   if (!nir_scalar_is_alu(*s))
+      return false;
+
+   if (nir_scalar_alu_op(*s) == (shl ? nir_op_ishl : nir_op_ushr)) {
+      amount *= 8;
+   } else if (nir_scalar_alu_op(*s) == (shl ? nir_op_insert_u16 : nir_op_extract_u16) && amount == 2) {
+      amount = 1;
+   } else if (!(nir_scalar_alu_op(*s) == (shl ? nir_op_insert_u8 : nir_op_extract_u8) && amount == 3)) {
+      return false;
+   }
+
+   nir_scalar amount_s = nir_scalar_chase_alu_src(*s, 1);
+   if (!nir_scalar_is_const(amount_s) || nir_scalar_as_uint(amount_s) != amount)
+      return false;
+
+   *s = nir_scalar_chase_alu_src(*s, 0);
+   return true;
+}
+
+static bool
+parse_ror(nir_scalar s, nir_scalar *low, nir_scalar *high, unsigned *bytes)
+{
+   if (!nir_scalar_is_alu(s) || nir_scalar_alu_op(s) != nir_op_bitfield_select)
+      return false;
+
+   nir_scalar mask_s = nir_scalar_chase_alu_src(s, 0);
+   if (!nir_scalar_is_const(mask_s))
+      return false;
+
+   uint32_t mask = nir_scalar_as_uint(mask_s);
+   *bytes = util_bitcount(mask) / 8u;
+   if (*bytes < 1 || *bytes > 3 || mask != ~(uint32_t)(0xffffffff >> (*bytes * 8)))
+      return false;
+
+   *low = nir_scalar_chase_alu_src(s, 2);
+   *high = nir_scalar_chase_alu_src(s, 1);
+   if (!parse_shift(low, false, *bytes))
+      return false;
+   if (!parse_shift(high, true, 4 - *bytes))
+      return false;
+
+   return true;
+}
+
+struct mqsad {
+   nir_scalar ref;
+   nir_scalar src[2];
+
+   nir_scalar accum[4];
+   nir_alu_instr *msad[4];
+   unsigned first_msad_index;
+   uint8_t mask;
+};
+
+static bool
+is_mqsad_compatible(struct mqsad *mqsad, nir_scalar ref, nir_scalar src0, nir_scalar src1,
+                    unsigned idx, nir_alu_instr *msad)
+{
+   if (!nir_scalar_equal(ref, mqsad->ref) || !nir_scalar_equal(src0, mqsad->src[0]))
+      return false;
+   if ((mqsad->mask & 0b1110) && idx && !nir_scalar_equal(src1, mqsad->src[1]))
+      return false;
+
+   /* Ensure that this MSAD doesn't depend on any previous MSAD. */
+   nir_instr_worklist *wl = nir_instr_worklist_create();
+   nir_instr_worklist_add_ssa_srcs(wl, &msad->instr);
+   nir_foreach_instr_in_worklist(instr, wl) {
+      if (instr->block != msad->instr.block || instr->index < mqsad->first_msad_index)
+         continue;
+
+      for (unsigned i = 0; i < 4; i++) {
+         if (instr == &mqsad->msad[i]->instr) {
+            nir_instr_worklist_destroy(wl);
+            return false;
+         }
+      }
+
+      nir_instr_worklist_add_ssa_srcs(wl, instr);
+   }
+   nir_instr_worklist_destroy(wl);
+
+   return true;
+}
+
+static void
+parse_msad(nir_alu_instr *msad, struct mqsad *mqsad)
+{
+   if (msad->def.num_components != 1)
+      return;
+
+   nir_scalar msad_s = nir_get_scalar(&msad->def, 0);
+   nir_scalar ref = nir_scalar_chase_alu_src(msad_s, 0);
+   nir_scalar accum = nir_scalar_chase_alu_src(msad_s, 2);
+
+   nir_scalar src0, src1;
+   unsigned idx;
+   if (!parse_ror(nir_scalar_chase_alu_src(msad_s, 1), &src0, &src1, &idx)) {
+      idx = 0;
+      src0 = nir_scalar_chase_alu_src(msad_s, 1);
+   }
+
+   if (mqsad->mask && !is_mqsad_compatible(mqsad, ref, src0, src1, idx, msad))
+      memset(mqsad, 0, sizeof(*mqsad));
+
+   /* Add this instruction to the in-progress MQSAD. */
+   mqsad->ref = ref;
+   mqsad->src[0] = src0;
+   if (idx)
+      mqsad->src[1] = src1;
+
+   mqsad->accum[idx] = accum;
+   mqsad->msad[idx] = msad;
+   if (!mqsad->mask)
+      mqsad->first_msad_index = msad->instr.index;
+   mqsad->mask |= 1 << idx;
+}
+
+static void
+create_msad(nir_builder *b, struct mqsad *mqsad)
+{
+   nir_def *mqsad_def = nir_mqsad_4x8(b, nir_channel(b, mqsad->ref.def, mqsad->ref.comp),
+                                      nir_vec_scalars(b, mqsad->src, 2),
+                                      nir_vec_scalars(b, mqsad->accum, 4));
+
+   for (unsigned i = 0; i < 4; i++)
+      nir_def_rewrite_uses(&mqsad->msad[i]->def, nir_channel(b, mqsad_def, i));
+
+   memset(mqsad, 0, sizeof(*mqsad));
+}
+
+bool
+nir_opt_mqsad(nir_shader *shader)
+{
+   bool progress = false;
+   nir_foreach_function_impl(impl, shader) {
+      bool progress_impl = false;
+
+      nir_metadata_require(impl, nir_metadata_instr_index);
+
+      nir_foreach_block(block, impl) {
+         struct mqsad mqsad;
+         memset(&mqsad, 0, sizeof(mqsad));
+
+         nir_foreach_instr(instr, block) {
+            if (instr->type != nir_instr_type_alu)
+               continue;
+
+            nir_alu_instr *alu = nir_instr_as_alu(instr);
+            if (alu->op != nir_op_msad_4x8)
+               continue;
+
+            parse_msad(alu, &mqsad);
+
+            if (mqsad.mask == 0xf) {
+               nir_builder b = nir_builder_at(nir_before_instr(instr));
+               create_msad(&b, &mqsad);
+               progress_impl = true;
+            }
+         }
+      }
+
+      if (progress_impl) {
+         nir_metadata_preserve(impl, nir_metadata_block_index | nir_metadata_dominance);
+         progress = true;
+      } else {
+         nir_metadata_preserve(impl, nir_metadata_block_index);
+      }
+   }
+
+   return progress;
+}
diff --git a/src/compiler/nir/tests/algebraic_tests.cpp b/src/compiler/nir/tests/algebraic_tests.cpp
index a6fcc660efade..3d1ef8dd90980 100644
--- a/src/compiler/nir/tests/algebraic_tests.cpp
+++ b/src/compiler/nir/tests/algebraic_tests.cpp
@@ -37,6 +37,8 @@ protected:
 
    void test_2src_op(nir_op op, int64_t src0, int64_t src1);
 
+   void require_one_alu(nir_op op);
+
    nir_variable *res_var;
 };
 
@@ -85,6 +87,18 @@ void algebraic_test_base::test_2src_op(nir_op op, int64_t src0, int64_t src1)
    test_op(op, nir_imm_int(b, src0), nir_imm_int(b, src1), NULL, NULL, desc);
 }
 
+void algebraic_test_base::require_one_alu(nir_op op)
+{
+   unsigned count = 0;
+   nir_foreach_instr(instr, nir_start_block(b->impl)) {
+      if (instr->type == nir_instr_type_alu) {
+         ASSERT_TRUE(nir_instr_as_alu(instr)->op == op);
+         ASSERT_EQ(count, 0);
+         count++;
+      }
+   }
+}
+
 class nir_opt_algebraic_test : public algebraic_test_base {
 protected:
    virtual void run_pass() {
@@ -99,6 +113,13 @@ protected:
    }
 };
 
+class nir_opt_mqsad_test : public algebraic_test_base {
+protected:
+   virtual void run_pass() {
+      nir_opt_mqsad(b->shader);
+   }
+};
+
 TEST_F(nir_opt_algebraic_test, umod_pow2_src2)
 {
    for (int i = 0; i <= 9; i++)
@@ -162,14 +183,48 @@ TEST_F(nir_opt_algebraic_test, msad)
       nir_opt_dce(b->shader);
    }
 
-   unsigned count = 0;
-   nir_foreach_instr(instr, nir_start_block(b->impl)) {
-      if (instr->type == nir_instr_type_alu) {
-         ASSERT_TRUE(nir_instr_as_alu(instr)->op == nir_op_msad_4x8);
-         ASSERT_EQ(count, 0);
-         count++;
+   require_one_alu(nir_op_msad_4x8);
+}
+
+TEST_F(nir_opt_mqsad_test, mqsad)
+{
+   nir_def *ref = nir_load_var(b, nir_local_variable_create(b->impl, glsl_int_type(), "ref"));
+   nir_def *src = nir_load_var(b, nir_local_variable_create(b->impl, glsl_ivec_type(2), "src"));
+   nir_def *accum = nir_load_var(b, nir_local_variable_create(b->impl, glsl_ivec_type(4), "accum"));
+
+   nir_def *srcx = nir_channel(b, src, 0);
+   nir_def *srcy = nir_channel(b, src, 1);
+
+   nir_def *res[4];
+   for (unsigned i = 0; i < 4; i++) {
+      nir_def *src1 = srcx;
+      switch (i) {
+      case 0:
+         break;
+      case 1:
+         src1 = nir_bitfield_select(b, nir_imm_int(b, 0xff000000), nir_ishl_imm(b, srcy, 24),
+                                    nir_ushr_imm(b, srcx, 8));
+         break;
+      case 2:
+         src1 = nir_bitfield_select(b, nir_imm_int(b, 0xffff0000), nir_ishl_imm(b, srcy, 16),
+                                    nir_extract_u16(b, srcx, nir_imm_int(b, 1)));
+         break;
+      case 3:
+         src1 = nir_bitfield_select(b, nir_imm_int(b, 0xffffff00), nir_ishl_imm(b, srcy, 8),
+                                    nir_extract_u8_imm(b, srcx, 3));
+         break;
       }
+
+      res[i] = nir_msad_4x8(b, ref, src1, nir_channel(b, accum, i));
    }
+
+   nir_store_var(b, nir_local_variable_create(b->impl, glsl_ivec_type(4), "res"), nir_vec(b, res, 4), 0xf);
+
+   ASSERT_TRUE(nir_opt_mqsad(b->shader));
+   nir_copy_prop(b->shader);
+   nir_opt_dce(b->shader);
+
+   require_one_alu(nir_op_mqsad_4x8);
 }
 
 TEST_F(nir_opt_idiv_const_test, umod)
-- 
GitLab


From 7bcaa133693c58a3352865a4b2d29d9b09b9b596 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Fri, 5 Jan 2024 17:38:40 +0000
Subject: [PATCH 2/4] aco: implement mqsad_4x8

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/aco_instruction_selection.cpp      | 13 +++++++++++++
 .../compiler/aco_instruction_selection_setup.cpp    |  1 +
 src/amd/compiler/aco_opcodes.py                     |  2 +-
 3 files changed, 15 insertions(+), 1 deletion(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 1fe6918aa51f1..6746aab5b5638 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -3425,6 +3425,19 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
       emit_vop3a_instruction(ctx, instr, aco_opcode::v_msad_u8, dst, false, 3u, true);
       break;
    }
+   case nir_op_mqsad_4x8: {
+      assert(dst.regClass() == v4);
+      Temp ref = get_alu_src(ctx, instr->src[0]);
+      Temp src = get_alu_src(ctx, instr->src[1], 2);
+      Temp accum = get_alu_src(ctx, instr->src[2], 4);
+      Builder::Result res = bld.vop3(aco_opcode::v_mqsad_u32_u8, Definition(dst), as_vgpr(ctx, src),
+                                     as_vgpr(ctx, ref), as_vgpr(ctx, accum));
+      res.instr->operands[0].setLateKill(true);
+      res.instr->operands[1].setLateKill(true);
+      res.instr->operands[2].setLateKill(true);
+      emit_split_vector(ctx, dst, 4);
+      break;
+   }
    case nir_op_fquantize2f16: {
       Temp src = get_alu_src(ctx, instr->src[0]);
       Temp f16;
diff --git a/src/amd/compiler/aco_instruction_selection_setup.cpp b/src/amd/compiler/aco_instruction_selection_setup.cpp
index 32e9a08a80867..178b7d38221ec 100644
--- a/src/amd/compiler/aco_instruction_selection_setup.cpp
+++ b/src/amd/compiler/aco_instruction_selection_setup.cpp
@@ -393,6 +393,7 @@ init_context(isel_context* ctx, nir_shader* shader)
                case nir_op_frexp_exp:
                case nir_op_cube_amd:
                case nir_op_msad_4x8:
+               case nir_op_mqsad_4x8:
                case nir_op_udot_4x8_uadd:
                case nir_op_sdot_4x8_iadd:
                case nir_op_sudot_4x8_iadd:
diff --git a/src/amd/compiler/aco_opcodes.py b/src/amd/compiler/aco_opcodes.py
index 1cf23b5e061b7..743ce9a141dbe 100644
--- a/src/amd/compiler/aco_opcodes.py
+++ b/src/amd/compiler/aco_opcodes.py
@@ -1175,7 +1175,7 @@ VOP3 = {
    (0x172, 0x172, 0x1e5, 0x1e5, 0x172, 0x23a, "v_qsad_pk_u16_u8", False, False, dst(2), src(2, 1, 2)),
    (0x173, 0x173, 0x1e6, 0x1e6, 0x173, 0x23b, "v_mqsad_pk_u16_u8", False, False, dst(2), src(2, 1, 2)),
    (0x174, 0x174, 0x292, 0x292, 0x174, 0x32f, "v_trig_preop_f64", False, False, dst(2), src(2, 2), InstrClass.ValuDouble),
-   (   -1, 0x175, 0x1e7, 0x1e7, 0x175, 0x23d, "v_mqsad_u32_u8", False, False, dst(4), src(2, 1, 4)),
+   (   -1, 0x175, 0x1e7, 0x1e7, 0x175, 0x23d, "v_mqsad_u32_u8", False, False, dst(4), src(2, 1, 4), InstrClass.ValuQuarterRate32),
    (   -1, 0x176, 0x1e8, 0x1e8, 0x176, 0x2fe, "v_mad_u64_u32", False, False, dst(2, VCC), src(1, 1, 2), InstrClass.Valu64),
    (   -1, 0x177, 0x1e9, 0x1e9, 0x177, 0x2ff, "v_mad_i64_i32", False, False, dst(2, VCC), src(1, 1, 2), InstrClass.Valu64),
    (   -1,    -1, 0x1ea, 0x1ea,    -1,    -1, "v_mad_legacy_f16", True, True, dst(1), src(1, 1, 1)),
-- 
GitLab


From 1120e9d91bfdad9b55e3af68601b70d8438aadf4 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Fri, 5 Jan 2024 17:40:25 +0000
Subject: [PATCH 3/4] ac/llvm: implement mqsad_4x8

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/llvm/ac_nir_to_llvm.c | 37 ++++++-----------------------------
 1 file changed, 6 insertions(+), 31 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 06dfaed1a39bb..ac6efb418a3b4 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -542,41 +542,11 @@ static bool visit_alu(struct ac_nir_context *ctx, const nir_alu_instr *instr)
 {
    LLVMValueRef src[16], result = NULL;
    unsigned num_components = instr->def.num_components;
-   unsigned src_components;
    LLVMTypeRef def_type = get_def_type(ctx, &instr->def);
 
    assert(nir_op_infos[instr->op].num_inputs <= ARRAY_SIZE(src));
-   switch (instr->op) {
-   case nir_op_vec2:
-   case nir_op_vec3:
-   case nir_op_vec4:
-   case nir_op_vec5:
-   case nir_op_vec8:
-   case nir_op_vec16:
-   case nir_op_unpack_32_4x8:
-   case nir_op_unpack_32_2x16:
-   case nir_op_unpack_64_2x32:
-   case nir_op_unpack_64_4x16:
-      src_components = 1;
-      break;
-   case nir_op_pack_snorm_2x16:
-   case nir_op_pack_unorm_2x16:
-   case nir_op_pack_uint_2x16:
-   case nir_op_pack_sint_2x16:
-      src_components = 2;
-      break;
-   case nir_op_cube_amd:
-      src_components = 3;
-      break;
-   case nir_op_pack_32_4x8:
-      src_components = 4;
-      break;
-   default:
-      src_components = num_components;
-      break;
-   }
    for (unsigned i = 0; i < nir_op_infos[instr->op].num_inputs; i++)
-      src[i] = get_alu_src(ctx, instr->src[i], src_components);
+      src[i] = get_alu_src(ctx, instr->src[i], nir_ssa_alu_instr_src_components(instr, i));
 
    switch (instr->op) {
    case nir_op_mov:
@@ -1258,6 +1228,11 @@ static bool visit_alu(struct ac_nir_context *ctx, const nir_alu_instr *instr)
                                   (LLVMValueRef[]){src[1], src[0], src[2]}, 3, 0);
       break;
 
+   case nir_op_mqsad_4x8:
+      result = ac_build_intrinsic(&ctx->ac, "llvm.amdgcn.mqsad.u32.u8", ctx->ac.v4i32,
+                                  (LLVMValueRef[]){src[1], src[0], src[2]}, 3, 0);
+      break;
+
    default:
       fprintf(stderr, "Unknown NIR alu instr: ");
       nir_print_instr(&instr->instr, stderr);
-- 
GitLab


From b38434d8eb23a6ded8e69fa0c83771e035655f6b Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Fri, 5 Jan 2024 17:42:41 +0000
Subject: [PATCH 4/4] radv: optimize msad_4x8 to mqsad_4x8

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/vulkan/radv_pipeline_compute.c  |  2 +-
 src/amd/vulkan/radv_pipeline_graphics.c |  2 +-
 src/amd/vulkan/radv_pipeline_rt.c       |  2 +-
 src/amd/vulkan/radv_shader.c            | 13 ++++++++++---
 src/amd/vulkan/radv_shader.h            |  2 +-
 5 files changed, 14 insertions(+), 7 deletions(-)

diff --git a/src/amd/vulkan/radv_pipeline_compute.c b/src/amd/vulkan/radv_pipeline_compute.c
index a3bbb92b58a93..ed9ff613c43a3 100644
--- a/src/amd/vulkan/radv_pipeline_compute.c
+++ b/src/amd/vulkan/radv_pipeline_compute.c
@@ -141,7 +141,7 @@ radv_compile_cs(struct radv_device *device, struct vk_pipeline_cache *cache, str
    /* Compile SPIR-V shader to NIR. */
    cs_stage->nir = radv_shader_spirv_to_nir(device, cs_stage, pipeline_key, is_internal);
 
-   radv_optimize_nir(cs_stage->nir, pipeline_key->optimisations_disabled);
+   radv_optimize_nir(device, cs_stage->nir, pipeline_key->optimisations_disabled);
 
    /* Gather info again, information such as outputs_read can be out-of-date. */
    nir_shader_gather_info(cs_stage->nir, nir_shader_get_entrypoint(cs_stage->nir));
diff --git a/src/amd/vulkan/radv_pipeline_graphics.c b/src/amd/vulkan/radv_pipeline_graphics.c
index bc693edbf9735..de9ec731a832c 100644
--- a/src/amd/vulkan/radv_pipeline_graphics.c
+++ b/src/amd/vulkan/radv_pipeline_graphics.c
@@ -2539,7 +2539,7 @@ radv_graphics_shaders_compile(struct radv_device *device, struct vk_pipeline_cac
    {
       int64_t stage_start = os_time_get_nano();
 
-      radv_optimize_nir(stages[i].nir, optimize_conservatively);
+      radv_optimize_nir(device, stages[i].nir, optimize_conservatively);
 
       /* Gather info again, information such as outputs_read can be out-of-date. */
       nir_shader_gather_info(stages[i].nir, nir_shader_get_entrypoint(stages[i].nir));
diff --git a/src/amd/vulkan/radv_pipeline_rt.c b/src/amd/vulkan/radv_pipeline_rt.c
index 0023527d0e07f..4adbcfe219fb1 100644
--- a/src/amd/vulkan/radv_pipeline_rt.c
+++ b/src/amd/vulkan/radv_pipeline_rt.c
@@ -414,7 +414,7 @@ radv_rt_nir_to_asm(struct radv_device *device, struct vk_pipeline_cache *cache,
       temp_stage.nir = shaders[i];
       radv_nir_lower_rt_abi(temp_stage.nir, pCreateInfo, &temp_stage.args, &stage->info, stack_size, i > 0, device,
                             pipeline, monolithic);
-      radv_optimize_nir(temp_stage.nir, pipeline_key->optimisations_disabled);
+      radv_optimize_nir(device, temp_stage.nir, pipeline_key->optimisations_disabled);
       radv_postprocess_nir(device, pipeline_key, &temp_stage);
 
       if (radv_can_dump_shader(device, temp_stage.nir, false))
diff --git a/src/amd/vulkan/radv_shader.c b/src/amd/vulkan/radv_shader.c
index a762fd5690d44..ed7ade3c13dd7 100644
--- a/src/amd/vulkan/radv_shader.c
+++ b/src/amd/vulkan/radv_shader.c
@@ -174,7 +174,7 @@ radv_can_dump_shader_stats(struct radv_device *device, nir_shader *nir)
 }
 
 void
-radv_optimize_nir(struct nir_shader *shader, bool optimize_conservatively)
+radv_optimize_nir(struct radv_device *device, struct nir_shader *shader, bool optimize_conservatively)
 {
    bool progress;
 
@@ -227,6 +227,13 @@ radv_optimize_nir(struct nir_shader *shader, bool optimize_conservatively)
    } while (progress && !optimize_conservatively);
    _mesa_set_destroy(skip, NULL);
 
+   if (device->physical_device->rad_info.gfx_level >= GFX7) {
+      bool mqsad = false;
+      NIR_PASS(mqsad, shader, nir_opt_mqsad);
+      if (mqsad)
+         NIR_PASS(_, shader, nir_opt_dce);
+   }
+
    NIR_PASS(progress, shader, nir_opt_shrink_vectors);
    NIR_PASS(progress, shader, nir_remove_dead_variables, nir_var_function_temp | nir_var_shader_in | nir_var_shader_out,
             NULL);
@@ -671,7 +678,7 @@ radv_shader_spirv_to_nir(struct radv_device *device, const struct radv_shader_st
    NIR_PASS(_, nir, nir_opt_shrink_stores, !device->instance->disable_shrink_image_store);
 
    if (!key->optimisations_disabled)
-      radv_optimize_nir(nir, false);
+      radv_optimize_nir(device, nir, false);
 
    /* We call nir_lower_var_copies() after the first radv_optimize_nir()
     * to remove any copies introduced by nir_opt_find_array_copies().
@@ -744,7 +751,7 @@ radv_shader_spirv_to_nir(struct radv_device *device, const struct radv_shader_st
    if (ac_nir_lower_indirect_derefs(nir, device->physical_device->rad_info.gfx_level) && !key->optimisations_disabled &&
        nir->info.stage != MESA_SHADER_COMPUTE) {
       /* Optimize the lowered code before the linking optimizations. */
-      radv_optimize_nir(nir, false);
+      radv_optimize_nir(device, nir, false);
    }
 
    return nir;
diff --git a/src/amd/vulkan/radv_shader.h b/src/amd/vulkan/radv_shader.h
index 345526b151367..c3233742755ca 100644
--- a/src/amd/vulkan/radv_shader.h
+++ b/src/amd/vulkan/radv_shader.h
@@ -717,7 +717,7 @@ struct radv_shader_dma_submission {
 struct radv_pipeline_layout;
 struct radv_shader_stage;
 
-void radv_optimize_nir(struct nir_shader *shader, bool optimize_conservatively);
+void radv_optimize_nir(struct radv_device *device, struct nir_shader *shader, bool optimize_conservatively);
 void radv_optimize_nir_algebraic(nir_shader *shader, bool opt_offsets);
 
 void radv_postprocess_nir(struct radv_device *device, const struct radv_pipeline_key *pipeline_key,
-- 
GitLab

