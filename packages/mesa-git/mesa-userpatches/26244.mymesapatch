From 5a6456409a1d1925383b8fe312441c91063761d8 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Fri, 17 Nov 2023 10:36:42 +0800
Subject: [PATCH 1/2] aco: set MIMG unrm for GL_TEXTURE_RECTANGLE

This fixes VDPAU compositor shaders compiled by ACO.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/compiler/aco_instruction_selection.cpp | 1 +
 1 file changed, 1 insertion(+)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 72d51ac43519..449c23c68d4f 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -9897,6 +9897,7 @@ visit_tex(isel_context* ctx, nir_tex_instr* instr)
    tex->dim = dim;
    tex->dmask = dmask & 0xf;
    tex->da = da;
+   tex->unrm = instr->sampler_dim == GLSL_SAMPLER_DIM_RECT;
    tex->tfe = instr->is_sparse;
    tex->d16 = d16;
    tex->a16 = a16;
-- 
GitLab


From a0bdba5628d6db0e01e391ae540c99b50a1366d6 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Fri, 17 Nov 2023 10:46:33 +0800
Subject: [PATCH 2/2] aco: handle GL_TEXTURE_RECTANGLE in
 tg4_integer_workarounds

Ported from LLVM side lower_gather4_integer().

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 .../compiler/aco_instruction_selection.cpp    | 74 ++++++++++---------
 1 file changed, 39 insertions(+), 35 deletions(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 449c23c68d4f..f787ba6e04e1 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -9554,42 +9554,46 @@ visit_tex(isel_context* ctx, nir_tex_instr* instr)
    Temp tg4_compare_cube_wa64 = Temp();
 
    if (tg4_integer_workarounds) {
-      Temp tg4_lod = bld.copy(bld.def(v1), Operand::zero());
-      Temp size = bld.tmp(v2);
-      MIMG_instruction* tex = emit_mimg(bld, aco_opcode::image_get_resinfo, size, resource,
-                                        Operand(s4), std::vector<Temp>{tg4_lod});
-      tex->dim = dim;
-      tex->dmask = 0x3;
-      tex->da = da;
-      emit_split_vector(ctx, size, size.size());
-
       Temp half_texel[2];
-      for (unsigned i = 0; i < 2; i++) {
-         half_texel[i] = emit_extract_vector(ctx, size, i, v1);
-         half_texel[i] = bld.vop1(aco_opcode::v_cvt_f32_i32, bld.def(v1), half_texel[i]);
-         half_texel[i] = bld.vop1(aco_opcode::v_rcp_iflag_f32, bld.def(v1), half_texel[i]);
-         half_texel[i] = bld.vop2(aco_opcode::v_mul_f32, bld.def(v1),
-                                  Operand::c32(0xbf000000 /*-0.5*/), half_texel[i]);
-      }
-
-      if (instr->sampler_dim == GLSL_SAMPLER_DIM_2D && !instr->is_array) {
-         /* In vulkan, whether the sampler uses unnormalized
-          * coordinates or not is a dynamic property of the
-          * sampler. Hence, to figure out whether or not we
-          * need to divide by the texture size, we need to test
-          * the sampler at runtime. This tests the bit set by
-          * radv_init_sampler().
-          */
-         unsigned bit_idx = ffs(S_008F30_FORCE_UNNORMALIZED(1)) - 1;
-         Temp dword0 = emit_extract_vector(ctx, sampler, 0, s1);
-         Temp not_needed =
-            bld.sopc(aco_opcode::s_bitcmp0_b32, bld.def(s1, scc), dword0, Operand::c32(bit_idx));
-
-         not_needed = bool_to_vector_condition(ctx, not_needed);
-         half_texel[0] = bld.vop2(aco_opcode::v_cndmask_b32, bld.def(v1),
-                                  Operand::c32(0xbf000000 /*-0.5*/), half_texel[0], not_needed);
-         half_texel[1] = bld.vop2(aco_opcode::v_cndmask_b32, bld.def(v1),
-                                  Operand::c32(0xbf000000 /*-0.5*/), half_texel[1], not_needed);
+      if (instr->sampler_dim == GLSL_SAMPLER_DIM_RECT) {
+         half_texel[0] = half_texel[1] = bld.copy(bld.def(v1), Operand::c32(0xbf000000 /*-0.5*/));
+      } else {
+         Temp tg4_lod = bld.copy(bld.def(v1), Operand::zero());
+         Temp size = bld.tmp(v2);
+         MIMG_instruction* tex = emit_mimg(bld, aco_opcode::image_get_resinfo, size, resource,
+                                           Operand(s4), std::vector<Temp>{tg4_lod});
+         tex->dim = dim;
+         tex->dmask = 0x3;
+         tex->da = da;
+         emit_split_vector(ctx, size, size.size());
+
+         for (unsigned i = 0; i < 2; i++) {
+            half_texel[i] = emit_extract_vector(ctx, size, i, v1);
+            half_texel[i] = bld.vop1(aco_opcode::v_cvt_f32_i32, bld.def(v1), half_texel[i]);
+            half_texel[i] = bld.vop1(aco_opcode::v_rcp_iflag_f32, bld.def(v1), half_texel[i]);
+            half_texel[i] = bld.vop2(aco_opcode::v_mul_f32, bld.def(v1),
+                                     Operand::c32(0xbf000000 /*-0.5*/), half_texel[i]);
+         }
+
+         if (instr->sampler_dim == GLSL_SAMPLER_DIM_2D && !instr->is_array) {
+            /* In vulkan, whether the sampler uses unnormalized
+             * coordinates or not is a dynamic property of the
+             * sampler. Hence, to figure out whether or not we
+             * need to divide by the texture size, we need to test
+             * the sampler at runtime. This tests the bit set by
+             * radv_init_sampler().
+             */
+            unsigned bit_idx = ffs(S_008F30_FORCE_UNNORMALIZED(1)) - 1;
+            Temp dword0 = emit_extract_vector(ctx, sampler, 0, s1);
+            Temp not_needed =
+               bld.sopc(aco_opcode::s_bitcmp0_b32, bld.def(s1, scc), dword0, Operand::c32(bit_idx));
+
+            not_needed = bool_to_vector_condition(ctx, not_needed);
+            half_texel[0] = bld.vop2(aco_opcode::v_cndmask_b32, bld.def(v1),
+                                     Operand::c32(0xbf000000 /*-0.5*/), half_texel[0], not_needed);
+            half_texel[1] = bld.vop2(aco_opcode::v_cndmask_b32, bld.def(v1),
+                                     Operand::c32(0xbf000000 /*-0.5*/), half_texel[1], not_needed);
+         }
       }
 
       Temp new_coords[2] = {bld.vop2(aco_opcode::v_add_f32, bld.def(v1), coords[0], half_texel[0]),
-- 
GitLab

