From c2bdf49036b4040d0457d6fd0000a5444c58bc0e Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 16 Nov 2022 20:07:53 +0000
Subject: [PATCH 1/3] ac/llvm: add support for fp32 addition atomics

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/llvm/ac_nir_to_llvm.c | 44 +++++++++++++++++++++++++++++++----
 1 file changed, 39 insertions(+), 5 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index b89fe706516f..72256df34129 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -2012,6 +2012,9 @@ static LLVMValueRef visit_atomic_ssbo(struct ac_nir_context *ctx, nir_intrinsic_
    case nir_intrinsic_ssbo_atomic_comp_swap:
       op = "cmpswap";
       break;
+   case nir_intrinsic_ssbo_atomic_fadd:
+      op = "fadd";
+      break;
    case nir_intrinsic_ssbo_atomic_fmin:
       op = "fmin";
       break;
@@ -2033,7 +2036,8 @@ static LLVMValueRef visit_atomic_ssbo(struct ac_nir_context *ctx, nir_intrinsic_
       if (instr->intrinsic == nir_intrinsic_ssbo_atomic_comp_swap) {
          params[arg_count++] = ac_llvm_extract_elem(&ctx->ac, get_src(ctx, instr->src[3]), 0);
       }
-      if (instr->intrinsic == nir_intrinsic_ssbo_atomic_fmin ||
+      if (instr->intrinsic == nir_intrinsic_ssbo_atomic_fadd ||
+          instr->intrinsic == nir_intrinsic_ssbo_atomic_fmin ||
           instr->intrinsic == nir_intrinsic_ssbo_atomic_fmax) {
          data = ac_to_float(&ctx->ac, data);
          return_type = LLVMTypeOf(data);
@@ -2049,7 +2053,8 @@ static LLVMValueRef visit_atomic_ssbo(struct ac_nir_context *ctx, nir_intrinsic_
 
       result = ac_build_intrinsic(&ctx->ac, name, return_type, params, arg_count, 0);
 
-      if (instr->intrinsic == nir_intrinsic_ssbo_atomic_fmin ||
+      if (instr->intrinsic == nir_intrinsic_ssbo_atomic_fadd ||
+          instr->intrinsic == nir_intrinsic_ssbo_atomic_fmin ||
           instr->intrinsic == nir_intrinsic_ssbo_atomic_fmax) {
          result = ac_to_integer(&ctx->ac, result);
       }
@@ -2213,8 +2218,10 @@ static LLVMValueRef visit_global_atomic(struct ac_nir_context *ctx,
    /* use "singlethread" sync scope to implement relaxed ordering */
    const char *sync_scope = "singlethread-one-as";
 
-   if (instr->intrinsic == nir_intrinsic_global_atomic_fmin ||
+   if (instr->intrinsic == nir_intrinsic_global_atomic_fadd ||
+       instr->intrinsic == nir_intrinsic_global_atomic_fmin ||
        instr->intrinsic == nir_intrinsic_global_atomic_fmax ||
+       instr->intrinsic == nir_intrinsic_global_atomic_fadd_amd ||
        instr->intrinsic == nir_intrinsic_global_atomic_fmin_amd ||
        instr->intrinsic == nir_intrinsic_global_atomic_fmax_amd) {
       data = ac_to_float(&ctx->ac, data);
@@ -2229,11 +2236,29 @@ static LLVMValueRef visit_global_atomic(struct ac_nir_context *ctx,
       LLVMValueRef data1 = get_src(ctx, instr->src[2]);
       result = ac_build_atomic_cmp_xchg(&ctx->ac, addr, data, data1, sync_scope);
       result = LLVMBuildExtractValue(ctx->ac.builder, result, 0, "");
-   } else if (instr->intrinsic == nir_intrinsic_global_atomic_fmin ||
+   } else if (instr->intrinsic == nir_intrinsic_global_atomic_fadd ||
+              instr->intrinsic == nir_intrinsic_global_atomic_fmin ||
               instr->intrinsic == nir_intrinsic_global_atomic_fmax ||
+              instr->intrinsic == nir_intrinsic_global_atomic_fadd_amd ||
               instr->intrinsic == nir_intrinsic_global_atomic_fmin_amd ||
               instr->intrinsic == nir_intrinsic_global_atomic_fmax_amd) {
-      const char *op = instr->intrinsic == nir_intrinsic_global_atomic_fmin ? "fmin" : "fmax";
+      const char *op = NULL;
+      switch (instr->intrinsic) {
+      case nir_intrinsic_global_atomic_fadd:
+      case nir_intrinsic_global_atomic_fadd_amd:
+         op = "fadd";
+         break;
+      case nir_intrinsic_global_atomic_fmin:
+      case nir_intrinsic_global_atomic_fmin_amd:
+         op = "fmin";
+         break;
+      case nir_intrinsic_global_atomic_fmax:
+      case nir_intrinsic_global_atomic_fmax_amd:
+         op = "fmax";
+         break;
+      default:
+         break;
+      }
       char name[64], type[8];
       LLVMValueRef params[2];
       int arg_count = 0;
@@ -2854,6 +2879,10 @@ static LLVMValueRef visit_image_atomic(struct ac_nir_context *ctx, const nir_int
       atomic_name = "dec";
       atomic_subop = ac_atomic_dec_wrap;
       break;
+   case nir_intrinsic_bindless_image_atomic_fadd:
+   case nir_intrinsic_image_deref_atomic_fadd:
+      atomic_name = "fadd";
+      break;
    case nir_intrinsic_bindless_image_atomic_fmin:
    case nir_intrinsic_image_deref_atomic_fmin:
       atomic_name = "fmin";
@@ -3798,6 +3827,7 @@ static bool visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_global_atomic_xor:
    case nir_intrinsic_global_atomic_exchange:
    case nir_intrinsic_global_atomic_comp_swap:
+   case nir_intrinsic_global_atomic_fadd:
    case nir_intrinsic_global_atomic_fmin:
    case nir_intrinsic_global_atomic_fmax:
    case nir_intrinsic_global_atomic_add_amd:
@@ -3810,6 +3840,7 @@ static bool visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_global_atomic_xor_amd:
    case nir_intrinsic_global_atomic_exchange_amd:
    case nir_intrinsic_global_atomic_comp_swap_amd:
+   case nir_intrinsic_global_atomic_fadd_amd:
    case nir_intrinsic_global_atomic_fmin_amd:
    case nir_intrinsic_global_atomic_fmax_amd:
       result = visit_global_atomic(ctx, instr);
@@ -3824,6 +3855,7 @@ static bool visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_ssbo_atomic_xor:
    case nir_intrinsic_ssbo_atomic_exchange:
    case nir_intrinsic_ssbo_atomic_comp_swap:
+   case nir_intrinsic_ssbo_atomic_fadd:
    case nir_intrinsic_ssbo_atomic_fmin:
    case nir_intrinsic_ssbo_atomic_fmax:
       result = visit_atomic_ssbo(ctx, instr);
@@ -3886,6 +3918,7 @@ static bool visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_bindless_image_atomic_comp_swap:
    case nir_intrinsic_bindless_image_atomic_inc_wrap:
    case nir_intrinsic_bindless_image_atomic_dec_wrap:
+   case nir_intrinsic_bindless_image_atomic_fadd:
    case nir_intrinsic_bindless_image_atomic_fmin:
    case nir_intrinsic_bindless_image_atomic_fmax:
       result = visit_image_atomic(ctx, instr, true);
@@ -3902,6 +3935,7 @@ static bool visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_image_deref_atomic_comp_swap:
    case nir_intrinsic_image_deref_atomic_inc_wrap:
    case nir_intrinsic_image_deref_atomic_dec_wrap:
+   case nir_intrinsic_image_deref_atomic_fadd:
    case nir_intrinsic_image_deref_atomic_fmin:
    case nir_intrinsic_image_deref_atomic_fmax:
       result = visit_image_atomic(ctx, instr, false);
-- 
GitLab


From 64de930c1efb36b6514b487704dfda05f80971e1 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 16 Nov 2022 20:08:07 +0000
Subject: [PATCH 2/3] aco: add support for fp32 addition atomics

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/aco_instruction_selection.cpp   | 16 ++++++++++++++++
 .../compiler/aco_instruction_selection_setup.cpp |  3 +++
 2 files changed, 19 insertions(+)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 86fe15857873..477d6ce07209 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -6663,6 +6663,11 @@ visit_image_atomic(isel_context* ctx, nir_intrinsic_instr* instr)
       buf_op64 = aco_opcode::buffer_atomic_cmpswap_x2;
       image_op = aco_opcode::image_atomic_cmpswap;
       break;
+   case nir_intrinsic_bindless_image_atomic_fadd:
+      buf_op = aco_opcode::buffer_atomic_add_f32;
+      buf_op64 = aco_opcode::num_opcodes;
+      image_op = aco_opcode::num_opcodes;
+      break;
    case nir_intrinsic_bindless_image_atomic_fmin:
       buf_op = aco_opcode::buffer_atomic_fmin;
       buf_op64 = aco_opcode::buffer_atomic_fmin_x2;
@@ -6857,6 +6862,10 @@ visit_atomic_ssbo(isel_context* ctx, nir_intrinsic_instr* instr)
       op32 = aco_opcode::buffer_atomic_cmpswap;
       op64 = aco_opcode::buffer_atomic_cmpswap_x2;
       break;
+   case nir_intrinsic_ssbo_atomic_fadd:
+      op32 = aco_opcode::buffer_atomic_add_f32;
+      op64 = aco_opcode::num_opcodes;
+      break;
    case nir_intrinsic_ssbo_atomic_fmin:
       op32 = aco_opcode::buffer_atomic_fmin;
       op64 = aco_opcode::buffer_atomic_fmin_x2;
@@ -7115,6 +7124,10 @@ visit_global_atomic(isel_context* ctx, nir_intrinsic_instr* instr)
          op32 = global ? aco_opcode::global_atomic_cmpswap : aco_opcode::flat_atomic_cmpswap;
          op64 = global ? aco_opcode::global_atomic_cmpswap_x2 : aco_opcode::flat_atomic_cmpswap_x2;
          break;
+      case nir_intrinsic_global_atomic_fadd_amd:
+         op32 = global ? aco_opcode::global_atomic_add_f32 : aco_opcode::flat_atomic_add_f32;
+         op64 = aco_opcode::num_opcodes;
+         break;
       case nir_intrinsic_global_atomic_fmin_amd:
          op32 = global ? aco_opcode::global_atomic_fmin : aco_opcode::flat_atomic_fmin;
          op64 = global ? aco_opcode::global_atomic_fmin_x2 : aco_opcode::flat_atomic_fmin_x2;
@@ -8427,6 +8440,7 @@ visit_intrinsic(isel_context* ctx, nir_intrinsic_instr* instr)
    case nir_intrinsic_bindless_image_atomic_xor:
    case nir_intrinsic_bindless_image_atomic_exchange:
    case nir_intrinsic_bindless_image_atomic_comp_swap:
+   case nir_intrinsic_bindless_image_atomic_fadd:
    case nir_intrinsic_bindless_image_atomic_fmin:
    case nir_intrinsic_bindless_image_atomic_fmax: visit_image_atomic(ctx, instr); break;
    case nir_intrinsic_load_ssbo: visit_load_ssbo(ctx, instr); break;
@@ -8446,6 +8460,7 @@ visit_intrinsic(isel_context* ctx, nir_intrinsic_instr* instr)
    case nir_intrinsic_global_atomic_xor_amd:
    case nir_intrinsic_global_atomic_exchange_amd:
    case nir_intrinsic_global_atomic_comp_swap_amd:
+   case nir_intrinsic_global_atomic_fadd_amd:
    case nir_intrinsic_global_atomic_fmin_amd:
    case nir_intrinsic_global_atomic_fmax_amd: visit_global_atomic(ctx, instr); break;
    case nir_intrinsic_ssbo_atomic_add:
@@ -8458,6 +8473,7 @@ visit_intrinsic(isel_context* ctx, nir_intrinsic_instr* instr)
    case nir_intrinsic_ssbo_atomic_xor:
    case nir_intrinsic_ssbo_atomic_exchange:
    case nir_intrinsic_ssbo_atomic_comp_swap:
+   case nir_intrinsic_ssbo_atomic_fadd:
    case nir_intrinsic_ssbo_atomic_fmin:
    case nir_intrinsic_ssbo_atomic_fmax: visit_atomic_ssbo(ctx, instr); break;
    case nir_intrinsic_load_scratch: visit_load_scratch(ctx, instr); break;
diff --git a/src/amd/compiler/aco_instruction_selection_setup.cpp b/src/amd/compiler/aco_instruction_selection_setup.cpp
index 61064622988f..40dc142b8e3f 100644
--- a/src/amd/compiler/aco_instruction_selection_setup.cpp
+++ b/src/amd/compiler/aco_instruction_selection_setup.cpp
@@ -636,6 +636,7 @@ init_context(isel_context* ctx, nir_shader* shader)
                case nir_intrinsic_ssbo_atomic_xor:
                case nir_intrinsic_ssbo_atomic_exchange:
                case nir_intrinsic_ssbo_atomic_comp_swap:
+               case nir_intrinsic_ssbo_atomic_fadd:
                case nir_intrinsic_ssbo_atomic_fmin:
                case nir_intrinsic_ssbo_atomic_fmax:
                case nir_intrinsic_global_atomic_add_amd:
@@ -648,6 +649,7 @@ init_context(isel_context* ctx, nir_shader* shader)
                case nir_intrinsic_global_atomic_xor_amd:
                case nir_intrinsic_global_atomic_exchange_amd:
                case nir_intrinsic_global_atomic_comp_swap_amd:
+               case nir_intrinsic_global_atomic_fadd_amd:
                case nir_intrinsic_global_atomic_fmin_amd:
                case nir_intrinsic_global_atomic_fmax_amd:
                case nir_intrinsic_bindless_image_atomic_add:
@@ -660,6 +662,7 @@ init_context(isel_context* ctx, nir_shader* shader)
                case nir_intrinsic_bindless_image_atomic_xor:
                case nir_intrinsic_bindless_image_atomic_exchange:
                case nir_intrinsic_bindless_image_atomic_comp_swap:
+               case nir_intrinsic_bindless_image_atomic_fadd:
                case nir_intrinsic_bindless_image_atomic_fmin:
                case nir_intrinsic_bindless_image_atomic_fmax:
                case nir_intrinsic_bindless_image_size:
-- 
GitLab


From fce808f7a963f8e68d55d1f866a08922da319a2a Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 16 Nov 2022 20:08:22 +0000
Subject: [PATCH 3/3] radv/gfx11: expose shaderBufferFloat32AtomicAdd

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/vulkan/radv_device.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index dc00ed6fdc7f..445945de93e3 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -1606,7 +1606,7 @@ radv_GetPhysicalDeviceFeatures2(VkPhysicalDevice physicalDevice,
          VkPhysicalDeviceShaderAtomicFloatFeaturesEXT *features =
             (VkPhysicalDeviceShaderAtomicFloatFeaturesEXT *)ext;
          features->shaderBufferFloat32Atomics = true;
-         features->shaderBufferFloat32AtomicAdd = false;
+         features->shaderBufferFloat32AtomicAdd = pdevice->rad_info.gfx_level >= GFX11;
          features->shaderBufferFloat64Atomics = true;
          features->shaderBufferFloat64AtomicAdd = false;
          features->shaderSharedFloat32Atomics = true;
-- 
GitLab

