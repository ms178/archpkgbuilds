From 691e6968fa578aebe3ebc2518da8bdb0bbc71084 Mon Sep 17 00:00:00 2001
From: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date: Wed, 8 Jun 2022 00:37:09 +0200
Subject: [PATCH 1/3] radv: Add implementation of cmd buffers for a sparse
 binding queue.

None of the commands are allowed on these ...

Reviewed-by: Tatsuyuki Ishi <ishitatsuyuki@gmail.com>
Reviewed-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/16935>
---
 src/amd/vulkan/radv_cmd_buffer.c | 91 +++++++++++++++++++-------------
 src/amd/vulkan/radv_private.h    |  1 +
 2 files changed, 54 insertions(+), 38 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index ee0993231a86..5bed357d3bb3 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -308,37 +308,39 @@ radv_destroy_cmd_buffer(struct radv_cmd_buffer *cmd_buffer)
 {
    list_del(&cmd_buffer->pool_link);
 
-   util_dynarray_fini(&cmd_buffer->cached_vertex_formats);
+   if (cmd_buffer->qf != RADV_QUEUE_SPARSE) {
+      util_dynarray_fini(&cmd_buffer->cached_vertex_formats);
 
-   list_for_each_entry_safe(struct radv_cmd_buffer_upload, up, &cmd_buffer->upload.list, list)
-   {
-      cmd_buffer->device->ws->buffer_destroy(cmd_buffer->device->ws, up->upload_bo);
-      list_del(&up->list);
-      free(up);
-   }
+      list_for_each_entry_safe(struct radv_cmd_buffer_upload, up, &cmd_buffer->upload.list, list)
+      {
+         cmd_buffer->device->ws->buffer_destroy(cmd_buffer->device->ws, up->upload_bo);
+         list_del(&up->list);
+         free(up);
+      }
 
-   if (cmd_buffer->upload.upload_bo)
-      cmd_buffer->device->ws->buffer_destroy(cmd_buffer->device->ws, cmd_buffer->upload.upload_bo);
+      if (cmd_buffer->upload.upload_bo)
+         cmd_buffer->device->ws->buffer_destroy(cmd_buffer->device->ws,
+                                                cmd_buffer->upload.upload_bo);
 
-   if (cmd_buffer->state.own_render_pass) {
-      radv_DestroyRenderPass(radv_device_to_handle(cmd_buffer->device),
-                             radv_render_pass_to_handle(cmd_buffer->state.pass), NULL);
-      cmd_buffer->state.own_render_pass = false;
-   }
+      if (cmd_buffer->state.own_render_pass) {
+         radv_DestroyRenderPass(radv_device_to_handle(cmd_buffer->device),
+                                radv_render_pass_to_handle(cmd_buffer->state.pass), NULL);
+         cmd_buffer->state.own_render_pass = false;
+      }
 
-   if (cmd_buffer->cs)
-      cmd_buffer->device->ws->cs_destroy(cmd_buffer->cs);
-   if (cmd_buffer->ace_internal.cs)
-      cmd_buffer->device->ws->cs_destroy(cmd_buffer->ace_internal.cs);
+      if (cmd_buffer->cs)
+         cmd_buffer->device->ws->cs_destroy(cmd_buffer->cs);
+      if (cmd_buffer->ace_internal.cs)
+         cmd_buffer->device->ws->cs_destroy(cmd_buffer->ace_internal.cs);
 
-   for (unsigned i = 0; i < MAX_BIND_POINTS; i++) {
-      struct radv_descriptor_set_header *set = &cmd_buffer->descriptors[i].push_set.set;
-      free(set->mapped_ptr);
-      if (set->layout)
-         vk_descriptor_set_layout_unref(&cmd_buffer->device->vk, &set->layout->vk);
-      vk_object_base_finish(&set->base);
+      for (unsigned i = 0; i < MAX_BIND_POINTS; i++) {
+         struct radv_descriptor_set_header *set = &cmd_buffer->descriptors[i].push_set.set;
+         free(set->mapped_ptr);
+         if (set->layout)
+            vk_descriptor_set_layout_unref(&cmd_buffer->device->vk, &set->layout->vk);
+         vk_object_base_finish(&set->base);
+      }
    }
-
    vk_object_base_finish(&cmd_buffer->meta_push_descriptors.base);
 
    vk_command_buffer_finish(&cmd_buffer->vk);
@@ -369,12 +371,16 @@ radv_create_cmd_buffer(struct radv_device *device, struct radv_cmd_pool *pool,
    list_addtail(&cmd_buffer->pool_link, &pool->cmd_buffers);
    cmd_buffer->qf = vk_queue_to_radv(device->physical_device, pool->vk.queue_family_index);
 
-   ring = radv_queue_family_to_ring(device->physical_device, cmd_buffer->qf);
+   if (cmd_buffer->qf != RADV_QUEUE_SPARSE) {
+      ring = radv_queue_family_to_ring(device->physical_device, cmd_buffer->qf);
 
-   cmd_buffer->cs = device->ws->cs_create(device->ws, ring);
-   if (!cmd_buffer->cs) {
-      radv_destroy_cmd_buffer(cmd_buffer);
-      return vk_error(device, VK_ERROR_OUT_OF_HOST_MEMORY);
+      cmd_buffer->cs = device->ws->cs_create(device->ws, ring);
+      if (!cmd_buffer->cs) {
+         radv_destroy_cmd_buffer(cmd_buffer);
+         return vk_error(device, VK_ERROR_OUT_OF_HOST_MEMORY);
+      }
+
+      list_inithead(&cmd_buffer->upload.list);
    }
 
    vk_object_base_init(&device->vk, &cmd_buffer->meta_push_descriptors.base,
@@ -388,8 +394,6 @@ radv_create_cmd_buffer(struct radv_device *device, struct radv_cmd_pool *pool,
 
    *pCommandBuffer = radv_cmd_buffer_to_handle(cmd_buffer);
 
-   list_inithead(&cmd_buffer->upload.list);
-
    return VK_SUCCESS;
 }
 
@@ -398,6 +402,12 @@ radv_reset_cmd_buffer(struct radv_cmd_buffer *cmd_buffer)
 {
    vk_command_buffer_reset(&cmd_buffer->vk);
 
+   cmd_buffer->record_result = VK_SUCCESS;
+   cmd_buffer->status = RADV_CMD_BUFFER_STATUS_INITIAL;
+
+   if (cmd_buffer->qf == RADV_QUEUE_SPARSE)
+      return VK_SUCCESS;
+
    cmd_buffer->device->ws->cs_reset(cmd_buffer->cs);
    if (cmd_buffer->ace_internal.cs)
       cmd_buffer->device->ws->cs_reset(cmd_buffer->ace_internal.cs);
@@ -436,8 +446,6 @@ radv_reset_cmd_buffer(struct radv_cmd_buffer *cmd_buffer)
       radv_cs_add_buffer(cmd_buffer->device->ws, cmd_buffer->cs, cmd_buffer->upload.upload_bo);
    cmd_buffer->upload.offset = 0;
 
-   cmd_buffer->record_result = VK_SUCCESS;
-
    memset(cmd_buffer->vertex_binding_buffers, 0, sizeof(struct radv_buffer *) * cmd_buffer->used_vertex_bindings);
    cmd_buffer->used_vertex_bindings = 0;
 
@@ -482,8 +490,6 @@ radv_reset_cmd_buffer(struct radv_cmd_buffer *cmd_buffer)
       }
    }
 
-   cmd_buffer->status = RADV_CMD_BUFFER_STATUS_INITIAL;
-
    return cmd_buffer->record_result;
 }
 
@@ -4901,6 +4907,11 @@ radv_BeginCommandBuffer(VkCommandBuffer commandBuffer, const VkCommandBufferBegi
          return result;
    }
 
+   cmd_buffer->status = RADV_CMD_BUFFER_STATUS_RECORDING;
+
+   if (cmd_buffer->qf == RADV_QUEUE_SPARSE)
+      return result;
+
    memset(&cmd_buffer->state, 0, sizeof(cmd_buffer->state));
    cmd_buffer->state.last_primitive_reset_en = -1;
    cmd_buffer->state.last_index_type = -1;
@@ -4965,8 +4976,6 @@ radv_BeginCommandBuffer(VkCommandBuffer commandBuffer, const VkCommandBufferBegi
 
    radv_describe_begin_cmd_buffer(cmd_buffer);
 
-   cmd_buffer->status = RADV_CMD_BUFFER_STATUS_RECORDING;
-
    return result;
 }
 
@@ -5312,6 +5321,12 @@ radv_EndCommandBuffer(VkCommandBuffer commandBuffer)
 {
    RADV_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, commandBuffer);
 
+   if (cmd_buffer->qf == RADV_QUEUE_SPARSE) {
+      cmd_buffer->status = RADV_CMD_BUFFER_STATUS_EXECUTABLE;
+
+      return cmd_buffer->record_result;
+   }
+
    radv_emit_mip_change_flush_default(cmd_buffer);
 
    if (cmd_buffer->qf != RADV_QUEUE_TRANSFER) {
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index d54d67a28355..3b36b62e684f 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -255,6 +255,7 @@ enum radv_queue_family {
    RADV_QUEUE_GENERAL,
    RADV_QUEUE_COMPUTE,
    RADV_QUEUE_TRANSFER,
+   RADV_QUEUE_SPARSE,
    RADV_MAX_QUEUE_FAMILIES,
    RADV_QUEUE_FOREIGN = RADV_MAX_QUEUE_FAMILIES,
    RADV_QUEUE_IGNORED,
-- 
GitLab


From 81f8104a9732279427470a263a6308e306c7526d Mon Sep 17 00:00:00 2001
From: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date: Wed, 8 Jun 2022 00:37:50 +0200
Subject: [PATCH 2/3] radv: Remove the sparse binding queue from coherent
 images.

Never access the image on the queue family, so no need.

(Technically not sure if this is needed for Vulkan, somewhat of
 a backstop in case apps do it)

Reviewed-by: Tatsuyuki Ishi <ishitatsuyuki@gmail.com>
Reviewed-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/16935>
---
 src/amd/vulkan/radv_image.c | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/src/amd/vulkan/radv_image.c b/src/amd/vulkan/radv_image.c
index 3f1e0c4e69b7..6e71a4f5367e 100644
--- a/src/amd/vulkan/radv_image.c
+++ b/src/amd/vulkan/radv_image.c
@@ -1873,6 +1873,9 @@ radv_image_create(VkDevice _device, const struct radv_image_create_info *create_
          else
             image->queue_family_mask |= 1u << vk_queue_to_radv(device->physical_device,
                                                                pCreateInfo->pQueueFamilyIndices[i]);
+
+      /* This queue never really accesses the image. */
+      image->queue_family_mask &= ~(1u << RADV_QUEUE_SPARSE);
    }
 
    const VkExternalMemoryImageCreateInfo *external_info =
-- 
GitLab


From f59c78a4a3c981efce4cf391b10a575a967b8940 Mon Sep 17 00:00:00 2001
From: Bas Nieuwenhuizen <bas@basnieuwenhuizen.nl>
Date: Wed, 8 Jun 2022 02:18:37 +0200
Subject: [PATCH 3/3] radv: Move sparse binding into a dedicated queue.

1) This better reflects the reality that we only have one timeline
   of sparse binding changes.

2) Allows making it a threaded queue from the start in prep of
   explicit sync stuff.

Reviewed-by: Tatsuyuki Ishi <ishitatsuyuki@gmail.com>
Reviewed-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/16935>
---
 src/amd/vulkan/layers/radv_sqtt_layer.c |  2 +-
 src/amd/vulkan/radv_device.c            | 76 +++++++++++++++++++++----
 2 files changed, 67 insertions(+), 11 deletions(-)

diff --git a/src/amd/vulkan/layers/radv_sqtt_layer.c b/src/amd/vulkan/layers/radv_sqtt_layer.c
index 917d27ccdfcd..536908a42ed4 100644
--- a/src/amd/vulkan/layers/radv_sqtt_layer.c
+++ b/src/amd/vulkan/layers/radv_sqtt_layer.c
@@ -143,7 +143,7 @@ radv_describe_begin_cmd_buffer(struct radv_cmd_buffer *cmd_buffer)
    marker.device_id_low = device_id;
    marker.device_id_high = device_id >> 32;
    marker.queue = cmd_buffer->qf;
-   marker.queue_flags = VK_QUEUE_COMPUTE_BIT | VK_QUEUE_TRANSFER_BIT | VK_QUEUE_SPARSE_BINDING_BIT;
+   marker.queue_flags = VK_QUEUE_COMPUTE_BIT | VK_QUEUE_TRANSFER_BIT;
 
    if (cmd_buffer->qf == RADV_QUEUE_GENERAL)
       marker.queue_flags |= VK_QUEUE_GRAPHICS_BIT;
diff --git a/src/amd/vulkan/radv_device.c b/src/amd/vulkan/radv_device.c
index 6720ac1bcc6f..7f48b7e196bd 100644
--- a/src/amd/vulkan/radv_device.c
+++ b/src/amd/vulkan/radv_device.c
@@ -91,6 +91,8 @@ typedef void *drmDevicePtr;
 #endif
 
 static VkResult radv_queue_submit(struct vk_queue *vqueue, struct vk_queue_submit *submission);
+static VkResult radv_queue_sparse_submit(struct vk_queue *vqueue,
+                                         struct vk_queue_submit *submission);
 
 uint64_t
 radv_get_current_time(void)
@@ -654,6 +656,9 @@ radv_physical_device_init_queue_table(struct radv_physical_device *pdevice)
       pdevice->vk_queue_to_radv[idx] = RADV_QUEUE_COMPUTE;
       idx++;
    }
+
+   pdevice->vk_queue_to_radv[idx++] = RADV_QUEUE_SPARSE;
+
    pdevice->num_queues = idx;
 }
 
@@ -2606,7 +2611,7 @@ radv_get_physical_device_queue_family_properties(struct radv_physical_device *pd
                                                  uint32_t *pCount,
                                                  VkQueueFamilyProperties **pQueueFamilyProperties)
 {
-   int num_queue_families = 1;
+   int num_queue_families = 2;
    int idx;
    if (pdevice->rad_info.ip[AMD_IP_COMPUTE].num_queues > 0 &&
        !(pdevice->instance->debug_flags & RADV_DEBUG_NO_COMPUTE_QUEUE))
@@ -2623,8 +2628,7 @@ radv_get_physical_device_queue_family_properties(struct radv_physical_device *pd
    idx = 0;
    if (*pCount >= 1) {
       *pQueueFamilyProperties[idx] = (VkQueueFamilyProperties){
-         .queueFlags = VK_QUEUE_GRAPHICS_BIT | VK_QUEUE_COMPUTE_BIT | VK_QUEUE_TRANSFER_BIT |
-                       VK_QUEUE_SPARSE_BINDING_BIT,
+         .queueFlags = VK_QUEUE_GRAPHICS_BIT | VK_QUEUE_COMPUTE_BIT | VK_QUEUE_TRANSFER_BIT,
          .queueCount = 1,
          .timestampValidBits = 64,
          .minImageTransferGranularity = (VkExtent3D){1, 1, 1},
@@ -2636,8 +2640,7 @@ radv_get_physical_device_queue_family_properties(struct radv_physical_device *pd
        !(pdevice->instance->debug_flags & RADV_DEBUG_NO_COMPUTE_QUEUE)) {
       if (*pCount > idx) {
          *pQueueFamilyProperties[idx] = (VkQueueFamilyProperties){
-            .queueFlags =
-               VK_QUEUE_COMPUTE_BIT | VK_QUEUE_TRANSFER_BIT | VK_QUEUE_SPARSE_BINDING_BIT,
+            .queueFlags = VK_QUEUE_COMPUTE_BIT | VK_QUEUE_TRANSFER_BIT,
             .queueCount = pdevice->rad_info.ip[AMD_IP_COMPUTE].num_queues,
             .timestampValidBits = 64,
             .minImageTransferGranularity = (VkExtent3D){1, 1, 1},
@@ -2645,6 +2648,16 @@ radv_get_physical_device_queue_family_properties(struct radv_physical_device *pd
          idx++;
       }
    }
+
+   if (*pCount > idx) {
+      *pQueueFamilyProperties[idx] = (VkQueueFamilyProperties){
+         .queueFlags = VK_QUEUE_SPARSE_BINDING_BIT,
+         .queueCount = 1,
+         .timestampValidBits = 64,
+         .minImageTransferGranularity = (VkExtent3D){1, 1, 1},
+      };
+      idx++;
+   }
    *pCount = idx;
 }
 
@@ -2668,9 +2681,10 @@ radv_GetPhysicalDeviceQueueFamilyProperties2(VkPhysicalDevice physicalDevice, ui
       &pQueueFamilyProperties[0].queueFamilyProperties,
       &pQueueFamilyProperties[1].queueFamilyProperties,
       &pQueueFamilyProperties[2].queueFamilyProperties,
+      &pQueueFamilyProperties[3].queueFamilyProperties,
    };
    radv_get_physical_device_queue_family_properties(pdevice, pCount, properties);
-   assert(*pCount <= 3);
+   assert(*pCount <= 4);
 
    for (uint32_t i = 0; i < *pCount; i++) {
       vk_foreach_struct(ext, pQueueFamilyProperties[i].pNext)
@@ -2872,7 +2886,12 @@ radv_queue_init(struct radv_device *device, struct radv_queue *queue, int idx,
    if (result != VK_SUCCESS)
       return result;
 
-   queue->vk.driver_submit = radv_queue_submit;
+   if (queue->state.qf == RADV_QUEUE_SPARSE) {
+      queue->vk.driver_submit = radv_queue_sparse_submit;
+      vk_queue_enable_submit_thread(&queue->vk);
+   } else {
+      queue->vk.driver_submit = radv_queue_submit;
+   }
 
    return VK_SUCCESS;
 }
@@ -5260,15 +5279,53 @@ fail:
 }
 
 static VkResult
-radv_queue_submit(struct vk_queue *vqueue, struct vk_queue_submit *submission)
+radv_queue_sparse_submit(struct vk_queue *vqueue, struct vk_queue_submit *submission)
 {
    struct radv_queue *queue = (struct radv_queue *)vqueue;
+   struct radv_device *device = queue->device;
    VkResult result;
 
-   result = radv_queue_submit_bind_sparse_memory(queue->device, submission);
+   result = radv_queue_submit_bind_sparse_memory(device, submission);
+   if (result != VK_SUCCESS)
+      goto fail;
+
+   /* We do a CPU wait here, in part to avoid more winsys mechanisms. In the likely kernel explicit
+    * sync mechanism, we'd need to do a CPU wait anyway. Haven't seen this be a perf issue yet, but
+    * we have to make sure the queue always has its submission thread enabled. */
+   result =
+      vk_sync_wait_many(&device->vk, submission->wait_count, submission->waits, 0, UINT64_MAX);
    if (result != VK_SUCCESS)
       goto fail;
 
+   /* Ignore all the commandbuffers. They're necessarily empty anyway. */
+
+   for (unsigned i = 0; i < submission->signal_count; ++i) {
+      result = vk_sync_signal(&device->vk, submission->signals[i].sync,
+                              submission->signals[i].signal_value);
+      if (result != VK_SUCCESS)
+         goto fail;
+   }
+
+fail:
+   if (result != VK_SUCCESS && result != VK_ERROR_DEVICE_LOST) {
+      /* When something bad happened during the submission, such as
+       * an out of memory issue, it might be hard to recover from
+       * this inconsistent state. To avoid this sort of problem, we
+       * assume that we are in a really bad situation and return
+       * VK_ERROR_DEVICE_LOST to ensure the clients do not attempt
+       * to submit the same job again to this device.
+       */
+      result = vk_device_set_lost(&queue->device->vk, "vkQueueSubmit() failed");
+   }
+   return result;
+}
+
+static VkResult
+radv_queue_submit(struct vk_queue *vqueue, struct vk_queue_submit *submission)
+{
+   struct radv_queue *queue = (struct radv_queue *)vqueue;
+   VkResult result;
+
    if (!submission->command_buffer_count && !submission->wait_count && !submission->signal_count)
       return VK_SUCCESS;
 
@@ -5278,7 +5335,6 @@ radv_queue_submit(struct vk_queue *vqueue, struct vk_queue_submit *submission)
       result = radv_queue_submit_normal(queue, submission);
    }
 
-fail:
    if (result != VK_SUCCESS && result != VK_ERROR_DEVICE_LOST) {
       /* When something bad happened during the submission, such as
        * an out of memory issue, it might be hard to recover from
-- 
GitLab

