From 6b852cfd20215b454f9c42a8d7927c9108b8f923 Mon Sep 17 00:00:00 2001
From: Timothy Arceri <tarceri@itsqueeze.com>
Date: Wed, 21 Dec 2022 10:29:45 +1100
Subject: [PATCH 1/7] nir/nir_opt_copy_prop_vars: remove extra loop

The fix in 947f7b452a55 introduced an extra loop over the copies
array to find the correct entry in the case it had been moved.

The problem is these loops can be iterated over millions of times
so lets simply update the entry pointer in the case we change its
location in the array.
---
 src/compiler/nir/nir_opt_copy_prop_vars.c | 37 +++++++++--------------
 1 file changed, 15 insertions(+), 22 deletions(-)

diff --git a/src/compiler/nir/nir_opt_copy_prop_vars.c b/src/compiler/nir/nir_opt_copy_prop_vars.c
index 9a689d50b853..4e9c98d73ec4 100644
--- a/src/compiler/nir/nir_opt_copy_prop_vars.c
+++ b/src/compiler/nir/nir_opt_copy_prop_vars.c
@@ -327,10 +327,15 @@ copy_entry_create(struct util_dynarray *copies,
  */
 static void
 copy_entry_remove(struct util_dynarray *copies,
-                  struct copy_entry *entry)
+                  struct copy_entry *entry,
+                  struct copy_entry **relocated_entry)
 {
    const struct copy_entry *src =
       util_dynarray_pop_ptr(copies, struct copy_entry);
+
+   if (relocated_entry && *relocated_entry == src)
+      *relocated_entry = entry;
+
    if (src != entry)
       *entry = *src;
 }
@@ -377,14 +382,14 @@ lookup_entry_and_kill_aliases(struct copy_prop_var_state *state,
 {
    /* TODO: Take into account the write_mask. */
 
-   nir_deref_instr *dst_match = NULL;
+   struct copy_entry *entry = NULL;
    util_dynarray_foreach_reverse(copies, struct copy_entry, iter) {
       if (!iter->src.is_ssa) {
          /* If this write aliases the source of some entry, get rid of it */
          nir_deref_compare_result result =
             nir_compare_derefs_and_paths(state->mem_ctx, &iter->src.deref, deref);
          if (result & nir_derefs_may_alias_bit) {
-            copy_entry_remove(copies, iter);
+            copy_entry_remove(copies, iter, entry ? &entry : NULL);
             continue;
          }
       }
@@ -393,26 +398,14 @@ lookup_entry_and_kill_aliases(struct copy_prop_var_state *state,
          nir_compare_derefs_and_paths(state->mem_ctx, &iter->dst, deref);
 
       if (comp & nir_derefs_equal_bit) {
-         /* Removing entries invalidate previous iter pointers, so we'll
-          * collect the matching entry later.  Just make sure it is unique.
-          */
-         assert(!dst_match);
-         dst_match = iter->dst.instr;
+         /* Make sure it is unique. */
+         assert(!entry);
+         entry = iter;
       } else if (comp & nir_derefs_may_alias_bit) {
-         copy_entry_remove(copies, iter);
+         copy_entry_remove(copies, iter, entry ? &entry : NULL);
       }
    }
 
-   struct copy_entry *entry = NULL;
-   if (dst_match) {
-      util_dynarray_foreach(copies, struct copy_entry, iter) {
-         if (iter->dst.instr == dst_match) {
-            entry = iter;
-            break;
-         }
-      }
-      assert(entry);
-   }
    return entry;
 }
 
@@ -427,7 +420,7 @@ kill_aliases(struct copy_prop_var_state *state,
    struct copy_entry *entry =
       lookup_entry_and_kill_aliases(state, copies, deref, write_mask);
    if (entry)
-      copy_entry_remove(copies, entry);
+      copy_entry_remove(copies, entry, NULL);
 }
 
 static struct copy_entry *
@@ -454,7 +447,7 @@ apply_barrier_for_modes(struct util_dynarray *copies,
    util_dynarray_foreach_reverse(copies, struct copy_entry, iter) {
       if (nir_deref_mode_may_be(iter->dst.instr, modes) ||
           (!iter->src.is_ssa && nir_deref_mode_may_be(iter->src.deref.instr, modes)))
-         copy_entry_remove(copies, iter);
+         copy_entry_remove(copies, iter, NULL);
    }
 }
 
@@ -754,7 +747,7 @@ invalidate_copies_for_cf_node(struct copy_prop_var_state *state,
    if (written->modes) {
       util_dynarray_foreach_reverse(copies, struct copy_entry, entry) {
          if (nir_deref_mode_may_be(entry->dst.instr, written->modes))
-            copy_entry_remove(copies, entry);
+            copy_entry_remove(copies, entry, NULL);
       }
    }
 
-- 
GitLab


From e37cc67a11a7f8446136993e85bf3450ad5aa5cb Mon Sep 17 00:00:00 2001
From: Timothy Arceri <tarceri@itsqueeze.com>
Date: Thu, 15 Dec 2022 11:48:58 +1100
Subject: [PATCH 2/7] nir/nir_opt_copy_prop_vars: avoid comparison explosion

Previously the pass was comparing every deref to every load/store
causing the pass to slow down more the larger the shader is.

Here we use a hash table so we can simple store everything needed
for comparision of a var separately.
---
 src/compiler/nir/nir_opt_copy_prop_vars.c | 301 +++++++++++++++++-----
 1 file changed, 239 insertions(+), 62 deletions(-)

diff --git a/src/compiler/nir/nir_opt_copy_prop_vars.c b/src/compiler/nir/nir_opt_copy_prop_vars.c
index 4e9c98d73ec4..4581f952a608 100644
--- a/src/compiler/nir/nir_opt_copy_prop_vars.c
+++ b/src/compiler/nir/nir_opt_copy_prop_vars.c
@@ -53,6 +53,15 @@ static const bool debug = false;
  * Removal of dead writes to variables is handled by another pass.
  */
 
+struct copies {
+   /* Hash table of copies referenced by variables */
+   struct hash_table ht;
+
+   /* Array of derefs that can't be chased back to a variable */
+   struct util_dynarray arr;
+};
+
+
 struct vars_written {
    nir_variable_mode modes;
 
@@ -309,15 +318,53 @@ gather_vars_written(struct copy_prop_var_state *state,
    }
 }
 
+static struct util_dynarray *
+copies_array_for_var(struct copy_prop_var_state *state,
+                     struct hash_table *copies, nir_variable *var)
+{
+   struct hash_entry *entry = _mesa_hash_table_search(copies, var);
+   if (entry != NULL)
+      return entry->data;
+
+   struct util_dynarray *empty_array =
+      ralloc(state->mem_ctx, struct util_dynarray);
+   util_dynarray_init(empty_array, state->mem_ctx);
+
+   _mesa_hash_table_insert(copies, var, empty_array);
+
+   return empty_array;
+}
+
+static struct util_dynarray *
+copies_array_for_deref(struct copy_prop_var_state *state,
+                       struct copies *copies, nir_deref_and_path *deref)
+{
+   nir_get_deref_path(state->mem_ctx, deref);
+
+   struct util_dynarray *copies_array;
+   if (deref->_path->path[0]->deref_type != nir_deref_type_var) {
+      copies_array = &copies->arr;
+   } else {
+      copies_array =
+         copies_array_for_var(state, &copies->ht, deref->_path->path[0]->var);
+   }
+
+   return copies_array;
+}
+
+
 static struct copy_entry *
-copy_entry_create(struct util_dynarray *copies,
-                  nir_deref_and_path *deref)
+copy_entry_create(struct copy_prop_var_state *state,
+                  struct copies *copies, nir_deref_and_path *deref)
 {
+   struct util_dynarray *copies_array =
+      copies_array_for_deref(state, copies, deref);
+
    struct copy_entry new_entry = {
       .dst = *deref,
    };
-   util_dynarray_append(copies, struct copy_entry, new_entry);
-   return util_dynarray_top_ptr(copies, struct copy_entry);
+   util_dynarray_append(copies_array, struct copy_entry, new_entry);
+   return util_dynarray_top_ptr(copies_array, struct copy_entry);
 }
 
 /* Remove copy entry by swapping it with the last element and reducing the
@@ -351,13 +398,16 @@ is_array_deref_of_vector(const nir_deref_and_path *deref)
 
 static struct copy_entry *
 lookup_entry_for_deref(struct copy_prop_var_state *state,
-                       struct util_dynarray *copies,
+                       struct copies *copies,
                        nir_deref_and_path *deref,
                        nir_deref_compare_result allowed_comparisons,
                        bool *equal)
 {
+   struct util_dynarray *copies_array =
+      copies_array_for_deref(state, copies, deref);
+
    struct copy_entry *entry = NULL;
-   util_dynarray_foreach(copies, struct copy_entry, iter) {
+   util_dynarray_foreach(copies_array, struct copy_entry, iter) {
       nir_deref_compare_result result =
          nir_compare_derefs_and_paths(state->mem_ctx, &iter->dst, deref);
       if (result & allowed_comparisons) {
@@ -374,22 +424,23 @@ lookup_entry_for_deref(struct copy_prop_var_state *state,
    return entry;
 }
 
-static struct copy_entry *
-lookup_entry_and_kill_aliases(struct copy_prop_var_state *state,
-                              struct util_dynarray *copies,
-                              nir_deref_and_path *deref,
-                              unsigned write_mask)
-{
-   /* TODO: Take into account the write_mask. */
-
-   struct copy_entry *entry = NULL;
-   util_dynarray_foreach_reverse(copies, struct copy_entry, iter) {
+static void
+lookup_entry_and_kill_aliases_copy_array(struct copy_prop_var_state *state,
+                                         struct util_dynarray *copies_array,
+                                         nir_deref_and_path *deref,
+                                         unsigned write_mask,
+                                         bool remove_entry,
+                                         struct copy_entry **entry,
+                                         bool *entry_removed) {
+
+   util_dynarray_foreach_reverse(copies_array, struct copy_entry, iter) {
       if (!iter->src.is_ssa) {
          /* If this write aliases the source of some entry, get rid of it */
          nir_deref_compare_result result =
-            nir_compare_derefs_and_paths(state->mem_ctx, &iter->src.deref, deref);
+            nir_compare_derefs_and_paths(state->mem_ctx, &iter->src.deref,
+                                         deref);
          if (result & nir_derefs_may_alias_bit) {
-            copy_entry_remove(copies, iter, entry ? &entry : NULL);
+            copy_entry_remove(copies_array, iter, *entry ? entry : NULL);
             continue;
          }
       }
@@ -399,58 +450,121 @@ lookup_entry_and_kill_aliases(struct copy_prop_var_state *state,
 
       if (comp & nir_derefs_equal_bit) {
          /* Make sure it is unique. */
-         assert(!entry);
-         entry = iter;
+         assert(!*entry && !*entry_removed);
+         if (remove_entry) {
+            copy_entry_remove(copies_array, iter, NULL);
+            *entry_removed = true;
+         } else {
+            *entry = iter;
+         }
       } else if (comp & nir_derefs_may_alias_bit) {
-         copy_entry_remove(copies, iter, entry ? &entry : NULL);
+         copy_entry_remove(copies_array, iter, *entry ? entry : NULL);
       }
    }
+}
+
+static struct copy_entry *
+lookup_entry_and_kill_aliases(struct copy_prop_var_state *state,
+                              struct copies *copies,
+                              nir_deref_and_path *deref,
+                              unsigned write_mask,
+                              bool remove_entry)
+{
+   /* TODO: Take into account the write_mask. */
+
+   bool UNUSED entry_removed = false;
+   struct copy_entry *entry = NULL;
+
+   nir_get_deref_path(state->mem_ctx, deref);
+
+   /* For any other variable types if the variables are different,
+    * they don't alias. So we only need to compare different vars and loop
+    * over the hash table for ssbos and shared vars.
+    */
+   if (deref->_path->path[0]->var->data.mode == nir_var_mem_ssbo ||
+       deref->_path->path[0]->var->data.mode == nir_var_mem_shared ||
+       deref->_path->path[0]->deref_type != nir_deref_type_var) {
+
+      hash_table_foreach(&copies->ht, ht_entry) {
+         struct util_dynarray *copies_array =
+            (struct util_dynarray *) ht_entry->data;
+
+         nir_variable *var = (nir_variable *) ht_entry->key;
+         if (deref->_path->path[0]->deref_type != nir_deref_type_cast &&
+             var->data.mode != deref->_path->path[0]->var->data.mode)
+            continue;
+
+         lookup_entry_and_kill_aliases_copy_array(state, copies_array, deref,
+                                                  write_mask, remove_entry,
+                                                  &entry, &entry_removed);
+      }
+
+      lookup_entry_and_kill_aliases_copy_array(state, &copies->arr, deref,
+                                                  write_mask, remove_entry,
+                                                  &entry, &entry_removed);
+   } else {
+      struct util_dynarray *copies_array =
+         copies_array_for_var(state, &copies->ht, deref->_path->path[0]->var);
+
+      lookup_entry_and_kill_aliases_copy_array(state, copies_array, deref,
+                                               write_mask, remove_entry,
+                                               &entry, &entry_removed);
+   }
 
    return entry;
 }
 
 static void
 kill_aliases(struct copy_prop_var_state *state,
-             struct util_dynarray *copies,
+             struct copies *copies,
              nir_deref_and_path *deref,
              unsigned write_mask)
 {
    /* TODO: Take into account the write_mask. */
 
-   struct copy_entry *entry =
-      lookup_entry_and_kill_aliases(state, copies, deref, write_mask);
-   if (entry)
-      copy_entry_remove(copies, entry, NULL);
+   lookup_entry_and_kill_aliases(state, copies, deref, write_mask, true);
 }
 
 static struct copy_entry *
 get_entry_and_kill_aliases(struct copy_prop_var_state *state,
-                           struct util_dynarray *copies,
+                           struct copies *copies,
                            nir_deref_and_path *deref,
                            unsigned write_mask)
 {
    /* TODO: Take into account the write_mask. */
 
    struct copy_entry *entry =
-      lookup_entry_and_kill_aliases(state, copies, deref, write_mask);
-
+      lookup_entry_and_kill_aliases(state, copies, deref, write_mask, false);
    if (entry == NULL)
-      entry = copy_entry_create(copies, deref);
+      entry = copy_entry_create(state, copies, deref);
 
    return entry;
 }
 
 static void
-apply_barrier_for_modes(struct util_dynarray *copies,
-                        nir_variable_mode modes)
+apply_barrier_for_modes_to_dynarr(struct util_dynarray *copies_array,
+                                 nir_variable_mode modes)
 {
-   util_dynarray_foreach_reverse(copies, struct copy_entry, iter) {
+   util_dynarray_foreach_reverse(copies_array, struct copy_entry, iter) {
       if (nir_deref_mode_may_be(iter->dst.instr, modes) ||
           (!iter->src.is_ssa && nir_deref_mode_may_be(iter->src.deref.instr, modes)))
-         copy_entry_remove(copies, iter, NULL);
+         copy_entry_remove(copies_array, iter, NULL);
    }
 }
 
+static void
+apply_barrier_for_modes(struct copies *copies,
+                        nir_variable_mode modes)
+{
+   hash_table_foreach(&copies->ht, ht_entry) {
+      struct util_dynarray *copies_array =
+         (struct util_dynarray *) ht_entry->data;
+      apply_barrier_for_modes_to_dynarr(copies_array, modes);
+   }
+
+   apply_barrier_for_modes_to_dynarr(&copies->arr, modes);
+}
+
 static void
 value_set_from_value(struct value *value, const struct value *from,
                      unsigned base_index, unsigned write_mask)
@@ -737,7 +851,7 @@ try_load_from_entry(struct copy_prop_var_state *state, struct copy_entry *entry,
 
 static void
 invalidate_copies_for_cf_node(struct copy_prop_var_state *state,
-                              struct util_dynarray *copies,
+                              struct copies *copies,
                               nir_cf_node *cf_node)
 {
    struct hash_entry *ht_entry = _mesa_hash_table_search(state->vars_written_map, cf_node);
@@ -745,9 +859,18 @@ invalidate_copies_for_cf_node(struct copy_prop_var_state *state,
 
    struct vars_written *written = ht_entry->data;
    if (written->modes) {
-      util_dynarray_foreach_reverse(copies, struct copy_entry, entry) {
+      hash_table_foreach(&copies->ht, ht_entry) {
+         struct util_dynarray *copies_array =
+            (struct util_dynarray *) ht_entry->data;
+         util_dynarray_foreach_reverse(copies_array, struct copy_entry, entry) {
+            if (nir_deref_mode_may_be(entry->dst.instr, written->modes))
+               copy_entry_remove(copies_array, entry, NULL);
+         }
+      }
+
+      util_dynarray_foreach_reverse(&copies->arr, struct copy_entry, entry) {
          if (nir_deref_mode_may_be(entry->dst.instr, written->modes))
-            copy_entry_remove(copies, entry, NULL);
+            copy_entry_remove(&copies->arr, entry, NULL);
       }
    }
 
@@ -808,17 +931,26 @@ dump_instr(nir_instr *instr)
 }
 
 static void
-dump_copy_entries(struct util_dynarray *copies)
+dump_copy_entries(struct copies *copies)
 {
-   util_dynarray_foreach(copies, struct copy_entry, iter)
+   hash_table_foreach(&copies->ht, ht_entry) {
+      struct util_dynarray *copies_array =
+         (struct util_dynarray *) ht_entry->data;
+
+      util_dynarray_foreach(copies_array, struct copy_entry, iter)
+         print_copy_entry(iter);
+   }
+
+   util_dynarray_foreach(&copies->arr, struct copy_entry, iter)
       print_copy_entry(iter);
+
    printf("\n");
 }
 
 static void
 copy_prop_vars_block(struct copy_prop_var_state *state,
                      nir_builder *b, nir_block *block,
-                     struct util_dynarray *copies)
+                     struct copies *copies)
 {
    if (debug) {
       printf("# block%d\n", block->index);
@@ -994,7 +1126,10 @@ copy_prop_vars_block(struct copy_prop_var_state *state,
             entry = NULL;
 
          if (!entry)
-            entry = copy_entry_create(copies, &vec_src);
+            entry = copy_entry_create(state, copies, &vec_src);
+
+         if (!entry)
+            break;
 
          /* Update the entry with the value of the load.  This way
           * we can potentially remove subsequent loads.
@@ -1050,7 +1185,8 @@ copy_prop_vars_block(struct copy_prop_var_state *state,
             unsigned wrmask = nir_intrinsic_write_mask(intrin);
             struct copy_entry *entry =
                get_entry_and_kill_aliases(state, copies, &vec_dst, wrmask);
-            value_set_from_value(&entry->src, &value, vec_index, wrmask);
+            if (entry)
+               value_set_from_value(&entry->src, &value, vec_index, wrmask);
          }
 
          break;
@@ -1130,7 +1266,8 @@ copy_prop_vars_block(struct copy_prop_var_state *state,
 
          struct copy_entry *dst_entry =
             get_entry_and_kill_aliases(state, copies, &dst, full_mask);
-         value_set_from_value(&dst_entry->src, &value, 0, full_mask);
+         if (dst_entry)
+            value_set_from_value(&dst_entry->src, &value, 0, full_mask);
          break;
       }
 
@@ -1196,20 +1333,57 @@ copy_prop_vars_block(struct copy_prop_var_state *state,
    }
 }
 
+static void
+clone_copies(struct copy_prop_var_state *state, struct copies *copies,
+             struct copies *clones)
+{
+   hash_table_foreach(&copies->ht, entry) {
+      struct util_dynarray *cloned_copies =
+         ralloc(state->mem_ctx, struct util_dynarray);
+      util_dynarray_clone(cloned_copies, state->mem_ctx,
+                          (struct util_dynarray *) entry->data);
+      _mesa_hash_table_insert(&clones->ht, entry->key, cloned_copies);
+   }
+
+   util_dynarray_clone(&clones->arr, state->mem_ctx, &copies->arr);
+}
+
+static struct copies *
+create_copies_structure(struct copy_prop_var_state *state)
+{
+   struct copies *copies = ralloc(state->mem_ctx, struct copies);
+
+   _mesa_hash_table_init(&copies->ht, state->mem_ctx, _mesa_hash_pointer,
+                         _mesa_key_pointer_equal);
+   util_dynarray_init(&copies->arr, state->mem_ctx);
+
+   return copies;
+}
+
+static void
+clear_copies_structure(struct copies *copies)
+{
+   hash_table_foreach(&copies->ht, entry) {
+      util_dynarray_fini((struct util_dynarray *) entry->data);
+   }
+   util_dynarray_fini(&copies->arr);
+   ralloc_free(copies);
+}
+
 static void
 copy_prop_vars_cf_node(struct copy_prop_var_state *state,
-                       struct util_dynarray *copies,
-                       nir_cf_node *cf_node)
+                       struct copies *copies, nir_cf_node *cf_node)
 {
    switch (cf_node->type) {
    case nir_cf_node_function: {
       nir_function_impl *impl = nir_cf_node_as_function(cf_node);
 
-      struct util_dynarray impl_copies;
-      util_dynarray_init(&impl_copies, state->mem_ctx);
+      struct copies *impl_copies = create_copies_structure(state);
 
       foreach_list_typed_safe(nir_cf_node, cf_node, node, &impl->body)
-         copy_prop_vars_cf_node(state, &impl_copies, cf_node);
+         copy_prop_vars_cf_node(state, impl_copies, cf_node);
+
+      clear_copies_structure(impl_copies);
 
       break;
    }
@@ -1225,22 +1399,24 @@ copy_prop_vars_cf_node(struct copy_prop_var_state *state,
    case nir_cf_node_if: {
       nir_if *if_stmt = nir_cf_node_as_if(cf_node);
 
-      /* Clone the copies for each branch of the if statement.  The idea is
+      /* Create new hash tables for tracking vars and fill it with clones of
+       * the copy arrays for each variable we are tracking.
+       *
+       * We clone the copies for each branch of the if statement.  The idea is
        * that they both see the same state of available copies, but do not
        * interfere to each other.
        */
+      struct copies *then_copies = create_copies_structure(state);
+      struct copies *else_copies = create_copies_structure(state);
 
-      struct util_dynarray then_copies;
-      util_dynarray_clone(&then_copies, state->mem_ctx, copies);
-
-      struct util_dynarray else_copies;
-      util_dynarray_clone(&else_copies, state->mem_ctx, copies);
+      clone_copies(state, copies, then_copies);
+      clone_copies(state, copies, else_copies);
 
       foreach_list_typed_safe(nir_cf_node, cf_node, node, &if_stmt->then_list)
-         copy_prop_vars_cf_node(state, &then_copies, cf_node);
+         copy_prop_vars_cf_node(state, then_copies, cf_node);
 
       foreach_list_typed_safe(nir_cf_node, cf_node, node, &if_stmt->else_list)
-         copy_prop_vars_cf_node(state, &else_copies, cf_node);
+         copy_prop_vars_cf_node(state, else_copies, cf_node);
 
       /* Both branches copies can be ignored, since the effect of running both
        * branches was captured in the first pass that collects vars_written.
@@ -1248,8 +1424,8 @@ copy_prop_vars_cf_node(struct copy_prop_var_state *state,
 
       invalidate_copies_for_cf_node(state, copies, cf_node);
 
-      util_dynarray_fini(&then_copies);
-      util_dynarray_fini(&else_copies);
+      clear_copies_structure(then_copies);
+      clear_copies_structure(else_copies);
 
       break;
    }
@@ -1263,13 +1439,14 @@ copy_prop_vars_cf_node(struct copy_prop_var_state *state,
 
       invalidate_copies_for_cf_node(state, copies, cf_node);
 
-      struct util_dynarray loop_copies;
-      util_dynarray_clone(&loop_copies, state->mem_ctx, copies);
+
+      struct copies *loop_copies = create_copies_structure(state);
+      clone_copies(state, copies, loop_copies);
 
       foreach_list_typed_safe(nir_cf_node, cf_node, node, &loop->body)
-         copy_prop_vars_cf_node(state, &loop_copies, cf_node);
+         copy_prop_vars_cf_node(state, loop_copies, cf_node);
 
-      util_dynarray_fini(&loop_copies);
+      clear_copies_structure(loop_copies);
 
       break;
    }
-- 
GitLab


From c16ad2042501a8f95f96248b11c67793c3740040 Mon Sep 17 00:00:00 2001
From: Timothy Arceri <tarceri@itsqueeze.com>
Date: Fri, 16 Dec 2022 14:20:21 +1100
Subject: [PATCH 3/7] nir/nir_opt_copy_prop_vars: reuse hash tables

Due to how this pass works we can end up thrashing memory if we
do not reuse these hash tables rather than reusing them.
---
 src/compiler/nir/nir_opt_copy_prop_vars.c | 50 +++++++++++++++--------
 1 file changed, 33 insertions(+), 17 deletions(-)

diff --git a/src/compiler/nir/nir_opt_copy_prop_vars.c b/src/compiler/nir/nir_opt_copy_prop_vars.c
index 4581f952a608..68685c3503bb 100644
--- a/src/compiler/nir/nir_opt_copy_prop_vars.c
+++ b/src/compiler/nir/nir_opt_copy_prop_vars.c
@@ -54,6 +54,8 @@ static const bool debug = false;
  */
 
 struct copies {
+   struct list_head node;
+
    /* Hash table of copies referenced by variables */
    struct hash_table ht;
 
@@ -61,7 +63,6 @@ struct copies {
    struct util_dynarray arr;
 };
 
-
 struct vars_written {
    nir_variable_mode modes;
 
@@ -110,6 +111,9 @@ struct copy_prop_var_state {
     */
    struct hash_table *vars_written_map;
 
+   /* List of copy structures ready for reuse */
+   struct list_head unused_copy_structs_list;
+
    bool progress;
 };
 
@@ -1348,26 +1352,38 @@ clone_copies(struct copy_prop_var_state *state, struct copies *copies,
    util_dynarray_clone(&clones->arr, state->mem_ctx, &copies->arr);
 }
 
+/* Returns an existing struct for reuse or creates a new on if they are
+ * all in use. This greatly reduces the time spent allocating memory if we
+ * were to just creating a fresh one each time.
+ */
 static struct copies *
-create_copies_structure(struct copy_prop_var_state *state)
+get_copies_structure(struct copy_prop_var_state *state)
 {
-   struct copies *copies = ralloc(state->mem_ctx, struct copies);
+   struct copies *copies;
+   if (list_is_empty(&state->unused_copy_structs_list)) {
+      copies = ralloc(state->mem_ctx, struct copies);
 
-   _mesa_hash_table_init(&copies->ht, state->mem_ctx, _mesa_hash_pointer,
+      _mesa_hash_table_init(&copies->ht, state->mem_ctx, _mesa_hash_pointer,
                          _mesa_key_pointer_equal);
-   util_dynarray_init(&copies->arr, state->mem_ctx);
+      util_dynarray_init(&copies->arr, state->mem_ctx);
+   } else {
+      copies = list_entry(state->unused_copy_structs_list.next,
+                          struct copies, node);
+      list_del(&copies->node);
+   }
 
    return copies;
 }
 
 static void
-clear_copies_structure(struct copies *copies)
+clear_copies_structure(struct copy_prop_var_state *state,
+                       struct copies *copies)
 {
    hash_table_foreach(&copies->ht, entry) {
       util_dynarray_fini((struct util_dynarray *) entry->data);
    }
-   util_dynarray_fini(&copies->arr);
-   ralloc_free(copies);
+
+   list_add(&copies->node, &state->unused_copy_structs_list);
 }
 
 static void
@@ -1378,12 +1394,12 @@ copy_prop_vars_cf_node(struct copy_prop_var_state *state,
    case nir_cf_node_function: {
       nir_function_impl *impl = nir_cf_node_as_function(cf_node);
 
-      struct copies *impl_copies = create_copies_structure(state);
+      struct copies *impl_copies = get_copies_structure(state);
 
       foreach_list_typed_safe(nir_cf_node, cf_node, node, &impl->body)
          copy_prop_vars_cf_node(state, impl_copies, cf_node);
 
-      clear_copies_structure(impl_copies);
+      clear_copies_structure(state, impl_copies);
 
       break;
    }
@@ -1406,8 +1422,8 @@ copy_prop_vars_cf_node(struct copy_prop_var_state *state,
        * that they both see the same state of available copies, but do not
        * interfere to each other.
        */
-      struct copies *then_copies = create_copies_structure(state);
-      struct copies *else_copies = create_copies_structure(state);
+      struct copies *then_copies = get_copies_structure(state);
+      struct copies *else_copies = get_copies_structure(state);
 
       clone_copies(state, copies, then_copies);
       clone_copies(state, copies, else_copies);
@@ -1424,8 +1440,8 @@ copy_prop_vars_cf_node(struct copy_prop_var_state *state,
 
       invalidate_copies_for_cf_node(state, copies, cf_node);
 
-      clear_copies_structure(then_copies);
-      clear_copies_structure(else_copies);
+      clear_copies_structure(state, then_copies);
+      clear_copies_structure(state, else_copies);
 
       break;
    }
@@ -1439,14 +1455,13 @@ copy_prop_vars_cf_node(struct copy_prop_var_state *state,
 
       invalidate_copies_for_cf_node(state, copies, cf_node);
 
-
-      struct copies *loop_copies = create_copies_structure(state);
+      struct copies *loop_copies = get_copies_structure(state);
       clone_copies(state, copies, loop_copies);
 
       foreach_list_typed_safe(nir_cf_node, cf_node, node, &loop->body)
          copy_prop_vars_cf_node(state, loop_copies, cf_node);
 
-      clear_copies_structure(loop_copies);
+      clear_copies_structure(state, loop_copies);
 
       break;
    }
@@ -1473,6 +1488,7 @@ nir_copy_prop_vars_impl(nir_function_impl *impl)
 
       .vars_written_map = _mesa_pointer_hash_table_create(mem_ctx),
    };
+   list_inithead(&state.unused_copy_structs_list);
 
    gather_vars_written(&state, NULL, &impl->cf_node);
 
-- 
GitLab


From 69054f9cca87ad981319f900afa834dc266eb92e Mon Sep 17 00:00:00 2001
From: Timothy Arceri <tarceri@itsqueeze.com>
Date: Fri, 16 Dec 2022 16:29:15 +1100
Subject: [PATCH 4/7] nir/nir_opt_copy_prop_vars: reuse dynamic arrays

As per the previous commit if we don't reuse these dynamic arrays
we end up needlessly thrashing the memory handling functions.
---
 src/compiler/nir/nir_opt_copy_prop_vars.c | 57 ++++++++++++++++-------
 1 file changed, 41 insertions(+), 16 deletions(-)

diff --git a/src/compiler/nir/nir_opt_copy_prop_vars.c b/src/compiler/nir/nir_opt_copy_prop_vars.c
index 68685c3503bb..f57deb768d70 100644
--- a/src/compiler/nir/nir_opt_copy_prop_vars.c
+++ b/src/compiler/nir/nir_opt_copy_prop_vars.c
@@ -63,6 +63,11 @@ struct copies {
    struct util_dynarray arr;
 };
 
+struct copies_dynarray {
+   struct list_head node;
+   struct util_dynarray arr;
+};
+
 struct vars_written {
    nir_variable_mode modes;
 
@@ -114,6 +119,9 @@ struct copy_prop_var_state {
    /* List of copy structures ready for reuse */
    struct list_head unused_copy_structs_list;
 
+   /* List of dynamic arrays ready for reuse */
+   struct list_head unused_copy_dynarray_list;
+
    bool progress;
 };
 
@@ -322,21 +330,36 @@ gather_vars_written(struct copy_prop_var_state *state,
    }
 }
 
+static struct copies_dynarray *
+get_copies_dynarray(struct copy_prop_var_state *state)
+{
+   struct copies_dynarray *cp_arr;
+   if (list_is_empty(&state->unused_copy_dynarray_list)) {
+      cp_arr = ralloc(state->mem_ctx, struct copies_dynarray);
+      util_dynarray_init(&cp_arr->arr, state->mem_ctx);
+   } else {
+      cp_arr = list_entry(state->unused_copy_dynarray_list.next,
+                          struct copies_dynarray, node);
+      list_del(&cp_arr->node);
+      util_dynarray_clear(&cp_arr->arr);
+   }
+
+   return cp_arr;
+}
+
 static struct util_dynarray *
 copies_array_for_var(struct copy_prop_var_state *state,
                      struct hash_table *copies, nir_variable *var)
 {
    struct hash_entry *entry = _mesa_hash_table_search(copies, var);
    if (entry != NULL)
-      return entry->data;
+      return &((struct copies_dynarray *) entry->data)->arr;
 
-   struct util_dynarray *empty_array =
-      ralloc(state->mem_ctx, struct util_dynarray);
-   util_dynarray_init(empty_array, state->mem_ctx);
+   struct copies_dynarray *copies_array = get_copies_dynarray(state);
 
-   _mesa_hash_table_insert(copies, var, empty_array);
+   _mesa_hash_table_insert(copies, var, copies_array);
 
-   return empty_array;
+   return &copies_array->arr;
 }
 
 static struct util_dynarray *
@@ -491,7 +514,7 @@ lookup_entry_and_kill_aliases(struct copy_prop_var_state *state,
 
       hash_table_foreach(&copies->ht, ht_entry) {
          struct util_dynarray *copies_array =
-            (struct util_dynarray *) ht_entry->data;
+            &((struct copies_dynarray *) ht_entry->data)->arr;
 
          nir_variable *var = (nir_variable *) ht_entry->key;
          if (deref->_path->path[0]->deref_type != nir_deref_type_cast &&
@@ -562,7 +585,7 @@ apply_barrier_for_modes(struct copies *copies,
 {
    hash_table_foreach(&copies->ht, ht_entry) {
       struct util_dynarray *copies_array =
-         (struct util_dynarray *) ht_entry->data;
+         &((struct copies_dynarray *) ht_entry->data)->arr;
       apply_barrier_for_modes_to_dynarr(copies_array, modes);
    }
 
@@ -865,7 +888,7 @@ invalidate_copies_for_cf_node(struct copy_prop_var_state *state,
    if (written->modes) {
       hash_table_foreach(&copies->ht, ht_entry) {
          struct util_dynarray *copies_array =
-            (struct util_dynarray *) ht_entry->data;
+            &((struct copies_dynarray *) ht_entry->data)->arr;
          util_dynarray_foreach_reverse(copies_array, struct copy_entry, entry) {
             if (nir_deref_mode_may_be(entry->dst.instr, written->modes))
                copy_entry_remove(copies_array, entry, NULL);
@@ -939,7 +962,7 @@ dump_copy_entries(struct copies *copies)
 {
    hash_table_foreach(&copies->ht, ht_entry) {
       struct util_dynarray *copies_array =
-         (struct util_dynarray *) ht_entry->data;
+         &((struct copies_dynarray *) ht_entry->data)->arr;
 
       util_dynarray_foreach(copies_array, struct copy_entry, iter)
          print_copy_entry(iter);
@@ -1342,10 +1365,9 @@ clone_copies(struct copy_prop_var_state *state, struct copies *copies,
              struct copies *clones)
 {
    hash_table_foreach(&copies->ht, entry) {
-      struct util_dynarray *cloned_copies =
-         ralloc(state->mem_ctx, struct util_dynarray);
-      util_dynarray_clone(cloned_copies, state->mem_ctx,
-                          (struct util_dynarray *) entry->data);
+      struct copies_dynarray *cloned_copies = get_copies_dynarray(state);
+      util_dynarray_clone(&cloned_copies->arr, state->mem_ctx,
+                          &((struct copies_dynarray *) entry->data)->arr);
       _mesa_hash_table_insert(&clones->ht, entry->key, cloned_copies);
    }
 
@@ -1379,8 +1401,10 @@ static void
 clear_copies_structure(struct copy_prop_var_state *state,
                        struct copies *copies)
 {
-   hash_table_foreach(&copies->ht, entry) {
-      util_dynarray_fini((struct util_dynarray *) entry->data);
+   hash_table_foreach_remove(&copies->ht, entry) {
+      struct copies_dynarray *cp_arr =
+        (struct copies_dynarray *) entry->data;
+      list_add(&cp_arr->node, &state->unused_copy_dynarray_list);
    }
 
    list_add(&copies->node, &state->unused_copy_structs_list);
@@ -1489,6 +1513,7 @@ nir_copy_prop_vars_impl(nir_function_impl *impl)
       .vars_written_map = _mesa_pointer_hash_table_create(mem_ctx),
    };
    list_inithead(&state.unused_copy_structs_list);
+   list_inithead(&state.unused_copy_dynarray_list);
 
    gather_vars_written(&state, NULL, &impl->cf_node);
 
-- 
GitLab


From 3381526630dab1db3aa4560b87f0f85e13446e4a Mon Sep 17 00:00:00 2001
From: Timothy Arceri <tarceri@itsqueeze.com>
Date: Sun, 18 Dec 2022 12:36:15 +1100
Subject: [PATCH 5/7] nir/nir_opt_copy_prop_vars: reorder clone calls

This helps with the reuse of dynamic arrays.
---
 src/compiler/nir/nir_opt_copy_prop_vars.c | 13 +++++++------
 1 file changed, 7 insertions(+), 6 deletions(-)

diff --git a/src/compiler/nir/nir_opt_copy_prop_vars.c b/src/compiler/nir/nir_opt_copy_prop_vars.c
index f57deb768d70..7c9087d60e17 100644
--- a/src/compiler/nir/nir_opt_copy_prop_vars.c
+++ b/src/compiler/nir/nir_opt_copy_prop_vars.c
@@ -1447,26 +1447,27 @@ copy_prop_vars_cf_node(struct copy_prop_var_state *state,
        * interfere to each other.
        */
       struct copies *then_copies = get_copies_structure(state);
-      struct copies *else_copies = get_copies_structure(state);
-
       clone_copies(state, copies, then_copies);
-      clone_copies(state, copies, else_copies);
 
       foreach_list_typed_safe(nir_cf_node, cf_node, node, &if_stmt->then_list)
          copy_prop_vars_cf_node(state, then_copies, cf_node);
 
+      clear_copies_structure(state, then_copies);
+
+      struct copies *else_copies = get_copies_structure(state);
+      clone_copies(state, copies, else_copies);
+
       foreach_list_typed_safe(nir_cf_node, cf_node, node, &if_stmt->else_list)
          copy_prop_vars_cf_node(state, else_copies, cf_node);
 
+      clear_copies_structure(state, else_copies);
+
       /* Both branches copies can be ignored, since the effect of running both
        * branches was captured in the first pass that collects vars_written.
        */
 
       invalidate_copies_for_cf_node(state, copies, cf_node);
 
-      clear_copies_structure(state, then_copies);
-      clear_copies_structure(state, else_copies);
-
       break;
    }
 
-- 
GitLab


From 919d4059fe30c004674e3f46930bf408f9b227dc Mon Sep 17 00:00:00 2001
From: Timothy Arceri <tarceri@itsqueeze.com>
Date: Sun, 18 Dec 2022 12:44:16 +1100
Subject: [PATCH 6/7] nir/nir_opt_copy_prop_vars: don't call memset when
 cloning

This makes the pass significantly faster cutting execution time
by around 30% in the cts test
dEQP-GLES31.functional.ubo.random.all_per_block_buffers.20

This 30% improvement is in addition to all the improvements from
the proceeding patches.
---
 src/compiler/nir/nir_opt_copy_prop_vars.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/src/compiler/nir/nir_opt_copy_prop_vars.c b/src/compiler/nir/nir_opt_copy_prop_vars.c
index 7c9087d60e17..b6a1ea2fa474 100644
--- a/src/compiler/nir/nir_opt_copy_prop_vars.c
+++ b/src/compiler/nir/nir_opt_copy_prop_vars.c
@@ -1366,8 +1366,8 @@ clone_copies(struct copy_prop_var_state *state, struct copies *copies,
 {
    hash_table_foreach(&copies->ht, entry) {
       struct copies_dynarray *cloned_copies = get_copies_dynarray(state);
-      util_dynarray_clone(&cloned_copies->arr, state->mem_ctx,
-                          &((struct copies_dynarray *) entry->data)->arr);
+      util_dynarray_append_dynarray(&cloned_copies->arr,
+                                    &((struct copies_dynarray *) entry->data)->arr);
       _mesa_hash_table_insert(&clones->ht, entry->key, cloned_copies);
    }
 
-- 
GitLab


From 86b0f0eb703ca337853a94b92a1b20b6a3cf56e8 Mon Sep 17 00:00:00 2001
From: Timothy Arceri <tarceri@itsqueeze.com>
Date: Fri, 13 Jan 2023 12:57:23 +1100
Subject: [PATCH 7/7] ci: enable dEQP-VK.ubo.random.all_shared_buffer.48

The previous commits fix the slow compile time, allowing us to
enable this test.

Closes: https://gitlab.freedesktop.org/mesa/mesa/-/issues/5152
---
 src/broadcom/ci/broadcom-rpi4-skips.txt   | 1 -
 src/freedreno/ci/freedreno-a630-skips.txt | 4 ----
 src/intel/ci/anv-tgl-skips.txt            | 1 -
 3 files changed, 6 deletions(-)
 delete mode 100644 src/intel/ci/anv-tgl-skips.txt

diff --git a/src/broadcom/ci/broadcom-rpi4-skips.txt b/src/broadcom/ci/broadcom-rpi4-skips.txt
index fa3556ea7534..1245e5edf7ed 100644
--- a/src/broadcom/ci/broadcom-rpi4-skips.txt
+++ b/src/broadcom/ci/broadcom-rpi4-skips.txt
@@ -91,4 +91,3 @@ dEQP-VK.texture.explicit_lod.2d.sizes.128x128_linear_linear_mipmap_linear_repeat
 dEQP-VK.texture.explicit_lod.2d.sizes.128x128_nearest_linear_mipmap_linear_clamp
 dEQP-VK.texture.explicit_lod.2d.sizes.128x128_nearest_linear_mipmap_linear_repeat
 dEQP-VK.ubo.random.all_out_of_order_offsets.45
-dEQP-VK.ubo.random.all_shared_buffer.48
diff --git a/src/freedreno/ci/freedreno-a630-skips.txt b/src/freedreno/ci/freedreno-a630-skips.txt
index f05e0b3a9bc0..870ca6bd0f75 100644
--- a/src/freedreno/ci/freedreno-a630-skips.txt
+++ b/src/freedreno/ci/freedreno-a630-skips.txt
@@ -27,10 +27,6 @@ dEQP-VK.api.command_buffers.record_many_draws_secondary_2
 spill-dEQP-VK.graphicsfuzz.cov-function-two-loops-limit-using-arguments-array-element-copies
 spill-dEQP-VK.graphicsfuzz.cov-nested-loop-large-array-index-using-vector-components
 
-# timeout, spending all its time in nir_compare_deref_paths()
-# https://gitlab.freedesktop.org/mesa/mesa/-/issues/5152
-dEQP-VK.ubo.random.all_shared_buffer.48
-
 # Still running after 3 hours, time is spent in batch_draw_tracking().
 KHR-GLES31.core.shader_image_load_store.basic-allFormats-store-fs
 
diff --git a/src/intel/ci/anv-tgl-skips.txt b/src/intel/ci/anv-tgl-skips.txt
deleted file mode 100644
index 24011a95cade..000000000000
--- a/src/intel/ci/anv-tgl-skips.txt
+++ /dev/null
@@ -1 +0,0 @@
-dEQP-VK.ubo.random.all_shared_buffer.48
-- 
GitLab

