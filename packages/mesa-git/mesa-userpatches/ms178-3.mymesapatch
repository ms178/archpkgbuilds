--- a/src/amd/vulkan/radv_sdma.c	2025-05-19 11:47:40.547779442 +0200
+++ b/src/amd/vulkan/radv_sdma.c	2025-05-19 12:13:27.829581389 +0200
@@ -50,19 +50,30 @@ radv_sdma_pitch_alignment(const struct r
 }
 
 ALWAYS_INLINE static void
-radv_sdma_check_pitches(const unsigned pitch, const unsigned slice_pitch, const unsigned bpp, const bool uses_depth)
-{
-   ASSERTED const unsigned pitch_alignment = MAX2(1, 4 / bpp);
-   assert(pitch);
-   assert(pitch <= (1 << 14));
-   assert(util_is_aligned(pitch, pitch_alignment));
-
-   if (uses_depth) {
-      ASSERTED const unsigned slice_pitch_alignment = 4;
-      assert(slice_pitch);
-      assert(slice_pitch <= (1 << 28));
-      assert(util_is_aligned(slice_pitch, slice_pitch_alignment));
-   }
+radv_sdma_check_pitches(const struct radv_device *device,
+                        unsigned                  pitch,
+                        unsigned                  slice_pitch,
+                        unsigned                  bpp,
+                        bool                      uses_depth)
+{
+    const struct radv_physical_device *pdev = radv_device_physical(device);
+    const enum   sdma_version          ver  = pdev->info.sdma_ip_version;
+
+    const unsigned pitch_bits = (ver >= SDMA_7_0) ? 16 :
+    (ver >= SDMA_4_0) ? 19 : 14;
+
+    ASSERTED unsigned pitch_align = MAX2(1, 4 / bpp);
+
+    assert(pitch);
+    assert(pitch <= (1u << pitch_bits));
+    assert(util_is_aligned(pitch, pitch_align));
+
+    if (uses_depth) {
+        ASSERTED unsigned slice_align = 4;
+        assert(slice_pitch);
+        assert(slice_pitch <= (1 << 28));
+        assert(util_is_aligned(slice_pitch, slice_align));
+    }
 }
 
 ALWAYS_INLINE static enum gfx9_resource_type
@@ -104,15 +115,16 @@ radv_sdma_pixel_extent_to_blocks(const V
 }
 
 ALWAYS_INLINE static VkOffset3D
-radv_sdma_pixel_offset_to_blocks(const VkOffset3D offset, const unsigned blk_w, const unsigned blk_h)
-{
-   const VkOffset3D r = {
-      .x = DIV_ROUND_UP(offset.x, blk_w),
-      .y = DIV_ROUND_UP(offset.y, blk_h),
-      .z = offset.z,
-   };
-
-   return r;
+radv_sdma_pixel_offset_to_blocks(const VkOffset3D offset,
+                                 unsigned          blk_w,
+                                 unsigned          blk_h)
+{
+    VkOffset3D r = {
+        .x = offset.x / blk_w,
+        .y = offset.y / blk_h,
+        .z = offset.z,
+    };
+    return r;
 }
 
 ALWAYS_INLINE static unsigned
@@ -131,7 +143,7 @@ static struct radv_sdma_chunked_copy_inf
 radv_sdma_get_chunked_copy_info(const struct radv_device *const device, const struct radv_sdma_surf *const img,
                                 const VkExtent3D extent)
 {
-   const unsigned extent_horizontal_blocks = DIV_ROUND_UP(extent.width, img->blk_w);
+   const unsigned extent_horizontal_blocks = DIV_ROUND_UP(extent.width * img->texel_scale, img->blk_w);
    const unsigned extent_vertical_blocks = DIV_ROUND_UP(extent.height, img->blk_h);
    const unsigned aligned_row_pitch = ALIGN(extent_horizontal_blocks, 4);
    const unsigned aligned_row_bytes = aligned_row_pitch * img->bpp;
@@ -162,7 +174,8 @@ radv_sdma_get_bpe(const struct radv_imag
 
    if (is_stencil_only) {
       return 1;
-   } else if (vk_format_is_96bit(image->vk.format)) {
+   } else if (image->vk.format == VK_FORMAT_R32G32B32_UINT || image->vk.format == VK_FORMAT_R32G32B32_SINT ||
+              image->vk.format == VK_FORMAT_R32G32B32_SFLOAT) {
       /* Adjust the bpp for 96-bits formats because SDMA expects a power of two. */
       return 4;
    } else {
@@ -173,7 +186,8 @@ radv_sdma_get_bpe(const struct radv_imag
 static uint32_t
 radv_sdma_get_texel_scale(const struct radv_image *const image)
 {
-   if (vk_format_is_96bit(image->vk.format)) {
+   if (image->vk.format == VK_FORMAT_R32G32B32_UINT || image->vk.format == VK_FORMAT_R32G32B32_SINT ||
+       image->vk.format == VK_FORMAT_R32G32B32_SFLOAT) {
       return 3;
    } else {
       return 1;
@@ -278,71 +292,92 @@ radv_sdma_get_tiled_header_dword(const s
 }
 
 struct radv_sdma_surf
-radv_sdma_get_surf(const struct radv_device *const device, const struct radv_image *const image,
-                   const VkImageSubresourceLayers subresource, const VkOffset3D offset)
-{
-   assert(util_bitcount(subresource.aspectMask) == 1);
-
-   const struct radv_physical_device *pdev = radv_device_physical(device);
-   const unsigned plane_idx = radv_plane_from_aspect(subresource.aspectMask);
-   const unsigned binding_idx = image->disjoint ? plane_idx : 0;
-   const struct radeon_surf *const surf = &image->planes[plane_idx].surface;
-   const struct radv_image_binding *binding = &image->bindings[binding_idx];
-   const uint64_t va = binding->addr;
-   const uint32_t bpe = radv_sdma_get_bpe(image, subresource.aspectMask);
-   struct radv_sdma_surf info = {
-      .extent =
-         {
-            .width = vk_format_get_plane_width(image->vk.format, plane_idx, image->vk.extent.width),
-            .height = vk_format_get_plane_height(image->vk.format, plane_idx, image->vk.extent.height),
-            .depth = image->vk.image_type == VK_IMAGE_TYPE_3D ? image->vk.extent.depth : image->vk.array_layers,
-         },
-      .offset =
-         {
+radv_sdma_get_surf(const struct radv_device            *device,
+                   const struct radv_image             *image,
+                   const VkImageSubresourceLayers       subresource,
+                   const VkOffset3D                     offset)
+{
+    const struct radv_physical_device *pdev       = radv_device_physical(device);
+    const enum   sdma_version          ver        = pdev->info.sdma_ip_version;
+
+    const unsigned plane_idx   = radv_plane_from_aspect(subresource.aspectMask);
+    const unsigned binding_idx = image->disjoint ? plane_idx : 0;
+
+    const struct radeon_surf          *surf    = &image->planes[plane_idx].surface;
+    const struct radv_image_binding   *binding = &image->bindings[binding_idx];
+    const uint64_t                     base_va = binding->addr;
+    const uint32_t                     bpe     = radv_sdma_get_bpe(image,
+                                                                   subresource.aspectMask);
+
+    struct radv_sdma_surf info = {
+        .extent =
+        {
+            .width  = vk_format_get_plane_width (image->vk.format, plane_idx,
+                                                 image->vk.extent.width),
+                                                 .height = vk_format_get_plane_height(image->vk.format, plane_idx,
+                                                                                      image->vk.extent.height),
+                                                                                      .depth  = (image->vk.image_type == VK_IMAGE_TYPE_3D) ?
+                                                                                      image->vk.extent.depth : image->vk.array_layers,
+        },
+        .offset =
+        {
             .x = offset.x,
             .y = offset.y,
-            .z = image->vk.image_type == VK_IMAGE_TYPE_3D ? offset.z : subresource.baseArrayLayer,
-         },
-      .bpp = bpe,
-      .blk_w = surf->blk_w,
-      .blk_h = surf->blk_h,
-      .mip_levels = image->vk.mip_levels,
-      .micro_tile_mode = surf->micro_tile_mode,
-      .texel_scale = radv_sdma_get_texel_scale(image),
-      .is_linear = surf->is_linear,
-      .is_3d = surf->u.gfx9.resource_type == RADEON_RESOURCE_3D,
-   };
-
-   const uint64_t surf_offset = (subresource.aspectMask == VK_IMAGE_ASPECT_STENCIL_BIT) ? surf->u.gfx9.zs.stencil_offset
-                                                                                        : surf->u.gfx9.surf_offset;
-
-   if (surf->is_linear) {
-      info.va = va + surf_offset + surf->u.gfx9.offset[subresource.mipLevel];
-      info.pitch = surf->u.gfx9.pitch[subresource.mipLevel];
-      info.slice_pitch = surf->blk_w * surf->blk_h * surf->u.gfx9.surf_slice_size / bpe;
-   } else {
-      /* 1D resources should be linear. */
-      assert(surf->u.gfx9.resource_type != RADEON_RESOURCE_1D);
-
-      info.va = (va + surf_offset) | surf->tile_swizzle << 8;
-
-      info.info_dword = radv_sdma_get_tiled_info_dword(device, image, surf, subresource);
-      info.header_dword = radv_sdma_get_tiled_header_dword(device, image, subresource);
-
-      if (pdev->info.gfx_level >= GFX12) {
-         info.is_compressed = binding->bo && binding->bo->gfx12_allow_dcc;
-      } else if (pdev->info.sdma_supports_compression &&
-                 (radv_dcc_enabled(image, subresource.mipLevel) || radv_htile_enabled(image, subresource.mipLevel))) {
-         info.is_compressed = true;
-      }
+            .z = (image->vk.image_type == VK_IMAGE_TYPE_3D) ?
+            offset.z : subresource.baseArrayLayer,
+        },
+        .bpp            = bpe,
+        .blk_w          = surf->blk_w,
+        .blk_h          = surf->blk_h,
+        .mip_levels     = image->vk.mip_levels,
+        .micro_tile_mode= surf->micro_tile_mode,
+        .texel_scale    = radv_sdma_get_texel_scale(image),
+        .is_linear      = surf->is_linear,
+        .is_3d          = surf->u.gfx9.resource_type == RADEON_RESOURCE_3D,
+    };
+
+    const uint64_t surf_offset =
+    (subresource.aspectMask == VK_IMAGE_ASPECT_STENCIL_BIT) ?
+    surf->u.gfx9.zs.stencil_offset : surf->u.gfx9.surf_offset;
+
+    if (surf->is_linear) {
+        info.va          = base_va + surf_offset +
+        surf->u.gfx9.offset[subresource.mipLevel];
+
+        /* Convert byte pitch/size to SDMA element counts. */
+        info.pitch       = surf->u.gfx9.pitch[subresource.mipLevel] / bpe;
+        info.slice_pitch = surf->u.gfx9.surf_slice_size           / bpe;
+    } else {
+        /* 1D tiled resources should not exist. */
+        assert(surf->u.gfx9.resource_type != RADEON_RESOURCE_1D);
+
+        info.va = (base_va + surf_offset) | surf->tile_swizzle << 8;
+
+        info.info_dword   = radv_sdma_get_tiled_info_dword(device, image,
+                                                           surf, subresource);
+        info.header_dword = radv_sdma_get_tiled_header_dword(device, image,
+                                                             subresource);
+
+        if (pdev->info.gfx_level >= GFX12) {
+            info.is_compressed = binding->bo && binding->bo->gfx12_allow_dcc;
+        } else if (pdev->info.sdma_supports_compression &&
+            (radv_dcc_enabled(image, subresource.mipLevel) ||
+            radv_htile_enabled(image, subresource.mipLevel))) {
+            info.is_compressed = true;
+            }
+
+            /* SDMA < 5.0 cannot handle metadata. */
+            if (ver < SDMA_5_0)
+                info.is_compressed = false;
+
+        if (info.is_compressed) {
+            info.meta_va     = base_va + surf->meta_offset;
+            info.meta_config = radv_sdma_get_metadata_config(device, image,
+                                                             surf, subresource);
+        }
+    }
 
-      if (info.is_compressed) {
-         info.meta_va = va + surf->meta_offset;
-         info.meta_config = radv_sdma_get_metadata_config(device, image, surf, subresource);
-      }
-   }
-
-   return info;
+    return info;
 }
 
 void
@@ -450,157 +485,189 @@ radv_sdma_copy_memory(const struct radv_
 }
 
 void
-radv_sdma_fill_memory(const struct radv_device *device, struct radeon_cmdbuf *cs, const uint64_t va,
-                      const uint64_t size, const uint32_t value)
-{
-   const struct radv_physical_device *pdev = radv_device_physical(device);
-
-   const uint32_t fill_size = 2; /* This means that the count is in dwords. */
-   const uint32_t constant_fill_header = SDMA_PACKET(SDMA_OPCODE_CONSTANT_FILL, 0, 0) | (fill_size & 0x3) << 30;
-
-   /* This packet is the same since SDMA v2.4, haven't bothered to check older versions. */
-   const enum sdma_version ver = pdev->info.sdma_ip_version;
-   assert(ver >= SDMA_2_4);
-
-   /* Maximum allowed fill size depends on the GPU.
-    * Emit as many packets as necessary to fill all the bytes we need.
-    */
-   const uint64_t max_fill_bytes = BITFIELD64_MASK(ver >= SDMA_6_0 ? 30 : 22) & ~0x3;
-   const unsigned num_packets = DIV_ROUND_UP(size, max_fill_bytes);
-   ASSERTED unsigned cdw_max = radeon_check_space(device->ws, cs, num_packets * 5);
-
-   radeon_begin(cs);
-
-   for (unsigned i = 0; i < num_packets; ++i) {
-      const uint64_t offset = i * max_fill_bytes;
-      const uint64_t fill_bytes = MIN2(size - offset, max_fill_bytes);
-      const uint64_t fill_va = va + offset;
-
-      radeon_emit(constant_fill_header);
-      radeon_emit(fill_va);
-      radeon_emit(fill_va >> 32);
-      radeon_emit(value);
-      radeon_emit(fill_bytes - 1); /* Must be programmed in bytes, even if the fill is done in dwords. */
-   }
-
-   radeon_end();
-   assert(cs->cdw <= cdw_max);
+radv_sdma_fill_memory(const struct radv_device *device,
+                      struct radeon_cmdbuf     *cs,
+                      const uint64_t            va,
+                      const uint64_t            size,
+                      const uint32_t            value)
+{
+    const struct radv_physical_device *pdev = radv_device_physical(device);
+
+    const uint32_t fill_size = 2; /* count is in dwords */
+    const uint32_t header =
+    SDMA_PACKET(SDMA_OPCODE_CONSTANT_FILL, 0, 0) |
+    (fill_size & 0x3) << 30;
+
+    const enum sdma_version ver = pdev->info.sdma_ip_version;
+    assert(ver >= SDMA_2_4);
+
+    const unsigned length_bits =
+    (ver >= SDMA_6_0) ? 30 :
+    (ver >= SDMA_4_0) ? 26 : 22;
+
+    const uint64_t max_fill_bytes =
+    BITFIELD64_MASK(length_bits) & ~0x3ull;
+
+    const unsigned num_packets = DIV_ROUND_UP(size, max_fill_bytes);
+    ASSERTED unsigned cdw_max = radeon_check_space(device->ws, cs,
+                                                   num_packets * 5);
+
+    radeon_begin(cs);
+    for (unsigned i = 0; i < num_packets; ++i) {
+        const uint64_t offset     = (uint64_t)i * max_fill_bytes;
+        const uint64_t fill_bytes = MIN2(size - offset, max_fill_bytes);
+        const uint64_t fill_va    = va + offset;
+
+        radeon_emit(header);
+        radeon_emit(fill_va);
+        radeon_emit(fill_va >> 32);
+        radeon_emit(value);
+        radeon_emit(fill_bytes - 1);
+    }
+    radeon_end();
+    assert(cs->cdw <= cdw_max);
 }
 
 static void
-radv_sdma_emit_copy_linear_sub_window(const struct radv_device *device, struct radeon_cmdbuf *cs,
-                                      const struct radv_sdma_surf *const src, const struct radv_sdma_surf *const dst,
-                                      const VkExtent3D pix_extent)
-{
-   /* This packet is the same since SDMA v2.4, haven't bothered to check older versions.
-    * The main difference is the bitfield sizes:
-    *
-    * v2.4 - src/dst_pitch: 14 bits, rect_z: 11 bits
-    * v4.0 - src/dst_pitch: 19 bits, rect_z: 11 bits
-    * v5.0 - src/dst_pitch: 19 bits, rect_z: 13 bits
-    *
-    * We currently use the smallest limits (from SDMA v2.4).
-    */
+radv_sdma_emit_copy_linear_sub_window(const struct radv_device    *device,
+                                      struct radeon_cmdbuf        *cs,
+                                      const struct radv_sdma_surf *src,
+                                      const struct radv_sdma_surf *dst,
+                                      VkExtent3D                   pix_extent)
+{
+    const struct radv_physical_device *pdev = radv_device_physical(device);
+    const enum sdma_version ver = pdev->info.sdma_ip_version;
+
+    VkOffset3D src_off = radv_sdma_pixel_offset_to_blocks(src->offset,
+                                                          src->blk_w, src->blk_h);
+    VkOffset3D dst_off = radv_sdma_pixel_offset_to_blocks(dst->offset,
+                                                          dst->blk_w, dst->blk_h);
+    VkExtent3D ext     = radv_sdma_pixel_extent_to_blocks(pix_extent,
+                                                          src->blk_w, src->blk_h);
+
+    unsigned src_pitch       = radv_sdma_pixels_to_blocks(src->pitch, src->blk_w);
+    unsigned dst_pitch       = radv_sdma_pixels_to_blocks(dst->pitch, dst->blk_w);
+    unsigned src_slice_pitch = radv_sdma_pixel_area_to_blocks(src->slice_pitch,
+                                                              src->blk_w, src->blk_h);
+    unsigned dst_slice_pitch = radv_sdma_pixel_area_to_blocks(dst->slice_pitch,
+                                                              dst->blk_w, dst->blk_h);
+
+    assert(src->bpp == dst->bpp);
+    assert(util_is_power_of_two_nonzero(src->bpp));
+
+    radv_sdma_check_pitches(device, src->pitch, src->slice_pitch,
+                            src->bpp, false);
+    radv_sdma_check_pitches(device, dst->pitch, dst->slice_pitch,
+                            dst->bpp, false);
+
+    const unsigned texel_scale =
+    src->texel_scale ? src->texel_scale : dst->texel_scale;
+    assert(texel_scale);
+
+    src_off.x *= texel_scale;
+    dst_off.x *= texel_scale;
+    ext.width *= texel_scale;
+
+    ASSERTED unsigned cdw_end = radeon_check_space(device->ws, cs, 13);
+
+    radeon_begin(cs);
+    radeon_emit(SDMA_PACKET(SDMA_OPCODE_COPY,
+                            SDMA_COPY_SUB_OPCODE_LINEAR_SUB_WINDOW, 0) |
+                            util_logbase2(src->bpp) << 29);
+    radeon_emit(src->va);
+    radeon_emit(src->va >> 32);
+    radeon_emit(src_off.x | src_off.y << 16);
+    radeon_emit(src_off.z |
+    (src_pitch - 1) << (ver >= SDMA_7_0 ? 16 : 13));
+    radeon_emit(src_slice_pitch - 1);
+
+    radeon_emit(dst->va);
+    radeon_emit(dst->va >> 32);
+    radeon_emit(dst_off.x | dst_off.y << 16);
+    radeon_emit(dst_off.z |
+    (dst_pitch - 1) << (ver >= SDMA_7_0 ? 16 : 13));
+    radeon_emit(dst_slice_pitch - 1);
+
+    radeon_emit((ext.width - 1) | (ext.height - 1) << 16);
+    radeon_emit((ext.depth - 1));
+    radeon_end();
 
-   const struct radv_physical_device *pdev = radv_device_physical(device);
-   VkOffset3D src_off = radv_sdma_pixel_offset_to_blocks(src->offset, src->blk_w, src->blk_h);
-   VkOffset3D dst_off = radv_sdma_pixel_offset_to_blocks(dst->offset, dst->blk_w, dst->blk_h);
-   VkExtent3D ext = radv_sdma_pixel_extent_to_blocks(pix_extent, src->blk_w, src->blk_h);
-   const unsigned src_pitch = radv_sdma_pixels_to_blocks(src->pitch, src->blk_w);
-   const unsigned dst_pitch = radv_sdma_pixels_to_blocks(dst->pitch, dst->blk_w);
-   const unsigned src_slice_pitch = radv_sdma_pixel_area_to_blocks(src->slice_pitch, src->blk_w, src->blk_h);
-   const unsigned dst_slice_pitch = radv_sdma_pixel_area_to_blocks(dst->slice_pitch, dst->blk_w, dst->blk_h);
-   const enum sdma_version ver = pdev->info.sdma_ip_version;
-
-   assert(src->bpp == dst->bpp);
-   assert(util_is_power_of_two_nonzero(src->bpp));
-   radv_sdma_check_pitches(src->pitch, src->slice_pitch, src->bpp, false);
-   radv_sdma_check_pitches(dst->pitch, dst->slice_pitch, dst->bpp, false);
-
-   /* Adjust offset/extent for 96-bits formats because SDMA expects a power of two bpp. */
-   const uint32_t texel_scale = src->texel_scale == 1 ? dst->texel_scale : src->texel_scale;
-   assert(texel_scale);
-   src_off.x *= texel_scale;
-   dst_off.x *= texel_scale;
-   ext.width *= texel_scale;
-
-   ASSERTED unsigned cdw_end = radeon_check_space(device->ws, cs, 13);
-
-   radeon_begin(cs);
-   radeon_emit(SDMA_PACKET(SDMA_OPCODE_COPY, SDMA_COPY_SUB_OPCODE_LINEAR_SUB_WINDOW, 0) | util_logbase2(src->bpp)
-                                                                                             << 29);
-   radeon_emit(src->va);
-   radeon_emit(src->va >> 32);
-   radeon_emit(src_off.x | src_off.y << 16);
-   radeon_emit(src_off.z | (src_pitch - 1) << (ver >= SDMA_7_0 ? 16 : 13));
-   radeon_emit(src_slice_pitch - 1);
-   radeon_emit(dst->va);
-   radeon_emit(dst->va >> 32);
-   radeon_emit(dst_off.x | dst_off.y << 16);
-   radeon_emit(dst_off.z | (dst_pitch - 1) << (ver >= SDMA_7_0 ? 16 : 13));
-   radeon_emit(dst_slice_pitch - 1);
-   radeon_emit((ext.width - 1) | (ext.height - 1) << 16);
-   radeon_emit((ext.depth - 1));
-   radeon_end();
-
-   assert(cs->cdw == cdw_end);
+    assert(cs->cdw == cdw_end);
 }
 
 static void
-radv_sdma_emit_copy_tiled_sub_window(const struct radv_device *device, struct radeon_cmdbuf *cs,
-                                     const struct radv_sdma_surf *const tiled,
-                                     const struct radv_sdma_surf *const linear, const VkExtent3D pix_extent,
-                                     const bool detile)
-{
-   const struct radv_physical_device *pdev = radv_device_physical(device);
-
-   if (!pdev->info.sdma_supports_compression) {
-      assert(!tiled->is_compressed);
-   }
-
-   const VkOffset3D linear_off = radv_sdma_pixel_offset_to_blocks(linear->offset, linear->blk_w, linear->blk_h);
-   const VkOffset3D tiled_off = radv_sdma_pixel_offset_to_blocks(tiled->offset, tiled->blk_w, tiled->blk_h);
-   const VkExtent3D tiled_ext = radv_sdma_pixel_extent_to_blocks(tiled->extent, tiled->blk_w, tiled->blk_h);
-   const VkExtent3D ext = radv_sdma_pixel_extent_to_blocks(pix_extent, tiled->blk_w, tiled->blk_h);
-   const unsigned linear_pitch = radv_sdma_pixels_to_blocks(linear->pitch, tiled->blk_w);
-   const unsigned linear_slice_pitch = radv_sdma_pixel_area_to_blocks(linear->slice_pitch, tiled->blk_w, tiled->blk_h);
-   const bool dcc = tiled->is_compressed;
-   const bool uses_depth = linear_off.z != 0 || tiled_off.z != 0 || ext.depth != 1;
-
-   assert(util_is_power_of_two_nonzero(tiled->bpp));
-   radv_sdma_check_pitches(linear_pitch, linear_slice_pitch, tiled->bpp, uses_depth);
-
-   ASSERTED unsigned cdw_end = radeon_check_space(device->ws, cs, 14 + (dcc ? 3 : 0));
-
-   radeon_begin(cs);
-   radeon_emit(SDMA_PACKET(SDMA_OPCODE_COPY, SDMA_COPY_SUB_OPCODE_TILED_SUB_WINDOW, 0) | dcc << 19 | detile << 31 |
-               tiled->header_dword);
-   radeon_emit(tiled->va);
-   radeon_emit(tiled->va >> 32);
-   radeon_emit(tiled_off.x | tiled_off.y << 16);
-   radeon_emit(tiled_off.z | (tiled_ext.width - 1) << 16);
-   radeon_emit((tiled_ext.height - 1) | (tiled_ext.depth - 1) << 16);
-   radeon_emit(tiled->info_dword);
-   radeon_emit(linear->va);
-   radeon_emit(linear->va >> 32);
-   radeon_emit(linear_off.x | linear_off.y << 16);
-   radeon_emit(linear_off.z | (linear_pitch - 1) << 16);
-   radeon_emit(linear_slice_pitch - 1);
-   radeon_emit((ext.width - 1) | (ext.height - 1) << 16);
-   radeon_emit((ext.depth - 1));
-
-   if (tiled->is_compressed) {
-      if (pdev->info.sdma_ip_version >= SDMA_7_0) {
-         radeon_emit(tiled->meta_config | SDMA7_DCC_WRITE_CM(!detile));
-      } else {
-         radeon_emit(tiled->meta_va);
-         radeon_emit(tiled->meta_va >> 32);
-         radeon_emit(tiled->meta_config | SDMA5_DCC_WRITE_COMPRESS(!detile));
-      }
-   }
-
-   radeon_end();
-   assert(cs->cdw <= cdw_end);
+radv_sdma_emit_copy_tiled_sub_window(const struct radv_device    *device,
+                                     struct radeon_cmdbuf        *cs,
+                                     const struct radv_sdma_surf *tiled,
+                                     const struct radv_sdma_surf *linear,
+                                     VkExtent3D                   pix_extent,
+                                     bool                         detile)
+{
+    const struct radv_physical_device *pdev = radv_device_physical(device);
+    if (!pdev->info.sdma_supports_compression)
+        assert(!tiled->is_compressed);
+
+    VkOffset3D linear_off =
+    radv_sdma_pixel_offset_to_blocks(linear->offset,
+                                     linear->blk_w, linear->blk_h);
+    VkOffset3D tiled_off  =
+    radv_sdma_pixel_offset_to_blocks(tiled->offset,
+                                     tiled->blk_w,  tiled->blk_h);
+    VkExtent3D tiled_ext  =
+    radv_sdma_pixel_extent_to_blocks(tiled->extent,
+                                     tiled->blk_w,  tiled->blk_h);
+    VkExtent3D ext        =
+    radv_sdma_pixel_extent_to_blocks(pix_extent,
+                                     tiled->blk_w,  tiled->blk_h);
+
+    unsigned linear_pitch =
+    radv_sdma_pixels_to_blocks(linear->pitch, tiled->blk_w);
+    unsigned linear_slice_pitch =
+    radv_sdma_pixel_area_to_blocks(linear->slice_pitch,
+                                   tiled->blk_w, tiled->blk_h);
+
+    bool dcc        = tiled->is_compressed;
+    bool uses_depth = linear_off.z || tiled_off.z || ext.depth != 1;
+
+    radv_sdma_check_pitches(device, linear_pitch, linear_slice_pitch,
+                            tiled->bpp, uses_depth);
+
+    ASSERTED unsigned cdw_end =
+    radeon_check_space(device->ws, cs, 14 + (dcc ? 3 : 0));
+
+    radeon_begin(cs);
+    radeon_emit(SDMA_PACKET(SDMA_OPCODE_COPY,
+                            SDMA_COPY_SUB_OPCODE_TILED_SUB_WINDOW, 0) |
+                            dcc << 19 | detile << 31 | tiled->header_dword);
+
+    radeon_emit(tiled->va);
+    radeon_emit(tiled->va >> 32);
+    radeon_emit(tiled_off.x | tiled_off.y << 16);
+    radeon_emit(tiled_off.z | (tiled_ext.width  - 1) << 16);
+    radeon_emit((tiled_ext.height - 1) |
+    (tiled_ext.depth  - 1) << 16);
+    radeon_emit(tiled->info_dword);
+
+    radeon_emit(linear->va);
+    radeon_emit(linear->va >> 32);
+    radeon_emit(linear_off.x | linear_off.y << 16);
+    radeon_emit(linear_off.z | (linear_pitch - 1) << 16);
+    radeon_emit(linear_slice_pitch - 1);
+
+    radeon_emit((ext.width  - 1) | (ext.height - 1) << 16);
+    radeon_emit((ext.depth  - 1));
+
+    if (dcc) {
+        if (pdev->info.sdma_ip_version >= SDMA_7_0) {
+            radeon_emit(tiled->meta_config | SDMA7_DCC_WRITE_CM(!detile));
+        } else {
+            radeon_emit(tiled->meta_va);
+            radeon_emit(tiled->meta_va >> 32);
+            radeon_emit(tiled->meta_config | SDMA5_DCC_WRITE_COMPRESS(!detile));
+        }
+    }
+    radeon_end();
+    assert(cs->cdw <= cdw_end);
 }
 
 static void
@@ -719,71 +786,71 @@ radv_sdma_copy_buffer_image_unaligned(co
                                       const struct radv_sdma_surf *buf, const struct radv_sdma_surf *img_in,
                                       const VkExtent3D base_extent, struct radeon_winsys_bo *temp_bo, bool to_image)
 {
-   const struct radv_sdma_chunked_copy_info info = radv_sdma_get_chunked_copy_info(device, img_in, base_extent);
-   struct radv_sdma_surf img = *img_in;
-   struct radv_sdma_surf tmp = {
-      .va = temp_bo->va,
-      .bpp = img.bpp,
-      .blk_w = img.blk_w,
-      .blk_h = img.blk_h,
-      .pitch = info.aligned_row_pitch * img.blk_w,
-      .slice_pitch = info.aligned_row_pitch * img.blk_w * info.extent_vertical_blocks * img.blk_h,
-      .texel_scale = buf->texel_scale,
-   };
-
-   VkExtent3D extent = base_extent;
-   const unsigned buf_pitch_blocks = DIV_ROUND_UP(buf->pitch, img.blk_w);
-   const unsigned buf_slice_pitch_blocks = DIV_ROUND_UP(DIV_ROUND_UP(buf->slice_pitch, img.blk_w), img.blk_h);
-   assert(buf_pitch_blocks);
-   assert(buf_slice_pitch_blocks);
-   extent.depth = 1;
-
-   for (unsigned slice = 0; slice < base_extent.depth; ++slice) {
-      for (unsigned row = 0; row < info.extent_vertical_blocks; row += info.num_rows_per_copy) {
-         const unsigned rows = MIN2(info.extent_vertical_blocks - row, info.num_rows_per_copy);
-
-         img.offset.y = img_in->offset.y + row * img.blk_h;
-         img.offset.z = img_in->offset.z + slice;
-         extent.height = rows * img.blk_h;
-         tmp.slice_pitch = tmp.pitch * rows * img.blk_h;
-
-         if (!to_image) {
-            /* Copy the rows from the source image to the temporary buffer. */
-            if (img.is_linear)
-               radv_sdma_emit_copy_linear_sub_window(device, cs, &img, &tmp, extent);
-            else
-               radv_sdma_emit_copy_tiled_sub_window(device, cs, &img, &tmp, extent, true);
+    const struct radv_sdma_chunked_copy_info info = radv_sdma_get_chunked_copy_info(device, img_in, base_extent);
+    struct radv_sdma_surf img = *img_in;
+    struct radv_sdma_surf tmp = {
+        .va = temp_bo->va,
+        .bpp = img.bpp,
+        .blk_w = img.blk_w,
+        .blk_h = img.blk_h,
+        .pitch = info.aligned_row_pitch * img.blk_w,
+        .slice_pitch = info.aligned_row_pitch * img.blk_w * info.extent_vertical_blocks * img.blk_h,
+        .texel_scale = buf->texel_scale,
+    };
+
+    VkExtent3D extent = base_extent;
+    const unsigned buf_pitch_blocks = DIV_ROUND_UP(buf->pitch, img.blk_w);
+    const unsigned buf_slice_pitch_blocks = DIV_ROUND_UP(DIV_ROUND_UP(buf->slice_pitch, img.blk_w), img.blk_h);
+    assert(buf_pitch_blocks);
+    assert(buf_slice_pitch_blocks);
+    extent.depth = 1;
+
+    for (unsigned slice = 0; slice < base_extent.depth; ++slice) {
+        for (unsigned row = 0; row < info.extent_vertical_blocks; row += info.num_rows_per_copy) {
+            const unsigned rows = MIN2(info.extent_vertical_blocks - row, info.num_rows_per_copy);
+
+            img.offset.y = img_in->offset.y + row * img.blk_h;
+            img.offset.z = img_in->offset.z + slice;
+            extent.height = rows * img.blk_h;
+            tmp.slice_pitch = tmp.pitch * rows * img.blk_h;
+
+            if (!to_image) {
+                /* Copy the rows from the source image to the temporary buffer. */
+                if (img.is_linear)
+                    radv_sdma_emit_copy_linear_sub_window(device, cs, &img, &tmp, extent);
+                else
+                    radv_sdma_emit_copy_tiled_sub_window(device, cs, &img, &tmp, extent, true);
+
+                /* Wait for the copy to finish. */
+                radv_sdma_emit_nop(device, cs);
+            }
+
+            /* buffer to image: copy each row from source buffer to temporary buffer.
+             * image to buffer: copy each row from temporary buffer to destination buffer.
+             */
+            for (unsigned r = 0; r < rows; ++r) {
+                const uint64_t buf_va =
+                buf->va + slice * buf_slice_pitch_blocks * img.bpp + (row + r) * buf_pitch_blocks * img.bpp;
+                const uint64_t tmp_va = tmp.va + r * info.aligned_row_pitch * img.bpp;
+                radv_sdma_copy_memory(device, cs, to_image ? buf_va : tmp_va, to_image ? tmp_va : buf_va,
+                                      info.extent_horizontal_blocks * img.bpp);
+            }
 
             /* Wait for the copy to finish. */
             radv_sdma_emit_nop(device, cs);
-         }
 
-         /* buffer to image: copy each row from source buffer to temporary buffer.
-          * image to buffer: copy each row from temporary buffer to destination buffer.
-          */
-         for (unsigned r = 0; r < rows; ++r) {
-            const uint64_t buf_va =
-               buf->va + slice * buf_slice_pitch_blocks * img.bpp + (row + r) * buf_pitch_blocks * img.bpp;
-            const uint64_t tmp_va = tmp.va + r * info.aligned_row_pitch * img.bpp;
-            radv_sdma_copy_memory(device, cs, to_image ? buf_va : tmp_va, to_image ? tmp_va : buf_va,
-                                  info.extent_horizontal_blocks * img.bpp);
-         }
-
-         /* Wait for the copy to finish. */
-         radv_sdma_emit_nop(device, cs);
-
-         if (to_image) {
-            /* Copy the rows from the temporary buffer to the destination image. */
-            if (img.is_linear)
-               radv_sdma_emit_copy_linear_sub_window(device, cs, &tmp, &img, extent);
-            else
-               radv_sdma_emit_copy_tiled_sub_window(device, cs, &img, &tmp, extent, false);
-
-            /* Wait for the copy to finish. */
-            radv_sdma_emit_nop(device, cs);
-         }
-      }
-   }
+            if (to_image) {
+                /* Copy the rows from the temporary buffer to the destination image. */
+                if (img.is_linear)
+                    radv_sdma_emit_copy_linear_sub_window(device, cs, &tmp, &img, extent);
+                else
+                    radv_sdma_emit_copy_tiled_sub_window(device, cs, &img, &tmp, extent, false);
+
+                /* Wait for the copy to finish. */
+                radv_sdma_emit_nop(device, cs);
+            }
+        }
+    }
 }
 
 void
