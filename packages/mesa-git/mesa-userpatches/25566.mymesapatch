From f2a28b28c87a27690beae3c7488d6b9e08425336 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 4 Oct 2023 14:14:19 +0100
Subject: [PATCH 1/4] nir/lower_fp16_casts: correctly round RTNE f64->f16 casts

Based on brw_nir_lower_conversions.

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/compiler/nir/nir_lower_fp16_conv.c | 62 +++++++++++++++++++++++++-
 1 file changed, 60 insertions(+), 2 deletions(-)

diff --git a/src/compiler/nir/nir_lower_fp16_conv.c b/src/compiler/nir/nir_lower_fp16_conv.c
index 571cdf40f081b..50ece5cecb56c 100644
--- a/src/compiler/nir/nir_lower_fp16_conv.c
+++ b/src/compiler/nir/nir_lower_fp16_conv.c
@@ -69,8 +69,6 @@ float_to_half_impl(nir_builder *b, nir_def *src, nir_rounding_mode mode)
    nir_def *f32infinity = nir_imm_int(b, 255 << 23);
    nir_def *f16max = nir_imm_int(b, (127 + 16) << 23);
 
-   if (src->bit_size == 64)
-      src = nir_f2f32(b, src);
    nir_def *sign = nir_iand_imm(b, src, 0x80000000);
    nir_def *one = nir_imm_int(b, 1);
 
@@ -168,6 +166,64 @@ float_to_half_impl(nir_builder *b, nir_def *src, nir_rounding_mode mode)
    return nir_u2u16(b, nir_ior(b, fp16, nir_ushr_imm(b, sign, 16)));
 }
 
+static nir_def *
+split_f2f16_conversion(nir_builder *b, nir_def *src, nir_rounding_mode rnd)
+{
+   nir_def *tmp = nir_f2f32(b, src);
+
+   if (rnd == nir_rounding_mode_rtne) {
+      /* We round down from double to half float by going through float in
+       * between, but this can give us inaccurate results in some cases. One
+       * such case is 0x40ee6a0000000001, which should round to 0x7b9b, but
+       * going through float first turns into 0x7b9a instead. This is because
+       * the first non-fitting bit is set, so we get a tie, but with the least
+       * significant bit of the original number set, the tie should break
+       * rounding up. The cast to float, however, turns into 0x47735000, which
+       * when going to half still ties, but now we lost the tie-up bit, and
+       * instead we round to the nearest even, which in this case is down.
+       *
+       * To fix this, we check if the original would have tied, and if the tie
+       * would have rounded up, and if both are true, set the least
+       * significant bit of the intermediate float to 1, so that a tie on the
+       * next cast rounds up as well. If the rounding already got rid of the
+       * tie, that set bit will just be truncated anyway and the end result
+       * doesn't change.
+       *
+       * Another failing case is 0x40effdffffffffff. This one doesn't have the
+       * tie from double to half, so it just rounds down to 0x7bff (65504.0),
+       * but going through float first, it turns into 0x477ff000, which does
+       * have the tie bit for half set, and when that one gets rounded it
+       * turns into 0x7c00 (Infinity).
+       * The fix for that one is to make sure the intermediate float does not
+       * have the tie bit set if the original didn't have it.
+       *
+       * For the RTZ case, we don't need to do anything, as the intermediate
+       * float should be ok already.
+       */
+      int significand_bits16 = 10;
+      int significand_bits32 = 23;
+      int significand_bits64 = 52;
+      int f64_to_16_tie_bit = significand_bits64 - significand_bits16 - 1;
+      int f32_to_16_tie_bit = significand_bits32 - significand_bits16 - 1;
+      uint64_t f64_rounds_up_mask = ((1ULL << f64_to_16_tie_bit) - 1);
+
+      nir_def *would_tie = nir_iand_imm(b, src, 1ULL << f64_to_16_tie_bit);
+      nir_def *would_rnd_up = nir_iand_imm(b, src, f64_rounds_up_mask);
+
+      nir_def *tie_up = nir_b2i32(b, nir_ine_imm(b, would_rnd_up, 0));
+
+      nir_def *break_tie = nir_bcsel(b,
+                                     nir_ine_imm(b, would_tie, 0),
+                                     nir_imm_int(b, ~0),
+                                     nir_imm_int(b, ~(1U << f32_to_16_tie_bit)));
+
+      tmp = nir_ior(b, tmp, tie_up);
+      tmp = nir_iand(b, tmp, break_tie);
+   }
+
+   return tmp;
+}
+
 static bool
 lower_fp16_cast_impl(nir_builder *b, nir_instr *instr, void *data)
 {
@@ -242,6 +298,8 @@ lower_fp16_cast_impl(nir_builder *b, nir_instr *instr, void *data)
 
    for (unsigned i = 0; i < dst->num_components; i++) {
       nir_def *comp = nir_channel(b, src, swizzle ? swizzle[i] : i);
+      if (comp->bit_size == 64)
+         comp = split_f2f16_conversion(b, comp, mode);
       rets[i] = float_to_half_impl(b, comp, mode);
    }
 
-- 
GitLab


From 9afd3c8cfb02aa16cf1bd30c298adde21e964443 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 4 Oct 2023 14:23:59 +0100
Subject: [PATCH 2/4] nir/lower_fp16_casts: add option to split fp64 casts

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/compiler/nir/nir.h                 |  1 +
 src/compiler/nir/nir_lower_fp16_conv.c | 46 +++++++++++++++++++++-----
 2 files changed, 38 insertions(+), 9 deletions(-)

diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index dbab63aa32bd5..23e294ae42c08 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -6010,6 +6010,7 @@ typedef enum {
    nir_lower_fp16_ru = (1 << 2),
    nir_lower_fp16_rd = (1 << 3),
    nir_lower_fp16_all = 0xf,
+   nir_lower_fp16_split_fp64 = (1 << 4),
 } nir_lower_fp16_cast_options;
 bool nir_lower_fp16_casts(nir_shader *shader, nir_lower_fp16_cast_options options);
 bool nir_normalize_cubemap_coords(nir_shader *shader);
diff --git a/src/compiler/nir/nir_lower_fp16_conv.c b/src/compiler/nir/nir_lower_fp16_conv.c
index 50ece5cecb56c..b6990b3da9cd0 100644
--- a/src/compiler/nir/nir_lower_fp16_conv.c
+++ b/src/compiler/nir/nir_lower_fp16_conv.c
@@ -227,13 +227,15 @@ split_f2f16_conversion(nir_builder *b, nir_def *src, nir_rounding_mode rnd)
 static bool
 lower_fp16_cast_impl(nir_builder *b, nir_instr *instr, void *data)
 {
-   nir_def *src, *dst;
+   nir_lower_fp16_cast_options options = *(nir_lower_fp16_cast_options *)data;
+   nir_src *src;
+   nir_def *dst;
    uint8_t *swizzle = NULL;
    nir_rounding_mode mode = nir_rounding_mode_undef;
 
    if (instr->type == nir_instr_type_alu) {
       nir_alu_instr *alu = nir_instr_as_alu(instr);
-      src = alu->src[0].src.ssa;
+      src = &alu->src[0].src;
       swizzle = alu->src[0].swizzle;
       dst = &alu->def;
       switch (alu->op) {
@@ -249,22 +251,48 @@ lower_fp16_cast_impl(nir_builder *b, nir_instr *instr, void *data)
       case nir_op_f2f16_rtz:
          mode = nir_rounding_mode_rtz;
          break;
+      case nir_op_f2f64:
+         if (src->ssa->bit_size == 16 && (options & nir_lower_fp16_split_fp64)) {
+            b->cursor = nir_before_instr(instr);
+            nir_src_rewrite(src, nir_f2f32(b, src->ssa));
+            return true;
+         }
+         return false;
       default:
          return false;
       }
    } else if (instr->type == nir_instr_type_intrinsic) {
       nir_intrinsic_instr *intrin = nir_instr_as_intrinsic(instr);
-      if (intrin->intrinsic != nir_intrinsic_convert_alu_types ||
-          nir_intrinsic_dest_type(intrin) != nir_type_float16)
+      if (intrin->intrinsic != nir_intrinsic_convert_alu_types)
          return false;
-      src = intrin->src[0].ssa;
+
+      src = &intrin->src[0];
       dst = &intrin->def;
       mode = nir_intrinsic_rounding_mode(intrin);
+
+      if (nir_intrinsic_src_type(intrin) == nir_type_float16 &&
+          nir_intrinsic_dest_type(intrin) == nir_type_float64 &&
+          (options & nir_lower_fp16_split_fp64)) {
+         b->cursor = nir_before_instr(instr);
+         nir_src_rewrite(src, nir_f2f32(b, src->ssa));
+         return true;
+      }
+
+      if (nir_intrinsic_dest_type(intrin) != nir_type_float16)
+         return false;
    } else {
       return false;
    }
 
-   nir_lower_fp16_cast_options options = *(nir_lower_fp16_cast_options *)data;
+   bool progress = false;
+   if (src->ssa->bit_size == 64 && (options & nir_lower_fp16_split_fp64)) {
+      b->cursor = nir_before_instr(instr);
+      nir_src_rewrite(src, split_f2f16_conversion(b, src->ssa, mode));
+      if (instr->type == nir_instr_type_intrinsic)
+         nir_intrinsic_set_src_type(nir_instr_as_intrinsic(instr), nir_type_float32);
+      progress = true;
+   }
+
    nir_lower_fp16_cast_options req_option = 0;
    switch (mode) {
    case nir_rounding_mode_rtz:
@@ -280,7 +308,7 @@ lower_fp16_cast_impl(nir_builder *b, nir_instr *instr, void *data)
       req_option = nir_lower_fp16_rd;
       break;
    case nir_rounding_mode_undef:
-      if (options == nir_lower_fp16_all) {
+      if ((options & nir_lower_fp16_all) == nir_lower_fp16_all) {
          /* Pick one arbitrarily for lowering */
          mode = nir_rounding_mode_rtne;
          req_option = nir_lower_fp16_rtne;
@@ -291,13 +319,13 @@ lower_fp16_cast_impl(nir_builder *b, nir_instr *instr, void *data)
       unreachable("Invalid rounding mode");
    }
    if (!(options & req_option))
-      return false;
+      return progress;
 
    b->cursor = nir_before_instr(instr);
    nir_def *rets[NIR_MAX_VEC_COMPONENTS] = { NULL };
 
    for (unsigned i = 0; i < dst->num_components; i++) {
-      nir_def *comp = nir_channel(b, src, swizzle ? swizzle[i] : i);
+      nir_def *comp = nir_channel(b, src->ssa, swizzle ? swizzle[i] : i);
       if (comp->bit_size == 64)
          comp = split_f2f16_conversion(b, comp, mode);
       rets[i] = float_to_half_impl(b, comp, mode);
-- 
GitLab


From 3f12f7db9afc10952aabeba3e92d87134416bfc4 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 4 Oct 2023 14:33:58 +0100
Subject: [PATCH 3/4] radv,aco: use nir_lower_fp16_casts

This correctly implements RTNE f64->f16.

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/aco_instruction_selection.cpp | 9 +++------
 src/amd/vulkan/radv_pipeline.c                 | 2 ++
 2 files changed, 5 insertions(+), 6 deletions(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 22fc17f71c331..0748e2156df92 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -2892,9 +2892,8 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
    }
    case nir_op_f2f16:
    case nir_op_f2f16_rtne: {
+      assert(instr->src[0].src.ssa->bit_size == 32);
       Temp src = get_alu_src(ctx, instr->src[0]);
-      if (instr->src[0].src.ssa->bit_size == 64)
-         src = bld.vop1(aco_opcode::v_cvt_f32_f64, bld.def(v1), src);
       if (instr->op == nir_op_f2f16_rtne && ctx->block->fp_mode.round16_64 != fp_round_ne)
          /* We emit s_round_mode/s_setreg_imm32 in lower_to_hw_instr to
           * keep value numbering and the scheduler simpler.
@@ -2905,9 +2904,8 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
       break;
    }
    case nir_op_f2f16_rtz: {
+      assert(instr->src[0].src.ssa->bit_size == 32);
       Temp src = get_alu_src(ctx, instr->src[0]);
-      if (instr->src[0].src.ssa->bit_size == 64)
-         src = bld.vop1(aco_opcode::v_cvt_f32_f64, bld.def(v1), src);
       if (ctx->block->fp_mode.round16_64 == fp_round_tz)
          bld.vop1(aco_opcode::v_cvt_f16_f32, Definition(dst), src);
       else if (ctx->program->gfx_level == GFX8 || ctx->program->gfx_level == GFX9)
@@ -2927,9 +2925,8 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
       break;
    }
    case nir_op_f2f64: {
+      assert(instr->src[0].src.ssa->bit_size == 32);
       Temp src = get_alu_src(ctx, instr->src[0]);
-      if (instr->src[0].src.ssa->bit_size == 16)
-         src = bld.vop1(aco_opcode::v_cvt_f32_f16, bld.def(v1), src);
       bld.vop1(aco_opcode::v_cvt_f64_f32, Definition(dst), src);
       break;
    }
diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index 9766f322ec80c..af0163bc5623c 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -726,6 +726,8 @@ radv_postprocess_nir(struct radv_device *device, const struct radv_pipeline_key
    radv_optimize_nir_algebraic(
       stage->nir, io_to_mem || lowered_ngg || stage->stage == MESA_SHADER_COMPUTE || stage->stage == MESA_SHADER_TASK);
 
+   NIR_PASS(_, stage->nir, nir_lower_fp16_casts, nir_lower_fp16_split_fp64);
+
    if (stage->nir->info.bit_sizes_int & (8 | 16)) {
       if (gfx_level >= GFX8) {
          NIR_PASS(_, stage->nir, nir_convert_to_lcssa, true, true);
-- 
GitLab


From 47898f04da4ed8a7f4a33c13e0574f8ab25b9852 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 4 Oct 2023 14:34:39 +0100
Subject: [PATCH 4/4] intel/compiler: use nir_lower_fp16_casts

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/intel/compiler/brw_nir.c                  |  4 +-
 .../compiler/brw_nir_lower_conversions.c      | 83 ++-----------------
 2 files changed, 10 insertions(+), 77 deletions(-)

diff --git a/src/intel/compiler/brw_nir.c b/src/intel/compiler/brw_nir.c
index 3ef61403616c4..04be46a4ae1b6 100644
--- a/src/intel/compiler/brw_nir.c
+++ b/src/intel/compiler/brw_nir.c
@@ -1658,12 +1658,14 @@ brw_postprocess_nir(nir_shader *nir, const struct brw_compiler *compiler,
    } while (progress);
 
 
-   if (OPT(brw_nir_lower_conversions)) {
+   if (OPT(nir_lower_fp16_casts, nir_lower_fp16_split_fp64)) {
       if (OPT(nir_lower_int64)) {
          brw_nir_optimize(nir, compiler);
       }
    }
 
+   OPT(brw_nir_lower_conversions);
+
    if (is_scalar)
       OPT(nir_lower_alu_to_scalar, NULL, NULL);
 
diff --git a/src/intel/compiler/brw_nir_lower_conversions.c b/src/intel/compiler/brw_nir_lower_conversions.c
index 68428ab0654d0..1c23b51a09949 100644
--- a/src/intel/compiler/brw_nir_lower_conversions.c
+++ b/src/intel/compiler/brw_nir_lower_conversions.c
@@ -24,81 +24,14 @@
 #include "brw_nir.h"
 #include "compiler/nir/nir_builder.h"
 
-static nir_rounding_mode
-get_opcode_rounding_mode(nir_op op, nir_alu_type dst_type,
-                         unsigned execution_mode)
-{
-   switch (op) {
-   case nir_op_f2f16_rtz:
-      return nir_rounding_mode_rtz;
-   case nir_op_f2f16_rtne:
-      return nir_rounding_mode_rtne;
-   default:
-      return nir_get_rounding_mode_from_float_controls(execution_mode,
-                                                       dst_type);
-   }
-}
-
 static void
 split_conversion(nir_builder *b, nir_alu_instr *alu, nir_alu_type src_type,
-                 nir_alu_type tmp_type, nir_alu_type dst_type,
-                 nir_rounding_mode rnd)
+                 nir_alu_type tmp_type, nir_alu_type dst_type)
 {
    b->cursor = nir_before_instr(&alu->instr);
    nir_def *src = nir_ssa_for_alu_src(b, alu, 0);
    nir_def *tmp = nir_type_convert(b, src, src_type, tmp_type, nir_rounding_mode_undef);
-
-   if (dst_type == nir_type_float16 && rnd == nir_rounding_mode_rtne) {
-      /* We round down from double to half float by going through float in
-       * between, but this can give us inaccurate results in some cases. One
-       * such case is 0x40ee6a0000000001, which should round to 0x7b9b, but
-       * going through float first turns into 0x7b9a instead. This is because
-       * the first non-fitting bit is set, so we get a tie, but with the least
-       * significant bit of the original number set, the tie should break
-       * rounding up. The cast to float, however, turns into 0x47735000, which
-       * when going to half still ties, but now we lost the tie-up bit, and
-       * instead we round to the nearest even, which in this case is down.
-       *
-       * To fix this, we check if the original would have tied, and if the tie
-       * would have rounded up, and if both are true, set the least
-       * significant bit of the intermediate float to 1, so that a tie on the
-       * next cast rounds up as well. If the rounding already got rid of the
-       * tie, that set bit will just be truncated anyway and the end result
-       * doesn't change.
-       *
-       * Another failing case is 0x40effdffffffffff. This one doesn't have the
-       * tie from double to half, so it just rounds down to 0x7bff (65504.0),
-       * but going through float first, it turns into 0x477ff000, which does
-       * have the tie bit for half set, and when that one gets rounded it
-       * turns into 0x7c00 (Infinity).
-       * The fix for that one is to make sure the intermediate float does not
-       * have the tie bit set if the original didn't have it.
-       *
-       * For the RTZ case, we don't need to do anything, as the intermediate
-       * float should be ok already.
-       */
-      int significand_bits16 = 10;
-      int significand_bits32 = 23;
-      int significand_bits64 = 52;
-      int f64_to_16_tie_bit = significand_bits64 - significand_bits16 - 1;
-      int f32_to_16_tie_bit = significand_bits32 - significand_bits16 - 1;
-      uint64_t f64_rounds_up_mask = ((1ULL << f64_to_16_tie_bit) - 1);
-
-      nir_def *would_tie = nir_iand_imm(b, src, 1ULL << f64_to_16_tie_bit);
-      nir_def *would_rnd_up = nir_iand_imm(b, src, f64_rounds_up_mask);
-
-      nir_def *tie_up = nir_b2i32(b, nir_ine_imm(b, would_rnd_up, 0));
-
-      nir_def *break_tie = nir_bcsel(b,
-                                     nir_ine_imm(b, would_tie, 0),
-                                     nir_imm_int(b, ~0),
-                                     nir_imm_int(b, ~(1U << f32_to_16_tie_bit)));
-
-      tmp = nir_ior(b, tmp, tie_up);
-      tmp = nir_iand(b, tmp, break_tie);
-   }
-
-   nir_def *res = nir_type_convert(b, tmp, tmp_type, dst_type, rnd);
+   nir_def *res = nir_type_convert(b, tmp, tmp_type, dst_type, nir_rounding_mode_undef);
    nir_def_rewrite_uses(&alu->def, res);
    nir_instr_remove(&alu->instr);
 }
@@ -127,12 +60,11 @@ lower_alu_instr(nir_builder *b, nir_alu_instr *alu)
     * 32-bit float type so we don't lose range when we convert from
     * a 64-bit integer.
     */
-   if ((src_full_type == nir_type_float16 && dst_bit_size == 64) ||
-       (src_bit_size == 64 && dst_full_type == nir_type_float16)) {
+   unsigned int64_types = nir_type_int64 | nir_type_uint64;
+   if ((src_full_type == nir_type_float16 && (dst_full_type & int64_types)) ||
+       ((src_full_type & int64_types) && dst_full_type == nir_type_float16)) {
       split_conversion(b, alu, src_type, nir_type_float | 32,
-                       dst_type | dst_bit_size,
-                       get_opcode_rounding_mode(alu->op, dst_full_type,
-                                                b->shader->info.float_controls_execution_mode));
+                       dst_type | dst_bit_size);
       return true;
    }
 
@@ -152,8 +84,7 @@ lower_alu_instr(nir_builder *b, nir_alu_instr *alu)
     */
    if ((src_bit_size == 8 && dst_bit_size == 64) ||
        (src_bit_size == 64 && dst_bit_size == 8)) {
-      split_conversion(b, alu, src_type, dst_type | 32, dst_type | dst_bit_size,
-                       nir_rounding_mode_undef);
+      split_conversion(b, alu, src_type, dst_type | 32, dst_type | dst_bit_size);
       return true;
    }
 
-- 
GitLab

