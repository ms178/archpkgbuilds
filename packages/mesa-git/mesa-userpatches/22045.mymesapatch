From 85741201443e19d1df022b79bc17772bb8008773 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Fri, 3 Mar 2023 11:36:20 +0800
Subject: [PATCH 1/8] radeonsi: expose si_nir_load_internal_binding

PS polygon stippling is going to use it too.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 .../drivers/radeonsi/si_nir_lower_abi.c       | 21 ++++++++++---------
 .../drivers/radeonsi/si_shader_internal.h     |  5 +++++
 2 files changed, 16 insertions(+), 10 deletions(-)

diff --git a/src/gallium/drivers/radeonsi/si_nir_lower_abi.c b/src/gallium/drivers/radeonsi/si_nir_lower_abi.c
index 27ed661e054f..0212f075b2db 100644
--- a/src/gallium/drivers/radeonsi/si_nir_lower_abi.c
+++ b/src/gallium/drivers/radeonsi/si_nir_lower_abi.c
@@ -40,7 +40,7 @@ struct lower_abi_state {
    ac_nir_unpack_arg(b, &args->ac, args->vs_state_bits, \
                      field##__SHIFT, util_bitcount(field##__MASK))
 
-static nir_ssa_def *load_internal_binding(nir_builder *b, struct si_shader_args *args,
+nir_ssa_def *si_nir_load_internal_binding(nir_builder *b, struct si_shader_args *args,
                                           unsigned slot, unsigned num_components)
 {
    nir_ssa_def *addr = ac_nir_load_arg(b, &args->ac, args->internal_bindings);
@@ -86,7 +86,7 @@ static nir_ssa_def *build_attr_ring_desc(nir_builder *b, struct si_shader *shade
 
    nir_ssa_def *attr_address =
       sel->stage == MESA_SHADER_VERTEX && sel->info.base.vs.blit_sgprs_amd ?
-      load_internal_binding(b, args, SI_GS_ATTRIBUTE_RING, 4) :
+      si_nir_load_internal_binding(b, args, SI_GS_ATTRIBUTE_RING, 4) :
       ac_nir_load_arg(b, &args->ac, args->gs_attr_address);
 
    unsigned stride = 16 * shader->info.nr_param_exports;
@@ -147,7 +147,7 @@ fetch_framebuffer(nir_builder *b, struct si_shader_args *args,
       if (sel->screen->info.gfx_level < GFX11 &&
           !(sel->screen->debug_flags & DBG(NO_FMASK))) {
          nir_ssa_def *desc =
-            load_internal_binding(b, args, SI_PS_IMAGE_COLORBUF0_FMASK, 8);
+            si_nir_load_internal_binding(b, args, SI_PS_IMAGE_COLORBUF0_FMASK, 8);
 
          nir_ssa_def *fmask =
             nir_bindless_image_fragment_mask_load_amd(
@@ -165,7 +165,7 @@ fetch_framebuffer(nir_builder *b, struct si_shader_args *args,
       sample_id = zero;
    }
 
-   nir_ssa_def *desc = load_internal_binding(b, args, SI_PS_IMAGE_COLORBUF0, 8);
+   nir_ssa_def *desc = si_nir_load_internal_binding(b, args, SI_PS_IMAGE_COLORBUF0, 8);
 
    return nir_bindless_image_load(b, 4, 32, desc, coords, sample_id, zero,
                                   .image_dim = dim,
@@ -252,7 +252,7 @@ static bool lower_abi_instr(nir_builder *b, nir_instr *instr, struct lower_abi_s
    }
    case nir_intrinsic_load_tess_level_outer_default:
    case nir_intrinsic_load_tess_level_inner_default: {
-      nir_ssa_def *buf = load_internal_binding(b, args, SI_HS_CONST_DEFAULT_TESS_LEVELS, 4);
+      nir_ssa_def *buf = si_nir_load_internal_binding(b, args, SI_HS_CONST_DEFAULT_TESS_LEVELS, 4);
       unsigned num_components = intrin->dest.ssa.num_components;
       unsigned offset =
          intrin->intrinsic == nir_intrinsic_load_tess_level_inner_default ? 16 : 0;
@@ -359,19 +359,20 @@ static bool lower_abi_instr(nir_builder *b, nir_instr *instr, struct lower_abi_s
       replacement = nir_i2b(b, GET_FIELD_NIR(VS_STATE_CLAMP_VERTEX_COLOR));
       break;
    case nir_intrinsic_load_user_clip_plane: {
-      nir_ssa_def *buf = load_internal_binding(b, args, SI_VS_CONST_CLIP_PLANES, 4);
+      nir_ssa_def *buf = si_nir_load_internal_binding(b, args, SI_VS_CONST_CLIP_PLANES, 4);
       unsigned offset = nir_intrinsic_ucp_id(intrin) * 16;
       replacement = nir_load_smem_buffer_amd(b, 4, buf, nir_imm_int(b, offset));
       break;
    }
    case nir_intrinsic_load_streamout_buffer_amd: {
       unsigned slot = SI_VS_STREAMOUT_BUF0 + nir_intrinsic_base(intrin);
-      replacement = load_internal_binding(b, args, slot, 4);
+      replacement = si_nir_load_internal_binding(b, args, slot, 4);
       break;
    }
    case nir_intrinsic_atomic_add_gs_emit_prim_count_amd:
    case nir_intrinsic_atomic_add_gs_invocation_count_amd: {
-      nir_ssa_def *buf = load_internal_binding(b, args, SI_GS_QUERY_EMULATED_COUNTERS_BUF, 4);
+      nir_ssa_def *buf =
+         si_nir_load_internal_binding(b, args, SI_GS_QUERY_EMULATED_COUNTERS_BUF, 4);
 
       enum pipe_statistics_query_index index =
          intrin->intrinsic == nir_intrinsic_atomic_add_gs_emit_prim_count_amd ?
@@ -384,7 +385,7 @@ static bool lower_abi_instr(nir_builder *b, nir_instr *instr, struct lower_abi_s
    }
    case nir_intrinsic_atomic_add_gen_prim_count_amd:
    case nir_intrinsic_atomic_add_xfb_prim_count_amd: {
-      nir_ssa_def *buf = load_internal_binding(b, args, SI_GS_QUERY_BUF, 4);
+      nir_ssa_def *buf = si_nir_load_internal_binding(b, args, SI_GS_QUERY_BUF, 4);
 
       unsigned stream = nir_intrinsic_stream_id(intrin);
       unsigned offset = intrin->intrinsic == nir_intrinsic_atomic_add_gen_prim_count_amd ?
@@ -451,7 +452,7 @@ static bool lower_abi_instr(nir_builder *b, nir_instr *instr, struct lower_abi_s
          /* offset = sample_id * 8  (8 = 2 floats containing samplepos.xy) */
          nir_ssa_def *offset = nir_ishl_imm(b, sample_id, 3);
 
-         nir_ssa_def *buf = load_internal_binding(b, args, SI_PS_CONST_SAMPLE_POSITIONS, 4);
+         nir_ssa_def *buf = si_nir_load_internal_binding(b, args, SI_PS_CONST_SAMPLE_POSITIONS, 4);
          nir_ssa_def *sample_pos = nir_load_smem_buffer_amd(b, 2, buf, offset);
 
          sample_pos = nir_fsub(b, sample_pos, nir_imm_float(b, 0.5));
diff --git a/src/gallium/drivers/radeonsi/si_shader_internal.h b/src/gallium/drivers/radeonsi/si_shader_internal.h
index be71169878c0..90da6a9c4139 100644
--- a/src/gallium/drivers/radeonsi/si_shader_internal.h
+++ b/src/gallium/drivers/radeonsi/si_shader_internal.h
@@ -131,6 +131,9 @@ static inline struct si_shader_context *si_shader_context_from_abi(struct ac_sha
 struct ac_nir_gs_output_info;
 typedef struct ac_nir_gs_output_info ac_nir_gs_output_info;
 
+struct nir_builder;
+typedef struct nir_builder nir_builder;
+
 /* si_shader.c */
 bool si_is_multi_part_shader(struct si_shader *shader);
 bool si_is_merged_shader(struct si_shader *shader);
@@ -159,6 +162,8 @@ unsigned gfx10_ngg_get_scratch_dw_size(struct si_shader *shader);
 bool gfx10_ngg_calculate_subgroup_info(struct si_shader *shader);
 
 /* si_nir_lower_abi.c */
+nir_ssa_def *si_nir_load_internal_binding(nir_builder *b, struct si_shader_args *args,
+                                          unsigned slot, unsigned num_components);
 bool si_nir_lower_abi(nir_shader *nir, struct si_shader *shader, struct si_shader_args *args);
 
 /* si_nir_lower_resource.c */
-- 
GitLab


From 97b3f13a0808ddf91d7d06939c3c203fe53cdada Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Sat, 18 Mar 2023 21:32:16 +0800
Subject: [PATCH 2/8] ac/nir: add ac_nir_load_arg_at_offset

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir.c | 12 +++++++-----
 src/amd/common/ac_nir.h |  9 ++++++++-
 2 files changed, 15 insertions(+), 6 deletions(-)

diff --git a/src/amd/common/ac_nir.c b/src/amd/common/ac_nir.c
index fe9968a7548e..7802b162e5b8 100644
--- a/src/amd/common/ac_nir.c
+++ b/src/amd/common/ac_nir.c
@@ -27,14 +27,16 @@
 #include "nir_xfb_info.h"
 
 nir_ssa_def *
-ac_nir_load_arg(nir_builder *b, const struct ac_shader_args *ac_args, struct ac_arg arg)
+ac_nir_load_arg_at_offset(nir_builder *b, const struct ac_shader_args *ac_args,
+                          struct ac_arg arg, unsigned offset)
 {
-   unsigned num_components = ac_args->args[arg.arg_index].size;
+   unsigned arg_index = arg.arg_index + offset;
+   unsigned num_components = ac_args->args[arg_index].size;
 
-   if (ac_args->args[arg.arg_index].file == AC_ARG_SGPR)
-      return nir_load_scalar_arg_amd(b, num_components, .base = arg.arg_index);
+   if (ac_args->args[arg_index].file == AC_ARG_SGPR)
+      return nir_load_scalar_arg_amd(b, num_components, .base = arg_index);
    else
-      return nir_load_vector_arg_amd(b, num_components, .base = arg.arg_index);
+      return nir_load_vector_arg_amd(b, num_components, .base = arg_index);
 }
 
 nir_ssa_def *
diff --git a/src/amd/common/ac_nir.h b/src/amd/common/ac_nir.h
index d3eafbdeeac7..50015108491a 100644
--- a/src/amd/common/ac_nir.h
+++ b/src/amd/common/ac_nir.h
@@ -67,7 +67,14 @@ typedef struct nir_builder nir_builder;
 typedef void (*ac_nir_cull_accepted)(nir_builder *b, void *state);
 
 nir_ssa_def *
-ac_nir_load_arg(nir_builder *b, const struct ac_shader_args *ac_args, struct ac_arg arg);
+ac_nir_load_arg_at_offset(nir_builder *b, const struct ac_shader_args *ac_args,
+                          struct ac_arg arg, unsigned offset);
+
+static inline nir_ssa_def *
+ac_nir_load_arg(nir_builder *b, const struct ac_shader_args *ac_args, struct ac_arg arg)
+{
+   return ac_nir_load_arg_at_offset(b, ac_args, arg, 0);
+}
 
 nir_ssa_def *
 ac_nir_unpack_arg(nir_builder *b, const struct ac_shader_args *ac_args, struct ac_arg arg,
-- 
GitLab


From fc40cd11aefdf0b843a3c1cc4cd45dd9379b6ead Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Sat, 18 Mar 2023 21:35:45 +0800
Subject: [PATCH 3/8] radeonsi: add si_nir_lower_vs_inputs

Ported from llvm:
* si_load_vs_input
* ac_build_opencoded_load_format
* ac_ufN_to_float
* get_vertex_index
* ac_build_fast_udiv_nuw

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/gallium/drivers/radeonsi/meson.build      |   1 +
 .../drivers/radeonsi/si_nir_lower_vs_inputs.c | 641 ++++++++++++++++++
 .../drivers/radeonsi/si_shader_internal.h     |   4 +
 3 files changed, 646 insertions(+)
 create mode 100644 src/gallium/drivers/radeonsi/si_nir_lower_vs_inputs.c

diff --git a/src/gallium/drivers/radeonsi/meson.build b/src/gallium/drivers/radeonsi/meson.build
index 2d37d56a7c05..c2b44fc9dc80 100644
--- a/src/gallium/drivers/radeonsi/meson.build
+++ b/src/gallium/drivers/radeonsi/meson.build
@@ -47,6 +47,7 @@ files_libradeonsi = files(
   'si_query.h',
   'si_nir_lower_abi.c',
   'si_nir_lower_resource.c',
+  'si_nir_lower_vs_inputs.c',
   'si_nir_optim.c',
   'si_sdma_copy_image.c',
   'si_shader.c',
diff --git a/src/gallium/drivers/radeonsi/si_nir_lower_vs_inputs.c b/src/gallium/drivers/radeonsi/si_nir_lower_vs_inputs.c
new file mode 100644
index 000000000000..8afdc9f7f523
--- /dev/null
+++ b/src/gallium/drivers/radeonsi/si_nir_lower_vs_inputs.c
@@ -0,0 +1,641 @@
+/*
+ * Copyright 2023 Advanced Micro Devices, Inc.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * on the rights to use, copy, modify, merge, publish, distribute, sub
+ * license, and/or sell copies of the Software, and to permit persons to whom
+ * the Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHOR(S) AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
+ * USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "nir_builder.h"
+
+#include "ac_nir.h"
+#include "si_shader_internal.h"
+#include "si_state.h"
+#include "si_pipe.h"
+
+struct lower_vs_inputs_state {
+   struct si_shader *shader;
+   struct si_shader_args *args;
+
+   nir_ssa_def *instance_divisor_constbuf;
+   nir_ssa_def *vertex_index[16];
+};
+
+/* See ac_build_fast_udiv_nuw */
+static nir_ssa_def *
+fast_udiv_nuw(nir_builder *b, nir_ssa_def *num, nir_ssa_def *divisor)
+{
+   nir_ssa_def *multiplier = nir_channel(b, divisor, 0);
+   nir_ssa_def *pre_shift = nir_channel(b, divisor, 1);
+   nir_ssa_def *post_shift = nir_channel(b, divisor, 2);
+   nir_ssa_def *increment = nir_channel(b, divisor, 3);
+
+   num = nir_ushr(b, num, pre_shift);
+   num = nir_iadd_nuw(b, num, increment);
+   num = nir_imul(b, nir_u2u64(b, num), nir_u2u64(b, multiplier));
+   num = nir_unpack_64_2x32_split_y(b, num);
+   return nir_ushr(b, num, post_shift);
+}
+
+static nir_ssa_def *
+get_vertex_index_for_mono_shader(nir_builder *b, int input_index,
+                                 struct lower_vs_inputs_state *s)
+{
+   const union si_shader_key *key = &s->shader->key;
+
+   bool divisor_is_one =
+      key->ge.part.vs.prolog.instance_divisor_is_one & (1u << input_index);
+   bool divisor_is_fetched =
+      key->ge.part.vs.prolog.instance_divisor_is_fetched & (1u << input_index);
+
+   if (divisor_is_one || divisor_is_fetched) {
+      nir_ssa_def *instance_id = nir_load_instance_id(b);
+
+      /* This is used to determine vs vgpr count in si_get_vs_vgpr_comp_cnt(). */
+      s->shader->info.uses_instanceid = true;
+
+      nir_ssa_def *index = NULL;
+      if (divisor_is_one) {
+         index = instance_id;
+      } else {
+         nir_ssa_def *offset = nir_imm_int(b, input_index * 16);
+         nir_ssa_def *divisor =
+            nir_load_smem_buffer_amd(b, 4, s->instance_divisor_constbuf, offset);
+
+         /* The faster NUW version doesn't work when InstanceID == UINT_MAX.
+          * Such InstanceID might not be achievable in a reasonable time though.
+          */
+         index = fast_udiv_nuw(b, instance_id, divisor);
+      }
+
+      nir_ssa_def *start_instance = nir_load_base_instance(b);
+      return nir_iadd(b, index, start_instance);
+   } else {
+      nir_ssa_def *vertex_id = nir_load_vertex_id_zero_base(b);
+      nir_ssa_def *base_vertex = nir_load_first_vertex(b);
+
+      return nir_iadd(b, vertex_id, base_vertex);
+   }
+}
+
+static nir_ssa_def *
+get_vertex_index_for_part_shader(nir_builder *b, int input_index,
+                                 struct lower_vs_inputs_state *s)
+{
+   return ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vertex_index0, input_index);
+}
+
+static void
+get_vertex_index_for_all_inputs(nir_shader *nir, struct lower_vs_inputs_state *s)
+{
+   nir_function_impl *impl = nir_shader_get_entrypoint(nir);
+
+   nir_builder builder;
+   nir_builder_init(&builder, impl);
+   nir_builder *b = &builder;
+
+   b->cursor = nir_before_cf_list(&impl->body);
+
+   const struct si_shader_selector *sel = s->shader->selector;
+   const union si_shader_key *key = &s->shader->key;
+
+   if (key->ge.part.vs.prolog.instance_divisor_is_fetched) {
+      s->instance_divisor_constbuf =
+         si_nir_load_internal_binding(b, s->args, SI_VS_CONST_INSTANCE_DIVISORS, 4);
+   }
+
+   for (int i = 0; i < sel->info.num_inputs; i++) {
+      s->vertex_index[i] = s->shader->is_monolithic ?
+         get_vertex_index_for_mono_shader(b, i, s) :
+         get_vertex_index_for_part_shader(b, i, s);
+   }
+}
+
+static void
+load_vs_input_from_blit_sgpr(nir_builder *b, unsigned input_index,
+                             struct lower_vs_inputs_state *s,
+                             nir_ssa_def *out[4])
+{
+   nir_ssa_def *vertex_id = nir_load_vertex_id_zero_base(b);
+   nir_ssa_def *sel_x1 = nir_uge(b, nir_imm_int(b, 1), vertex_id);
+   /* Use nir_ine, because we have 3 vertices and only
+    * the middle one should use y2.
+    */
+   nir_ssa_def *sel_y1 = nir_ine_imm(b, vertex_id, 1);
+
+   if (input_index == 0) {
+      /* Position: */
+      nir_ssa_def *x1y1 = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 0);
+      nir_ssa_def *x2y2 = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 1);
+
+      x1y1 = nir_i2i32(b, nir_unpack_32_2x16(b, x1y1));
+      x2y2 = nir_i2i32(b, nir_unpack_32_2x16(b, x2y2));
+
+      nir_ssa_def *x1 = nir_channel(b, x1y1, 0);
+      nir_ssa_def *y1 = nir_channel(b, x1y1, 1);
+      nir_ssa_def *x2 = nir_channel(b, x2y2, 0);
+      nir_ssa_def *y2 = nir_channel(b, x2y2, 1);
+
+      out[0] = nir_i2f32(b, nir_bcsel(b, sel_x1, x1, x2));
+      out[1] = nir_i2f32(b, nir_bcsel(b, sel_y1, y1, y2));
+      out[2] = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 2);
+      out[3] = nir_imm_float(b, 1);
+   } else {
+      /* Color or texture coordinates: */
+      assert(input_index == 1);
+
+      unsigned vs_blit_property = s->shader->selector->info.base.vs.blit_sgprs_amd;
+      if (vs_blit_property == SI_VS_BLIT_SGPRS_POS_COLOR) {
+         for (int i = 0; i < 4; i++)
+            out[i] = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 3 + i);
+      } else {
+         assert(vs_blit_property == SI_VS_BLIT_SGPRS_POS_TEXCOORD);
+
+         nir_ssa_def *x1 = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 3);
+         nir_ssa_def *y1 = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 4);
+         nir_ssa_def *x2 = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 5);
+         nir_ssa_def *y2 = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 6);
+
+         out[0] = nir_bcsel(b, sel_x1, x1, x2);
+         out[1] = nir_bcsel(b, sel_y1, y1, y2);
+         out[2] = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 7);
+         out[3] = ac_nir_load_arg_at_offset(b, &s->args->ac, s->args->vs_blit_inputs, 8);
+      }
+   }
+}
+
+/**
+ * Convert an 11- or 10-bit unsigned floating point number to an f32.
+ *
+ * The input exponent is expected to be biased analogous to IEEE-754, i.e. by
+ * 2^(exp_bits-1) - 1 (as defined in OpenGL and other graphics APIs).
+ */
+static nir_ssa_def *
+ufN_to_float(nir_builder *b, nir_ssa_def *src, unsigned exp_bits, unsigned mant_bits)
+{
+   assert(src->bit_size == 32);
+
+   nir_ssa_def *mantissa = nir_iand_imm(b, src, (1 << mant_bits) - 1);
+
+   /* Converting normal numbers is just a shift + correcting the exponent bias */
+   unsigned normal_shift = 23 - mant_bits;
+   unsigned bias_shift = 127 - ((1 << (exp_bits - 1)) - 1);
+
+   nir_ssa_def *shifted = nir_ishl_imm(b, src, normal_shift);
+   nir_ssa_def *normal = nir_iadd_imm(b, shifted, bias_shift << 23);
+
+   /* Converting nan/inf numbers is the same, but with a different exponent update */
+   nir_ssa_def *naninf = nir_ior_imm(b, normal, 0xff << 23);
+
+   /* Converting denormals is the complex case: determine the leading zeros of the
+    * mantissa to obtain the correct shift for the mantissa and exponent correction.
+    */
+   nir_ssa_def *ctlz = nir_uclz(b, mantissa);
+   /* Shift such that the leading 1 ends up as the LSB of the exponent field. */
+   nir_ssa_def *denormal = nir_ishl(b, mantissa, nir_iadd_imm(b, ctlz, -8));
+
+   unsigned denormal_exp = bias_shift + (32 - mant_bits) - 1;
+   nir_ssa_def *tmp = nir_isub_imm(b, denormal_exp, ctlz);
+   denormal = nir_iadd(b, denormal, nir_ishl_imm(b, tmp, 23));
+
+   /* Select the final result. */
+   nir_ssa_def *cond = nir_uge(b, src, nir_imm_int(b, ((1ULL << exp_bits) - 1) << mant_bits));
+   nir_ssa_def *result = nir_bcsel(b, cond, naninf, normal);
+
+   cond = nir_uge(b, src, nir_imm_int(b, 1ULL << mant_bits));
+   result = nir_bcsel(b, cond, result, denormal);
+
+   cond = nir_ine_imm(b, src, 0);
+   result = nir_bcsel(b, cond, result, nir_imm_int(b, 0));
+
+   return result;
+}
+
+/**
+ * Generate a fully general open coded buffer format fetch with all required
+ * fixups suitable for vertex fetch, using non-format buffer loads.
+ *
+ * Some combinations of argument values have special interpretations:
+ * - size = 8 bytes, format = fixed indicates PIPE_FORMAT_R11G11B10_FLOAT
+ * - size = 8 bytes, format != {float,fixed} indicates a 2_10_10_10 data format
+ */
+static void
+opencoded_load_format(nir_builder *b, nir_ssa_def *rsrc, nir_ssa_def *vindex,
+                      union si_vs_fix_fetch fix_fetch, bool known_aligned,
+                      enum amd_gfx_level gfx_level, nir_ssa_def *out[4])
+{
+   unsigned log_size = fix_fetch.u.log_size;
+   unsigned num_channels = fix_fetch.u.num_channels_m1 + 1;
+   unsigned format = fix_fetch.u.format;
+   bool reverse = fix_fetch.u.reverse;
+
+   unsigned load_log_size = log_size;
+   unsigned load_num_channels = num_channels;
+   if (log_size == 3) {
+      load_log_size = 2;
+      if (format == AC_FETCH_FORMAT_FLOAT) {
+         load_num_channels = 2 * num_channels;
+      } else {
+         load_num_channels = 1; /* 10_11_11 or 2_10_10_10 */
+      }
+   }
+
+   int log_recombine = 0;
+   if ((gfx_level == GFX6 || gfx_level >= GFX10) && !known_aligned) {
+      /* Avoid alignment restrictions by loading one byte at a time. */
+      load_num_channels <<= load_log_size;
+      log_recombine = load_log_size;
+      load_log_size = 0;
+   } else if (load_num_channels == 2 || load_num_channels == 4) {
+      log_recombine = -util_logbase2(load_num_channels);
+      load_num_channels = 1;
+      load_log_size += -log_recombine;
+   }
+
+   nir_ssa_def *loads[32]; /* up to 32 bytes */
+   for (unsigned i = 0; i < load_num_channels; ++i) {
+      nir_ssa_def *soffset = nir_imm_int(b, i << load_log_size);
+      unsigned num_channels = 1 << (MAX2(load_log_size, 2) - 2);
+      unsigned bit_size = 8 << MIN2(load_log_size, 2);
+      nir_ssa_def *zero = nir_imm_int(b, 0);
+
+      loads[i] = nir_load_buffer_amd(b, num_channels, bit_size, rsrc, zero, soffset, vindex);
+   }
+
+   if (log_recombine > 0) {
+      /* Recombine bytes if necessary (GFX6 only) */
+      unsigned dst_bitsize = log_recombine == 2 ? 32 : 16;
+
+      for (unsigned src = 0, dst = 0; src < load_num_channels; ++dst) {
+         nir_ssa_def *accum = NULL;
+         for (unsigned i = 0; i < (1 << log_recombine); ++i, ++src) {
+            nir_ssa_def *tmp = nir_u2uN(b, loads[src], dst_bitsize);
+            if (i == 0) {
+               accum = tmp;
+            } else {
+               tmp = nir_ishl_imm(b, tmp, 8 * i);
+               accum = nir_ior(b, accum, tmp);
+            }
+         }
+         loads[dst] = accum;
+      }
+   } else if (log_recombine < 0) {
+      /* Split vectors of dwords */
+      if (load_log_size > 2) {
+         assert(load_num_channels == 1);
+         nir_ssa_def *loaded = loads[0];
+         unsigned log_split = load_log_size - 2;
+         log_recombine += log_split;
+         load_num_channels = 1 << log_split;
+         load_log_size = 2;
+         for (unsigned i = 0; i < load_num_channels; ++i)
+            loads[i] = nir_channel(b, loaded, i);
+      }
+
+      /* Further split dwords and shorts if required */
+      if (log_recombine < 0) {
+         for (unsigned src = load_num_channels, dst = load_num_channels << -log_recombine;
+              src > 0; --src) {
+            unsigned dst_bits = 1 << (3 + load_log_size + log_recombine);
+            nir_ssa_def *loaded = loads[src - 1];
+            for (unsigned i = 1 << -log_recombine; i > 0; --i, --dst) {
+               nir_ssa_def *tmp = nir_ushr_imm(b, loaded, dst_bits * (i - 1));
+               loads[dst - 1] = nir_u2uN(b, tmp, dst_bits);
+            }
+         }
+      }
+   }
+
+   if (log_size == 3) {
+      switch (format) {
+      case AC_FETCH_FORMAT_FLOAT: {
+         for (unsigned i = 0; i < num_channels; ++i)
+            loads[i] = nir_pack_64_2x32_split(b, loads[2 * i], loads[2 * i + 1]);
+         break;
+      }
+      case AC_FETCH_FORMAT_FIXED: {
+         /* 10_11_11_FLOAT */
+         nir_ssa_def *data = loads[0];
+         nir_ssa_def *red = nir_iand_imm(b, data, 2047);
+         nir_ssa_def *green = nir_iand_imm(b, nir_ushr_imm(b, data, 11), 2047);
+         nir_ssa_def *blue = nir_ushr_imm(b, data, 22);
+
+         loads[0] = ufN_to_float(b, red, 5, 6);
+         loads[1] = ufN_to_float(b, green, 5, 6);
+         loads[2] = ufN_to_float(b, blue, 5, 5);
+
+         num_channels = 3;
+         log_size = 2;
+         format = AC_FETCH_FORMAT_FLOAT;
+         break;
+      }
+      case AC_FETCH_FORMAT_UINT:
+      case AC_FETCH_FORMAT_UNORM:
+      case AC_FETCH_FORMAT_USCALED: {
+         /* 2_10_10_10 data formats */
+         nir_ssa_def *data = loads[0];
+
+         loads[0] = nir_ubfe_imm(b, data, 0, 10);
+         loads[1] = nir_ubfe_imm(b, data, 10, 10);
+         loads[2] = nir_ubfe_imm(b, data, 20, 10);
+         loads[3] = nir_ubfe_imm(b, data, 30, 2);
+
+         num_channels = 4;
+         break;
+      }
+      case AC_FETCH_FORMAT_SINT:
+      case AC_FETCH_FORMAT_SNORM:
+      case AC_FETCH_FORMAT_SSCALED: {
+         /* 2_10_10_10 data formats */
+         nir_ssa_def *data = loads[0];
+
+         loads[0] = nir_ibfe_imm(b, data, 0, 10);
+         loads[1] = nir_ibfe_imm(b, data, 10, 10);
+         loads[2] = nir_ibfe_imm(b, data, 20, 10);
+         loads[3] = nir_ibfe_imm(b, data, 30, 2);
+
+         num_channels = 4;
+         break;
+      }
+      default:
+         unreachable("invalid fetch format");
+         break;
+      }
+   }
+
+   switch (format) {
+   case AC_FETCH_FORMAT_FLOAT:
+      if (log_size != 2) {
+         for (unsigned chan = 0; chan < num_channels; ++chan)
+            loads[chan] = nir_f2f32(b, loads[chan]);
+      }
+      break;
+   case AC_FETCH_FORMAT_UINT:
+      if (log_size != 2) {
+         for (unsigned chan = 0; chan < num_channels; ++chan)
+            loads[chan] = nir_u2u32(b, loads[chan]);
+      }
+      break;
+   case AC_FETCH_FORMAT_SINT:
+      if (log_size != 2) {
+         for (unsigned chan = 0; chan < num_channels; ++chan)
+            loads[chan] = nir_i2i32(b, loads[chan]);
+      }
+      break;
+   case AC_FETCH_FORMAT_USCALED:
+      for (unsigned chan = 0; chan < num_channels; ++chan)
+         loads[chan] = nir_u2f32(b, loads[chan]);
+      break;
+   case AC_FETCH_FORMAT_SSCALED:
+      for (unsigned chan = 0; chan < num_channels; ++chan)
+         loads[chan] = nir_i2f32(b, loads[chan]);
+      break;
+   case AC_FETCH_FORMAT_FIXED:
+      for (unsigned chan = 0; chan < num_channels; ++chan) {
+         nir_ssa_def *tmp = nir_i2f32(b, loads[chan]);
+         loads[chan] = nir_fmul_imm(b, tmp, 1.0 / 0x10000);
+      }
+      break;
+   case AC_FETCH_FORMAT_UNORM:
+      for (unsigned chan = 0; chan < num_channels; ++chan) {
+         /* 2_10_10_10 data formats */
+         unsigned bits = log_size == 3 ? (chan == 3 ? 2 : 10) : (8 << log_size);
+         nir_ssa_def *tmp = nir_u2f32(b, loads[chan]);
+         loads[chan] = nir_fmul_imm(b, tmp, 1.0 / BITFIELD64_MASK(bits));
+      }
+      break;
+   case AC_FETCH_FORMAT_SNORM:
+      for (unsigned chan = 0; chan < num_channels; ++chan) {
+         /* 2_10_10_10 data formats */
+         unsigned bits = log_size == 3 ? (chan == 3 ? 2 : 10) : (8 << log_size);
+         nir_ssa_def *tmp = nir_i2f32(b, loads[chan]);
+         tmp = nir_fmul_imm(b, tmp, 1.0 / BITFIELD64_MASK(bits - 1));
+         /* Clamp to [-1, 1] */
+         tmp = nir_fmax(b, tmp, nir_imm_float(b, -1));
+         loads[chan] = nir_fmin(b, tmp, nir_imm_float(b, 1));
+      }
+      break;
+   default:
+      unreachable("invalid fetch format");
+      break;
+   }
+
+   while (num_channels < 4) {
+      unsigned pad_value = num_channels == 3 ? 1 : 0;
+      loads[num_channels] =
+         format == AC_FETCH_FORMAT_UINT || format == AC_FETCH_FORMAT_SINT ?
+         nir_imm_int(b, pad_value) : nir_imm_float(b, pad_value);
+      num_channels++;
+   }
+
+   if (reverse) {
+      nir_ssa_def *tmp = loads[0];
+      loads[0] = loads[2];
+      loads[2] = tmp;
+   }
+
+   memcpy(out, loads, 4 * sizeof(out[0]));
+}
+
+static void
+load_vs_input_from_vertex_buffer(nir_builder *b, unsigned input_index,
+                                 struct lower_vs_inputs_state *s,
+                                 unsigned bit_size, nir_ssa_def *out[4])
+{
+   const struct si_shader_selector *sel = s->shader->selector;
+   const union si_shader_key *key = &s->shader->key;
+
+   nir_ssa_def *vb_desc;
+   if (input_index < sel->info.num_vbos_in_user_sgprs) {
+      vb_desc = ac_nir_load_arg(b, &s->args->ac, s->args->vb_descriptors[input_index]);
+   } else {
+      unsigned index = input_index - sel->info.num_vbos_in_user_sgprs;
+      nir_ssa_def *addr = ac_nir_load_arg(b, &s->args->ac, s->args->ac.vertex_buffers);
+      vb_desc = nir_load_smem_amd(b, 4, addr, nir_imm_int(b, index * 16));
+   }
+
+   nir_ssa_def *vertex_index = s->vertex_index[input_index];
+
+   /* Use the open-coded implementation for all loads of doubles and
+    * of dword-sized data that needs fixups. We need to insert conversion
+    * code anyway.
+    */
+   bool opencode = key->ge.mono.vs_fetch_opencode & (1 << input_index);
+   union si_vs_fix_fetch fix_fetch = key->ge.mono.vs_fix_fetch[input_index];
+   if (opencode ||
+       (fix_fetch.u.log_size == 3 && fix_fetch.u.format == AC_FETCH_FORMAT_FLOAT) ||
+       fix_fetch.u.log_size == 2) {
+      opencoded_load_format(b, vb_desc, vertex_index, fix_fetch, !opencode,
+                            sel->screen->info.gfx_level, out);
+
+      if (bit_size == 16) {
+         if (fix_fetch.u.format == AC_FETCH_FORMAT_UINT ||
+             fix_fetch.u.format == AC_FETCH_FORMAT_SINT) {
+            for (unsigned i = 0; i < 4; i++)
+               out[i] = nir_u2u16(b, out[i]);
+         } else {
+            for (unsigned i = 0; i < 4; i++)
+               out[i] = nir_f2f16(b, out[i]);
+         }
+      }
+      return;
+   }
+
+   unsigned required_channels = util_last_bit(sel->info.input[input_index].usage_mask);
+   if (required_channels == 0) {
+      for (unsigned i = 0; i < 4; ++i)
+         out[i] = nir_ssa_undef(b, 1, bit_size);
+      return;
+   }
+
+   /* Do multiple loads for special formats. */
+   nir_ssa_def *fetches[4];
+   unsigned num_fetches;
+   unsigned fetch_stride;
+   unsigned channels_per_fetch;
+
+   if (fix_fetch.u.log_size <= 1 && fix_fetch.u.num_channels_m1 == 2) {
+      num_fetches = MIN2(required_channels, 3);
+      fetch_stride = 1 << fix_fetch.u.log_size;
+      channels_per_fetch = 1;
+   } else {
+      num_fetches = 1;
+      fetch_stride = 0;
+      channels_per_fetch = required_channels;
+   }
+
+   for (unsigned i = 0; i < num_fetches; ++i) {
+      nir_ssa_def *zero = nir_imm_int(b, 0);
+      fetches[i] = nir_load_buffer_amd(b, channels_per_fetch, bit_size, vb_desc,
+                                       zero, zero, vertex_index,
+                                       .base = fetch_stride * i,
+                                       .access = ACCESS_USES_FORMAT_AMD);
+   }
+
+   if (num_fetches == 1 && channels_per_fetch > 1) {
+      nir_ssa_def *fetch = fetches[0];
+      for (unsigned i = 0; i < channels_per_fetch; ++i)
+         fetches[i] = nir_channel(b, fetch, i);
+
+      num_fetches = channels_per_fetch;
+      channels_per_fetch = 1;
+   }
+
+   for (unsigned i = num_fetches; i < 4; ++i)
+      fetches[i] = nir_ssa_undef(b, 1, bit_size);
+
+   if (fix_fetch.u.log_size <= 1 && fix_fetch.u.num_channels_m1 == 2 && required_channels == 4) {
+      if (fix_fetch.u.format == AC_FETCH_FORMAT_UINT || fix_fetch.u.format == AC_FETCH_FORMAT_SINT)
+         fetches[3] = nir_imm_intN_t(b, 1, bit_size);
+      else
+         fetches[3] = nir_imm_floatN_t(b, 1, bit_size);
+   } else if (fix_fetch.u.log_size == 3 &&
+              (fix_fetch.u.format == AC_FETCH_FORMAT_SNORM ||
+               fix_fetch.u.format == AC_FETCH_FORMAT_SSCALED ||
+               fix_fetch.u.format == AC_FETCH_FORMAT_SINT) &&
+              required_channels == 4) {
+
+      /* For 2_10_10_10, the hardware returns an unsigned value;
+       * convert it to a signed one.
+       */
+      nir_ssa_def *tmp = fetches[3];
+
+      /* First, recover the sign-extended signed integer value. */
+      if (fix_fetch.u.format == AC_FETCH_FORMAT_SSCALED)
+         tmp = nir_f2uN(b, tmp, bit_size);
+
+      /* For the integer-like cases, do a natural sign extension.
+       *
+       * For the SNORM case, the values are 0.0, 0.333, 0.666, 1.0
+       * and happen to contain 0, 1, 2, 3 as the two LSBs of the
+       * exponent.
+       */
+      tmp = nir_ishl_imm(b, tmp, fix_fetch.u.format == AC_FETCH_FORMAT_SNORM ? 7 : 30);
+      tmp = nir_ishr_imm(b, tmp, 30);
+
+      /* Convert back to the right type. */
+      if (fix_fetch.u.format == AC_FETCH_FORMAT_SNORM) {
+         tmp = nir_i2fN(b, tmp, bit_size);
+         /* Clamp to [-1, 1] */
+         tmp = nir_fmax(b, tmp, nir_imm_float(b, -1));
+         tmp = nir_fmin(b, tmp, nir_imm_float(b, 1));
+      } else if (fix_fetch.u.format == AC_FETCH_FORMAT_SSCALED) {
+         tmp = nir_i2fN(b, tmp, bit_size);
+      }
+
+      fetches[3] = tmp;
+   }
+
+   memcpy(out, fetches, 4 * sizeof(out[0]));
+}
+
+static bool
+lower_vs_input_instr(nir_builder *b, nir_instr *instr, void *state)
+{
+   if (instr->type != nir_instr_type_intrinsic)
+      return false;
+
+   nir_intrinsic_instr *intrin = nir_instr_as_intrinsic(instr);
+   if (intrin->intrinsic != nir_intrinsic_load_input)
+      return false;
+
+   struct lower_vs_inputs_state *s = (struct lower_vs_inputs_state *)state;
+
+   b->cursor = nir_before_instr(instr);
+
+   unsigned input_index = nir_intrinsic_base(intrin);
+   unsigned component = nir_intrinsic_component(intrin);
+   unsigned num_components = intrin->dest.ssa.num_components;
+
+   nir_ssa_def *comp[4];
+   if (s->shader->selector->info.base.vs.blit_sgprs_amd)
+      load_vs_input_from_blit_sgpr(b, input_index, s, comp);
+   else
+      load_vs_input_from_vertex_buffer(b, input_index, s, intrin->dest.ssa.bit_size, comp);
+
+   nir_ssa_def *replacement = nir_vec(b, &comp[component], num_components);
+
+   nir_ssa_def_rewrite_uses(&intrin->dest.ssa, replacement);
+   nir_instr_remove(instr);
+   nir_instr_free(instr);
+
+   return true;
+}
+
+bool
+si_nir_lower_vs_inputs(nir_shader *nir, struct si_shader *shader, struct si_shader_args *args)
+{
+   const struct si_shader_selector *sel = shader->selector;
+
+   /* no inputs to lower */
+   if (!sel->info.num_inputs)
+      return false;
+
+   struct lower_vs_inputs_state state = {
+      .shader = shader,
+      .args = args,
+   };
+
+   if (!sel->info.base.vs.blit_sgprs_amd)
+      get_vertex_index_for_all_inputs(nir, &state);
+
+   return nir_shader_instructions_pass(nir, lower_vs_input_instr,
+                                       nir_metadata_dominance | nir_metadata_block_index,
+                                       &state);
+}
diff --git a/src/gallium/drivers/radeonsi/si_shader_internal.h b/src/gallium/drivers/radeonsi/si_shader_internal.h
index 90da6a9c4139..c28e559b779e 100644
--- a/src/gallium/drivers/radeonsi/si_shader_internal.h
+++ b/src/gallium/drivers/radeonsi/si_shader_internal.h
@@ -170,6 +170,10 @@ bool si_nir_lower_abi(nir_shader *nir, struct si_shader *shader, struct si_shade
 bool si_nir_lower_resource(nir_shader *nir, struct si_shader *shader,
                            struct si_shader_args *args);
 
+/* si_nir_lower_vs_inputs.c */
+bool si_nir_lower_vs_inputs(nir_shader *nir, struct si_shader *shader,
+                            struct si_shader_args *args);
+
 /* si_shader_llvm.c */
 bool si_compile_llvm(struct si_screen *sscreen, struct si_shader_binary *binary,
                      struct ac_shader_config *conf, struct ac_llvm_compiler *compiler,
-- 
GitLab


From b152ecaa21e8e55622bf1b7687dcffe6717de3bb Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Mon, 20 Mar 2023 11:49:20 +0800
Subject: [PATCH 4/8] ac/llvm: vs_rel_patch_id can also be fixed up

It's currently used when LS store output to LDS.
The LS/HS bug fix seems does not affect this case.
But we'd better treat it as other fixed args.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/llvm/ac_nir_to_llvm.c                 | 4 ++--
 src/amd/llvm/ac_shader_abi.h                  | 1 +
 src/amd/vulkan/radv_nir_to_llvm.c             | 8 +++-----
 src/gallium/drivers/radeonsi/si_shader_llvm.c | 2 ++
 4 files changed, 8 insertions(+), 7 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 194296b4ef33..115183c3a1d6 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -2889,8 +2889,8 @@ static LLVMValueRef visit_load_local_invocation_index(struct ac_nir_context *ctx
                            ac_unpack_param(&ctx->ac, ac_get_arg(&ctx->ac, ctx->args->tcs_wave_id), 0, 3),
                            LLVMConstInt(ctx->ac.i32, ctx->ac.wave_size, 0),
                            ac_get_thread_id(&ctx->ac));
-   } else if (ctx->args->vs_rel_patch_id.used) {
-      return ac_get_arg(&ctx->ac, ctx->args->vs_rel_patch_id);
+   } else if (ctx->abi->vs_rel_patch_id) {
+      return ctx->abi->vs_rel_patch_id;
    } else if (ctx->args->merged_wave_info.used) {
       /* Thread ID in threadgroup in merged ESGS. */
       LLVMValueRef wave_id = ac_unpack_param(&ctx->ac, ac_get_arg(&ctx->ac, ctx->args->merged_wave_info), 24, 4);
diff --git a/src/amd/llvm/ac_shader_abi.h b/src/amd/llvm/ac_shader_abi.h
index 6a84e685127e..ee56be083952 100644
--- a/src/amd/llvm/ac_shader_abi.h
+++ b/src/amd/llvm/ac_shader_abi.h
@@ -44,6 +44,7 @@ struct ac_shader_abi {
 
    /* These input registers sometimes need to be fixed up. */
    LLVMValueRef vertex_id;
+   LLVMValueRef vs_rel_patch_id;
    LLVMValueRef instance_id;
    LLVMValueRef persp_centroid, linear_centroid;
    LLVMValueRef color0, color1;
diff --git a/src/amd/vulkan/radv_nir_to_llvm.c b/src/amd/vulkan/radv_nir_to_llvm.c
index 502615d7ca67..580a4dd6aaaa 100644
--- a/src/amd/vulkan/radv_nir_to_llvm.c
+++ b/src/amd/vulkan/radv_nir_to_llvm.c
@@ -56,8 +56,6 @@ struct radv_shader_context {
 
    LLVMValueRef descriptor_sets[MAX_SETS];
 
-   LLVMValueRef vs_rel_patch_id;
-
    LLVMValueRef gs_wave_id;
 
    uint64_t output_mask;
@@ -626,9 +624,9 @@ ac_nir_fixup_ls_hs_input_vgprs(struct radv_shader_context *ctx)
    ctx->abi.instance_id =
       LLVMBuildSelect(ctx->ac.builder, hs_empty, ac_get_arg(&ctx->ac, ctx->args->ac.vertex_id),
                       ctx->abi.instance_id, "");
-   ctx->vs_rel_patch_id =
+   ctx->abi.vs_rel_patch_id =
       LLVMBuildSelect(ctx->ac.builder, hs_empty, ac_get_arg(&ctx->ac, ctx->args->ac.tcs_rel_ids),
-                      ctx->vs_rel_patch_id, "");
+                      ctx->abi.vs_rel_patch_id, "");
    ctx->abi.vertex_id =
       LLVMBuildSelect(ctx->ac.builder, hs_empty, ac_get_arg(&ctx->ac, ctx->args->ac.tcs_patch_id),
                       ctx->abi.vertex_id, "");
@@ -744,7 +742,7 @@ ac_translate_nir_to_llvm(struct ac_llvm_compiler *ac_llvm,
    if (args->ac.vertex_id.used)
       ctx.abi.vertex_id = ac_get_arg(&ctx.ac, args->ac.vertex_id);
    if (args->ac.vs_rel_patch_id.used)
-      ctx.vs_rel_patch_id = ac_get_arg(&ctx.ac, args->ac.vs_rel_patch_id);
+      ctx.abi.vs_rel_patch_id = ac_get_arg(&ctx.ac, args->ac.vs_rel_patch_id);
    if (args->ac.instance_id.used)
       ctx.abi.instance_id = ac_get_arg(&ctx.ac, args->ac.instance_id);
 
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm.c b/src/gallium/drivers/radeonsi/si_shader_llvm.c
index 685e152c2d9f..ac712a23e2b1 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm.c
@@ -244,6 +244,8 @@ void si_llvm_create_main_func(struct si_shader_context *ctx)
    if (ctx->stage == MESA_SHADER_VERTEX) {
       ctx->abi.vertex_id = ac_get_arg(&ctx->ac, ctx->args->ac.vertex_id);
       ctx->abi.instance_id = ac_get_arg(&ctx->ac, ctx->args->ac.instance_id);
+      if (ctx->args->ac.vs_rel_patch_id.used)
+         ctx->abi.vs_rel_patch_id = ac_get_arg(&ctx->ac, ctx->args->ac.vs_rel_patch_id);
    } else if (ctx->stage == MESA_SHADER_FRAGMENT) {
       ctx->abi.persp_centroid = ac_get_arg(&ctx->ac, ctx->args->ac.persp_centroid);
       ctx->abi.linear_centroid = ac_get_arg(&ctx->ac, ctx->args->ac.linear_centroid);
-- 
GitLab


From 0c9009ceda8debfe77ad95535bd1d44603b2f0ae Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Mon, 20 Mar 2023 12:15:02 +0800
Subject: [PATCH 5/8] ac/llvm: move ac_fixup_ls_hs_input_vgprs to amd common

To be shared with radeonsi.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/llvm/ac_nir_to_llvm.c     | 20 ++++++++++++++++++++
 src/amd/llvm/ac_nir_to_llvm.h     |  3 +++
 src/amd/vulkan/radv_nir_to_llvm.c | 20 +-------------------
 3 files changed, 24 insertions(+), 19 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 115183c3a1d6..5d3c8ad38143 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -5125,3 +5125,23 @@ bool ac_nir_translate(struct ac_llvm_context *ac, struct ac_shader_abi *abi,
 
    return true;
 }
+
+/* Fixup the HW not emitting the TCS regs if there are no HS threads. */
+void ac_fixup_ls_hs_input_vgprs(struct ac_llvm_context *ac, struct ac_shader_abi *abi,
+                                const struct ac_shader_args *args)
+{
+   LLVMValueRef count = ac_unpack_param(ac, ac_get_arg(ac, args->merged_wave_info), 8, 8);
+   LLVMValueRef hs_empty = LLVMBuildICmp(ac->builder, LLVMIntEQ, count, ac->i32_0, "");
+
+   abi->instance_id =
+      LLVMBuildSelect(ac->builder, hs_empty, ac_get_arg(ac, args->vertex_id),
+                      abi->instance_id, "");
+
+   abi->vs_rel_patch_id =
+      LLVMBuildSelect(ac->builder, hs_empty, ac_get_arg(ac, args->tcs_rel_ids),
+                      abi->vs_rel_patch_id, "");
+
+   abi->vertex_id =
+      LLVMBuildSelect(ac->builder, hs_empty, ac_get_arg(ac, args->tcs_patch_id),
+                      abi->vertex_id, "");
+}
diff --git a/src/amd/llvm/ac_nir_to_llvm.h b/src/amd/llvm/ac_nir_to_llvm.h
index 33888f1f0157..e0c6f2f1651d 100644
--- a/src/amd/llvm/ac_nir_to_llvm.h
+++ b/src/amd/llvm/ac_nir_to_llvm.h
@@ -50,4 +50,7 @@ static inline unsigned ac_llvm_reg_index_soa(unsigned index, unsigned chan)
 bool ac_nir_translate(struct ac_llvm_context *ac, struct ac_shader_abi *abi,
                       const struct ac_shader_args *args, struct nir_shader *nir);
 
+void ac_fixup_ls_hs_input_vgprs(struct ac_llvm_context *ac, struct ac_shader_abi *abi,
+                                const struct ac_shader_args *args);
+
 #endif /* AC_NIR_TO_LLVM_H */
diff --git a/src/amd/vulkan/radv_nir_to_llvm.c b/src/amd/vulkan/radv_nir_to_llvm.c
index 580a4dd6aaaa..4d10d00c837d 100644
--- a/src/amd/vulkan/radv_nir_to_llvm.c
+++ b/src/amd/vulkan/radv_nir_to_llvm.c
@@ -614,24 +614,6 @@ ac_llvm_finalize_module(struct radv_shader_context *ctx, LLVMPassManagerRef pass
    ac_llvm_context_dispose(&ctx->ac);
 }
 
-/* Fixup the HW not emitting the TCS regs if there are no HS threads. */
-static void
-ac_nir_fixup_ls_hs_input_vgprs(struct radv_shader_context *ctx)
-{
-   LLVMValueRef count =
-      ac_unpack_param(&ctx->ac, ac_get_arg(&ctx->ac, ctx->args->ac.merged_wave_info), 8, 8);
-   LLVMValueRef hs_empty = LLVMBuildICmp(ctx->ac.builder, LLVMIntEQ, count, ctx->ac.i32_0, "");
-   ctx->abi.instance_id =
-      LLVMBuildSelect(ctx->ac.builder, hs_empty, ac_get_arg(&ctx->ac, ctx->args->ac.vertex_id),
-                      ctx->abi.instance_id, "");
-   ctx->abi.vs_rel_patch_id =
-      LLVMBuildSelect(ctx->ac.builder, hs_empty, ac_get_arg(&ctx->ac, ctx->args->ac.tcs_rel_ids),
-                      ctx->abi.vs_rel_patch_id, "");
-   ctx->abi.vertex_id =
-      LLVMBuildSelect(ctx->ac.builder, hs_empty, ac_get_arg(&ctx->ac, ctx->args->ac.tcs_patch_id),
-                      ctx->abi.vertex_id, "");
-}
-
 static void
 prepare_gs_input_vgprs(struct radv_shader_context *ctx, bool merged)
 {
@@ -748,7 +730,7 @@ ac_translate_nir_to_llvm(struct ac_llvm_compiler *ac_llvm,
 
    if (options->has_ls_vgpr_init_bug &&
        shaders[shader_count - 1]->info.stage == MESA_SHADER_TESS_CTRL)
-      ac_nir_fixup_ls_hs_input_vgprs(&ctx);
+      ac_fixup_ls_hs_input_vgprs(&ctx.ac, &ctx.abi, &args->ac);
 
    if (is_ngg) {
       if (!info->is_ngg_passthrough)
-- 
GitLab


From 3def360bf4eed5e41293368f45da76a7732173f1 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Mon, 20 Mar 2023 12:26:57 +0800
Subject: [PATCH 6/8] radeonsi: monolithic VS emit prolog in nir directly

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/gallium/drivers/radeonsi/si_shader.c      |  6 +-
 src/gallium/drivers/radeonsi/si_shader_llvm.c | 77 ++++---------------
 2 files changed, 18 insertions(+), 65 deletions(-)

diff --git a/src/gallium/drivers/radeonsi/si_shader.c b/src/gallium/drivers/radeonsi/si_shader.c
index fac4047bcb3b..548647e91110 100644
--- a/src/gallium/drivers/radeonsi/si_shader.c
+++ b/src/gallium/drivers/radeonsi/si_shader.c
@@ -1967,6 +1967,9 @@ struct nir_shader *si_get_nir_shader(struct si_shader *shader,
     */
    progress2 |= ac_nir_lower_indirect_derefs(nir, sel->screen->info.gfx_level);
 
+   if (sel->stage == MESA_SHADER_VERTEX)
+      progress2 |= si_nir_lower_vs_inputs(nir, shader, args);
+
    bool opt_offsets = si_lower_io_to_mem(shader, nir, tcs_vgpr_only_inputs);
 
    if (is_last_vgt_stage) {
@@ -2210,7 +2213,8 @@ bool si_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *compi
 
    si_update_shader_binary_info(shader, nir);
 
-   shader->info.uses_instanceid = sel->info.uses_instanceid;
+   /* uses_instanceid may be set by si_nir_lower_vs_inputs(). */
+   shader->info.uses_instanceid |= sel->info.uses_instanceid;
    shader->info.private_mem_vgprs = DIV_ROUND_UP(nir->scratch_size, 4);
 
    /* Set the FP ALU behavior. */
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm.c b/src/gallium/drivers/radeonsi/si_shader_llvm.c
index ac712a23e2b1..f9f21fa8372d 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm.c
@@ -238,14 +238,17 @@ void si_llvm_create_main_func(struct si_shader_context *ctx)
       LLVMSetAlignment(ctx->ac.lds.value, 256);
    }
 
-   /* Unlike radv, we override these arguments in the prolog, so to the
-    * API shader they appear as normal arguments.
-    */
    if (ctx->stage == MESA_SHADER_VERTEX) {
       ctx->abi.vertex_id = ac_get_arg(&ctx->ac, ctx->args->ac.vertex_id);
       ctx->abi.instance_id = ac_get_arg(&ctx->ac, ctx->args->ac.instance_id);
       if (ctx->args->ac.vs_rel_patch_id.used)
          ctx->abi.vs_rel_patch_id = ac_get_arg(&ctx->ac, ctx->args->ac.vs_rel_patch_id);
+
+      /* Part mode VS shader will fix in prolog, so to the API shader they
+       * appear as normal arguments.
+       */
+      if (shader->is_monolithic && shader->key.ge.part.vs.prolog.ls_vgpr_fix)
+         ac_fixup_ls_hs_input_vgprs(&ctx->ac, &ctx->abi, &ctx->args->ac);
    } else if (ctx->stage == MESA_SHADER_FRAGMENT) {
       ctx->abi.persp_centroid = ac_get_arg(&ctx->ac, ctx->args->ac.persp_centroid);
       ctx->abi.linear_centroid = ac_get_arg(&ctx->ac, ctx->args->ac.linear_centroid);
@@ -778,8 +781,6 @@ static bool si_llvm_translate_nir(struct si_shader_context *ctx, struct si_shade
 
    switch (ctx->stage) {
    case MESA_SHADER_VERTEX:
-      si_llvm_init_vs_callbacks(ctx);
-
       /* preload instance_divisor_constbuf to be used for input load after culling */
       if (ctx->shader->key.ge.opt.ngg_culling &&
           ctx->shader->key.ge.part.vs.prolog.instance_divisor_is_fetched) {
@@ -1100,37 +1101,16 @@ bool si_llvm_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *
       return false;
    }
 
-   if (shader->is_monolithic && sel->stage == MESA_SHADER_VERTEX &&
-       si_vs_needs_prolog(sel, &shader->key.ge.part.vs.prolog)) {
-      struct ac_llvm_pointer parts[2];
-      parts[1] = ctx.main_fn;
-
-       /* Preserve main arguments. */
-      enum ac_arg_type main_arg_types[AC_MAX_ARGS];
-      for (int i = 0; i < ctx.args->ac.arg_count; i++)
-         main_arg_types[i] = ctx.args->ac.args[i].type;
-      main_arg_types[MIN2(AC_MAX_ARGS - 1, ctx.args->ac.arg_count)] = AC_ARG_INVALID;
-
-      union si_shader_part_key prolog_key;
-      si_get_vs_prolog_key(&sel->info, shader->info.num_input_sgprs,
-                           &shader->key.ge.part.vs.prolog, shader, &prolog_key);
-      prolog_key.vs_prolog.is_monolithic = true;
-      si_llvm_build_vs_prolog(&ctx, &prolog_key, false);
-      parts[0] = ctx.main_fn;
-
-      si_build_wrapper_function(&ctx, parts, 2, 1, 0, main_arg_types, false);
-   } else if (shader->is_monolithic && sel->stage == MESA_SHADER_TESS_CTRL) {
+   if (shader->is_monolithic && sel->stage == MESA_SHADER_TESS_CTRL) {
       /* Preserve main arguments. */
       enum ac_arg_type main_arg_types[AC_MAX_ARGS];
 
       if (sscreen->info.gfx_level >= GFX9) {
          struct si_shader_selector *ls = shader->key.ge.part.tcs.ls;
-         struct ac_llvm_pointer parts[3];
-         bool vs_needs_prolog =
-            si_vs_needs_prolog(ls, &shader->key.ge.part.tcs.ls_prolog);
+         struct ac_llvm_pointer parts[2];
 
          /* TCS main part */
-         parts[2] = ctx.main_fn;
+         parts[1] = ctx.main_fn;
 
          struct si_shader shader_ls = {};
          shader_ls.selector = ls;
@@ -1153,29 +1133,17 @@ bool si_llvm_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *
             return false;
          }
          shader->info.uses_instanceid |= ls->info.uses_instanceid;
-         parts[1] = ctx.main_fn;
+         parts[0] = ctx.main_fn;
 
          for (int i = 0; i < ctx.args->ac.arg_count; i++)
             main_arg_types[i] = ctx.args->ac.args[i].type;
          main_arg_types[MIN2(AC_MAX_ARGS - 1, ctx.args->ac.arg_count)] = AC_ARG_INVALID;
 
-         /* LS prolog */
-         if (vs_needs_prolog) {
-            union si_shader_part_key vs_prolog_key;
-            si_get_vs_prolog_key(&ls->info, shader_ls.info.num_input_sgprs,
-                                 &shader->key.ge.part.tcs.ls_prolog, shader, &vs_prolog_key);
-            vs_prolog_key.vs_prolog.is_monolithic = true;
-            si_llvm_build_vs_prolog(&ctx, &vs_prolog_key, false);
-            parts[0] = ctx.main_fn;
-         }
-
          /* Reset the shader context. */
          ctx.shader = shader;
          ctx.stage = MESA_SHADER_TESS_CTRL;
 
-         si_build_wrapper_function(&ctx, parts + !vs_needs_prolog, 3 - !vs_needs_prolog,
-                                   vs_needs_prolog, vs_needs_prolog ? 2 : 1,
-                                   main_arg_types,
+         si_build_wrapper_function(&ctx, parts, 2, 0, 1, main_arg_types,
                                    shader->key.ge.opt.same_patch_vertices);
       }
    } else if (shader->is_monolithic && sel->stage == MESA_SHADER_GEOMETRY) {
@@ -1183,7 +1151,6 @@ bool si_llvm_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *
          enum ac_arg_type main_arg_types[AC_MAX_ARGS];
 
          struct si_shader_selector *es = shader->key.ge.part.gs.es;
-         struct ac_llvm_pointer es_prolog = {};
          struct ac_llvm_pointer es_main = {};
          struct ac_llvm_pointer gs_main = ctx.main_fn;
 
@@ -1218,32 +1185,14 @@ bool si_llvm_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *
             main_arg_types[i] = ctx.args->ac.args[i].type;
          main_arg_types[MIN2(AC_MAX_ARGS - 1, ctx.args->ac.arg_count)] = AC_ARG_INVALID;
 
-         /* ES prolog */
-         if (es->stage == MESA_SHADER_VERTEX &&
-             si_vs_needs_prolog(es, &shader->key.ge.part.gs.vs_prolog)) {
-            union si_shader_part_key vs_prolog_key;
-            si_get_vs_prolog_key(&es->info, shader_es.info.num_input_sgprs,
-                                 &shader->key.ge.part.gs.vs_prolog, shader, &vs_prolog_key);
-            vs_prolog_key.vs_prolog.is_monolithic = true;
-            si_llvm_build_vs_prolog(&ctx, &vs_prolog_key, false);
-            es_prolog = ctx.main_fn;
-         }
-
          /* Reset the shader context. */
          ctx.shader = shader;
          ctx.stage = MESA_SHADER_GEOMETRY;
 
          /* Prepare the array of shader parts. */
-         struct ac_llvm_pointer parts[4];
-         unsigned num_parts = 0, main_part;
-
-         if (es_prolog.value)
-            parts[num_parts++] = es_prolog;
-
-         parts[main_part = num_parts++] = es_main;
-         parts[num_parts++] = gs_main;
+         struct ac_llvm_pointer parts[2] = {es_main, gs_main};
 
-         si_build_wrapper_function(&ctx, parts, num_parts, main_part, main_part + 1, main_arg_types, false);
+         si_build_wrapper_function(&ctx, parts, 2, 0, 1, main_arg_types, false);
       } else {
          /* Nothing to do for gfx6-8. The shader has only 1 part and it's ctx.main_fn. */
       }
-- 
GitLab


From 33d37d57f3f8a606a67c9d6cee0bdb5f895611eb Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Mon, 20 Mar 2023 12:33:26 +0800
Subject: [PATCH 7/8] ac/llvm,radeonsi: remove abi->load_inputs implementation

No nir_load_input in VS now.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/llvm/ac_nir_to_llvm.c                 |   3 -
 src/amd/llvm/ac_shader_abi.h                  |   5 -
 .../drivers/radeonsi/si_shader_internal.h     |   1 -
 .../drivers/radeonsi/si_shader_llvm_vs.c      | 260 ------------------
 4 files changed, 269 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 5d3c8ad38143..e648b25c94a4 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -3324,9 +3324,6 @@ static LLVMValueRef visit_load(struct ac_nir_context *ctx, nir_intrinsic_instr *
    /* No indirect indexing is allowed after this point. */
    assert(!indir_index);
 
-   if (ctx->stage == MESA_SHADER_VERTEX && !is_output)
-      return ctx->abi->load_inputs(ctx->abi, base, component, count, 0, component_type);
-
    /* Other non-fragment cases have outputs in temporaries. */
    if (is_output && (ctx->stage == MESA_SHADER_VERTEX || ctx->stage == MESA_SHADER_TESS_EVAL)) {
       assert(is_output);
diff --git a/src/amd/llvm/ac_shader_abi.h b/src/amd/llvm/ac_shader_abi.h
index ee56be083952..5a9494c094c3 100644
--- a/src/amd/llvm/ac_shader_abi.h
+++ b/src/amd/llvm/ac_shader_abi.h
@@ -66,11 +66,6 @@ struct ac_shader_abi {
    void (*emit_vertex_with_counter)(struct ac_shader_abi *abi, unsigned stream,
                                     LLVMValueRef vertexidx, LLVMValueRef *addrs);
 
-   LLVMValueRef (*load_inputs)(struct ac_shader_abi *abi,
-                               unsigned driver_location, unsigned component,
-                               unsigned num_components, unsigned vertex_index,
-                               LLVMTypeRef type);
-
    LLVMValueRef (*load_tess_varyings)(struct ac_shader_abi *abi, LLVMTypeRef type,
                                       LLVMValueRef vertex_index, LLVMValueRef param_index,
                                       unsigned driver_location, unsigned component,
diff --git a/src/gallium/drivers/radeonsi/si_shader_internal.h b/src/gallium/drivers/radeonsi/si_shader_internal.h
index c28e559b779e..979ce1cae347 100644
--- a/src/gallium/drivers/radeonsi/si_shader_internal.h
+++ b/src/gallium/drivers/radeonsi/si_shader_internal.h
@@ -238,6 +238,5 @@ void si_llvm_ps_build_end(struct si_shader_context *ctx);
 /* si_shader_llvm_vs.c */
 void si_llvm_build_vs_prolog(struct si_shader_context *ctx, union si_shader_part_key *key,
                              bool separate_prolog);
-void si_llvm_init_vs_callbacks(struct si_shader_context *ctx);
 
 #endif
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm_vs.c b/src/gallium/drivers/radeonsi/si_shader_llvm_vs.c
index bb5fb2d27615..96e297b5a021 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm_vs.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm_vs.c
@@ -28,17 +28,6 @@
 #include "util/u_memory.h"
 #include "ac_nir.h"
 
-static LLVMValueRef unpack_sint16(struct si_shader_context *ctx, LLVMValueRef i32, unsigned index)
-{
-   assert(index <= 1);
-
-   if (index == 1)
-      return LLVMBuildAShr(ctx->ac.builder, i32, LLVMConstInt(ctx->ac.i32, 16, 0), "");
-
-   return LLVMBuildSExt(ctx->ac.builder, LLVMBuildTrunc(ctx->ac.builder, i32, ctx->ac.i16, ""),
-                        ctx->ac.i32, "");
-}
-
 static LLVMValueRef get_vertex_index(struct si_shader_context *ctx,
                                      struct si_vs_prolog_bits *key, unsigned input_index,
                                      LLVMValueRef instance_divisor_constbuf,
@@ -86,250 +75,6 @@ static LLVMValueRef get_vertex_index(struct si_shader_context *ctx,
    return index;
 }
 
-static void load_input_vs(struct si_shader_context *ctx, unsigned input_index, LLVMValueRef out[4])
-{
-   const struct si_shader_info *info = &ctx->shader->selector->info;
-   unsigned vs_blit_property = info->base.vs.blit_sgprs_amd;
-
-   if (vs_blit_property) {
-      LLVMValueRef vertex_id = ctx->abi.vertex_id;
-      LLVMValueRef sel_x1 =
-         LLVMBuildICmp(ctx->ac.builder, LLVMIntULE, vertex_id, ctx->ac.i32_1, "");
-      /* Use LLVMIntNE, because we have 3 vertices and only
-       * the middle one should use y2.
-       */
-      LLVMValueRef sel_y1 = LLVMBuildICmp(ctx->ac.builder, LLVMIntNE, vertex_id, ctx->ac.i32_1, "");
-
-      unsigned param_vs_blit_inputs = ctx->args->vs_blit_inputs.arg_index;
-      if (input_index == 0) {
-         /* Position: */
-         LLVMValueRef x1y1 = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs);
-         LLVMValueRef x2y2 = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs + 1);
-
-         LLVMValueRef x1 = unpack_sint16(ctx, x1y1, 0);
-         LLVMValueRef y1 = unpack_sint16(ctx, x1y1, 1);
-         LLVMValueRef x2 = unpack_sint16(ctx, x2y2, 0);
-         LLVMValueRef y2 = unpack_sint16(ctx, x2y2, 1);
-
-         LLVMValueRef x = LLVMBuildSelect(ctx->ac.builder, sel_x1, x1, x2, "");
-         LLVMValueRef y = LLVMBuildSelect(ctx->ac.builder, sel_y1, y1, y2, "");
-
-         out[0] = LLVMBuildSIToFP(ctx->ac.builder, x, ctx->ac.f32, "");
-         out[1] = LLVMBuildSIToFP(ctx->ac.builder, y, ctx->ac.f32, "");
-         out[2] = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs + 2);
-         out[3] = ctx->ac.f32_1;
-         return;
-      }
-
-      /* Color or texture coordinates: */
-      assert(input_index == 1);
-
-      if (vs_blit_property == SI_VS_BLIT_SGPRS_POS_COLOR) {
-         for (int i = 0; i < 4; i++) {
-            out[i] = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs + 3 + i);
-         }
-      } else {
-         assert(vs_blit_property == SI_VS_BLIT_SGPRS_POS_TEXCOORD);
-         LLVMValueRef x1 = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs + 3);
-         LLVMValueRef y1 = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs + 4);
-         LLVMValueRef x2 = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs + 5);
-         LLVMValueRef y2 = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs + 6);
-
-         out[0] = LLVMBuildSelect(ctx->ac.builder, sel_x1, x1, x2, "");
-         out[1] = LLVMBuildSelect(ctx->ac.builder, sel_y1, y1, y2, "");
-         out[2] = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs + 7);
-         out[3] = LLVMGetParam(ctx->main_fn.value, param_vs_blit_inputs + 8);
-      }
-      return;
-   }
-
-   /* Set can_speculate=false to help keep all loads grouped together
-    * for better latency hiding. If it was true, LLVM could move the loads forward
-    * and accidentally double memory latency by doing:
-    *
-    *    buffer_load_dword_xyzw
-    *    s_waitcnt vmcnt(0)
-    *    buffer_load_dword_xyzw
-    *    s_waitcnt vmcnt(0)
-    *
-    * ... which is what we must prevent at all cost.
-    */
-   const bool can_speculate = false;
-   unsigned bit_size = info->input[input_index].fp16_lo_hi_valid & 0x1 ? 16 : 32;
-   LLVMTypeRef int_type = bit_size == 16 ? ctx->ac.i16 : ctx->ac.i32;
-   LLVMTypeRef float_type = bit_size == 16 ? ctx->ac.f16 : ctx->ac.f32;
-   unsigned num_vbos_in_user_sgprs = ctx->shader->selector->info.num_vbos_in_user_sgprs;
-   union si_vs_fix_fetch fix_fetch;
-   LLVMValueRef vb_desc;
-   LLVMValueRef vertex_index = NULL;
-   LLVMValueRef tmp;
-
-   if (input_index < num_vbos_in_user_sgprs) {
-      vb_desc = ac_get_arg(&ctx->ac, ctx->args->vb_descriptors[input_index]);
-   } else {
-      unsigned index = input_index - num_vbos_in_user_sgprs;
-      vb_desc = ac_build_load_to_sgpr(
-         &ctx->ac, ac_get_ptr_arg(&ctx->ac, &ctx->args->ac, ctx->args->ac.vertex_buffers),
-         LLVMConstInt(ctx->ac.i32, index, 0));
-   }
-
-   if (ctx->abi.vertex_id_replaced) {
-      /* Only ngg culling will replace vertex_id, and ngg culling is an optimization key
-       * field, so the shader must be monolithic.
-       */
-      assert(ctx->shader->is_monolithic);
-      assert(ctx->abi.instance_id_replaced);
-
-      vertex_index = get_vertex_index(ctx, &ctx->shader->key.ge.part.vs.prolog,
-                                      input_index, ctx->instance_divisor_constbuf,
-                                      ctx->args->ac.start_instance.arg_index,
-                                      ctx->args->ac.base_vertex.arg_index);
-   } else {
-      vertex_index = LLVMGetParam(ctx->main_fn.value,
-                                  ctx->args->vertex_index0.arg_index + input_index);
-   }
-
-   /* Use the open-coded implementation for all loads of doubles and
-    * of dword-sized data that needs fixups. We need to insert conversion
-    * code anyway, and the amd/common code does it for us.
-    */
-   bool opencode = ctx->shader->key.ge.mono.vs_fetch_opencode & (1 << input_index);
-   fix_fetch.bits = ctx->shader->key.ge.mono.vs_fix_fetch[input_index].bits;
-   if (opencode || (fix_fetch.u.log_size == 3 && fix_fetch.u.format == AC_FETCH_FORMAT_FLOAT) ||
-       (fix_fetch.u.log_size == 2)) {
-      tmp = ac_build_opencoded_load_format(&ctx->ac, fix_fetch.u.log_size,
-                                           fix_fetch.u.num_channels_m1 + 1, fix_fetch.u.format,
-                                           fix_fetch.u.reverse, !opencode, vb_desc, vertex_index,
-                                           ctx->ac.i32_0, ctx->ac.i32_0, 0, can_speculate);
-      for (unsigned i = 0; i < 4; ++i)
-         out[i] =
-            LLVMBuildExtractElement(ctx->ac.builder, tmp, LLVMConstInt(ctx->ac.i32, i, false), "");
-
-      if (bit_size == 16) {
-         if (fix_fetch.u.format == AC_FETCH_FORMAT_UINT ||
-             fix_fetch.u.format == AC_FETCH_FORMAT_SINT) {
-            for (unsigned i = 0; i < 4; i++)
-               out[i] = LLVMBuildTrunc(ctx->ac.builder, out[i], ctx->ac.i16, "");
-         } else {
-            for (unsigned i = 0; i < 4; i++) {
-               out[i] = ac_to_float(&ctx->ac, out[i]);
-               out[i] = LLVMBuildFPTrunc(ctx->ac.builder, out[i], ctx->ac.f16, "");
-            }
-         }
-      }
-      return;
-   }
-
-   unsigned required_channels = util_last_bit(info->input[input_index].usage_mask);
-   if (required_channels == 0) {
-      for (unsigned i = 0; i < 4; ++i)
-         out[i] = LLVMGetUndef(ctx->ac.f32);
-      return;
-   }
-
-   /* Do multiple loads for special formats. */
-   LLVMValueRef fetches[4];
-   unsigned num_fetches;
-   unsigned fetch_stride;
-   unsigned channels_per_fetch;
-
-   if (fix_fetch.u.log_size <= 1 && fix_fetch.u.num_channels_m1 == 2) {
-      num_fetches = MIN2(required_channels, 3);
-      fetch_stride = 1 << fix_fetch.u.log_size;
-      channels_per_fetch = 1;
-   } else {
-      num_fetches = 1;
-      fetch_stride = 0;
-      channels_per_fetch = required_channels;
-   }
-
-   for (unsigned i = 0; i < num_fetches; ++i) {
-      LLVMValueRef voffset = LLVMConstInt(ctx->ac.i32, fetch_stride * i, 0);
-      fetches[i] = ac_build_buffer_load_format(&ctx->ac, vb_desc, vertex_index, voffset,
-                                               channels_per_fetch, 0, can_speculate,
-                                               bit_size == 16, false);
-   }
-
-   if (num_fetches == 1 && channels_per_fetch > 1) {
-      LLVMValueRef fetch = fetches[0];
-      for (unsigned i = 0; i < channels_per_fetch; ++i) {
-         tmp = LLVMConstInt(ctx->ac.i32, i, false);
-         fetches[i] = LLVMBuildExtractElement(ctx->ac.builder, fetch, tmp, "");
-      }
-      num_fetches = channels_per_fetch;
-      channels_per_fetch = 1;
-   }
-
-   for (unsigned i = num_fetches; i < 4; ++i)
-      fetches[i] = LLVMGetUndef(float_type);
-
-   if (fix_fetch.u.log_size <= 1 && fix_fetch.u.num_channels_m1 == 2 && required_channels == 4) {
-      if (fix_fetch.u.format == AC_FETCH_FORMAT_UINT || fix_fetch.u.format == AC_FETCH_FORMAT_SINT)
-         fetches[3] = LLVMConstInt(int_type, 1, 0);
-      else
-         fetches[3] = LLVMConstReal(float_type, 1);
-   } else if (fix_fetch.u.log_size == 3 &&
-              (fix_fetch.u.format == AC_FETCH_FORMAT_SNORM ||
-               fix_fetch.u.format == AC_FETCH_FORMAT_SSCALED ||
-               fix_fetch.u.format == AC_FETCH_FORMAT_SINT) &&
-              required_channels == 4) {
-
-      /* For 2_10_10_10, the hardware returns an unsigned value;
-       * convert it to a signed one.
-       */
-      LLVMValueRef tmp = fetches[3];
-      LLVMValueRef c30 = LLVMConstInt(int_type, 30, 0);
-
-      /* First, recover the sign-extended signed integer value. */
-      if (fix_fetch.u.format == AC_FETCH_FORMAT_SSCALED)
-         tmp = LLVMBuildFPToUI(ctx->ac.builder, tmp, int_type, "");
-      else
-         tmp = ac_to_integer(&ctx->ac, tmp);
-
-      /* For the integer-like cases, do a natural sign extension.
-       *
-       * For the SNORM case, the values are 0.0, 0.333, 0.666, 1.0
-       * and happen to contain 0, 1, 2, 3 as the two LSBs of the
-       * exponent.
-       */
-      tmp = LLVMBuildShl(
-         ctx->ac.builder, tmp,
-         fix_fetch.u.format == AC_FETCH_FORMAT_SNORM ? LLVMConstInt(int_type, 7, 0) : c30, "");
-      tmp = LLVMBuildAShr(ctx->ac.builder, tmp, c30, "");
-
-      /* Convert back to the right type. */
-      if (fix_fetch.u.format == AC_FETCH_FORMAT_SNORM) {
-         LLVMValueRef clamp;
-         LLVMValueRef neg_one = LLVMConstReal(float_type, -1.0);
-         tmp = LLVMBuildSIToFP(ctx->ac.builder, tmp, float_type, "");
-         clamp = LLVMBuildFCmp(ctx->ac.builder, LLVMRealULT, tmp, neg_one, "");
-         tmp = LLVMBuildSelect(ctx->ac.builder, clamp, neg_one, tmp, "");
-      } else if (fix_fetch.u.format == AC_FETCH_FORMAT_SSCALED) {
-         tmp = LLVMBuildSIToFP(ctx->ac.builder, tmp, float_type, "");
-      }
-
-      fetches[3] = tmp;
-   }
-
-   for (unsigned i = 0; i < 4; ++i)
-      out[i] = ac_to_float(&ctx->ac, fetches[i]);
-}
-
-static LLVMValueRef si_load_vs_input(struct ac_shader_abi *abi, unsigned driver_location,
-                                     unsigned component, unsigned num_components,
-                                     unsigned vertex_index, LLVMTypeRef type)
-{
-   struct si_shader_context *ctx = si_shader_context_from_abi(abi);
-   LLVMValueRef values[4];
-
-   load_input_vs(ctx, driver_location, values);
-
-   for (unsigned i = 0; i < 4; i++)
-      values[i] = LLVMBuildBitCast(ctx->ac.builder, values[i], type, "");
-
-   return ac_build_varying_gather_values(&ctx->ac, values, num_components, component);
-}
-
 /**
  * Build the vertex shader prolog function.
  *
@@ -463,8 +208,3 @@ void si_llvm_build_vs_prolog(struct si_shader_context *ctx, union si_shader_part
 
    si_llvm_build_ret(ctx, ret);
 }
-
-void si_llvm_init_vs_callbacks(struct si_shader_context *ctx)
-{
-   ctx->abi.load_inputs = si_load_vs_input;
-}
-- 
GitLab


From c1e637e602e2a9c23cf8df2db2b2cf454cec9305 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Mon, 20 Mar 2023 12:37:22 +0800
Subject: [PATCH 8/8] ac/llvm: remove ac_build_opencoded_load_format

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/llvm/ac_llvm_build.c | 291 -----------------------------------
 src/amd/llvm/ac_llvm_build.h |   7 -
 2 files changed, 298 deletions(-)

diff --git a/src/amd/llvm/ac_llvm_build.c b/src/amd/llvm/ac_llvm_build.c
index 85792da15cc2..3655a207a1d9 100644
--- a/src/amd/llvm/ac_llvm_build.c
+++ b/src/amd/llvm/ac_llvm_build.c
@@ -1523,297 +1523,6 @@ LLVMValueRef ac_build_buffer_load_byte(struct ac_llvm_context *ctx, LLVMValueRef
                                       false, false);
 }
 
-/**
- * Convert an 11- or 10-bit unsigned floating point number to an f32.
- *
- * The input exponent is expected to be biased analogous to IEEE-754, i.e. by
- * 2^(exp_bits-1) - 1 (as defined in OpenGL and other graphics APIs).
- */
-static LLVMValueRef ac_ufN_to_float(struct ac_llvm_context *ctx, LLVMValueRef src,
-                                    unsigned exp_bits, unsigned mant_bits)
-{
-   assert(LLVMTypeOf(src) == ctx->i32);
-
-   LLVMValueRef tmp;
-   LLVMValueRef mantissa;
-   mantissa =
-      LLVMBuildAnd(ctx->builder, src, LLVMConstInt(ctx->i32, (1 << mant_bits) - 1, false), "");
-
-   /* Converting normal numbers is just a shift + correcting the exponent bias */
-   unsigned normal_shift = 23 - mant_bits;
-   unsigned bias_shift = 127 - ((1 << (exp_bits - 1)) - 1);
-   LLVMValueRef shifted, normal;
-
-   shifted = LLVMBuildShl(ctx->builder, src, LLVMConstInt(ctx->i32, normal_shift, false), "");
-   normal =
-      LLVMBuildAdd(ctx->builder, shifted, LLVMConstInt(ctx->i32, bias_shift << 23, false), "");
-
-   /* Converting nan/inf numbers is the same, but with a different exponent update */
-   LLVMValueRef naninf;
-   naninf = LLVMBuildOr(ctx->builder, normal, LLVMConstInt(ctx->i32, 0xff << 23, false), "");
-
-   /* Converting denormals is the complex case: determine the leading zeros of the
-    * mantissa to obtain the correct shift for the mantissa and exponent correction.
-    */
-   LLVMValueRef denormal;
-   LLVMValueRef params[2] = {
-      mantissa, ctx->i1true, /* result can be undef when arg is 0 */
-   };
-   LLVMValueRef ctlz =
-      ac_build_intrinsic(ctx, "llvm.ctlz.i32", ctx->i32, params, 2, 0);
-
-   /* Shift such that the leading 1 ends up as the LSB of the exponent field. */
-   tmp = LLVMBuildSub(ctx->builder, ctlz, LLVMConstInt(ctx->i32, 8, false), "");
-   denormal = LLVMBuildShl(ctx->builder, mantissa, tmp, "");
-
-   unsigned denormal_exp = bias_shift + (32 - mant_bits) - 1;
-   tmp = LLVMBuildSub(ctx->builder, LLVMConstInt(ctx->i32, denormal_exp, false), ctlz, "");
-   tmp = LLVMBuildShl(ctx->builder, tmp, LLVMConstInt(ctx->i32, 23, false), "");
-   denormal = LLVMBuildAdd(ctx->builder, denormal, tmp, "");
-
-   /* Select the final result. */
-   LLVMValueRef result;
-
-   tmp = LLVMBuildICmp(ctx->builder, LLVMIntUGE, src,
-                       LLVMConstInt(ctx->i32, ((1ULL << exp_bits) - 1) << mant_bits, false), "");
-   result = LLVMBuildSelect(ctx->builder, tmp, naninf, normal, "");
-
-   tmp = LLVMBuildICmp(ctx->builder, LLVMIntUGE, src,
-                       LLVMConstInt(ctx->i32, 1ULL << mant_bits, false), "");
-   result = LLVMBuildSelect(ctx->builder, tmp, result, denormal, "");
-
-   tmp = LLVMBuildICmp(ctx->builder, LLVMIntNE, src, ctx->i32_0, "");
-   result = LLVMBuildSelect(ctx->builder, tmp, result, ctx->i32_0, "");
-
-   return ac_to_float(ctx, result);
-}
-
-/**
- * Generate a fully general open coded buffer format fetch with all required
- * fixups suitable for vertex fetch, using non-format buffer loads.
- *
- * Some combinations of argument values have special interpretations:
- * - size = 8 bytes, format = fixed indicates PIPE_FORMAT_R11G11B10_FLOAT
- * - size = 8 bytes, format != {float,fixed} indicates a 2_10_10_10 data format
- *
- * \param log_size log(size of channel in bytes)
- * \param num_channels number of channels (1 to 4)
- * \param format AC_FETCH_FORMAT_xxx value
- * \param reverse whether XYZ channels are reversed
- * \param known_aligned whether the source is known to be aligned to hardware's
- *                      effective element size for loading the given format
- *                      (note: this means dword alignment for 8_8_8_8, 16_16, etc.)
- * \param rsrc buffer resource descriptor
- * \return the resulting vector of floats or integers bitcast to <4 x i32>
- */
-LLVMValueRef ac_build_opencoded_load_format(struct ac_llvm_context *ctx, unsigned log_size,
-                                            unsigned num_channels, unsigned format, bool reverse,
-                                            bool known_aligned, LLVMValueRef rsrc,
-                                            LLVMValueRef vindex, LLVMValueRef voffset,
-                                            LLVMValueRef soffset, unsigned cache_policy,
-                                            bool can_speculate)
-{
-   LLVMValueRef tmp;
-   unsigned load_log_size = log_size;
-   unsigned load_num_channels = num_channels;
-   if (log_size == 3) {
-      load_log_size = 2;
-      if (format == AC_FETCH_FORMAT_FLOAT) {
-         load_num_channels = 2 * num_channels;
-      } else {
-         load_num_channels = 1; /* 10_11_11 or 2_10_10_10 */
-      }
-   }
-
-   int log_recombine = 0;
-   if ((ctx->gfx_level == GFX6 || ctx->gfx_level >= GFX10) && !known_aligned) {
-      /* Avoid alignment restrictions by loading one byte at a time. */
-      load_num_channels <<= load_log_size;
-      log_recombine = load_log_size;
-      load_log_size = 0;
-   } else if (load_num_channels == 2 || load_num_channels == 4) {
-      log_recombine = -util_logbase2(load_num_channels);
-      load_num_channels = 1;
-      load_log_size += -log_recombine;
-   }
-
-   LLVMValueRef loads[32]; /* up to 32 bytes */
-   for (unsigned i = 0; i < load_num_channels; ++i) {
-      tmp =
-         LLVMBuildAdd(ctx->builder, soffset, LLVMConstInt(ctx->i32, i << load_log_size, false), "");
-      LLVMTypeRef channel_type =
-         load_log_size == 0 ? ctx->i8 : load_log_size == 1 ? ctx->i16 : ctx->i32;
-      unsigned num_channels = 1 << (MAX2(load_log_size, 2) - 2);
-      loads[i] =
-         ac_build_buffer_load_common(ctx, rsrc, vindex, voffset, tmp, num_channels, channel_type,
-                                     cache_policy, can_speculate, false);
-      if (load_log_size >= 2)
-         loads[i] = ac_to_integer(ctx, loads[i]);
-   }
-
-   if (log_recombine > 0) {
-      /* Recombine bytes if necessary (GFX6 only) */
-      LLVMTypeRef dst_type = log_recombine == 2 ? ctx->i32 : ctx->i16;
-
-      for (unsigned src = 0, dst = 0; src < load_num_channels; ++dst) {
-         LLVMValueRef accum = NULL;
-         for (unsigned i = 0; i < (1 << log_recombine); ++i, ++src) {
-            tmp = LLVMBuildZExt(ctx->builder, loads[src], dst_type, "");
-            if (i == 0) {
-               accum = tmp;
-            } else {
-               tmp = LLVMBuildShl(ctx->builder, tmp, LLVMConstInt(dst_type, 8 * i, false), "");
-               accum = LLVMBuildOr(ctx->builder, accum, tmp, "");
-            }
-         }
-         loads[dst] = accum;
-      }
-   } else if (log_recombine < 0) {
-      /* Split vectors of dwords */
-      if (load_log_size > 2) {
-         assert(load_num_channels == 1);
-         LLVMValueRef loaded = loads[0];
-         unsigned log_split = load_log_size - 2;
-         log_recombine += log_split;
-         load_num_channels = 1 << log_split;
-         load_log_size = 2;
-         for (unsigned i = 0; i < load_num_channels; ++i) {
-            tmp = LLVMConstInt(ctx->i32, i, false);
-            loads[i] = LLVMBuildExtractElement(ctx->builder, loaded, tmp, "");
-         }
-      }
-
-      /* Further split dwords and shorts if required */
-      if (log_recombine < 0) {
-         for (unsigned src = load_num_channels, dst = load_num_channels << -log_recombine; src > 0;
-              --src) {
-            unsigned dst_bits = 1 << (3 + load_log_size + log_recombine);
-            LLVMTypeRef dst_type = LLVMIntTypeInContext(ctx->context, dst_bits);
-            LLVMValueRef loaded = loads[src - 1];
-            LLVMTypeRef loaded_type = LLVMTypeOf(loaded);
-            for (unsigned i = 1 << -log_recombine; i > 0; --i, --dst) {
-               tmp = LLVMConstInt(loaded_type, dst_bits * (i - 1), false);
-               tmp = LLVMBuildLShr(ctx->builder, loaded, tmp, "");
-               loads[dst - 1] = LLVMBuildTrunc(ctx->builder, tmp, dst_type, "");
-            }
-         }
-      }
-   }
-
-   if (log_size == 3) {
-      if (format == AC_FETCH_FORMAT_FLOAT) {
-         for (unsigned i = 0; i < num_channels; ++i) {
-            tmp = ac_build_gather_values(ctx, &loads[2 * i], 2);
-            loads[i] = LLVMBuildBitCast(ctx->builder, tmp, ctx->f64, "");
-         }
-      } else if (format == AC_FETCH_FORMAT_FIXED) {
-         /* 10_11_11_FLOAT */
-         LLVMValueRef data = loads[0];
-         LLVMValueRef i32_2047 = LLVMConstInt(ctx->i32, 2047, false);
-         LLVMValueRef r = LLVMBuildAnd(ctx->builder, data, i32_2047, "");
-         tmp = LLVMBuildLShr(ctx->builder, data, LLVMConstInt(ctx->i32, 11, false), "");
-         LLVMValueRef g = LLVMBuildAnd(ctx->builder, tmp, i32_2047, "");
-         LLVMValueRef b = LLVMBuildLShr(ctx->builder, data, LLVMConstInt(ctx->i32, 22, false), "");
-
-         loads[0] = ac_to_integer(ctx, ac_ufN_to_float(ctx, r, 5, 6));
-         loads[1] = ac_to_integer(ctx, ac_ufN_to_float(ctx, g, 5, 6));
-         loads[2] = ac_to_integer(ctx, ac_ufN_to_float(ctx, b, 5, 5));
-
-         num_channels = 3;
-         log_size = 2;
-         format = AC_FETCH_FORMAT_FLOAT;
-      } else {
-         /* 2_10_10_10 data formats */
-         LLVMValueRef data = loads[0];
-         LLVMTypeRef i10 = LLVMIntTypeInContext(ctx->context, 10);
-         LLVMTypeRef i2 = LLVMIntTypeInContext(ctx->context, 2);
-         loads[0] = LLVMBuildTrunc(ctx->builder, data, i10, "");
-         tmp = LLVMBuildLShr(ctx->builder, data, LLVMConstInt(ctx->i32, 10, false), "");
-         loads[1] = LLVMBuildTrunc(ctx->builder, tmp, i10, "");
-         tmp = LLVMBuildLShr(ctx->builder, data, LLVMConstInt(ctx->i32, 20, false), "");
-         loads[2] = LLVMBuildTrunc(ctx->builder, tmp, i10, "");
-         tmp = LLVMBuildLShr(ctx->builder, data, LLVMConstInt(ctx->i32, 30, false), "");
-         loads[3] = LLVMBuildTrunc(ctx->builder, tmp, i2, "");
-
-         num_channels = 4;
-      }
-   }
-
-   if (format == AC_FETCH_FORMAT_FLOAT) {
-      if (log_size != 2) {
-         for (unsigned chan = 0; chan < num_channels; ++chan) {
-            tmp = ac_to_float(ctx, loads[chan]);
-            if (log_size == 3)
-               tmp = LLVMBuildFPTrunc(ctx->builder, tmp, ctx->f32, "");
-            else if (log_size == 1)
-               tmp = LLVMBuildFPExt(ctx->builder, tmp, ctx->f32, "");
-            loads[chan] = ac_to_integer(ctx, tmp);
-         }
-      }
-   } else if (format == AC_FETCH_FORMAT_UINT) {
-      if (log_size != 2) {
-         for (unsigned chan = 0; chan < num_channels; ++chan)
-            loads[chan] = LLVMBuildZExt(ctx->builder, loads[chan], ctx->i32, "");
-      }
-   } else if (format == AC_FETCH_FORMAT_SINT) {
-      if (log_size != 2) {
-         for (unsigned chan = 0; chan < num_channels; ++chan)
-            loads[chan] = LLVMBuildSExt(ctx->builder, loads[chan], ctx->i32, "");
-      }
-   } else {
-      bool unsign = format == AC_FETCH_FORMAT_UNORM || format == AC_FETCH_FORMAT_USCALED ||
-                    format == AC_FETCH_FORMAT_UINT;
-
-      for (unsigned chan = 0; chan < num_channels; ++chan) {
-         if (unsign) {
-            tmp = LLVMBuildUIToFP(ctx->builder, loads[chan], ctx->f32, "");
-         } else {
-            tmp = LLVMBuildSIToFP(ctx->builder, loads[chan], ctx->f32, "");
-         }
-
-         LLVMValueRef scale = NULL;
-         if (format == AC_FETCH_FORMAT_FIXED) {
-            assert(log_size == 2);
-            scale = LLVMConstReal(ctx->f32, 1.0 / 0x10000);
-         } else if (format == AC_FETCH_FORMAT_UNORM) {
-            unsigned bits = LLVMGetIntTypeWidth(LLVMTypeOf(loads[chan]));
-            scale = LLVMConstReal(ctx->f32, 1.0 / (((uint64_t)1 << bits) - 1));
-         } else if (format == AC_FETCH_FORMAT_SNORM) {
-            unsigned bits = LLVMGetIntTypeWidth(LLVMTypeOf(loads[chan]));
-            scale = LLVMConstReal(ctx->f32, 1.0 / (((uint64_t)1 << (bits - 1)) - 1));
-         }
-         if (scale)
-            tmp = LLVMBuildFMul(ctx->builder, tmp, scale, "");
-
-         if (format == AC_FETCH_FORMAT_SNORM) {
-            /* Clamp to [-1, 1] */
-            LLVMValueRef neg_one = LLVMConstReal(ctx->f32, -1.0);
-            LLVMValueRef clamp = LLVMBuildFCmp(ctx->builder, LLVMRealULT, tmp, neg_one, "");
-            tmp = LLVMBuildSelect(ctx->builder, clamp, neg_one, tmp, "");
-         }
-
-         loads[chan] = ac_to_integer(ctx, tmp);
-      }
-   }
-
-   while (num_channels < 4) {
-      if (format == AC_FETCH_FORMAT_UINT || format == AC_FETCH_FORMAT_SINT) {
-         loads[num_channels] = num_channels == 3 ? ctx->i32_1 : ctx->i32_0;
-      } else {
-         loads[num_channels] = ac_to_integer(ctx, num_channels == 3 ? ctx->f32_1 : ctx->f32_0);
-      }
-      num_channels++;
-   }
-
-   if (reverse) {
-      tmp = loads[0];
-      loads[0] = loads[2];
-      loads[2] = tmp;
-   }
-
-   return ac_build_gather_values(ctx, loads, 4);
-}
-
 void ac_build_buffer_store_short(struct ac_llvm_context *ctx, LLVMValueRef rsrc,
                                  LLVMValueRef vdata, LLVMValueRef voffset, LLVMValueRef soffset,
                                  unsigned cache_policy)
diff --git a/src/amd/llvm/ac_llvm_build.h b/src/amd/llvm/ac_llvm_build.h
index 197a30bb1543..6c3e96674045 100644
--- a/src/amd/llvm/ac_llvm_build.h
+++ b/src/amd/llvm/ac_llvm_build.h
@@ -315,13 +315,6 @@ LLVMValueRef ac_build_safe_tbuffer_load(struct ac_llvm_context *ctx, LLVMValueRe
                                         unsigned cache_policy,
                                         bool can_speculate);
 
-LLVMValueRef ac_build_opencoded_load_format(struct ac_llvm_context *ctx, unsigned log_size,
-                                            unsigned num_channels, unsigned format, bool reverse,
-                                            bool known_aligned, LLVMValueRef rsrc,
-                                            LLVMValueRef vindex, LLVMValueRef voffset,
-                                            LLVMValueRef soffset, unsigned cache_policy,
-                                            bool can_speculate);
-
 void ac_build_buffer_store_short(struct ac_llvm_context *ctx, LLVMValueRef rsrc,
                                  LLVMValueRef vdata, LLVMValueRef voffset, LLVMValueRef soffset,
                                  unsigned cache_policy);
-- 
GitLab

