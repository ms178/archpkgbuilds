From ff5cfec20a78cde45e8abbaf30e69ba371839775 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Thu, 1 Dec 2022 20:22:16 +0000
Subject: [PATCH 1/4] nir/range_analysis: unsigned upper bound analysis for b2i

fossil-db (navi21):
Totals from 93 (0.07% of 135636) affected shaders:
Instrs: 133949 -> 133899 (-0.04%); split: -0.05%, +0.01%
CodeSize: 708124 -> 707528 (-0.08%); split: -0.09%, +0.01%
Latency: 2451564 -> 2450158 (-0.06%); split: -0.06%, +0.00%
InvThroughput: 398282 -> 397345 (-0.24%)
SClause: 4441 -> 4437 (-0.09%); split: -0.18%, +0.09%
Copies: 7578 -> 7546 (-0.42%); split: -0.55%, +0.13%

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/compiler/nir/nir_range_analysis.c | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/src/compiler/nir/nir_range_analysis.c b/src/compiler/nir/nir_range_analysis.c
index 56fd3f092363..7770bcf51ccf 100644
--- a/src/compiler/nir/nir_range_analysis.c
+++ b/src/compiler/nir/nir_range_analysis.c
@@ -1526,6 +1526,9 @@ nir_unsigned_upper_bound(nir_shader *shader, struct hash_table *range_ht,
       case nir_op_extract_i8:
       case nir_op_extract_u16:
       case nir_op_extract_i16:
+      case nir_op_b2i8:
+      case nir_op_b2i16:
+      case nir_op_b2i32:
          break;
       case nir_op_u2u1:
       case nir_op_u2u8:
@@ -1657,6 +1660,11 @@ nir_unsigned_upper_bound(nir_shader *shader, struct hash_table *range_ht,
       case nir_op_u2u32:
          res = MIN2(src0, max);
          break;
+      case nir_op_b2i8:
+      case nir_op_b2i16:
+      case nir_op_b2i32:
+         res = 1;
+         break;
       case nir_op_sad_u8x4:
          res = src2 + 4 * 255;
          break;
-- 
GitLab


From 5fabc9cf66c359c141319e9e2a39937788a3996b Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Thu, 1 Dec 2022 20:26:52 +0000
Subject: [PATCH 2/4] radv: set additions for scratch access as NUW

No fossil-db changes.

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/vulkan/radv_rt_shader.c | 12 +++++++-----
 1 file changed, 7 insertions(+), 5 deletions(-)

diff --git a/src/amd/vulkan/radv_rt_shader.c b/src/amd/vulkan/radv_rt_shader.c
index acf529eca864..bde520ef52db 100644
--- a/src/amd/vulkan/radv_rt_shader.c
+++ b/src/amd/vulkan/radv_rt_shader.c
@@ -342,7 +342,7 @@ lower_rt_instructions(nir_shader *shader, struct rt_variables *vars, unsigned ca
 
                nir_store_var(
                   &b_shader, vars->stack_ptr,
-                  nir_iadd_imm(&b_shader, nir_load_var(&b_shader, vars->stack_ptr), size), 1);
+                  nir_iadd_imm_nuw(&b_shader, nir_load_var(&b_shader, vars->stack_ptr), size), 1);
                nir_store_scratch(&b_shader, nir_imm_int(&b_shader, ret_idx),
                                  nir_load_var(&b_shader, vars->stack_ptr), .align_mul = 16);
 
@@ -363,7 +363,7 @@ lower_rt_instructions(nir_shader *shader, struct rt_variables *vars, unsigned ca
 
                nir_store_var(
                   &b_shader, vars->stack_ptr,
-                  nir_iadd_imm(&b_shader, nir_load_var(&b_shader, vars->stack_ptr), size), 1);
+                  nir_iadd_imm_nuw(&b_shader, nir_load_var(&b_shader, vars->stack_ptr), size), 1);
                nir_store_scratch(&b_shader, nir_imm_int(&b_shader, ret_idx),
                                  nir_load_var(&b_shader, vars->stack_ptr), .align_mul = 16);
 
@@ -413,13 +413,15 @@ lower_rt_instructions(nir_shader *shader, struct rt_variables *vars, unsigned ca
             case nir_intrinsic_load_scratch: {
                nir_instr_rewrite_src_ssa(
                   instr, &intr->src[0],
-                  nir_iadd(&b_shader, nir_load_var(&b_shader, vars->stack_ptr), intr->src[0].ssa));
+                  nir_iadd_nuw(&b_shader, nir_load_var(&b_shader, vars->stack_ptr),
+                               intr->src[0].ssa));
                continue;
             }
             case nir_intrinsic_store_scratch: {
                nir_instr_rewrite_src_ssa(
                   instr, &intr->src[1],
-                  nir_iadd(&b_shader, nir_load_var(&b_shader, vars->stack_ptr), intr->src[1].ssa));
+                  nir_iadd_nuw(&b_shader, nir_load_var(&b_shader, vars->stack_ptr),
+                               intr->src[1].ssa));
                continue;
             }
             case nir_intrinsic_load_rt_arg_scratch_offset_amd: {
@@ -1022,7 +1024,7 @@ handle_candidate_triangle(nir_builder *b, struct radv_triangle_intersection *int
       nir_bcsel(b, intersection->frontface, nir_imm_int(b, 0xFE), nir_imm_int(b, 0xFF));
 
    nir_ssa_def *barycentrics_addr =
-      nir_iadd_imm(b, nir_load_var(b, data->vars->stack_ptr), RADV_HIT_ATTRIB_OFFSET);
+      nir_iadd_imm_nuw(b, nir_load_var(b, data->vars->stack_ptr), RADV_HIT_ATTRIB_OFFSET);
    nir_ssa_def *prev_barycentrics = nir_load_scratch(b, 2, 32, barycentrics_addr, .align_mul = 16);
    nir_store_scratch(b, intersection->barycentrics, barycentrics_addr, .align_mul = 16);
 
-- 
GitLab


From d1a32327df98ffd5a0f377664b63afd668ef5b5b Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Thu, 1 Dec 2022 15:05:49 +0000
Subject: [PATCH 3/4] aco: more carefully apply constant offsets into scratch
 accesses

Death stranding does scratch_arr[80-idx]. This doesn't seem to work if we
try to combine the subtraction into the access.

fossil-db (navi21):
Totals from 52 (0.04% of 135636) affected shaders:
Instrs: 78560 -> 79036 (+0.61%)
CodeSize: 427940 -> 431188 (+0.76%)
Latency: 1313809 -> 1318142 (+0.33%)
InvThroughput: 292833 -> 293842 (+0.34%)
VClause: 2361 -> 2555 (+8.22%); split: -0.51%, +8.73%
Copies: 8767 -> 8746 (-0.24%); split: -0.35%, +0.11%

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
Fixes: 0e783d687a3 ("aco: use scratch_* for scratch load/store on GFX9+")
Closes: https://gitlab.freedesktop.org/mesa/mesa/-/issues/7735
---
 src/amd/compiler/aco_optimizer.cpp | 23 +++++++++++++++++++----
 1 file changed, 19 insertions(+), 4 deletions(-)

diff --git a/src/amd/compiler/aco_optimizer.cpp b/src/amd/compiler/aco_optimizer.cpp
index 822ea9967fb3..bbceb18a070e 100644
--- a/src/amd/compiler/aco_optimizer.cpp
+++ b/src/amd/compiler/aco_optimizer.cpp
@@ -1255,12 +1255,14 @@ is_op_canonicalized(opt_ctx& ctx, Operand op)
 }
 
 bool
-is_scratch_offset_valid(opt_ctx& ctx, Instruction* instr, int32_t offset)
+is_scratch_offset_valid(opt_ctx& ctx, Instruction* instr, int64_t offset0, int64_t offset1)
 {
    bool negative_unaligned_scratch_offset_bug = ctx.program->gfx_level == GFX10;
    int32_t min = ctx.program->dev.scratch_global_offset_min;
    int32_t max = ctx.program->dev.scratch_global_offset_max;
 
+   int64_t offset = offset0 + offset1;
+
    bool has_vgpr_offset = instr && !instr->operands[0].isUndefined();
    if (negative_unaligned_scratch_offset_bug && has_vgpr_offset && offset < 0 && offset % 4)
       return false;
@@ -1467,15 +1469,28 @@ label_instruction(opt_ctx& ctx, aco_ptr<Instruction>& instr)
          while (info.is_temp())
             info = ctx.info[info.temp.id()];
 
-         if (i <= 1 && parse_base_offset(ctx, instr.get(), i, &base, &offset, false) &&
+         /* The hardware probably does: 'scratch_base + u2u64(saddr) + i2i64(offset)'. This means
+          * we can't combine the addition if the unsigned addition overflows and offset is
+          * positive. In theory, there is also issues if
+          * 'ilt(offset, 0) && ige(saddr, 0) && ilt(saddr + offset, 0)', but that just
+          * replaces an already out-of-bounds access with a larger one since 'saddr + offset'
+          * would be larger than INT32_MAX.
+          */
+         if (i <= 1 && parse_base_offset(ctx, instr.get(), i, &base, &offset, true) &&
              base.regClass() == instr->operands[i].regClass() &&
-             is_scratch_offset_valid(ctx, instr.get(), scratch.offset + (int32_t)offset)) {
+             is_scratch_offset_valid(ctx, instr.get(), scratch.offset, (int32_t)offset)) {
+            instr->operands[i].setTemp(base);
+            scratch.offset += (int32_t)offset;
+            continue;
+         } else if (i <= 1 && parse_base_offset(ctx, instr.get(), i, &base, &offset, false) &&
+                    base.regClass() == instr->operands[i].regClass() && (int32_t)offset < 0 &&
+                    is_scratch_offset_valid(ctx, instr.get(), scratch.offset, (int32_t)offset)) {
             instr->operands[i].setTemp(base);
             scratch.offset += (int32_t)offset;
             continue;
          } else if (i <= 1 && info.is_constant_or_literal(32) &&
                     ctx.program->gfx_level >= GFX10_3 &&
-                    is_scratch_offset_valid(ctx, NULL, scratch.offset + (int32_t)info.val)) {
+                    is_scratch_offset_valid(ctx, NULL, scratch.offset, (int32_t)info.val)) {
             /* GFX10.3+ can disable both SADDR and ADDR. */
             instr->operands[i] = Operand(instr->operands[i].regClass());
             scratch.offset += (int32_t)info.val;
-- 
GitLab


From 2677038669bf5cf490884b8e118a7a939d3b196c Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Thu, 1 Dec 2022 18:04:49 +0000
Subject: [PATCH 4/4] aco: apply NUW to additions for scratch access

fossil-db (navi21):
Totals from 52 (0.04% of 135636) affected shaders:
Instrs: 79036 -> 78567 (-0.59%)
CodeSize: 431188 -> 427984 (-0.74%)
Latency: 1318142 -> 1313821 (-0.33%)
InvThroughput: 293842 -> 292836 (-0.34%)
VClause: 2555 -> 2361 (-7.59%); split: -8.06%, +0.47%
Copies: 8746 -> 8767 (+0.24%); split: -0.11%, +0.35%

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/aco_instruction_selection.cpp       | 5 ++++-
 src/amd/compiler/aco_instruction_selection_setup.cpp | 2 ++
 2 files changed, 6 insertions(+), 1 deletion(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 7ee69c2f9554..1a5dfd78b800 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -1873,7 +1873,10 @@ visit_alu_instr(isel_context* ctx, nir_alu_instr* instr)
       Temp src0 = get_alu_src(ctx, instr->src[0]);
       Temp src1 = get_alu_src(ctx, instr->src[1]);
       if (dst.type() == RegType::vgpr && dst.bytes() <= 4) {
-         bld.vadd32(Definition(dst), Operand(src0), Operand(src1));
+         if (instr->no_unsigned_wrap)
+            bld.nuw().vadd32(Definition(dst), Operand(src0), Operand(src1));
+         else
+            bld.vadd32(Definition(dst), Operand(src0), Operand(src1));
          break;
       }
 
diff --git a/src/amd/compiler/aco_instruction_selection_setup.cpp b/src/amd/compiler/aco_instruction_selection_setup.cpp
index c7356e452e3d..12a6e5514fd5 100644
--- a/src/amd/compiler/aco_instruction_selection_setup.cpp
+++ b/src/amd/compiler/aco_instruction_selection_setup.cpp
@@ -231,6 +231,8 @@ apply_nuw_to_offsets(isel_context* ctx, nir_function_impl* impl)
             if (!nir_src_is_divergent(intrin->src[2]))
                apply_nuw_to_ssa(ctx, intrin->src[2].ssa);
             break;
+         case nir_intrinsic_load_scratch: apply_nuw_to_ssa(ctx, intrin->src[0].ssa); break;
+         case nir_intrinsic_store_scratch: apply_nuw_to_ssa(ctx, intrin->src[1].ssa); break;
          default: break;
          }
       }
-- 
GitLab

