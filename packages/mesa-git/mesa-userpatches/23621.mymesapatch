From bc77e2414fb4a68918f90d09b61866a9f229d89b Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Tue, 13 Jun 2023 12:35:34 +0100
Subject: [PATCH 1/5] nir/peephole_select: allow some invocation broadcast
 intrinsics

fossil-db (navi21):
Totals from 3 (0.00% of 133428) affected shaders:
Instrs: 2074 -> 2083 (+0.43%)
CodeSize: 10596 -> 10692 (+0.91%)
Latency: 75754 -> 75946 (+0.25%)
InvThroughput: 16900 -> 16975 (+0.44%)
Copies: 312 -> 309 (-0.96%)
Branches: 150 -> 132 (-12.00%)

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/compiler/nir/nir_opt_peephole_select.c | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/src/compiler/nir/nir_opt_peephole_select.c b/src/compiler/nir/nir_opt_peephole_select.c
index 5ec9a54df72c0..6d5107fadc69f 100644
--- a/src/compiler/nir/nir_opt_peephole_select.c
+++ b/src/compiler/nir/nir_opt_peephole_select.c
@@ -143,6 +143,14 @@ block_check_for_allowed_instrs(nir_block *block, unsigned *count,
          case nir_intrinsic_load_frag_shading_rate:
          case nir_intrinsic_is_sparse_texels_resident:
          case nir_intrinsic_sparse_residency_code_and:
+         case nir_intrinsic_read_invocation:
+         case nir_intrinsic_quad_broadcast:
+         case nir_intrinsic_quad_swap_horizontal:
+         case nir_intrinsic_quad_swap_vertical:
+         case nir_intrinsic_quad_swap_diagonal:
+         case nir_intrinsic_quad_swizzle_amd:
+         case nir_intrinsic_masked_swizzle_amd:
+         case nir_intrinsic_lane_permute_16_amd:
             if (!alu_ok)
                return false;
             break;
-- 
GitLab


From e6b649d562501671c744618777821f4c4cd3c08b Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Tue, 13 Jun 2023 15:25:08 +0100
Subject: [PATCH 2/5] aco: include helpers in emit_uniform_{reduce,scan}

Found by inspection.

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/aco_instruction_selection.cpp | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index c04b17321651c..26089ebe31620 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -7918,6 +7918,7 @@ emit_uniform_reduce(isel_context* ctx, nir_intrinsic_instr* instr)
 
       Temp thread_count =
          bld.sop1(Builder::s_bcnt1_i32, bld.def(s1), bld.def(s1, scc), Operand(exec, bld.lm));
+      thread_count = emit_wqm(bld, thread_count);
 
       emit_addition_uniform_reduce(ctx, op, dst, instr->src[0], thread_count);
    } else {
@@ -7947,6 +7948,7 @@ emit_uniform_scan(isel_context* ctx, nir_intrinsic_instr* instr)
          packed_tid = emit_mbcnt(ctx, bld.tmp(v1), Operand(exec, bld.lm), Operand::c32(1u));
       else
          packed_tid = emit_mbcnt(ctx, bld.tmp(v1), Operand(exec, bld.lm));
+      packed_tid = emit_wqm(bld, packed_tid);
 
       emit_addition_uniform_reduce(ctx, op, dst, instr->src[0], packed_tid);
       return true;
-- 
GitLab


From 03b199d860c319a9e0550aa58cf86f536fc7a310 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Tue, 13 Jun 2023 15:27:26 +0100
Subject: [PATCH 3/5] nir,aco: add INCLUDE_HELPERS index to reduce intrinsic

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/aco_instruction_selection.cpp | 8 +++++---
 src/compiler/nir/nir_intrinsics.py             | 5 ++++-
 2 files changed, 9 insertions(+), 4 deletions(-)

diff --git a/src/amd/compiler/aco_instruction_selection.cpp b/src/amd/compiler/aco_instruction_selection.cpp
index 26089ebe31620..e1890ee7e40bc 100644
--- a/src/amd/compiler/aco_instruction_selection.cpp
+++ b/src/amd/compiler/aco_instruction_selection.cpp
@@ -7918,7 +7918,7 @@ emit_uniform_reduce(isel_context* ctx, nir_intrinsic_instr* instr)
 
       Temp thread_count =
          bld.sop1(Builder::s_bcnt1_i32, bld.def(s1), bld.def(s1, scc), Operand(exec, bld.lm));
-      thread_count = emit_wqm(bld, thread_count);
+      thread_count = emit_wqm(bld, thread_count, Temp(0, s1), nir_intrinsic_include_helpers(instr));
 
       emit_addition_uniform_reduce(ctx, op, dst, instr->src[0], thread_count);
    } else {
@@ -8548,6 +8548,8 @@ visit_intrinsic(isel_context* ctx, nir_intrinsic_instr* instr)
          instr->intrinsic == nir_intrinsic_reduce ? nir_intrinsic_cluster_size(instr) : 0;
       cluster_size = util_next_power_of_two(
          MIN2(cluster_size ? cluster_size : ctx->program->wave_size, ctx->program->wave_size));
+      bool create_helpers =
+         instr->intrinsic == nir_intrinsic_reduce && nir_intrinsic_include_helpers(instr);
 
       if (!nir_src_is_divergent(instr->src[0]) && cluster_size == ctx->program->wave_size &&
           instr->dest.ssa.bit_size != 1) {
@@ -8577,7 +8579,7 @@ visit_intrinsic(isel_context* ctx, nir_intrinsic_instr* instr)
 
          switch (instr->intrinsic) {
          case nir_intrinsic_reduce:
-            emit_wqm(bld, emit_boolean_reduce(ctx, op, cluster_size, src), dst);
+            emit_wqm(bld, emit_boolean_reduce(ctx, op, cluster_size, src), dst, create_helpers);
             break;
          case nir_intrinsic_exclusive_scan:
             emit_wqm(bld, emit_boolean_exclusive_scan(ctx, op, src), dst);
@@ -8606,7 +8608,7 @@ visit_intrinsic(isel_context* ctx, nir_intrinsic_instr* instr)
 
          Temp tmp_dst = emit_reduction_instr(ctx, aco_op, reduce_op, cluster_size,
                                              bld.def(dst.regClass()), src);
-         emit_wqm(bld, tmp_dst, dst);
+         emit_wqm(bld, tmp_dst, dst, create_helpers);
       }
       break;
    }
diff --git a/src/compiler/nir/nir_intrinsics.py b/src/compiler/nir/nir_intrinsics.py
index c5b5193ed7cfa..128651949aabb 100644
--- a/src/compiler/nir/nir_intrinsics.py
+++ b/src/compiler/nir/nir_intrinsics.py
@@ -172,6 +172,9 @@ index("unsigned", "reduction_op")
 # Cluster size for reduction operations
 index("unsigned", "cluster_size")
 
+# Requires that the operation creates and includes helper invocations
+index("bool", "include_helpers")
+
 # Parameter index for a load_param intrinsic
 index("unsigned", "param_idx")
 
@@ -467,7 +470,7 @@ intrinsic("rotate", src_comp=[0, 1], dest_comp=0, bit_sizes=src0,
           indices=[EXECUTION_SCOPE, CLUSTER_SIZE], flags=[CAN_ELIMINATE]);
 
 intrinsic("reduce", src_comp=[0], dest_comp=0, bit_sizes=src0,
-          indices=[REDUCTION_OP, CLUSTER_SIZE], flags=[CAN_ELIMINATE])
+          indices=[REDUCTION_OP, CLUSTER_SIZE, INCLUDE_HELPERS], flags=[CAN_ELIMINATE])
 intrinsic("inclusive_scan", src_comp=[0], dest_comp=0, bit_sizes=src0,
           indices=[REDUCTION_OP], flags=[CAN_ELIMINATE])
 intrinsic("exclusive_scan", src_comp=[0], dest_comp=0, bit_sizes=src0,
-- 
GitLab


From a708b599b54c7f9441d51ace80c7bc934cafe4fb Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Tue, 13 Jun 2023 14:07:53 +0100
Subject: [PATCH 4/5] nir/opt_intrinsic: optimize quad vote

Optimizes a quadAll()/quadAny() pattern created by dxil-spirv:
https://github.com/HansKristian-Work/dxil-spirv/commit/7adc87d4deaba8078bcdef8dfbebdda0165cd7bc

dxil-spirv can't use clustered reductions because they are not guaranteed
to include helper invocations.

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/compiler/nir/nir.h                |   6 ++
 src/compiler/nir/nir_opt_intrinsics.c | 132 +++++++++++++++++++++++++-
 2 files changed, 135 insertions(+), 3 deletions(-)

diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index a116011f2912b..4bae80ea057e8 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -3665,6 +3665,12 @@ typedef struct nir_shader_compiler_options {
     */
    bool optimize_sample_mask_in;
 
+   /**
+    * Optimize boolean reductions of quad broadcasts. This should only be enabled if
+    * nir_intrinsic_reduce supports INCLUDE_HELPERS.
+    */
+   bool optimize_quad_vote_to_reduce;
+
    bool lower_cs_local_index_to_id;
    bool lower_cs_local_id_to_index;
 
diff --git a/src/compiler/nir/nir_opt_intrinsics.c b/src/compiler/nir/nir_opt_intrinsics.c
index 0c5b33991ac1f..7a984efa3abab 100644
--- a/src/compiler/nir/nir_opt_intrinsics.c
+++ b/src/compiler/nir/nir_opt_intrinsics.c
@@ -92,9 +92,131 @@ try_opt_bcsel_of_shuffle(nir_builder *b, nir_alu_instr *alu,
    return shuffle;
 }
 
+static bool
+src_is_quad_broadcast(nir_block *block, nir_src src, nir_intrinsic_instr **intrin)
+{
+   nir_intrinsic_instr *broadcast = nir_src_as_intrinsic(src);
+   if (broadcast == NULL || broadcast->instr.block != block)
+      return false;
+
+   switch (broadcast->intrinsic) {
+   case nir_intrinsic_quad_broadcast:
+      if (!nir_src_is_const(broadcast->src[1]))
+         return false;
+      FALLTHROUGH;
+   case nir_intrinsic_quad_swap_horizontal:
+   case nir_intrinsic_quad_swap_vertical:
+   case nir_intrinsic_quad_swap_diagonal:
+   case nir_intrinsic_quad_swizzle_amd:
+      *intrin = broadcast;
+      return true;
+   default:
+      return false;
+   }
+}
+
+static bool
+src_is_alu(nir_op op, nir_src src, nir_src srcs[2])
+{
+   nir_alu_instr *alu = nir_src_as_alu_instr(src);
+   if (alu == NULL || alu->op != op)
+      return false;
+
+   if (!nir_alu_src_is_trivial_ssa(alu, 0) || !nir_alu_src_is_trivial_ssa(alu, 1))
+      return false;
+
+   srcs[0] = alu->src[0].src;
+   srcs[1] = alu->src[1].src;
+
+   return true;
+}
+
+static nir_ssa_def *
+try_opt_quad_vote(nir_builder *b, nir_alu_instr *alu, bool block_has_discard)
+{
+   if (block_has_discard)
+      return NULL;
+
+   if (!nir_alu_src_is_trivial_ssa(alu, 0) || !nir_alu_src_is_trivial_ssa(alu, 1))
+      return NULL;
+
+   nir_intrinsic_instr *quad_broadcasts[4];
+   nir_src srcs[2][2];
+   bool found = false;
+
+   /* Match (broadcast0 op broadcast1) op (broadcast2 op broadcast3). */
+   found = src_is_alu(alu->op, alu->src[0].src, srcs[0]) &&
+           src_is_alu(alu->op, alu->src[1].src, srcs[1]) &&
+           src_is_quad_broadcast(alu->instr.block, srcs[0][0], &quad_broadcasts[0]) &&
+           src_is_quad_broadcast(alu->instr.block, srcs[0][1], &quad_broadcasts[1]) &&
+           src_is_quad_broadcast(alu->instr.block, srcs[1][0], &quad_broadcasts[2]) &&
+           src_is_quad_broadcast(alu->instr.block, srcs[1][1], &quad_broadcasts[3]);
+
+   /* Match ((broadcast2 op broadcast3) op broadcast1) op broadcast0). */
+   if (!found) {
+      if ((src_is_alu(alu->op, alu->src[0].src, srcs[0]) &&
+           src_is_quad_broadcast(alu->instr.block, alu->src[1].src, &quad_broadcasts[0])) ||
+          (src_is_alu(alu->op, alu->src[1].src, srcs[0]) &&
+           src_is_quad_broadcast(alu->instr.block, alu->src[0].src, &quad_broadcasts[0]))) {
+         /* ((broadcast2 || broadcast3) || broadcast1) */
+         if ((src_is_alu(alu->op, srcs[0][0], srcs[1]) &&
+              src_is_quad_broadcast(alu->instr.block, srcs[0][1], &quad_broadcasts[1])) ||
+             (src_is_alu(alu->op, srcs[0][1], srcs[1]) &&
+              src_is_quad_broadcast(alu->instr.block, srcs[0][0], &quad_broadcasts[1]))) {
+            /* (broadcast2 || broadcast3) */
+            found = src_is_quad_broadcast(alu->instr.block, srcs[1][0], &quad_broadcasts[2]) &&
+                    src_is_quad_broadcast(alu->instr.block, srcs[1][1], &quad_broadcasts[3]);
+         }
+      }
+   }
+
+   if (!found)
+      return NULL;
+
+   /* Check if each lane in a quad reduces all lanes in the quad, and if all broadcasts read the
+    * same data.
+    */
+   uint16_t lanes_read = 0;
+   for (unsigned i = 0; i < 4; i++) {
+      if (!nir_srcs_equal(quad_broadcasts[i]->src[0], quad_broadcasts[0]->src[0]))
+         return NULL;
+
+      for (unsigned j = 0; j < 4; j++) {
+         unsigned lane;
+         switch (quad_broadcasts[i]->intrinsic) {
+         case nir_intrinsic_quad_broadcast:
+            lane = nir_src_as_uint(quad_broadcasts[i]->src[1]) & 0x3;
+            break;
+         case nir_intrinsic_quad_swap_horizontal:
+            lane = j ^ 1;
+            break;
+         case nir_intrinsic_quad_swap_vertical:
+            lane = j ^ 2;
+            break;
+         case nir_intrinsic_quad_swap_diagonal:
+            lane = 3 - j;
+            break;
+         case nir_intrinsic_quad_swizzle_amd:
+            lane = (nir_intrinsic_swizzle_mask(quad_broadcasts[i]) >> (j * 2)) & 0x3;
+            break;
+         default:
+            unreachable();
+         }
+         lanes_read |= (1 << lane) << (j * 4);
+      }
+   }
+
+   if (lanes_read != 0xffff)
+      return NULL;
+
+   /* Create reduction. */
+   return nir_reduce(b, quad_broadcasts[0]->src[0].ssa, .reduction_op = alu->op, .cluster_size = 4,
+                     .include_helpers = true);
+}
+
 static bool
 opt_intrinsics_alu(nir_builder *b, nir_alu_instr *alu,
-                   bool block_has_discard)
+                   bool block_has_discard, const struct nir_shader_compiler_options *options)
 {
    nir_ssa_def *replacement = NULL;
 
@@ -102,7 +224,11 @@ opt_intrinsics_alu(nir_builder *b, nir_alu_instr *alu,
    case nir_op_bcsel:
       replacement = try_opt_bcsel_of_shuffle(b, alu, block_has_discard);
       break;
-
+   case nir_op_iand:
+   case nir_op_ior:
+      if (nir_dest_bit_size(alu->dest.dest) == 1 && options->optimize_quad_vote_to_reduce)
+         replacement = try_opt_quad_vote(b, alu, block_has_discard);
+      break;
    default:
       break;
    }
@@ -182,7 +308,7 @@ opt_intrinsics_impl(nir_function_impl *impl,
          switch (instr->type) {
          case nir_instr_type_alu:
             if (opt_intrinsics_alu(&b, nir_instr_as_alu(instr),
-                                   block_has_discard))
+                                   block_has_discard, options))
                progress = true;
             break;
 
-- 
GitLab


From 814fe03b82ad38d65d207fea022ce361852407d9 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Tue, 13 Jun 2023 14:09:26 +0100
Subject: [PATCH 5/5] radv: use nir_opt_intrinsics

No fossil-db changes (navi21).

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/vulkan/radv_shader.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/src/amd/vulkan/radv_shader.c b/src/amd/vulkan/radv_shader.c
index e37994002e3c8..e0c77bd3465fe 100644
--- a/src/amd/vulkan/radv_shader.c
+++ b/src/amd/vulkan/radv_shader.c
@@ -120,6 +120,7 @@ get_nir_options_for_stage(struct radv_physical_device *device, gl_shader_stage s
                              nir_lower_iadd_sat64,
       .lower_doubles_options = nir_lower_drcp | nir_lower_dsqrt | nir_lower_drsq | nir_lower_ddiv,
       .divergence_analysis_options = nir_divergence_view_index_uniform,
+      .optimize_quad_vote_to_reduce = true,
    };
 }
 
@@ -211,6 +212,7 @@ radv_optimize_nir(struct nir_shader *shader, bool optimize_conservatively)
       NIR_PASS(progress, shader, nir_opt_cse);
       NIR_PASS(progress, shader, nir_opt_peephole_select, 8, true, true);
       NIR_PASS(progress, shader, nir_opt_constant_folding);
+      NIR_PASS(progress, shader, nir_opt_intrinsics);
       NIR_PASS(progress, shader, nir_opt_algebraic);
 
       NIR_PASS(progress, shader, nir_opt_undef);
-- 
GitLab

