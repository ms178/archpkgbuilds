From cf885985fda209e0b7cece68eb905cfe73c2bd32 Mon Sep 17 00:00:00 2001
From: Yonggang Luo <luoyonggang@gmail.com>
Date: Wed, 9 Aug 2023 14:02:42 +0800
Subject: [PATCH] =?UTF-8?q?util:=20Fixes=20note:=20the=20alignment=20of=20?=
 =?UTF-8?q?=E2=80=98=5FAtomic=20long=20long=20int=E2=80=99=20fields=20chan?=
 =?UTF-8?q?ged=20in=20GCC=2011.?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

This is a improve of https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/22121

Signed-off-by: Yonggang Luo <luoyonggang@gmail.com>
---
 src/amd/vulkan/radv_query.c                   | 22 +++++++-------
 .../vulkan/winsys/amdgpu/radv_amdgpu_winsys.h |  6 ++--
 src/util/disk_cache.c                         |  2 +-
 src/util/disk_cache_os.c                      | 10 +++----
 src/util/u_atomic.h                           | 30 ++++++++++++++-----
 5 files changed, 42 insertions(+), 28 deletions(-)

diff --git a/src/amd/vulkan/radv_query.c b/src/amd/vulkan/radv_query.c
index 1ae65d0cc8273..14c8781c6bd1d 100644
--- a/src/amd/vulkan/radv_query.c
+++ b/src/amd/vulkan/radv_query.c
@@ -1182,7 +1182,7 @@ radv_GetQueryPoolResults(VkDevice _device, VkQueryPool queryPool, uint32_t first
          uint64_t value;
 
          do {
-            value = p_atomic_read(src64);
+            value = p_atomic_read(&src64->value);
          } while (value == TIMESTAMP_NOT_READY && (flags & VK_QUERY_RESULT_WAIT_BIT));
 
          available = value != TIMESTAMP_NOT_READY;
@@ -1215,8 +1215,8 @@ radv_GetQueryPoolResults(VkDevice _device, VkQueryPool queryPool, uint32_t first
                continue;
 
             do {
-               start = p_atomic_read(src64 + 2 * i);
-               end = p_atomic_read(src64 + 2 * i + 1);
+               start = p_atomic_read(&src64->value + 2 * i);
+               end = p_atomic_read(&src64->value + 2 * i + 1);
             } while ((!(start & (1ull << 63)) || !(end & (1ull << 63))) && (flags & VK_QUERY_RESULT_WAIT_BIT));
 
             if (!(start & (1ull << 63)) || !(end & (1ull << 63)))
@@ -1293,7 +1293,7 @@ radv_GetQueryPoolResults(VkDevice _device, VkQueryPool queryPool, uint32_t first
          do {
             available = 1;
             for (int j = 0; j < 4; j++) {
-               if (!(p_atomic_read(src64 + j) & 0x8000000000000000UL))
+               if (!(p_atomic_read(&src64->value + j) & 0x8000000000000000UL))
                   available = 0;
             }
          } while (!available && (flags & VK_QUERY_RESULT_WAIT_BIT));
@@ -1301,8 +1301,8 @@ radv_GetQueryPoolResults(VkDevice _device, VkQueryPool queryPool, uint32_t first
          if (!available && !(flags & VK_QUERY_RESULT_PARTIAL_BIT))
             result = VK_NOT_READY;
 
-         num_primitives_written = src64[3] - src64[1];
-         primitive_storage_needed = src64[2] - src64[0];
+         num_primitives_written = src64[3].value - src64[1].value;
+         primitive_storage_needed = src64[2].value - src64[0].value;
 
          if (flags & VK_QUERY_RESULT_64_BIT) {
             if (available || (flags & VK_QUERY_RESULT_PARTIAL_BIT))
@@ -1333,8 +1333,8 @@ radv_GetQueryPoolResults(VkDevice _device, VkQueryPool queryPool, uint32_t first
           */
          do {
             available = 1;
-            if (!(p_atomic_read(src64 + 0) & 0x8000000000000000UL) ||
-                !(p_atomic_read(src64 + 2) & 0x8000000000000000UL)) {
+            if (!(p_atomic_read(&src64->value + 0) & 0x8000000000000000UL) ||
+                !(p_atomic_read(&src64->value + 2) & 0x8000000000000000UL)) {
                available = 0;
             }
          } while (!available && (flags & VK_QUERY_RESULT_WAIT_BIT));
@@ -1342,7 +1342,7 @@ radv_GetQueryPoolResults(VkDevice _device, VkQueryPool queryPool, uint32_t first
          if (!available && !(flags & VK_QUERY_RESULT_PARTIAL_BIT))
             result = VK_NOT_READY;
 
-         primitive_storage_needed = src64[2] - src64[0];
+         primitive_storage_needed = src64[2].value - src64[0].value;
 
          if (pool->uses_gds && device->physical_device->rad_info.gfx_level < GFX11) {
             uint32_t const *src32 = (uint32_t const *)src;
@@ -1369,13 +1369,13 @@ radv_GetQueryPoolResults(VkDevice _device, VkQueryPool queryPool, uint32_t first
          do {
             avail = true;
             for (unsigned i = 0; i < pc_pool->num_passes; ++i)
-               if (!p_atomic_read(src64 + pool->stride / 8 - i - 1))
+               if (!p_atomic_read(&src64->value + pool->stride / 8 - i - 1))
                   avail = false;
          } while (!avail && (flags & VK_QUERY_RESULT_WAIT_BIT));
 
          available = avail;
 
-         radv_pc_get_results(pc_pool, src64, dest);
+         radv_pc_get_results(pc_pool, &src64->value, dest);
          dest += pc_pool->num_counters * sizeof(union VkPerformanceCounterResultKHR);
          break;
       }
diff --git a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys.h b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys.h
index 5ebe34129baba..01afc12981261 100644
--- a/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys.h
+++ b/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_winsys.h
@@ -52,9 +52,9 @@ struct radv_amdgpu_winsys {
    bool reserve_vmid;
    uint64_t perftest;
 
-   p_atomic_uint64_t allocated_vram;
-   p_atomic_uint64_t allocated_vram_vis;
-   p_atomic_uint64_t allocated_gtt;
+   alignas(8) uint64_t allocated_vram;
+   alignas(8) uint64_t allocated_vram_vis;
+   alignas(8) uint64_t allocated_gtt;
 
    /* Global BO list */
    struct {
diff --git a/src/util/disk_cache.c b/src/util/disk_cache.c
index 8298f9d7b329b..bb565ccc956f2 100644
--- a/src/util/disk_cache.c
+++ b/src/util/disk_cache.c
@@ -450,7 +450,7 @@ cache_put(void *job, void *gdata, int thread_index)
          goto done;
 
       /* If the cache is too large, evict something else first. */
-      while (*dc_job->cache->size + dc_job->size > dc_job->cache->max_size &&
+      while (p_atomic_read_relaxed(&dc_job->cache->size->value) + dc_job->size > dc_job->cache->max_size &&
              i < 8) {
          disk_cache_evict_lru_item(dc_job->cache);
          i++;
diff --git a/src/util/disk_cache_os.c b/src/util/disk_cache_os.c
index 31586fcec39dd..cdb543b688cf1 100644
--- a/src/util/disk_cache_os.c
+++ b/src/util/disk_cache_os.c
@@ -456,7 +456,7 @@ disk_cache_evict_lru_item(struct disk_cache *cache)
    free(dir_path);
 
    if (size) {
-      p_atomic_add(cache->size, - (uint64_t)size);
+      p_atomic_add(&cache->size->value, - (uint64_t)size);
       return;
    }
 
@@ -483,7 +483,7 @@ disk_cache_evict_lru_item(struct disk_cache *cache)
    free_lru_file_list(lru_file_list);
 
    if (size)
-      p_atomic_add(cache->size, - (uint64_t)size);
+      p_atomic_add(&cache->size->value, - (uint64_t)size);
 }
 
 void
@@ -499,7 +499,7 @@ disk_cache_evict_item(struct disk_cache *cache, char *filename)
    free(filename);
 
    if (sb.st_blocks)
-      p_atomic_add(cache->size, - (uint64_t)sb.st_blocks * 512);
+      p_atomic_add(&cache->size->value, - (uint64_t)sb.st_blocks * 512);
 }
 
 static void *
@@ -819,7 +819,7 @@ disk_cache_write_item_to_disk(struct disk_cache_put_job *dc_job,
       goto done;
    }
 
-   p_atomic_add(dc_job->cache->size, sb.st_blocks * 512);
+   p_atomic_add(&dc_job->cache->size->value, sb.st_blocks * 512);
 
  done:
    if (fd_final != -1)
@@ -1056,7 +1056,7 @@ disk_cache_mmap_cache_index(void *mem_ctx, struct disk_cache *cache,
       goto path_fail;
    cache->index_mmap_size = size;
 
-   cache->size = (uint64_t *) cache->index_mmap;
+   cache->size = (p_atomic_uint64_t *) cache->index_mmap;
    cache->stored_keys = cache->index_mmap + sizeof(uint64_t);
    mapped = true;
 
diff --git a/src/util/u_atomic.h b/src/util/u_atomic.h
index ec77bb4d39ceb..7c27befc0d67c 100644
--- a/src/util/u_atomic.h
+++ b/src/util/u_atomic.h
@@ -340,16 +340,30 @@ static inline uint64_t p_atomic_xchg_64(uint64_t *v, uint64_t i)
                                       (assert(!"should not get here"), 0))
 #endif
 
-/* On x86 we can have sizeof(uint64_t) = 8 and _Alignof(uint64_t) = 4. causing split locks. The
- * implementation does handle that correctly, but with an internal mutex. Extend the alignment to
- * avoid this.
+/* On x86 we can have sizeof(uint64_t) = 8 and _Alignof(uint64_t) = 4. causing split locks.
+ * The implementation does handle that correctly, but with an internal mutex.
+ * Extend the alignment to avoid this.
+ * `p_atomic_int64_t` and `p_atomic_uint64_t` are used for casting any pointer to
+ * `p_atomic_int64_t *` and `p_atomic_uint64_t *`. That's for telling the compiler is accessing
+ * the 64 bits atomic in 8 byte aligned way to avoid clang `misaligned atomic operation` warning.
+ * To define 64 bits atomic memeber in struct type,
+ * use `alignas(8) int64_t $member` or `alignas(8) uint64_t $member` is enough.
  */
-#if  __STDC_VERSION__ >= 201112L && !defined(__STDC_NO_ATOMICS__) && defined(USE_GCC_ATOMIC_BUILTINS)
-typedef int64_t __attribute__((aligned(_Alignof(_Atomic(int64_t))))) p_atomic_int64_t;
-typedef uint64_t __attribute__((aligned(_Alignof(_Atomic(uint64_t))))) p_atomic_uint64_t;
+typedef struct {
+#ifndef __cplusplus
+   _Alignas(8)
 #else
-typedef int64_t p_atomic_int64_t;
-typedef uint64_t p_atomic_uint64_t;
+   alignas(8)
 #endif
+   int64_t value;
+} p_atomic_int64_t;
+typedef struct {
+#ifndef __cplusplus
+   _Alignas(8)
+#else
+   alignas(8)
+#endif
+   uint64_t value;
+} p_atomic_uint64_t;
 
 #endif /* U_ATOMIC_H */
-- 
GitLab

