From d610c9c1a2641b59b5dfaae3470788a450ed6634 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Wed, 7 Dec 2022 20:16:19 +0800
Subject: [PATCH 1/8] ac/nir/ngg: gs save data type of outputs

Prepare to support 16bit streamout and remove nir_variable output.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir_lower_ngg.c | 25 +++++++++++++++++++++----
 1 file changed, 21 insertions(+), 4 deletions(-)

diff --git a/src/amd/common/ac_nir_lower_ngg.c b/src/amd/common/ac_nir_lower_ngg.c
index 9cb28181ee9c..402959853473 100644
--- a/src/amd/common/ac_nir_lower_ngg.c
+++ b/src/amd/common/ac_nir_lower_ngg.c
@@ -57,6 +57,13 @@ typedef struct
    nir_ssa_def *chan[4];
 } vs_output;
 
+typedef struct
+{
+   nir_alu_type types[VARYING_SLOT_MAX][4];
+   nir_alu_type types_16bit_lo[16][4];
+   nir_alu_type types_16bit_hi[16][4];
+} shader_output_types;
+
 typedef struct
 {
    const ac_nir_lower_ngg_options *options;
@@ -129,6 +136,8 @@ typedef struct
    nir_variable *output_vars_16bit_lo[16][4];
    gs_output_info output_info_16bit_hi[16];
    gs_output_info output_info_16bit_lo[16];
+   /* output types for both 32bit and 16bit */
+   shader_output_types output_types;
    /* Count per stream. */
    nir_ssa_def *vertex_count[4];
    nir_ssa_def *primitive_count[4];
@@ -2409,6 +2418,7 @@ lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg
 
    /* Get corresponding output variable and usage info. */
    nir_variable **var;
+   nir_alu_type *type;
    gs_output_info *info;
    if (location >= VARYING_SLOT_VAR0_16BIT) {
       unsigned index = location - VARYING_SLOT_VAR0_16BIT;
@@ -2416,14 +2426,17 @@ lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg
 
       if (io_sem.high_16bits) {
          var = s->output_vars_16bit_hi[index];
+         type = s->output_types.types_16bit_hi[index];
          info = s->output_info_16bit_hi + index;
       } else {
          var = s->output_vars_16bit_lo[index];
+         type = s->output_types.types_16bit_lo[index];
          info = s->output_info_16bit_lo + index;
       }
    } else {
       assert(location < VARYING_SLOT_MAX);
       var = s->output_vars[location];
+      type = s->output_types.types[location];
       info = s->output_info + location;
    }
 
@@ -2453,6 +2466,8 @@ lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg
       info->no_varying = io_sem.no_varying;
       info->no_sysval_output = io_sem.no_sysval_output;
 
+      type[component] = src_type;
+
       if (!var[component]) {
          var[component] =
             nir_local_variable_create(s->impl, glsl_scalar_type(val_type), "output");
@@ -2756,6 +2771,8 @@ ngg_gs_export_vertices(nir_builder *b, nir_ssa_def *max_num_out_vtx, nir_ssa_def
          memset(output->chan, 0, sizeof(output->chan));
       }
 
+      nir_alu_type *types = s->output_types.types[slot];
+
       while (mask) {
          int start, count;
          u_bit_scan_consecutive_range(&mask, &start, &count);
@@ -2765,14 +2782,14 @@ ngg_gs_export_vertices(nir_builder *b, nir_ssa_def *max_num_out_vtx, nir_ssa_def
                             .align_mul = 4);
 
          for (int i = 0; i < count; i++) {
-            nir_variable *var = s->output_vars[slot][start + i];
-            assert(var);
-
             nir_ssa_def *val = nir_channel(b, load, i);
 
             if (s->options->gfx_level < GFX11 || is_pos) {
+               nir_alu_type type = types[start + i];
+               assert(type != nir_type_invalid);
+
                /* Convert to the expected bit size of the output variable. */
-               unsigned bit_size = glsl_base_type_bit_size(glsl_get_base_type(var->type));
+               unsigned bit_size = nir_alu_type_get_type_size(type);
                val = nir_u2uN(b, val, bit_size);
 
                nir_store_output(b, val, nir_imm_int(b, 0), .base = info->base,
-- 
GitLab


From f0d3eda5101c215cd9aa716b33232632d02d0e12 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Wed, 7 Dec 2022 21:15:47 +0800
Subject: [PATCH 2/8] ac/nir/ngg: gs store output use nir_ssa_def instead of
 nir_variable

Because we called nir_lower_io_to_temporaries which ensure the
store output and emit vertex in the same block.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir_lower_ngg.c | 66 +++++++++++++------------------
 1 file changed, 27 insertions(+), 39 deletions(-)

diff --git a/src/amd/common/ac_nir_lower_ngg.c b/src/amd/common/ac_nir_lower_ngg.c
index 402959853473..5d27ebc0d83f 100644
--- a/src/amd/common/ac_nir_lower_ngg.c
+++ b/src/amd/common/ac_nir_lower_ngg.c
@@ -129,11 +129,11 @@ typedef struct
    bool output_compile_time_known;
    bool streamout_enabled;
    /* 32 bit outputs */
-   nir_variable *output_vars[VARYING_SLOT_MAX][4];
+   nir_ssa_def *outputs[VARYING_SLOT_MAX][4];
    gs_output_info output_info[VARYING_SLOT_MAX];
    /* 16 bit outputs */
-   nir_variable *output_vars_16bit_hi[16][4];
-   nir_variable *output_vars_16bit_lo[16][4];
+   nir_ssa_def *outputs_16bit_hi[16][4];
+   nir_ssa_def *outputs_16bit_lo[16][4];
    gs_output_info output_info_16bit_hi[16];
    gs_output_info output_info_16bit_lo[16];
    /* output types for both 32bit and 16bit */
@@ -2406,7 +2406,6 @@ lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg
 
    nir_ssa_def *store_val = intrin->src[0].ssa;
    nir_alu_type src_type = nir_intrinsic_src_type(intrin);
-   enum glsl_base_type val_type = nir_get_glsl_base_type_for_nir_type(src_type);
 
    /* Small bitsize components consume the same amount of space as 32-bit components,
     * but 64-bit ones consume twice as many. (Vulkan spec 15.1.5)
@@ -2414,10 +2413,10 @@ lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg
     * 64-bit IO has been lowered to multi 32-bit IO.
     */
    assert(store_val->bit_size <= 32);
-   assert(glsl_base_type_get_bit_size(val_type) == store_val->bit_size);
+   assert(nir_alu_type_get_type_size(src_type) == store_val->bit_size);
 
    /* Get corresponding output variable and usage info. */
-   nir_variable **var;
+   nir_ssa_def **output;
    nir_alu_type *type;
    gs_output_info *info;
    if (location >= VARYING_SLOT_VAR0_16BIT) {
@@ -2425,17 +2424,17 @@ lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg
       assert(index < 16);
 
       if (io_sem.high_16bits) {
-         var = s->output_vars_16bit_hi[index];
+         output = s->outputs_16bit_hi[index];
          type = s->output_types.types_16bit_hi[index];
          info = s->output_info_16bit_hi + index;
       } else {
-         var = s->output_vars_16bit_lo[index];
+         output = s->outputs_16bit_lo[index];
          type = s->output_types.types_16bit_lo[index];
          info = s->output_info_16bit_lo + index;
       }
    } else {
       assert(location < VARYING_SLOT_MAX);
-      var = s->output_vars[location];
+      output = s->outputs[location];
       type = s->output_types.types[location];
       info = s->output_info + location;
    }
@@ -2466,15 +2465,14 @@ lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg
       info->no_varying = io_sem.no_varying;
       info->no_sysval_output = io_sem.no_sysval_output;
 
+      /* If type is set multiple times, the value must be same. */
+      assert(type[component] == nir_type_invalid || type[component] == src_type);
       type[component] = src_type;
 
-      if (!var[component]) {
-         var[component] =
-            nir_local_variable_create(s->impl, glsl_scalar_type(val_type), "output");
-      }
-      assert(glsl_get_base_type(var[component]->type) == val_type);
-
-      nir_store_var(b, var[component], nir_channel(b, store_val, comp), 0x1u);
+      /* Assume we have called nir_lower_io_to_temporaries which store output in the
+       * same block as EmitVertex, so we don't need to use nir_variable for outputs.
+       */
+      output[component] = nir_channel(b, store_val, comp);
    }
 
    nir_instr_remove(&intrin->instr);
@@ -2515,6 +2513,7 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
    u_foreach_bit64(slot, b->shader->info.outputs_written) {
       unsigned packed_location = util_bitcount64((b->shader->info.outputs_written & BITFIELD64_MASK(slot)));
       gs_output_info *info = &s->output_info[slot];
+      nir_ssa_def **output = s->outputs[slot];
 
       unsigned mask = gs_output_component_mask_with_stream(info, stream);
       if (!mask)
@@ -2525,21 +2524,17 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
          u_bit_scan_consecutive_range(&mask, &start, &count);
          nir_ssa_def *values[4] = {0};
          for (int c = start; c < start + count; ++c) {
-            nir_variable *var = s->output_vars[slot][c];
-            if (!var) {
+            if (!output[c]) {
                /* no one write to this output before */
                values[c - start] = nir_ssa_undef(b, 1, 32);
                continue;
             }
 
-            /* Load output from variable. */
-            nir_ssa_def *val = nir_load_var(b, var);
-
             /* extend 8/16 bit to 32 bit, 64 bit has been lowered */
-            values[c - start] = nir_u2uN(b, val, 32);
+            values[c - start] = nir_u2uN(b, output[c], 32);
 
-            /* Clear the variable (it is undefined after emit_vertex) */
-            nir_store_var(b, s->output_vars[slot][c], nir_ssa_undef(b, 1, val->bit_size), 0x1);
+            /* Clear the output (it is undefined after emit_vertex) */
+            output[c] = NULL;
          }
 
          nir_ssa_def *store_val = nir_vec(b, values, (unsigned)count);
@@ -2561,6 +2556,8 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
       if (!mask)
          continue;
 
+      nir_ssa_def **output_lo = s->outputs_16bit_lo[slot];
+      nir_ssa_def **output_hi = s->outputs_16bit_hi[slot];
       nir_ssa_def *undef = nir_ssa_undef(b, 1, 16);
 
       while (mask) {
@@ -2568,23 +2565,14 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
          u_bit_scan_consecutive_range(&mask, &start, &count);
          nir_ssa_def *values[4] = {0};
          for (int c = start; c < start + count; ++c) {
-            /* Load and reset the low half var. */
-            nir_ssa_def *lo = undef;
-            nir_variable *var_lo = s->output_vars_16bit_lo[slot][c];
-            if (var_lo) {
-               lo = nir_load_var(b, var_lo);
-               nir_store_var(b, var_lo, undef, 1);
-            }
-
-            /* Load and reset the high half var.*/
-            nir_ssa_def *hi = undef;
-            nir_variable *var_hi = s->output_vars_16bit_hi[slot][c];
-            if (var_hi) {
-               hi = nir_load_var(b, var_hi);
-               nir_store_var(b, var_hi, undef, 1);
-            }
+            nir_ssa_def *lo = output_lo[c] ? output_lo[c] : undef;
+            nir_ssa_def *hi = output_hi[c] ? output_hi[c] : undef;
 
             values[c - start] = nir_pack_32_2x16_split(b, lo, hi);
+
+            /* Reset outputs. */
+            output_lo[c] = NULL;
+            output_hi[c] = NULL;
          }
 
          nir_ssa_def *store_val = nir_vec(b, values, (unsigned)count);
-- 
GitLab


From a9d41a773857721bfbc92ce9ca9eb488e8ea8a75 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Thu, 8 Dec 2022 18:13:16 +0800
Subject: [PATCH 3/8] ac/nir/ngg: assert no offset for nogs/gs output handling

As we does not support nogs/gs indirect output, so the offset
is always 0.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir_lower_ngg.c | 20 ++++++++++----------
 1 file changed, 10 insertions(+), 10 deletions(-)

diff --git a/src/amd/common/ac_nir_lower_ngg.c b/src/amd/common/ac_nir_lower_ngg.c
index 5d27ebc0d83f..8bc0e53df167 100644
--- a/src/amd/common/ac_nir_lower_ngg.c
+++ b/src/amd/common/ac_nir_lower_ngg.c
@@ -1626,13 +1626,17 @@ do_ngg_nogs_store_output_to_lds(nir_builder *b, nir_instr *instr, void *state)
    if (intrin->intrinsic != nir_intrinsic_store_output)
       return false;
 
+   /* no indirect output */
+   assert(nir_src_is_const(intrin->src[1]) && !nir_src_as_uint(intrin->src[1]));
+
    b->cursor = nir_before_instr(instr);
 
+   nir_io_semantics sem = nir_intrinsic_io_semantics(intrin);
    unsigned component = nir_intrinsic_component(intrin);
    unsigned write_mask = nir_intrinsic_write_mask(intrin);
    nir_ssa_def *store_val = intrin->src[0].ssa;
 
-   if (nir_intrinsic_io_semantics(intrin).location == VARYING_SLOT_EDGE) {
+   if (sem.location == VARYING_SLOT_EDGE) {
       if (st->has_user_edgeflags) {
          /* clamp user edge flag to 1 for latter bit operations */
          store_val = nir_umin(b, store_val, nir_imm_int(b, 1));
@@ -1652,10 +1656,8 @@ do_ngg_nogs_store_output_to_lds(nir_builder *b, nir_instr *instr, void *state)
    /* user edge flag is stored at the beginning of a vertex if streamout is not enabled */
    unsigned offset = 0;
    if (st->streamout_enabled) {
-      unsigned base_offset = nir_src_as_uint(intrin->src[1]);
-      unsigned location = nir_intrinsic_io_semantics(intrin).location + base_offset;
       unsigned packed_location =
-         util_bitcount64(b->shader->info.outputs_written & BITFIELD64_MASK(location));
+         util_bitcount64(b->shader->info.outputs_written & BITFIELD64_MASK(sem.location));
       offset = packed_location * 16 + component * 4;
    }
 
@@ -2392,17 +2394,15 @@ ngg_gs_clear_primflags(nir_builder *b, nir_ssa_def *num_vertices, unsigned strea
 static bool
 lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg_gs_state *s)
 {
-   assert(nir_src_is_const(intrin->src[1]));
+   assert(nir_src_is_const(intrin->src[1]) && !nir_src_as_uint(intrin->src[1]));
    b->cursor = nir_before_instr(&intrin->instr);
 
    unsigned base = nir_intrinsic_base(intrin);
    unsigned writemask = nir_intrinsic_write_mask(intrin);
    unsigned component_offset = nir_intrinsic_component(intrin);
-   unsigned base_offset = nir_src_as_uint(intrin->src[1]);
    nir_io_semantics io_sem = nir_intrinsic_io_semantics(intrin);
 
-   unsigned location = io_sem.location + base_offset;
-   unsigned base_index = base + base_offset;
+   unsigned location = io_sem.location;
 
    nir_ssa_def *store_val = intrin->src[0].ssa;
    nir_alu_type src_type = nir_intrinsic_src_type(intrin);
@@ -2449,7 +2449,7 @@ lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg
       unsigned component = component_offset + comp;
 
       /* The same output should always belong to the same base. */
-      assert(!info->components_mask || info->base == base_index);
+      assert(!info->components_mask || info->base == base);
       /* The same output should always have same kill state. */
       assert(!info->components_mask ||
              (info->no_varying == io_sem.no_varying &&
@@ -2458,7 +2458,7 @@ lower_ngg_gs_store_output(nir_builder *b, nir_intrinsic_instr *intrin, lower_ngg
       assert(!(info->components_mask & (1 << component)) ||
              ((info->stream >> (component * 2)) & 3) == stream);
 
-      info->base = base_index;
+      info->base = base;
       /* Components of the same output slot may belong to different streams. */
       info->stream |= stream << (component * 2);
       info->components_mask |= BITFIELD_BIT(component);
-- 
GitLab


From f179515da0b8957b6a1d86a653e715987d0842b4 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Fri, 9 Dec 2022 14:44:21 +0800
Subject: [PATCH 4/8] ac/nir/ngg: always reset output when gs emit vertex

Follow the spec, all outputs even not this stream need to be
reset after emit vertex.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir_lower_ngg.c | 19 +++++++------------
 1 file changed, 7 insertions(+), 12 deletions(-)

diff --git a/src/amd/common/ac_nir_lower_ngg.c b/src/amd/common/ac_nir_lower_ngg.c
index 8bc0e53df167..26eaf4da3d35 100644
--- a/src/amd/common/ac_nir_lower_ngg.c
+++ b/src/amd/common/ac_nir_lower_ngg.c
@@ -2516,9 +2516,6 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
       nir_ssa_def **output = s->outputs[slot];
 
       unsigned mask = gs_output_component_mask_with_stream(info, stream);
-      if (!mask)
-         continue;
-
       while (mask) {
          int start, count;
          u_bit_scan_consecutive_range(&mask, &start, &count);
@@ -2532,9 +2529,6 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
 
             /* extend 8/16 bit to 32 bit, 64 bit has been lowered */
             values[c - start] = nir_u2uN(b, output[c], 32);
-
-            /* Clear the output (it is undefined after emit_vertex) */
-            output[c] = NULL;
          }
 
          nir_ssa_def *store_val = nir_vec(b, values, (unsigned)count);
@@ -2542,6 +2536,9 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
                           .base = packed_location * 16 + start * 4,
                           .align_mul = 4);
       }
+
+      /* Clear all outputs (they are undefined after emit_vertex) */
+      memset(s->outputs[slot], 0, sizeof(s->outputs[slot]));
    }
 
    /* Store 16bit outputs to LDS. */
@@ -2553,8 +2550,6 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
       unsigned mask_lo = gs_output_component_mask_with_stream(s->output_info_16bit_lo + slot, stream);
       unsigned mask_hi = gs_output_component_mask_with_stream(s->output_info_16bit_hi + slot, stream);
       unsigned mask = mask_lo | mask_hi;
-      if (!mask)
-         continue;
 
       nir_ssa_def **output_lo = s->outputs_16bit_lo[slot];
       nir_ssa_def **output_hi = s->outputs_16bit_hi[slot];
@@ -2569,10 +2564,6 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
             nir_ssa_def *hi = output_hi[c] ? output_hi[c] : undef;
 
             values[c - start] = nir_pack_32_2x16_split(b, lo, hi);
-
-            /* Reset outputs. */
-            output_lo[c] = NULL;
-            output_hi[c] = NULL;
          }
 
          nir_ssa_def *store_val = nir_vec(b, values, (unsigned)count);
@@ -2580,6 +2571,10 @@ lower_ngg_gs_emit_vertex_with_counter(nir_builder *b, nir_intrinsic_instr *intri
                           .base = packed_location * 16 + start * 4,
                           .align_mul = 4);
       }
+
+      /* Clear all outputs (they are undefined after emit_vertex) */
+      memset(s->outputs_16bit_lo[slot], 0, sizeof(s->outputs_16bit_lo[slot]));
+      memset(s->outputs_16bit_hi[slot], 0, sizeof(s->outputs_16bit_hi[slot]));
    }
 
    /* Calculate and store per-vertex primitive flags based on vertex counts:
-- 
GitLab


From 368f74b796b961451038eb077ca3f56ff6889647 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Fri, 9 Dec 2022 17:42:31 +0800
Subject: [PATCH 5/8] ac/nir/ngg: fix gs store output for no param offset slot
 when gfx11

When slot has no param offset, we should not emit store output for
them on gfx11.

Fixes: abe2e99e9e5 ("ac/nir/ngg: gs support 16bit outputs")
Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir_lower_ngg.c | 9 +++++----
 1 file changed, 5 insertions(+), 4 deletions(-)

diff --git a/src/amd/common/ac_nir_lower_ngg.c b/src/amd/common/ac_nir_lower_ngg.c
index 26eaf4da3d35..3800fe42fa8c 100644
--- a/src/amd/common/ac_nir_lower_ngg.c
+++ b/src/amd/common/ac_nir_lower_ngg.c
@@ -2832,10 +2832,7 @@ ngg_gs_export_vertices(nir_builder *b, nir_ssa_def *max_num_out_vtx, nir_ssa_def
             nir_ssa_def *val = nir_channel(b, load, i);
             unsigned comp = start + i;
 
-            if (output) {
-               /* low and high varyings have been packed when LDS store */
-               output->chan[comp] = val;
-            } else {
+            if (s->options->gfx_level < GFX11) {
                if (mask_lo & BITFIELD_BIT(comp)) {
                   nir_store_output(b, nir_unpack_32_2x16_split_x(b, val),
                                    nir_imm_int(b, 0),
@@ -2854,6 +2851,10 @@ ngg_gs_export_vertices(nir_builder *b, nir_ssa_def *max_num_out_vtx, nir_ssa_def
                                    .write_mask = 1);
                }
             }
+
+            /* low and high varyings have been packed when LDS store */
+            if (output)
+               output->chan[comp] = val;
          }
       }
    }
-- 
GitLab


From b4db2b5c9cac7fa4cd2b893147b9acf35d51c5e0 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Fri, 9 Dec 2022 18:05:15 +0800
Subject: [PATCH 6/8] ac/nir/ngg: fix gs 16bit output uninitialized channel
 when gfx11

Fixes: abe2e99e9e5 ("ac/nir/ngg: gs support 16bit outputs")
Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir_lower_ngg.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/src/amd/common/ac_nir_lower_ngg.c b/src/amd/common/ac_nir_lower_ngg.c
index 3800fe42fa8c..1df5c537e3f1 100644
--- a/src/amd/common/ac_nir_lower_ngg.c
+++ b/src/amd/common/ac_nir_lower_ngg.c
@@ -2818,6 +2818,7 @@ ngg_gs_export_vertices(nir_builder *b, nir_ssa_def *max_num_out_vtx, nir_ssa_def
           s->options->vs_output_param_offset[slot] <= AC_EXP_PARAM_OFFSET_31) {
          output = &outputs[num_outputs++];
          output->slot = slot;
+         memset(output->chan, 0, sizeof(output->chan));
       }
 
       while (mask) {
-- 
GitLab


From d695c7270bec3712c5bca896b3ed58a6c6a734da Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Thu, 8 Dec 2022 18:22:24 +0800
Subject: [PATCH 7/8] ac/nir/ngg: refine nogs outputs handling

Gather outputs in advance to save both output data and type. Output data
is used for streamout and gfx11 param export. Output type is used for
streamout latter.

The output info will also be used for nir vertex export in the future.

Singed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir_lower_ngg.c | 325 +++++++++++++++++++-----------
 1 file changed, 204 insertions(+), 121 deletions(-)

diff --git a/src/amd/common/ac_nir_lower_ngg.c b/src/amd/common/ac_nir_lower_ngg.c
index 1df5c537e3f1..4471ce0076c0 100644
--- a/src/amd/common/ac_nir_lower_ngg.c
+++ b/src/amd/common/ac_nir_lower_ngg.c
@@ -97,6 +97,12 @@ typedef struct
    nir_variable *clip_vertex_var;
    nir_variable *clipdist_neg_mask_var;
    bool has_clipdist;
+
+   /* outputs */
+   nir_ssa_def *outputs[VARYING_SLOT_MAX][4];
+   nir_ssa_def *outputs_16bit_lo[16][4];
+   nir_ssa_def *outputs_16bit_hi[16][4];
+   shader_output_types output_types;
 } lower_ngg_nogs_state;
 
 typedef struct
@@ -599,6 +605,9 @@ emit_store_ngg_nogs_es_primitive_id(nir_builder *b, lower_ngg_nogs_state *st)
    nir_store_output(b, prim_id, nir_imm_zero(b, 1, 32),
                     .base = st->options->primitive_id_location,
                     .src_type = nir_type_uint32, .io_semantics = io_sem);
+
+   /* Update outputs_written to reflect that the pass added a new output. */
+   b->shader->info.outputs_written |= VARYING_BIT_PRIMITIVE_ID;
 }
 
 static void
@@ -1614,66 +1623,111 @@ add_deferred_attribute_culling(nir_builder *b, nir_cf_list *original_extracted_c
       unreachable("Should be VS or TES.");
 }
 
-static bool
-do_ngg_nogs_store_output_to_lds(nir_builder *b, nir_instr *instr, void *state)
+static void
+ngg_nogs_store_edgeflag_to_lds(nir_builder *b, lower_ngg_nogs_state *s)
 {
-   lower_ngg_nogs_state *st = (lower_ngg_nogs_state *)state;
+   if (!s->outputs[VARYING_SLOT_EDGE][0])
+      return;
 
-   if (instr->type != nir_instr_type_intrinsic)
-      return false;
+   /* clamp user edge flag to 1 for latter bit operations */
+   nir_ssa_def *edgeflag = s->outputs[VARYING_SLOT_EDGE][0];
+   edgeflag = nir_umin(b, edgeflag, nir_imm_int(b, 1));
 
-   nir_intrinsic_instr *intrin = nir_instr_as_intrinsic(instr);
-   if (intrin->intrinsic != nir_intrinsic_store_output)
-      return false;
+   /* user edge flag is stored at the beginning of a vertex if streamout is not enabled */
+   unsigned offset = 0;
+   if (s->streamout_enabled) {
+      unsigned packed_location =
+         util_bitcount64(b->shader->info.outputs_written & BITFIELD64_MASK(VARYING_SLOT_EDGE));
+      offset = packed_location * 16;
+   }
 
-   /* no indirect output */
-   assert(nir_src_is_const(intrin->src[1]) && !nir_src_as_uint(intrin->src[1]));
+   nir_ssa_def *tid = nir_load_local_invocation_index(b);
+   nir_ssa_def *addr = pervertex_lds_addr(b, tid, s->pervertex_lds_bytes);
 
-   b->cursor = nir_before_instr(instr);
+   nir_store_shared(b, edgeflag, addr, .base = offset);
+}
 
-   nir_io_semantics sem = nir_intrinsic_io_semantics(intrin);
-   unsigned component = nir_intrinsic_component(intrin);
-   unsigned write_mask = nir_intrinsic_write_mask(intrin);
-   nir_ssa_def *store_val = intrin->src[0].ssa;
+static void
+ngg_nogs_store_xfb_outputs_to_lds(nir_builder *b, lower_ngg_nogs_state *s)
+{
+   nir_xfb_info *info = b->shader->xfb_info;
 
-   if (sem.location == VARYING_SLOT_EDGE) {
-      if (st->has_user_edgeflags) {
-         /* clamp user edge flag to 1 for latter bit operations */
-         store_val = nir_umin(b, store_val, nir_imm_int(b, 1));
-         /* remove instr after cursor point to the new node */
-         nir_instr_remove(instr);
+   uint64_t xfb_outputs = 0;
+   unsigned xfb_outputs_16bit = 0;
+   uint8_t xfb_mask[VARYING_SLOT_MAX] = {0};
+   uint8_t xfb_mask_16bit_lo[16] = {0};
+   uint8_t xfb_mask_16bit_hi[16] = {0};
+
+   /* Get XFB output mask for each slot. */
+   for (int i = 0; i < info->output_count; i++) {
+      nir_xfb_output_info *out = info->outputs + i;
+
+      if (out->location < VARYING_SLOT_VAR0_16BIT) {
+         xfb_outputs |= BITFIELD64_BIT(out->location);
+         xfb_mask[out->location] |= out->component_mask;
       } else {
-         /* remove the edge flag output anyway as it should not be passed to next stage */
-         nir_instr_remove(instr);
-         return true;
+         unsigned index = out->location - VARYING_SLOT_VAR0_16BIT;
+         xfb_outputs_16bit |= BITFIELD_BIT(index);
+
+         if (out->high_16bits)
+            xfb_mask_16bit_hi[index] |= out->component_mask;
+         else
+            xfb_mask_16bit_lo[index] |= out->component_mask;
       }
-   } else {
-      write_mask = nir_instr_xfb_write_mask(intrin) >> component;
-      if (!(write_mask && st->streamout_enabled))
-         return false;
    }
 
-   /* user edge flag is stored at the beginning of a vertex if streamout is not enabled */
-   unsigned offset = 0;
-   if (st->streamout_enabled) {
+   nir_ssa_def *tid = nir_load_local_invocation_index(b);
+   nir_ssa_def *addr = pervertex_lds_addr(b, tid, s->pervertex_lds_bytes);
+
+   u_foreach_bit64(slot, xfb_outputs) {
       unsigned packed_location =
-         util_bitcount64(b->shader->info.outputs_written & BITFIELD64_MASK(sem.location));
-      offset = packed_location * 16 + component * 4;
+         util_bitcount64(b->shader->info.outputs_written & BITFIELD64_MASK(slot));
+
+      unsigned mask = xfb_mask[slot];
+      while (mask) {
+         int start, count;
+         u_bit_scan_consecutive_range(&mask, &start, &count);
+         /* Outputs here are sure to be 32bit.
+          *
+          * 64bit outputs have been lowered to two 32bit. As 16bit outputs:
+          *   Vulkan does not allow streamout outputs less than 32bit.
+          *   OpenGL puts 16bit outputs in VARYING_SLOT_VAR0_16BIT.
+          */
+         nir_ssa_def *store_val = nir_vec(b, &s->outputs[slot][start], (unsigned)count);
+         nir_store_shared(b, store_val, addr, .base = packed_location * 16 + start * 4);
+      }
    }
 
-   nir_ssa_def *tid = nir_load_local_invocation_index(b);
-   nir_ssa_def *addr = pervertex_lds_addr(b, tid, st->pervertex_lds_bytes);
+   unsigned num_32bit_outputs = util_bitcount64(b->shader->info.outputs_written);
+   u_foreach_bit64(slot, xfb_outputs_16bit) {
+      unsigned packed_location = num_32bit_outputs +
+         util_bitcount(b->shader->info.outputs_written_16bit & BITFIELD_MASK(slot));
 
-   nir_store_shared(b, store_val, addr, .base = offset, .write_mask = write_mask);
+      unsigned mask_lo = xfb_mask_16bit_lo[slot];
+      unsigned mask_hi = xfb_mask_16bit_hi[slot];
 
-   return true;
-}
+      nir_ssa_def **outputs_lo = s->outputs_16bit_lo[slot];
+      nir_ssa_def **outputs_hi = s->outputs_16bit_hi[slot];
+      nir_ssa_def *undef = nir_ssa_undef(b, 1, 16);
 
-static void
-ngg_nogs_store_all_outputs_to_lds(nir_shader *shader, lower_ngg_nogs_state *st)
-{
-   nir_shader_instructions_pass(shader, do_ngg_nogs_store_output_to_lds,
-                                nir_metadata_block_index | nir_metadata_dominance, st);
+      unsigned mask = mask_lo | mask_hi;
+      while (mask) {
+         int start, count;
+         u_bit_scan_consecutive_range(&mask, &start, &count);
+
+         nir_ssa_def *values[4] = {0};
+         for (int c = start; c < start + count; ++c) {
+            nir_ssa_def *lo = mask_lo & BITFIELD_BIT(c) ? outputs_lo[c] : undef;
+            nir_ssa_def *hi = mask_hi & BITFIELD_BIT(c) ? outputs_hi[c] : undef;
+
+            /* extend 8/16 bit to 32 bit, 64 bit has been lowered */
+            values[c - start] = nir_pack_32_2x16_split(b, lo, hi);
+         }
+
+         nir_ssa_def *store_val = nir_vec(b, values, (unsigned)count);
+         nir_store_shared(b, store_val, addr, .base = packed_location * 16 + start * 4);
+      }
+   }
 }
 
 static void
@@ -1937,24 +1991,17 @@ ngg_nogs_get_pervertex_lds_size(gl_shader_stage stage,
    return pervertex_lds_bytes;
 }
 
-static unsigned
-gather_vs_outputs(nir_builder *b, struct exec_list *cf_list, vs_output *outputs,
-                  const uint8_t *vs_output_param_offset)
+static void
+ngg_nogs_gather_outputs(nir_builder *b, struct exec_list *cf_list, lower_ngg_nogs_state *s)
 {
-   uint64_t output_mask32 = 0;
-   nir_ssa_def *outputs32[VARYING_SLOT_MAX][4] = {0};
-
-   unsigned output_mask16_lo = 0;
-   unsigned output_mask16_hi = 0;
-   nir_ssa_def *outputs16_lo[16][4];
-   nir_ssa_def *outputs16_hi[16][4];
-
    /* Assume:
     * - the shader used nir_lower_io_to_temporaries
     * - 64-bit outputs are lowered
     * - no indirect indexing is present
     */
-   struct nir_cf_node *first_node = exec_node_data(nir_cf_node, exec_list_get_head(cf_list), node);
+   struct nir_cf_node *first_node =
+      exec_node_data(nir_cf_node, exec_list_get_head(cf_list), node);
+
    for (nir_block *block = nir_cf_node_cf_tree_first(first_node); block != NULL;
         block = nir_block_cf_tree_next(block)) {
       nir_foreach_instr_safe (instr, block) {
@@ -1967,61 +2014,92 @@ gather_vs_outputs(nir_builder *b, struct exec_list *cf_list, vs_output *outputs,
 
          assert(nir_src_is_const(intrin->src[1]) && !nir_src_as_uint(intrin->src[1]));
 
-         unsigned slot = nir_intrinsic_io_semantics(intrin).location;
-         if (vs_output_param_offset[slot] > AC_EXP_PARAM_OFFSET_31)
-            continue;
-
-         bool is_hi = nir_intrinsic_io_semantics(intrin).high_16bits;
-         bool is_16bit = slot >= VARYING_SLOT_VAR0_16BIT;
+         nir_io_semantics sem = nir_intrinsic_io_semantics(intrin);
+         unsigned slot = sem.location;
 
-         u_foreach_bit (i, nir_intrinsic_write_mask(intrin)) {
-            unsigned comp = nir_intrinsic_component(intrin) + i;
-            nir_ssa_def *chan = nir_channel(b, intrin->src[0].ssa, i);
-            if (is_16bit && is_hi)
-               outputs16_hi[slot - VARYING_SLOT_VAR0_16BIT][comp] = chan;
-            else if (is_16bit)
-               outputs16_lo[slot - VARYING_SLOT_VAR0_16BIT][comp] = chan;
-            else
-               outputs32[slot][comp] = chan;
+         nir_ssa_def **output;
+         nir_alu_type *type;
+         if (slot >= VARYING_SLOT_VAR0_16BIT) {
+            unsigned index = slot - VARYING_SLOT_VAR0_16BIT;
+            if (sem.high_16bits) {
+               output = s->outputs_16bit_hi[index];
+               type = s->output_types.types_16bit_hi[index];
+            } else {
+               output = s->outputs_16bit_lo[index];
+               type = s->output_types.types_16bit_lo[index];
+            }
+         } else {
+            output = s->outputs[slot];
+            type = s->output_types.types[slot];
          }
 
-         if (is_16bit && is_hi)
-            output_mask16_hi |= BITFIELD_BIT(slot - VARYING_SLOT_VAR0_16BIT);
-         else if (is_16bit)
-            output_mask16_lo |= BITFIELD_BIT(slot - VARYING_SLOT_VAR0_16BIT);
-         else
-            output_mask32 |= BITFIELD64_BIT(slot);
+         unsigned component = nir_intrinsic_component(intrin);
+         unsigned write_mask = nir_intrinsic_write_mask(intrin);
+         nir_alu_type src_type = nir_intrinsic_src_type(intrin);
 
-         if (slot >= VARYING_SLOT_VAR0 || !(BITFIELD64_BIT(slot) & POS_EXPORT_MASK))
-            nir_instr_remove(&intrin->instr);
+         u_foreach_bit (i, write_mask) {
+            unsigned c = component + i;
+            output[c] = nir_channel(b, intrin->src[0].ssa, i);
+            type[c] = src_type;
+         }
+
+         /* remove the edge flag output anyway as it should not be passed to next stage */
+         bool is_edge_slot = slot == VARYING_SLOT_EDGE;
+         /* remove non-pos-export slot when GFX11, they are written to buffer memory */
+         bool is_pos_export_slot = slot < VARYING_SLOT_MAX && (BITFIELD64_BIT(slot) & POS_EXPORT_MASK);
+         if (is_edge_slot || (s->options->gfx_level >= GFX11 && !is_pos_export_slot))
+            nir_instr_remove(instr);
       }
    }
+}
 
+static unsigned
+gather_vs_outputs(nir_builder *b, vs_output *outputs, lower_ngg_nogs_state *s)
+{
    unsigned num_outputs = 0;
-   u_foreach_bit64 (i, output_mask32) {
-      outputs[num_outputs].slot = i;
-      for (unsigned j = 0; j < 4; j++) {
-         nir_ssa_def *chan = outputs32[i][j];
+   u_foreach_bit64 (slot, b->shader->info.outputs_written) {
+      if (s->options->vs_output_param_offset[slot] > AC_EXP_PARAM_OFFSET_31)
+         continue;
+
+      /* skip output if no one written before */
+      if (!s->outputs[slot][0] && !s->outputs[slot][1] &&
+          !s->outputs[slot][2] && !s->outputs[slot][3])
+         continue;
+
+      outputs[num_outputs].slot = slot;
+      for (int i = 0; i < 4; i++) {
+         nir_ssa_def *chan = s->outputs[slot][i];
          /* RADV implements 16-bit outputs as 32-bit with VARYING_SLOT_VAR0-31. */
-         outputs[num_outputs].chan[j] = chan && chan->bit_size == 16 ? nir_u2u32(b, chan) : chan;
+         outputs[num_outputs].chan[i] = chan && chan->bit_size == 16 ? nir_u2u32(b, chan) : chan;
       }
       num_outputs++;
    }
 
-   if (output_mask16_lo | output_mask16_hi) {
+   u_foreach_bit (i, b->shader->info.outputs_written_16bit) {
+      unsigned slot = VARYING_SLOT_VAR0_16BIT + i;
+      if (s->options->vs_output_param_offset[slot] > AC_EXP_PARAM_OFFSET_31)
+         continue;
+
+      /* skip output if no one written before */
+      if (!s->outputs_16bit_lo[i][0] && !s->outputs_16bit_lo[i][1] &&
+          !s->outputs_16bit_lo[i][2] && !s->outputs_16bit_lo[i][3] &&
+          !s->outputs_16bit_hi[i][0] && !s->outputs_16bit_hi[i][1] &&
+          !s->outputs_16bit_hi[i][2] && !s->outputs_16bit_hi[i][3])
+         continue;
+
+      vs_output *output = &outputs[num_outputs++];
+      output->slot = slot;
+
+      nir_ssa_def **output_lo = s->outputs_16bit_lo[i];
+      nir_ssa_def **output_hi = s->outputs_16bit_hi[i];
       nir_ssa_def *undef = nir_ssa_undef(b, 1, 16);
-      u_foreach_bit (i, output_mask16_lo | output_mask16_hi) {
-         vs_output *output = &outputs[num_outputs++];
-
-         output->slot = i + VARYING_SLOT_VAR0_16BIT;
-         for (unsigned j = 0; j < 4; j++) {
-            nir_ssa_def *lo = output_mask16_lo & BITFIELD_BIT(i) ? outputs16_lo[i][j] : NULL;
-            nir_ssa_def *hi = output_mask16_hi & BITFIELD_BIT(i) ? outputs16_hi[i][j] : NULL;
-            if (lo || hi)
-               output->chan[j] = nir_pack_32_2x16_split(b, lo ? lo : undef, hi ? hi : undef);
-            else
-               output->chan[j] = NULL;
-         }
+      for (int j = 0; j < 4; j++) {
+         nir_ssa_def *lo = output_lo[j] ? output_lo[j] : undef;
+         nir_ssa_def *hi = output_hi[j] ? output_hi[j] : undef;
+         if (output_lo[j] || output_hi[j])
+            output->chan[j] = nir_pack_32_2x16_split(b, lo, hi);
+         else
+            output->chan[j] = NULL;
       }
    }
 
@@ -2225,20 +2303,45 @@ ac_nir_lower_ngg_nogs(nir_shader *shader, const ac_nir_lower_ngg_options *option
    }
    nir_pop_if(b, if_es_thread);
 
+   if (options->can_cull) {
+      /* Replace uniforms. */
+      apply_reusable_variables(b, &state);
+
+      /* Remove the redundant position output. */
+      remove_extra_pos_outputs(shader, &state);
+
+      /* After looking at the performance in apps eg. Doom Eternal, and The Witcher 3,
+       * it seems that it's best to put the position export always at the end, and
+       * then let ACO schedule it up (slightly) only when early prim export is used.
+       */
+      b->cursor = nir_before_instr(&export_vertex_instr->instr);
+
+      nir_ssa_def *pos_val = nir_load_var(b, state.position_value_var);
+      nir_io_semantics io_sem = { .location = VARYING_SLOT_POS, .num_slots = 1 };
+      nir_store_output(b, pos_val, nir_imm_int(b, 0), .base = state.position_store_base,
+                       .component = 0, .io_semantics = io_sem, .src_type = nir_type_float32);
+   }
+
+   /* Gather outputs data and types */
+   b->cursor = nir_after_cf_list(&if_es_thread->then_list);
+   ngg_nogs_gather_outputs(b, &if_es_thread->then_list, &state);
+
+   if (state.has_user_edgeflags)
+      ngg_nogs_store_edgeflag_to_lds(b, &state);
+
    if (state.streamout_enabled) {
       /* TODO: support culling after streamout. */
       assert(!options->can_cull);
 
-      ngg_nogs_build_streamout(b, &state);
-   }
+      ngg_nogs_store_xfb_outputs_to_lds(b, &state);
 
-   if (state.streamout_enabled || has_user_edgeflags) {
-      ngg_nogs_store_all_outputs_to_lds(shader, &state);
       b->cursor = nir_after_cf_list(&impl->body);
+      ngg_nogs_build_streamout(b, &state);
    }
 
    /* Take care of late primitive export */
    if (!state.early_prim_export) {
+      b->cursor = nir_after_cf_list(&impl->body);
       emit_ngg_nogs_prim_export(b, &state, nir_load_var(b, prim_exp_arg_var));
    }
 
@@ -2247,8 +2350,7 @@ ac_nir_lower_ngg_nogs(nir_shader *shader, const ac_nir_lower_ngg_options *option
       vs_output outputs[64];
 
       b->cursor = nir_after_cf_list(&if_es_thread->then_list);
-      unsigned num_outputs =
-         gather_vs_outputs(b, &if_es_thread->then_list, outputs, options->vs_output_param_offset);
+      unsigned num_outputs = gather_vs_outputs(b, outputs, &state);
 
       if (num_outputs) {
          b->cursor = nir_after_cf_node(&if_es_thread->cf_node);
@@ -2263,25 +2365,6 @@ ac_nir_lower_ngg_nogs(nir_shader *shader, const ac_nir_lower_ngg_options *option
       }
    }
 
-   if (options->can_cull) {
-      /* Replace uniforms. */
-      apply_reusable_variables(b, &state);
-
-      /* Remove the redundant position output. */
-      remove_extra_pos_outputs(shader, &state);
-
-      /* After looking at the performance in apps eg. Doom Eternal, and The Witcher 3,
-       * it seems that it's best to put the position export always at the end, and
-       * then let ACO schedule it up (slightly) only when early prim export is used.
-       */
-      b->cursor = nir_before_instr(&export_vertex_instr->instr);
-
-      nir_ssa_def *pos_val = nir_load_var(b, state.position_value_var);
-      nir_io_semantics io_sem = { .location = VARYING_SLOT_POS, .num_slots = 1 };
-      nir_store_output(b, pos_val, nir_imm_int(b, 0), .base = state.position_store_base,
-                       .component = 0, .io_semantics = io_sem);
-   }
-
    nir_metadata_preserve(impl, nir_metadata_none);
    nir_validate_shader(shader, "after emitting NGG VS/TES");
 
-- 
GitLab


From 846cbf4d5777b5df3bac298dd8573398b209621a Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Fri, 16 Dec 2022 14:12:12 +0800
Subject: [PATCH 8/8] ac/nir/ngg: implement 16bit output streamout

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir_lower_ngg.c | 52 ++++++++++++++++++++++++++++---
 1 file changed, 48 insertions(+), 4 deletions(-)

diff --git a/src/amd/common/ac_nir_lower_ngg.c b/src/amd/common/ac_nir_lower_ngg.c
index 4471ce0076c0..5fe8c4294842 100644
--- a/src/amd/common/ac_nir_lower_ngg.c
+++ b/src/amd/common/ac_nir_lower_ngg.c
@@ -1866,7 +1866,8 @@ static void
 ngg_build_streamout_vertex(nir_builder *b, nir_xfb_info *info,
                            unsigned stream, nir_ssa_def *so_buffer[4],
                            nir_ssa_def *buffer_offsets[4],
-                           nir_ssa_def *vtx_buffer_idx, nir_ssa_def *vtx_lds_addr)
+                           nir_ssa_def *vtx_buffer_idx, nir_ssa_def *vtx_lds_addr,
+                           shader_output_types *output_types)
 {
    nir_ssa_def *vtx_buffer_offsets[4];
    for (unsigned buffer = 0; buffer < 4; buffer++) {
@@ -1882,7 +1883,18 @@ ngg_build_streamout_vertex(nir_builder *b, nir_xfb_info *info,
       if (!out->component_mask || info->buffer_to_stream[out->buffer] != stream)
          continue;
 
-      unsigned base = util_bitcount64(b->shader->info.outputs_written & BITFIELD64_MASK(out->location));
+      unsigned base;
+      if (out->location >= VARYING_SLOT_VAR0_16BIT) {
+         base =
+            util_bitcount64(b->shader->info.outputs_written) +
+            util_bitcount(b->shader->info.outputs_written_16bit &
+                          BITFIELD_MASK(out->location - VARYING_SLOT_VAR0_16BIT));
+      } else {
+         base =
+            util_bitcount64(b->shader->info.outputs_written &
+                            BITFIELD64_MASK(out->location));
+      }
+
       unsigned offset = (base * 4 + out->component_offset) * 4;
       unsigned count = util_bitcount(out->component_mask);
 
@@ -1891,6 +1903,37 @@ ngg_build_streamout_vertex(nir_builder *b, nir_xfb_info *info,
       nir_ssa_def *out_data =
          nir_load_shared(b, count, 32, vtx_lds_addr, .base = offset);
 
+      /* Up-scaling 16bit outputs to 32bit.
+       *
+       * OpenGL ES will put 16bit medium precision varyings to VARYING_SLOT_VAR0_16BIT.
+       * We need to up-scaling them to 32bit when streamout to buffer.
+       *
+       * Vulkan does not allow 8/16bit varyings to be streamout.
+       */
+      if (out->location >= VARYING_SLOT_VAR0_16BIT) {
+         unsigned index = out->location - VARYING_SLOT_VAR0_16BIT;
+         nir_ssa_def *values[4];
+
+         for (int j = 0; j < count; j++) {
+            unsigned c = out->component_offset + j;
+            nir_ssa_def *v = nir_channel(b, out_data, j);
+            nir_alu_type t;
+
+            if (out->high_16bits) {
+               v = nir_unpack_32_2x16_split_y(b, v);
+               t = output_types->types_16bit_hi[index][c];
+            } else {
+               v = nir_unpack_32_2x16_split_x(b, v);
+               t = output_types->types_16bit_lo[index][c];
+            }
+
+            t = nir_alu_type_get_base_type(t);
+            values[j] = nir_convert_to_bit_size(b, v, t, 32);
+         }
+
+         out_data = nir_vec(b, values, count);
+      }
+
       nir_ssa_def *zero = nir_imm_int(b, 0);
       nir_store_buffer_amd(b, out_data, so_buffer[out->buffer],
                            vtx_buffer_offsets[out->buffer],
@@ -1936,7 +1979,7 @@ ngg_nogs_build_streamout(nir_builder *b, lower_ngg_nogs_state *s)
             nir_ssa_def *vtx_lds_addr = pervertex_lds_addr(b, vtx_lds_idx, vtx_lds_stride);
             ngg_build_streamout_vertex(b, info, 0, so_buffer, buffer_offsets,
                                        nir_iadd_imm(b, vtx_buffer_idx, i),
-                                       vtx_lds_addr);
+                                       vtx_lds_addr, &s->output_types);
          }
          nir_pop_if(b, if_valid_vertex);
       }
@@ -3199,7 +3242,8 @@ ngg_gs_build_streamout(nir_builder *b, lower_ngg_gs_state *st)
             ngg_build_streamout_vertex(b, info, stream, so_buffer,
                                        buffer_offsets,
                                        nir_iadd_imm(b, vtx_buffer_idx, i),
-                                       exported_vtx_lds_addr[i]);
+                                       exported_vtx_lds_addr[i],
+                                       &st->output_types);
          }
       }
       nir_pop_if(b, if_emit);
-- 
GitLab

