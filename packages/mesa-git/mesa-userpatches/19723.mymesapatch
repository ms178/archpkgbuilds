From bd478574018b4ae333957a137c2a63849bfab1cb Mon Sep 17 00:00:00 2001
From: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date: Mon, 14 Nov 2022 10:34:18 +0100
Subject: [PATCH 1/3] radv: re-emit streamout descriptors when a new pipeline
 is bound

The SGPR idx can be different.
Found by inspection.

Cc: 22.3 mesa-stable
Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/vulkan/radv_cmd_buffer.c | 5 +++++
 1 file changed, 5 insertions(+)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index b1eb3e99f585..6ab9f09aee74 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -5937,6 +5937,11 @@ radv_CmdBindPipeline(VkCommandBuffer commandBuffer, VkPipelineBindPoint pipeline
          cmd_buffer->state.dirty |= RADV_CMD_DIRTY_DYNAMIC_PROVOKING_VERTEX_MODE;
       }
 
+      /* Re-emit streamout descriptors because the SGPR idx can be different between pipelines. */
+      if (graphics_pipeline->last_vgt_api_stage_locs[AC_UD_STREAMOUT_BUFFERS].sgpr_idx != -1) {
+         cmd_buffer->state.dirty |= RADV_CMD_DIRTY_STREAMOUT_BUFFER;
+      }
+
       radv_bind_dynamic_state(cmd_buffer, &graphics_pipeline->dynamic_state);
 
       radv_bind_vs_input_state(cmd_buffer, graphics_pipeline);
-- 
GitLab


From dbed0853efc5c388209c2deca8153c7a60df478d Mon Sep 17 00:00:00 2001
From: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date: Mon, 14 Nov 2022 10:44:35 +0100
Subject: [PATCH 2/3] radv: reduce CPU overhead when emitting streamout
 descriptors

Only the last VGT stage can have streamout.

Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/vulkan/radv_cmd_buffer.c | 19 +++++++------------
 1 file changed, 7 insertions(+), 12 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index 6ab9f09aee74..1ee9731a0e48 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -4491,22 +4491,17 @@ static void
 radv_emit_streamout_buffers(struct radv_cmd_buffer *cmd_buffer, uint64_t va)
 {
    struct radv_graphics_pipeline *pipeline = cmd_buffer->state.graphics_pipeline;
-   struct radv_userdata_info *loc;
+   const struct radv_userdata_info *loc = &pipeline->last_vgt_api_stage_locs[AC_UD_STREAMOUT_BUFFERS];
+   const unsigned stage = pipeline->last_vgt_api_stage;
    uint32_t base_reg;
 
-   for (unsigned stage = 0; stage < MESA_VULKAN_SHADER_STAGES; ++stage) {
-      if (!radv_get_shader(&pipeline->base, stage))
-         continue;
-
-      loc = radv_lookup_user_sgpr(&pipeline->base, stage, AC_UD_STREAMOUT_BUFFERS);
-      if (loc->sgpr_idx == -1)
-         continue;
+   if (loc->sgpr_idx == -1)
+      return;
 
-      base_reg = pipeline->base.user_data_0[stage];
+   base_reg = pipeline->base.user_data_0[stage];
 
-      radv_emit_shader_pointer(cmd_buffer->device, cmd_buffer->cs, base_reg + loc->sgpr_idx * 4, va,
-                               false);
-   }
+   radv_emit_shader_pointer(cmd_buffer->device, cmd_buffer->cs, base_reg + loc->sgpr_idx * 4, va,
+                            false);
 
    if (radv_pipeline_has_gs_copy_shader(&pipeline->base)) {
       loc = &pipeline->base.gs_copy_shader->info.user_sgprs_locs.shader_data[AC_UD_STREAMOUT_BUFFERS];
-- 
GitLab


From 59bf4557876321bbadde8e81c804ce9c4559e106 Mon Sep 17 00:00:00 2001
From: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date: Mon, 14 Nov 2022 10:59:07 +0100
Subject: [PATCH 3/3] radv: split allocating and emitting streamout descriptors

To reduce overhead when a new pipeline with streamout is bound,
allocate descriptors at bind time and emit them separately.

Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/vulkan/radv_cmd_buffer.c | 123 ++++++++++++++-----------------
 src/amd/vulkan/radv_private.h    |   3 +
 2 files changed, 58 insertions(+), 68 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index 1ee9731a0e48..a43b606e0b1d 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -4488,15 +4488,17 @@ radv_flush_vertex_descriptors(struct radv_cmd_buffer *cmd_buffer)
 }
 
 static void
-radv_emit_streamout_buffers(struct radv_cmd_buffer *cmd_buffer, uint64_t va)
+radv_emit_streamout_buffer(struct radv_cmd_buffer *cmd_buffer)
 {
    struct radv_graphics_pipeline *pipeline = cmd_buffer->state.graphics_pipeline;
    const struct radv_userdata_info *loc = &pipeline->last_vgt_api_stage_locs[AC_UD_STREAMOUT_BUFFERS];
    const unsigned stage = pipeline->last_vgt_api_stage;
+   uint64_t va = cmd_buffer->state.streamout.va;
    uint32_t base_reg;
 
    if (loc->sgpr_idx == -1)
       return;
+   assert(va);
 
    base_reg = pipeline->base.user_data_0[stage];
 
@@ -4512,72 +4514,6 @@ radv_emit_streamout_buffers(struct radv_cmd_buffer *cmd_buffer, uint64_t va)
                                   va, false);
       }
    }
-}
-
-static void
-radv_flush_streamout_descriptors(struct radv_cmd_buffer *cmd_buffer)
-{
-   if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_STREAMOUT_BUFFER) {
-      struct radv_streamout_binding *sb = cmd_buffer->streamout_bindings;
-      struct radv_streamout_state *so = &cmd_buffer->state.streamout;
-      unsigned so_offset;
-      void *so_ptr;
-      uint64_t va;
-
-      /* Allocate some descriptor state for streamout buffers. */
-      if (!radv_cmd_buffer_upload_alloc(cmd_buffer, MAX_SO_BUFFERS * 16, &so_offset, &so_ptr))
-         return;
-
-      for (uint32_t i = 0; i < MAX_SO_BUFFERS; i++) {
-         struct radv_buffer *buffer = sb[i].buffer;
-         uint32_t *desc = &((uint32_t *)so_ptr)[i * 4];
-
-         if (!(so->enabled_mask & (1 << i)))
-            continue;
-
-         va = radv_buffer_get_va(buffer->bo) + buffer->offset;
-
-         va += sb[i].offset;
-
-         /* Set the descriptor.
-          *
-          * On GFX8, the format must be non-INVALID, otherwise
-          * the buffer will be considered not bound and store
-          * instructions will be no-ops.
-          */
-         uint32_t size = 0xffffffff;
-
-         /* Set the correct buffer size for NGG streamout because it's used to determine the max
-          * emit per buffer.
-          */
-         if (cmd_buffer->device->physical_device->use_ngg_streamout)
-            size = sb[i].size;
-
-         uint32_t rsrc_word3 =
-            S_008F0C_DST_SEL_X(V_008F0C_SQ_SEL_X) | S_008F0C_DST_SEL_Y(V_008F0C_SQ_SEL_Y) |
-            S_008F0C_DST_SEL_Z(V_008F0C_SQ_SEL_Z) | S_008F0C_DST_SEL_W(V_008F0C_SQ_SEL_W);
-
-         if (cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX11) {
-            rsrc_word3 |= S_008F0C_FORMAT(V_008F0C_GFX11_FORMAT_32_FLOAT) |
-                          S_008F0C_OOB_SELECT(V_008F0C_OOB_SELECT_RAW);
-         } else if (cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX10) {
-            rsrc_word3 |= S_008F0C_FORMAT(V_008F0C_GFX10_FORMAT_32_FLOAT) |
-                          S_008F0C_OOB_SELECT(V_008F0C_OOB_SELECT_RAW) | S_008F0C_RESOURCE_LEVEL(1);
-         } else {
-            rsrc_word3 |= S_008F0C_DATA_FORMAT(V_008F0C_BUF_DATA_FORMAT_32);
-         }
-
-         desc[0] = va;
-         desc[1] = S_008F04_BASE_ADDRESS_HI(va >> 32);
-         desc[2] = size;
-         desc[3] = rsrc_word3;
-      }
-
-      va = radv_buffer_get_va(cmd_buffer->upload.upload_bo);
-      va += so_offset;
-
-      radv_emit_streamout_buffers(cmd_buffer, va);
-   }
 
    cmd_buffer->state.dirty &= ~RADV_CMD_DIRTY_STREAMOUT_BUFFER;
 }
@@ -4669,7 +4605,8 @@ radv_upload_graphics_shader_descriptors(struct radv_cmd_buffer *cmd_buffer)
    if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_VERTEX_BUFFER)
       radv_flush_vertex_descriptors(cmd_buffer);
 
-   radv_flush_streamout_descriptors(cmd_buffer);
+   if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_STREAMOUT_BUFFER)
+      radv_emit_streamout_buffer(cmd_buffer);
 
    VkShaderStageFlags stages = VK_SHADER_STAGE_ALL_GRAPHICS | VK_SHADER_STAGE_MESH_BIT_EXT;
    radv_flush_descriptors(cmd_buffer, stages, &pipeline->base, VK_PIPELINE_BIND_POINT_GRAPHICS);
@@ -10307,6 +10244,8 @@ radv_CmdBindTransformFeedbackBuffersEXT(VkCommandBuffer commandBuffer, uint32_t
    RADV_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, commandBuffer);
    struct radv_streamout_binding *sb = cmd_buffer->streamout_bindings;
    uint8_t enabled_mask = 0;
+   unsigned so_offset;
+   void *so_ptr;
 
    assert(firstBinding + bindingCount <= MAX_SO_BUFFERS);
    for (uint32_t i = 0; i < bindingCount; i++) {
@@ -10326,6 +10265,54 @@ radv_CmdBindTransformFeedbackBuffersEXT(VkCommandBuffer commandBuffer, uint32_t
       enabled_mask |= 1 << idx;
    }
 
+   /* Allocate space for the streamout descriptors. */
+   if (!radv_cmd_buffer_upload_alloc(cmd_buffer, MAX_SO_BUFFERS * 16, &so_offset, &so_ptr))
+      return;
+
+   for (uint32_t i = 0; i < MAX_SO_BUFFERS; i++) {
+      struct radv_buffer *buffer = sb[i].buffer;
+      uint32_t *desc = &((uint32_t *)so_ptr)[i * 4];
+      uint64_t va;
+
+      if (!(enabled_mask & (1 << i)))
+         continue;
+
+      va = radv_buffer_get_va(buffer->bo) + buffer->offset + sb[i].offset;
+
+      /* Set the descriptor.
+       *
+       * On GFX8, the format must be non-INVALID, otherwise the buffer will be considered not bound
+       * and store instructions will be no-ops.
+       */
+      uint32_t size = 0xffffffff;
+
+      /* Set the correct buffer size for NGG streamout because it's used to determine the max emit
+       * per buffer.
+       */
+      if (cmd_buffer->device->physical_device->use_ngg_streamout)
+         size = sb[i].size;
+
+      uint32_t rsrc_word3 =
+         S_008F0C_DST_SEL_X(V_008F0C_SQ_SEL_X) | S_008F0C_DST_SEL_Y(V_008F0C_SQ_SEL_Y) |
+         S_008F0C_DST_SEL_Z(V_008F0C_SQ_SEL_Z) | S_008F0C_DST_SEL_W(V_008F0C_SQ_SEL_W);
+
+      if (cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX11) {
+         rsrc_word3 |= S_008F0C_FORMAT(V_008F0C_GFX11_FORMAT_32_FLOAT) |
+                       S_008F0C_OOB_SELECT(V_008F0C_OOB_SELECT_RAW);
+      } else if (cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX10) {
+         rsrc_word3 |= S_008F0C_FORMAT(V_008F0C_GFX10_FORMAT_32_FLOAT) |
+                       S_008F0C_OOB_SELECT(V_008F0C_OOB_SELECT_RAW) | S_008F0C_RESOURCE_LEVEL(1);
+      } else {
+         rsrc_word3 |= S_008F0C_DATA_FORMAT(V_008F0C_BUF_DATA_FORMAT_32);
+      }
+
+      desc[0] = va;
+      desc[1] = S_008F04_BASE_ADDRESS_HI(va >> 32);
+      desc[2] = size;
+      desc[3] = rsrc_word3;
+   }
+
+   cmd_buffer->state.streamout.va = radv_buffer_get_va(cmd_buffer->upload.upload_bo) + so_offset;
    cmd_buffer->state.streamout.enabled_mask |= enabled_mask;
 
    cmd_buffer->state.dirty |= RADV_CMD_DIRTY_STREAMOUT_BUFFER;
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index d3bd53aae927..91bd81e08f4c 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -1255,6 +1255,9 @@ struct radv_streamout_state {
 
    /* State of VGT_STRMOUT_(CONFIG|EN) */
    bool streamout_enabled;
+
+   /* Descriptors VA. */
+   uint64_t va;
 };
 
 struct radv_viewport_state {
-- 
GitLab

