From afcfd0a49d84138c2cc541f8ce76c4411a679558 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Tue, 26 Apr 2022 11:09:47 +0200
Subject: [PATCH 1/3] aco: Try to reassign split vector registers post-RA.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Eliminate unnecessary copies when the operand registers of a
p_split_vector instruction are not clobbered between the p_split_vector
and the user of its definitions.

This happens when p_split_vector doesn't kill its operand and its
definitions have a shorter lifespan that the operand. It affects every
NGG culling shader among other things.

This optimization exists because it's too difficult to solve it
in RA, and should be removed after we solved this in RA.

Fossil DB stats on Navi 21:

Totals from 58569 (45.52% of 128653) affected shaders:
CodeSize: 154792268 -> 154384536 (-0.26%)
Instrs: 29368054 -> 29266170 (-0.35%)
Latency: 136303418 -> 136300254 (-0.00%); split: -0.00%, +0.00%
InvThroughput: 21087866 -> 21087732 (-0.00%)
Copies: 2665691 -> 2563819 (-3.82%)

Signed-off-by: Timur Krist√≥f <timur.kristof@gmail.com>
---
 src/amd/compiler/aco_optimizer_postRA.cpp | 81 +++++++++++++++++++++++
 1 file changed, 81 insertions(+)

diff --git a/src/amd/compiler/aco_optimizer_postRA.cpp b/src/amd/compiler/aco_optimizer_postRA.cpp
index 8ced375dd63c..d8b3d829b364 100644
--- a/src/amd/compiler/aco_optimizer_postRA.cpp
+++ b/src/amd/compiler/aco_optimizer_postRA.cpp
@@ -536,6 +536,85 @@ try_combine_dpp(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
    }
 }
 
+void
+try_reassign_split_vector(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
+{
+   /* We are looking for the following pattern:
+    *
+    * sA, sB = p_split_vector s[X:Y]
+    * ... X and Y not clobbered here ...
+    * use sA or sB <--- current instruction
+    *
+    * If possible, we propagate the registers from the p_split_vector
+    * operand into the current instruction and the above is optimized into:
+    *
+    * use sX or sY
+    *
+    * Thereby, we "break" SSA for the affected operand of the current instruction.
+    * This optimization exists because it's too difficult to solve it
+    * in RA, and should be removed after we solved this in RA.
+    */
+
+   if (!instr->isVALU() && !instr->isSALU())
+      return;
+
+   for (unsigned i = 0; i < instr->operands.size(); i++) {
+      /* Find the instruction that writes the current operand. */
+      const Operand& op = instr->operands[i];
+      Idx op_instr_idx = last_writer_idx(ctx, op);
+      if (!op_instr_idx.found())
+         continue;
+
+      /* Check if the operand is written by p_split_vector. */
+      Instruction* split_vec = ctx.get(op_instr_idx);
+      if (split_vec->opcode != aco_opcode::p_split_vector)
+         continue;
+
+      /* Check if the p_split_vector operand's registers are clobbered. */
+      if (is_overwritten_since(ctx, split_vec->operands[0], op_instr_idx))
+         continue;
+
+      /* Don't do anything if p_split_vector kills its operand and the
+       * definitions already reuse the same registers as the operand.
+       */
+      if (split_vec->operands[0].isKill() &&
+          split_vec->operands[0].physReg() == split_vec->definitions[0].physReg())
+         continue;
+
+      /* Don't propagate VGPR to SALU. */
+      if (instr->isSALU() && split_vec->operands[0].regClass().type() == RegType::vgpr)
+         continue;
+
+      /* Don't propagate misaligned SGPRs to SALU. */
+      if (instr->isSALU() && op.bytes() > 4 &&
+          (split_vec->operands[0].physReg().reg() % (op.bytes() / 4) != 0))
+         continue;
+
+      /* Only propagate SGPR or constant to VALU when it's already SGPR. */
+      if (instr->isVALU() &&
+          (split_vec->operands[0].isConstant() ||
+           split_vec->operands[0].regClass().type() == RegType::sgpr) &&
+          op.regClass().type() != RegType::sgpr)
+         continue;
+
+      int reg_bytes = 0;
+
+      for (unsigned def_idx = 0; def_idx < split_vec->definitions.size(); ++def_idx) {
+         if (split_vec->definitions[def_idx].tempId() == op.tempId())
+            break;
+
+         reg_bytes += split_vec->definitions[def_idx].bytes();
+      }
+
+      /* Use the p_split_vector operand register directly.
+       * Note: unfortunately, this "breaks" SSA to some extent.
+       */
+      ctx.uses[op.tempId()]--;
+      PhysReg reg = split_vec->operands[0].physReg().advance(reg_bytes);
+      instr->operands[i].setFixed(reg);
+   }
+}
+
 void
 process_instruction(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
 {
@@ -552,6 +631,8 @@ process_instruction(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
 
    try_combine_dpp(ctx, instr);
 
+   try_reassign_split_vector(ctx, instr);
+
    if (instr)
       save_reg_writes(ctx, instr);
 
-- 
GitLab


From 359e74de73d13f904efbe2613bb66a074d6f3a77 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Wed, 2 Nov 2022 12:18:53 +0100
Subject: [PATCH 2/3] [SQUASH] simplify

combined stats:
Totals from 4060 (3.01% of 134913) affected shaders: (GFX10.3)
CodeSize: 19520048 -> 19507244 (-0.07%)
Instrs: 3609023 -> 3605879 (-0.09%)
Latency: 44885566 -> 44882769 (-0.01%); split: -0.01%, +0.00%
InvThroughput: 7531772 -> 7531564 (-0.00%); split: -0.00%, +0.00%
Copies: 252603 -> 249464 (-1.24%)
---
 src/amd/compiler/aco_optimizer_postRA.cpp | 59 ++++++++++++-----------
 1 file changed, 30 insertions(+), 29 deletions(-)

diff --git a/src/amd/compiler/aco_optimizer_postRA.cpp b/src/amd/compiler/aco_optimizer_postRA.cpp
index d8b3d829b364..0b287ff50df2 100644
--- a/src/amd/compiler/aco_optimizer_postRA.cpp
+++ b/src/amd/compiler/aco_optimizer_postRA.cpp
@@ -550,7 +550,7 @@ try_reassign_split_vector(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
     *
     * use sX or sY
     *
-    * Thereby, we "break" SSA for the affected operand of the current instruction.
+    * Thereby, we might violate register assignment rules.
     * This optimization exists because it's too difficult to solve it
     * in RA, and should be removed after we solved this in RA.
     */
@@ -570,48 +570,49 @@ try_reassign_split_vector(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
       if (split_vec->opcode != aco_opcode::p_split_vector)
          continue;
 
-      /* Check if the p_split_vector operand's registers are clobbered. */
-      if (is_overwritten_since(ctx, split_vec->operands[0], op_instr_idx))
-         continue;
+      Operand& split_op = split_vec->operands[0];
 
       /* Don't do anything if p_split_vector kills its operand and the
        * definitions already reuse the same registers as the operand.
        */
-      if (split_vec->operands[0].isKill() &&
-          split_vec->operands[0].physReg() == split_vec->definitions[0].physReg())
-         continue;
-
-      /* Don't propagate VGPR to SALU. */
-      if (instr->isSALU() && split_vec->operands[0].regClass().type() == RegType::vgpr)
+      if (!split_op.isTemp() || split_op.isKill())
          continue;
 
-      /* Don't propagate misaligned SGPRs to SALU. */
-      if (instr->isSALU() && op.bytes() > 4 &&
-          (split_vec->operands[0].physReg().reg() % (op.bytes() / 4) != 0))
+      /* Only propagate operands of the same type */
+      if (split_op.getTemp().type() != op.getTemp().type())
          continue;
 
-      /* Only propagate SGPR or constant to VALU when it's already SGPR. */
-      if (instr->isVALU() &&
-          (split_vec->operands[0].isConstant() ||
-           split_vec->operands[0].regClass().type() == RegType::sgpr) &&
-          op.regClass().type() != RegType::sgpr)
+      /* Check if the p_split_vector operand's registers are clobbered. */
+      if (is_overwritten_since(ctx, split_op, op_instr_idx))
          continue;
 
-      int reg_bytes = 0;
+      PhysReg reg = split_op.physReg();
+      for (Definition& def : split_vec->definitions) {
+         if (def.getTemp() != op.getTemp()) {
+            reg = reg.advance(def.bytes());
+            continue;
+         }
 
-      for (unsigned def_idx = 0; def_idx < split_vec->definitions.size(); ++def_idx) {
-         if (split_vec->definitions[def_idx].tempId() == op.tempId())
+         /* Don't propagate misaligned SGPRs.
+          * Note: No ALU instruction can take a variable larger than 64bit.
+          */
+         if (op.regClass() == s2 && reg.reg() % 2 != 0)
             break;
 
-         reg_bytes += split_vec->definitions[def_idx].bytes();
-      }
+         /* If there is only one use (left), recolor the split_vector definition */
+         if (ctx.uses[op.tempId()] == 1)
+            def.setFixed(reg);
+         else
+            ctx.uses[op.tempId()]--;
 
-      /* Use the p_split_vector operand register directly.
-       * Note: unfortunately, this "breaks" SSA to some extent.
-       */
-      ctx.uses[op.tempId()]--;
-      PhysReg reg = split_vec->operands[0].physReg().advance(reg_bytes);
-      instr->operands[i].setFixed(reg);
+         /* Use the p_split_vector operand register directly.
+          *
+          * Note: this might violate register assignment rules to some extend
+          *       in case the definition does not get recolored, eventually.
+          */
+         instr->operands[i].setFixed(reg);
+         break;
+      }
    }
 }
 
-- 
GitLab


From f9a0b49cc809b88f9ca1bd3b0c162aaa73a70109 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Wed, 2 Nov 2022 13:35:57 +0100
Subject: [PATCH 3/3] aco: Reassign dead definitions of p_split_vector to
 associated register

Any unused split_vector definition can always use the same register
as the operand. This avoids creating unnecessary copies.

Totals from 3916 (2.90% of 134913) affected shaders: (GFX10.3)
CodeSize: 18557692 -> 18480848 (-0.41%)
Instrs: 3431690 -> 3412502 (-0.56%)
Latency: 43009681 -> 42999246 (-0.02%); split: -0.03%, +0.00%
InvThroughput: 6710518 -> 6710070 (-0.01%); split: -0.01%, +0.00%
SClause: 130286 -> 130228 (-0.04%)
Copies: 234988 -> 215782 (-8.17%)
---
 src/amd/compiler/aco_optimizer_postRA.cpp | 19 +++++++++++++++++++
 1 file changed, 19 insertions(+)

diff --git a/src/amd/compiler/aco_optimizer_postRA.cpp b/src/amd/compiler/aco_optimizer_postRA.cpp
index 0b287ff50df2..d536284c2d66 100644
--- a/src/amd/compiler/aco_optimizer_postRA.cpp
+++ b/src/amd/compiler/aco_optimizer_postRA.cpp
@@ -539,6 +539,25 @@ try_combine_dpp(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
 void
 try_reassign_split_vector(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
 {
+   /* Any unused split_vector definition can always use the same register
+    * as the operand. This avoids creating unnecessary copies.
+    */
+   if (instr->opcode == aco_opcode::p_split_vector) {
+      Operand& op = instr->operands[0];
+      if (!op.isTemp() || op.isKill())
+         return;
+
+      PhysReg reg = op.physReg();
+      for (Definition& def : instr->definitions) {
+         if (def.getTemp().type() == op.getTemp().type() && def.isKill())
+            def.setFixed(reg);
+
+         reg = reg.advance(def.bytes());
+      }
+
+      return;
+   }
+
    /* We are looking for the following pattern:
     *
     * sA, sB = p_split_vector s[X:Y]
-- 
GitLab

