From da944e17dd9c39d33d0522b1dab0cf152aa32a71 Mon Sep 17 00:00:00 2001
From: Ganesh Belgur Ramachandra <ganesh.belgurramachandra@amd.com>
Date: Wed, 15 Nov 2023 01:12:40 -0600
Subject: [PATCH 1/3] radeonsi: includes nir pass for 64 bit operations

---
 src/gallium/drivers/radeonsi/si_shader_nir.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/src/gallium/drivers/radeonsi/si_shader_nir.c b/src/gallium/drivers/radeonsi/si_shader_nir.c
index c85f7b6af8b2..6681742ffd98 100644
--- a/src/gallium/drivers/radeonsi/si_shader_nir.c
+++ b/src/gallium/drivers/radeonsi/si_shader_nir.c
@@ -272,6 +272,7 @@ static void si_lower_nir(struct si_screen *sscreen, struct nir_shader *nir)
     * - ensure constant offsets for texture instructions are folded
     *   and copy-propagated
     */
+   NIR_PASS_V(nir, nir_lower_int64);
 
    const struct nir_lower_tex_options lower_tex_options = {
       .lower_txp = ~0u,
-- 
GitLab


From 8686c6ac4c14e72830c9e1693c8d0dd8bbb46c77 Mon Sep 17 00:00:00 2001
From: Ganesh Belgur Ramachandra <ganesh.belgurramachandra@amd.com>
Date: Tue, 31 Oct 2023 06:37:33 -0500
Subject: [PATCH 2/3] radeonsi: adds pack_*_unpack_64_2x32 utility functions

---
 .../drivers/radeonsi/si_shaderlib_nir.c       | 66 +++++++++++++++++++
 1 file changed, 66 insertions(+)

diff --git a/src/gallium/drivers/radeonsi/si_shaderlib_nir.c b/src/gallium/drivers/radeonsi/si_shaderlib_nir.c
index 2b4373d16e31..34c0d2f03303 100644
--- a/src/gallium/drivers/radeonsi/si_shaderlib_nir.c
+++ b/src/gallium/drivers/radeonsi/si_shaderlib_nir.c
@@ -49,18 +49,84 @@ static nir_def *get_global_ids(nir_builder *b, unsigned num_components)
    return nir_iadd(b, nir_imul(b, block_ids, block_size), local_ids);
 }
 
+/* unpack_2x16(src, x, y): x = src & 0xffff; y = src >> 16; */
 static void unpack_2x16(nir_builder *b, nir_def *src, nir_def **x, nir_def **y)
 {
    *x = nir_iand_imm(b, src, 0xffff);
    *y = nir_ushr_imm(b, src, 16);
 }
 
+/* unpack_2x16_signed(src, x, y): x = (int32_t)((uint16_t)src); y = src >> 16; */
 static void unpack_2x16_signed(nir_builder *b, nir_def *src, nir_def **x, nir_def **y)
 {
    *x = nir_i2i32(b, nir_u2u16(b, src));
    *y = nir_ishr_imm(b, src, 16);
 }
 
+/* pack_iadd_unpack_64_2x32(src0, src1, src2, src3):
+ *   uint64_t sum = (src0 | ((uint64_t)src1 << 32)) + (src2 | ((uint64_t)src3 << 32));
+ *   dst.x = sum.x; dst.y = sum.x >> 32;
+ */
+static nir_def *
+pack_iadd_unpack_64_2x32(nir_builder *build,
+                         nir_def *src0, nir_def *src1,
+                         nir_def *src2, nir_def *src3)
+{
+   nir_def *first = nir_pack_64_2x32_split(build, src0, src1);
+   nir_def *second = nir_pack_64_2x32_split(build, src2, src3);
+   nir_def *sum = nir_iadd(build, first, second);
+
+   return nir_unpack_64_2x32(build, sum);
+}
+
+/* pack_isub_unpack_64_2x32(src0, src1, src2, src3):
+ *   uint64_t difference = (src0 | ((uint64_t)src1 << 32)) - (src2 | ((uint64_t)src3 << 32));
+ *   dst.x = difference.x; dst.y = difference.x >> 32;
+ */
+static nir_def *
+pack_isub_unpack_64_2x32(nir_builder *build,
+                         nir_def *src0, nir_def *src1,
+                         nir_def *src2, nir_def *src3)
+{
+   nir_def *first = nir_pack_64_2x32_split(build, src0, src1);
+   nir_def *second = nir_pack_64_2x32_split(build, src2, src3);
+   nir_def *difference = nir_isub(build, first, second);
+
+   return nir_unpack_64_2x32(build, difference);
+}
+
+/* pack_imul_unpack_64_2x32(src0, src1, src2, src3):
+ *   uint64_t product = (src0 | ((uint64_t)src1 << 32)) * (src2 | ((uint64_t)src3 << 32));
+ *   dst.x = product.x; dst.y = product.x >> 32;
+ */
+static nir_def *
+pack_imul_unpack_64_2x32(nir_builder *build,
+                         nir_def *src0, nir_def *src1,
+                         nir_def *src2, nir_def *src3)
+{
+   nir_def *first = nir_pack_64_2x32_split(build, src0, src1);
+   nir_def *second = nir_pack_64_2x32_split(build, src2, src3);
+   nir_def *product = nir_imul(build, first, second);
+
+   return nir_unpack_64_2x32(build, product);
+}
+
+/* pack_udiv_unpack_64_2x32(src0, src1, src2, src3):
+ *   uint64_t quotient = (src0 | ((uint64_t)src1 << 32)) / (src2 | ((uint64_t)src3 << 32));
+ *   dst.x = quotient.x; dst.y = quotient.x >> 32;
+ */
+static nir_def *
+pack_udiv_unpack_64_2x32(nir_builder *build,
+                         nir_def *src0, nir_def *src1,
+                         nir_def *src2, nir_def *src3)
+{
+   nir_def *first = nir_pack_64_2x32_split(build, src0, src1);
+   nir_def *second = nir_pack_64_2x32_split(build, src2, src3);
+   nir_def *quotient = nir_udiv(build, first, second);
+
+   return nir_unpack_64_2x32(build, quotient);
+}
+
 static nir_def *
 deref_ssa(nir_builder *b, nir_variable *var)
 {
-- 
GitLab


From d32b8062a7c1ba0008b4aff13c5a856fdcf82045 Mon Sep 17 00:00:00 2001
From: Ganesh Belgur Ramachandra <ganesh.belgurramachandra@amd.com>
Date: Fri, 29 Sep 2023 13:00:49 -0500
Subject: [PATCH 3/3] radeonsi: "create_query_result_cs" shader in nir

---
 src/gallium/drivers/radeonsi/si_pipe.h        |   2 +-
 .../drivers/radeonsi/si_shaderlib_nir.c       | 406 ++++++++++++++++++
 .../drivers/radeonsi/si_shaderlib_tgsi.c      | 215 ----------
 3 files changed, 407 insertions(+), 216 deletions(-)

diff --git a/src/gallium/drivers/radeonsi/si_pipe.h b/src/gallium/drivers/radeonsi/si_pipe.h
index 83e18a1f1c23..77650ddbc1c3 100644
--- a/src/gallium/drivers/radeonsi/si_pipe.h
+++ b/src/gallium/drivers/radeonsi/si_pipe.h
@@ -1656,9 +1656,9 @@ void *si_create_clear_buffer_rmw_cs(struct si_context *sctx);
 void *si_clear_render_target_shader(struct si_context *sctx, enum pipe_texture_target type);
 void *si_clear_12bytes_buffer_shader(struct si_context *sctx);
 void *si_create_fmask_expand_cs(struct si_context *sctx, unsigned num_samples, bool is_array);
+void *si_create_query_result_cs(struct si_context *sctx);
 
 /* si_shaderlib_tgsi.c */
-void *si_create_query_result_cs(struct si_context *sctx);
 void *gfx11_create_sh_query_result_cs(struct si_context *sctx);
 
 /* gfx11_query.c */
diff --git a/src/gallium/drivers/radeonsi/si_shaderlib_nir.c b/src/gallium/drivers/radeonsi/si_shaderlib_nir.c
index 34c0d2f03303..6188e7bed262 100644
--- a/src/gallium/drivers/radeonsi/si_shaderlib_nir.c
+++ b/src/gallium/drivers/radeonsi/si_shaderlib_nir.c
@@ -928,3 +928,409 @@ void *si_get_blitter_vs(struct si_context *sctx, enum blitter_attrib_type type,
    *vs = create_shader_state(sctx, b.shader);
    return *vs;
 }
+
+/* Create the compute shader that is used to collect the results.
+ *
+ * One compute grid with a single thread is launched for every query result
+ * buffer. The thread (optionally) reads a previous summary buffer, then
+ * accumulates data from the query result buffer, and writes the result either
+ * to a summary buffer to be consumed by the next grid invocation or to the
+ * user-supplied buffer.
+ *
+ * Data layout:
+ *
+ * CONST
+ *  0.x = end_offset
+ *  0.y = result_stride
+ *  0.z = result_count
+ *  0.w = bit field:
+ *          1: read previously accumulated values
+ *          2: write accumulated values for chaining
+ *          4: write result available
+ *          8: convert result to boolean (0/1)
+ *         16: only read one dword and use that as result
+ *         32: apply timestamp conversion
+ *         64: store full 64 bits result
+ *        128: store signed 32 bits result
+ *        256: SO_OVERFLOW mode: take the difference of two successive half-pairs
+ *  1.x = fence_offset
+ *  1.y = pair_stride
+ *  1.z = pair_count
+ *
+ */
+void *si_create_query_result_cs(struct si_context *sctx)
+{
+   const nir_shader_compiler_options *options =
+      sctx->b.screen->get_compiler_options(sctx->b.screen, PIPE_SHADER_IR_NIR, PIPE_SHADER_COMPUTE);
+
+   nir_builder b =
+      nir_builder_init_simple_shader(MESA_SHADER_COMPUTE, options, "create_query_result_cs");
+   b.shader->info.workgroup_size[0] = 1;
+   b.shader->info.workgroup_size[1] = 1;
+   b.shader->info.workgroup_size[2] = 1;
+   b.shader->info.num_ubos = 1;
+   b.shader->info.num_ssbos = 3;
+   b.shader->num_uniforms = 2;
+
+   nir_def *var_undef = nir_undef(&b, 1, 32);
+   nir_def *zero = nir_imm_int(&b, 0);
+   nir_def *one = nir_imm_int(&b, 1);
+   nir_def *two = nir_imm_int(&b, 2);
+   nir_def *four = nir_imm_int(&b, 4);
+   nir_def *eight = nir_imm_int(&b, 8);
+   nir_def *sixteen = nir_imm_int(&b, 16);
+   nir_def *thirty_one = nir_imm_int(&b, 31);
+   nir_def *sixty_four = nir_imm_int(&b, 64);
+   nir_def *million = nir_imm_int(&b, 1000000);
+
+   /* Add the frequency into the shader for timestamp conversion
+    * so that the backend can use the full range of optimizations
+    * for divide-by-constant.
+    */
+   nir_def *clock_crystal_frequency = nir_imm_int(&b, sctx->screen->info.clock_crystal_freq);
+
+   /* uint32_t x, y, z = 0; */
+   nir_function_impl *e = nir_shader_get_entrypoint(b.shader);
+   nir_variable *x = nir_local_variable_create(e, glsl_uint_type(), "x");
+   nir_store_var(&b, x, var_undef, 0x1);
+   nir_variable *y = nir_local_variable_create(e, glsl_uint_type(), "y");
+   nir_store_var(&b, y, var_undef, 0x1);
+   nir_variable *z = nir_local_variable_create(e, glsl_uint_type(), "z");
+   nir_store_var(&b, z, zero, 0x1);
+
+   /* uint32_t ubo_1[4] = load_ubo(0, 0);
+    * uint32_t w = ubo_1[3];
+    * uint32_t ubo_2[4] = load_ubo(1, 16);
+    */
+   nir_def *ubo_1 = nir_load_ubo(&b, 4, 32, zero, zero, .range_base = 0, .range = 16);
+   nir_def *w = nir_channel(&b, ubo_1, 3);
+   nir_def *ubo_2 = nir_load_ubo(&b, 4, 32, zero, sixteen, .range_base = 16, .range = 16);
+
+   /* Check result availability.
+    *    if (w & (1u << 4) != 0) {
+    *       ...
+    */
+   nir_def *fifth_bit = nir_iand(&b, w, sixteen);
+   nir_if *if_fifth_bit_not_zero = nir_push_if(&b, nir_ine(&b, fifth_bit, zero)); {
+
+      /*   int32_t value = load_ssbo(0, ubo_2.x);
+       *   z = ~(value >> 31);
+       */
+      nir_def *value = nir_load_ssbo(&b, 1, 32, zero, nir_channel(&b, ubo_2, 0));
+      nir_def *bitmask = nir_inot(&b, nir_ishr(&b, value, thirty_one));
+      nir_store_var(&b, z, bitmask, 0x1);
+
+      /* Load result if available.
+       *    if (value < 0) {
+       *       uint32_t result[2] = load_ssbo(0, 0);
+       *       x = result[0];
+       *       y = result[1];
+       *    }
+       */
+      nir_if *if_less_than_zero = nir_push_if(&b, nir_ilt(&b, value, zero)); {
+         nir_def *result = nir_load_ssbo(&b, 2, 32, zero, zero);
+         nir_store_var(&b, x, nir_channel(&b, result, 0), 0x1);
+         nir_store_var(&b, y, nir_channel(&b, result, 1), 0x1);
+      }
+      nir_pop_if(&b, if_less_than_zero);
+   } nir_push_else(&b, if_fifth_bit_not_zero); {
+
+      /* } else {
+       *    x = 0; y = 0;
+       */
+      nir_store_var(&b, x, zero, 0x1);
+      nir_store_var(&b, y, zero, 0x1);
+
+      /* Load previously accumulated result if requested.
+       *    if (w & (1u << 0) != 0) {
+       *       uint32_t result[3] = load_ssbo(1, 0);
+       *       x = result[0];
+       *       y = result[1];
+       *       z = result[2];
+       *    }
+       */
+      nir_def *first_bit = nir_iand(&b, w, one);
+      nir_if *if_first_bit_not_zero = nir_push_if(&b, nir_ine(&b, first_bit, zero)); {
+         nir_def *result = nir_load_ssbo(&b, 3, 32, one, zero);
+         nir_store_var(&b, x, nir_channel(&b, result, 0), 0x1);
+         nir_store_var(&b, y, nir_channel(&b, result, 1), 0x1);
+         nir_store_var(&b, z, nir_channel(&b, result, 2), 0x1);
+      }
+      nir_pop_if(&b, if_first_bit_not_zero);
+
+      /* if (z == 0) {
+       *    uint32_t result_index = 0;
+       *    uint32_t pitch = 0;
+       *    ...
+       */
+      nir_def *z_value = nir_load_var(&b, z);
+      nir_if *if_z_value_zero = nir_push_if(&b, nir_ieq(&b, z_value, zero)); {
+         nir_variable *outer_loop_iter =
+            nir_local_variable_create(e, glsl_uint_type(), "outer_loop_iter");
+         nir_store_var(&b, outer_loop_iter, zero, 0x1);
+         nir_variable *pitch = nir_local_variable_create(e, glsl_uint_type(), "pitch");
+         nir_store_var(&b, pitch, zero, 0x1);
+
+         /* Outer loop.
+          *   while (result_index <= ubo_1.z) {
+          *      ...
+          */
+         nir_loop *loop_outer = nir_push_loop(&b); {
+
+            /* Break if result_index >= result_count. */
+            nir_def *result_index = nir_load_var(&b, outer_loop_iter);
+            nir_def *is_result_index_out_of_bound =
+               nir_uge(&b, result_index, nir_channel(&b, ubo_1, 2));
+            nir_if *if_out_of_bound = nir_push_if(&b, is_result_index_out_of_bound); {
+               nir_jump(&b, nir_jump_break);
+            }
+            nir_pop_if(&b, if_out_of_bound);
+
+            /* Load fence and check result availability.
+             *    pitch = i * ubo_1.y;
+             *    uint32_t address = ubo_2.x + pitch;
+             *    int32_t value = load_ssbo(0, address);
+             *    z = ~(value >> 31);
+             */
+            nir_def *pitch_outer_loop = nir_imul(&b, result_index, nir_channel(&b, ubo_1, 1));
+            nir_store_var(&b, pitch, pitch_outer_loop, 0x1);
+            nir_def *address = nir_iadd(&b, pitch_outer_loop, nir_channel(&b, ubo_2, 0));
+            nir_def *value = nir_load_ssbo(&b, 1, 32, zero, address);
+            nir_def *bitmask = nir_inot(&b, nir_ishr(&b, value, thirty_one));
+            nir_store_var(&b, z, bitmask, 0x1);
+
+            /*    if (z != 0) {
+             *       break;
+             *    }
+             */
+            nir_def *is_result_available = nir_ine(&b, bitmask, zero);
+            nir_if *if_result_available = nir_push_if(&b, is_result_available); {
+               nir_jump(&b, nir_jump_break);
+            }
+            nir_pop_if(&b, if_result_available);
+
+            /* Inner loop iterator.
+             *    uint32_t i = 0;
+             */
+            nir_variable *inner_loop_iter =
+               nir_local_variable_create(e, glsl_uint_type(), "inner_loop_iter");
+            nir_store_var(&b, inner_loop_iter, zero, 0x1);
+
+            /* Inner loop.
+             *    while (i <= ubo_2.z) {
+             *       ...
+             */
+            nir_loop *loop_inner = nir_push_loop(&b); {
+               nir_def *pitch_inner_loop = nir_load_var(&b, pitch);
+               nir_def *i = nir_load_var(&b, inner_loop_iter);
+
+               /* Load start and end.
+                * Note: pack_64_2x32(s[2]): (s[0] | (uint64_t) s[1] << 32);
+                *    uint32_t first[2] = load_ssbo(0, pitch);
+                *    uint32_t second[2] = load_ssbo(0, pitch + ubo_1.x);
+                *    uint64_t difference = pack_64_2x32(second) - pack_64_2x32(first);
+                */
+               nir_def *first = nir_load_ssbo(&b, 2, 32, zero, pitch_inner_loop);
+               nir_def *new_pitch = nir_iadd(&b, pitch_inner_loop, nir_channel(&b, ubo_1, 0));
+               nir_def *second = nir_load_ssbo(&b, 2, 32, zero, new_pitch);
+               nir_def *start_half_pair = pack_isub_unpack_64_2x32(&b,
+                                                                  nir_channel(&b, second, 0),
+                                                                  nir_channel(&b, second, 1),
+                                                                  nir_channel(&b, first, 0),
+                                                                  nir_channel(&b, first, 1));
+
+               /* Load second start/end half-pair and take the difference.
+                * Note: pack_64_2x32(s[2]): (s[0] | (uint64_t) s[1] << 32);
+                *    if (w & (1u << 8) != 0) {
+                *       uint32_t first[2] = load_ssbo(0, pitch + 8);
+                *       uint32_t second[2] = load_ssbo(0, pitch + ubo_1.x + 8);
+                *       uint64_t end_half_pair = pack_64_2x32(second) - pack_64_2x32(first);
+                *       difference = difference - end_half_pair;
+                *    }
+                */
+               nir_def *x_1, *y_1, *x_2, *y_2;
+               nir_def *ninth_bit = nir_iand(&b, w, nir_imm_int(&b, 256));
+               nir_if *if_ninth_bit_not_zero = nir_push_if(&b, nir_ine(&b, ninth_bit, zero)); {
+                  first = nir_load_ssbo(&b, 2, 32, zero, nir_iadd(&b, pitch_inner_loop, eight));
+                  second = nir_load_ssbo(&b, 2, 32, zero, nir_iadd(&b, new_pitch, eight));
+
+                  nir_def *end_half_pair = pack_isub_unpack_64_2x32(&b,
+                                                                    nir_channel(&b, second, 0),
+                                                                    nir_channel(&b, second, 1),
+                                                                    nir_channel(&b, first, 0),
+                                                                    nir_channel(&b, first, 1));
+
+                  nir_def *difference = pack_isub_unpack_64_2x32(&b,
+                                                                 nir_channel(&b, start_half_pair, 0),
+                                                                 nir_channel(&b, start_half_pair, 1),
+                                                                 nir_channel(&b, end_half_pair, 0),
+                                                                 nir_channel(&b, end_half_pair, 1));
+
+                  x_1 = nir_channel(&b, difference, 0);
+                  y_1 = nir_channel(&b, difference, 1);
+               } nir_push_else(&b, if_ninth_bit_not_zero); {
+                  x_2 = nir_channel(&b, start_half_pair, 0);
+                  y_2 = nir_channel(&b, start_half_pair, 1);
+               }
+               nir_pop_if(&b, if_ninth_bit_not_zero);
+
+               /* uint64_t sum = (x | (uint64_t) y << 32) + difference; */
+               nir_def *sum = pack_iadd_unpack_64_2x32(&b,
+                                                      nir_load_var(&b, x),
+                                                      nir_load_var(&b, y),
+                                                      nir_if_phi(&b, x_1, x_2),
+                                                      nir_if_phi(&b, y_1, y_2));
+
+               /* Increment inner loop iterator.
+                *    i++;
+                */
+               i = nir_iadd(&b, i, one);
+               nir_store_var(&b, inner_loop_iter, i, 0x1);
+
+               /* Update pitch value.
+                *    pitch = i * ubo_2.y + pitch;
+                */
+               nir_def *incremented_pitch = nir_iadd(&b,
+                                             nir_imul(&b, i, nir_channel(&b, ubo_2, 1)),
+                                             pitch_outer_loop);
+               nir_store_var(&b, pitch, incremented_pitch, 0x1);
+
+               /* Update x and y.
+                *    x = sum.x;
+                *    y = sum.x >> 32;
+                */
+               nir_store_var(&b, x, nir_channel(&b, sum, 0), 0x1);
+               nir_store_var(&b, y, nir_channel(&b, sum, 1), 0x1);
+
+               nir_def *is_greater_than_equal = nir_uge(&b, i, nir_channel(&b, ubo_2, 2));
+               nir_if *if_greater_than_equal = nir_push_if(&b, is_greater_than_equal); {
+                  nir_jump(&b, nir_jump_break);
+               }
+               nir_pop_if(&b, if_greater_than_equal);
+            }
+            nir_pop_loop(&b, loop_inner);
+
+            /* Increment pair iterator.
+             *    result_index++;
+             */
+            nir_store_var(&b, outer_loop_iter, nir_iadd(&b, result_index, one), 0x1);
+         }
+         nir_pop_loop(&b, loop_outer);
+      }
+      nir_pop_if(&b, if_z_value_zero);
+   }
+   nir_pop_if(&b, if_fifth_bit_not_zero);
+
+   nir_def *x_value = nir_load_var(&b, x);
+   nir_def *y_value = nir_load_var(&b, y);
+   nir_def *z_value = nir_load_var(&b, z);
+
+   /* Store accumulated data for chaining.
+    *    if (w & (1u << 1) != 0) {
+    *       store_ssbo(<x, y, z>, 2, 0);
+    */
+   nir_def *second_bit = nir_iand(&b, w, two);
+   nir_if *if_second_bit_not_zero = nir_push_if(&b, nir_ine(&b, second_bit, zero)); {
+      nir_store_ssbo(&b, nir_vec3(&b, x_value, y_value, z_value), two, zero);
+   } nir_push_else(&b, if_second_bit_not_zero); {
+
+      /* Store result availability.
+       *    } else {
+       *       if (w & (1u << 2) != 0) {
+       *          store_ssbo((~z & 1), 2, 0);
+       *          ...
+       */
+      nir_def *third_bit = nir_iand(&b, w, four);
+      nir_if *if_third_bit_not_zero = nir_push_if(&b, nir_ine(&b, third_bit, zero)); {
+         nir_def* not_z = nir_inot(&b, z_value);
+         nir_store_ssbo(&b, nir_iand(&b, not_z, one), two, zero);
+
+         /* Store full 64 bits result.
+          *    if (w & (1u << 6) != 0) {
+          *       store_ssbo(<0, 0>, 2, 0);
+          *    }
+          */
+         nir_def *seventh_bit = nir_iand(&b, w, sixty_four);
+         nir_if *if_seventh_bit_not_zero = nir_push_if(&b, nir_ine(&b, seventh_bit, zero)); {
+            nir_store_ssbo(&b, nir_imm_ivec2(&b, 0, 0), two, zero,
+                           .write_mask = (1u << 1));
+         }
+         nir_pop_if(&b, if_seventh_bit_not_zero);
+      } nir_push_else(&b, if_third_bit_not_zero); {
+
+         /* } else {
+          *    if (~z != 0) {
+          *       ...
+          */
+         nir_def *not_z = nir_inot(&b, z_value);
+         nir_if *if_not_z_not_zero = nir_push_if(&b, nir_ine(&b, not_z, zero)); {
+            nir_def *x_limit, *y_limit;
+
+            /* Apply timestamp conversion.
+             *    if (w & (1u << 5) != 0) {
+             *       uint64_t product = (x | (uint64_t) y << 32) * (uint64_t) 1000000;
+             *       uint64_t quotient = product / (uint64_t) clock_crystal_frequency;
+             *       x = quotient.x;
+             *       y = quotient.x >> 32;
+             *    }
+             */
+            nir_def *sixth_bit = nir_iand(&b, w, nir_imm_int(&b, 32));
+            nir_if *if_sixth_bit_not_zero = nir_push_if(&b, nir_ine(&b, sixth_bit, zero)); {
+               nir_def *product = pack_imul_unpack_64_2x32(&b, x_value, y_value, million, zero);
+               nir_def *quotient = pack_udiv_unpack_64_2x32(&b,
+                                                            nir_channel(&b, product, 0),
+                                                            nir_channel(&b, product, 1),
+                                                            clock_crystal_frequency,
+                                                            zero);
+               x_limit = nir_channel(&b, quotient, 0);
+               y_limit = nir_channel(&b, quotient, 1);
+            }
+            nir_pop_if(&b, if_sixth_bit_not_zero);
+
+            nir_def *new_x_value = nir_if_phi(&b, x_limit, x_value);
+            nir_def *new_y_value = nir_if_phi(&b, y_limit, y_value);
+
+            /* x = (w & (1u << 3) != 0) ? ((x | (uint64_t) y << 32) != 0) : x;
+             * y = (w & (1u << 3) != 0) ? 0 : y;
+             */
+            nir_def *fourth_bit = nir_iand(&b, w, eight);
+            nir_def *is_fourth_bit_zero = nir_ine(&b, fourth_bit, zero);
+            nir_def *xy = nir_pack_64_2x32_split(&b, new_x_value, new_y_value);
+            nir_def *is_not_zero_xy = nir_b2i32(&b, nir_ine(&b, xy, nir_imm_int64(&b, 0)));
+            new_x_value = nir_bcsel(&b, is_fourth_bit_zero, is_not_zero_xy, new_x_value);
+            new_y_value = nir_bcsel(&b, is_fourth_bit_zero, zero, new_y_value);
+
+            /* if (w & (1u << 6) != 0) {
+             *    store_ssbo(<x, y>, 2, 0);
+             * }
+             */
+            nir_def *seventh_bit = nir_iand(&b, w, sixty_four);
+            nir_if *if_seventh_bit_not_zero = nir_push_if(&b, nir_ine(&b, seventh_bit, zero)); {
+               nir_store_ssbo(&b, nir_vec2(&b, new_x_value, new_y_value), two, zero);
+            } nir_push_else(&b, if_seventh_bit_not_zero); {
+
+               /* Clamping.
+                *    } else {
+                *       x = (y != 0) ? UINT32_MAX : x;
+                *       x = (w & (1u << 7) != 0) ? min(x, INT_MAX) : x;
+                *       store_ssbo(x, 2, 0);
+                *    }
+                */
+               nir_def *is_not_zero = nir_ine(&b, new_y_value, zero);
+               new_x_value = nir_bcsel(&b, is_not_zero, nir_imm_int(&b, UINT32_MAX), new_x_value);
+               nir_def *eighth_bit = nir_iand(&b, w, nir_imm_int(&b, 128));
+               nir_def *is_eighth_bit_not_zero = nir_ine(&b, eighth_bit, zero);
+               nir_def *min = nir_umin(&b, new_x_value, nir_imm_int(&b, INT_MAX));
+               new_x_value = nir_bcsel(&b, is_eighth_bit_not_zero, min, new_x_value);
+               nir_store_ssbo(&b, new_x_value, two, zero);
+            }
+            nir_pop_if(&b, if_seventh_bit_not_zero);
+         }
+         nir_pop_if(&b, if_not_z_not_zero);
+      }
+      nir_pop_if(&b, if_third_bit_not_zero);
+   }
+   nir_pop_if(&b, if_second_bit_not_zero);
+
+   return create_shader_state(sctx, b.shader);
+}
diff --git a/src/gallium/drivers/radeonsi/si_shaderlib_tgsi.c b/src/gallium/drivers/radeonsi/si_shaderlib_tgsi.c
index 13acc4eefc7f..2eab564ca26e 100644
--- a/src/gallium/drivers/radeonsi/si_shaderlib_tgsi.c
+++ b/src/gallium/drivers/radeonsi/si_shaderlib_tgsi.c
@@ -8,221 +8,6 @@
 #include "tgsi/tgsi_text.h"
 #include "tgsi/tgsi_ureg.h"
 
-/* Create the compute shader that is used to collect the results.
- *
- * One compute grid with a single thread is launched for every query result
- * buffer. The thread (optionally) reads a previous summary buffer, then
- * accumulates data from the query result buffer, and writes the result either
- * to a summary buffer to be consumed by the next grid invocation or to the
- * user-supplied buffer.
- *
- * Data layout:
- *
- * CONST
- *  0.x = end_offset
- *  0.y = result_stride
- *  0.z = result_count
- *  0.w = bit field:
- *          1: read previously accumulated values
- *          2: write accumulated values for chaining
- *          4: write result available
- *          8: convert result to boolean (0/1)
- *         16: only read one dword and use that as result
- *         32: apply timestamp conversion
- *         64: store full 64 bits result
- *        128: store signed 32 bits result
- *        256: SO_OVERFLOW mode: take the difference of two successive half-pairs
- *  1.x = fence_offset
- *  1.y = pair_stride
- *  1.z = pair_count
- *
- * BUFFER[0] = query result buffer
- * BUFFER[1] = previous summary buffer
- * BUFFER[2] = next summary buffer or user-supplied buffer
- */
-void *si_create_query_result_cs(struct si_context *sctx)
-{
-   /* TEMP[0].xy = accumulated result so far
-    * TEMP[0].z = result not available
-    *
-    * TEMP[1].x = current result index
-    * TEMP[1].y = current pair index
-    */
-   static const char text_tmpl[] =
-      "COMP\n"
-      "PROPERTY CS_FIXED_BLOCK_WIDTH 1\n"
-      "PROPERTY CS_FIXED_BLOCK_HEIGHT 1\n"
-      "PROPERTY CS_FIXED_BLOCK_DEPTH 1\n"
-      "DCL BUFFER[0]\n"
-      "DCL BUFFER[1]\n"
-      "DCL BUFFER[2]\n"
-      "DCL CONST[0][0..1]\n"
-      "DCL TEMP[0..5]\n"
-      "IMM[0] UINT32 {0, 31, 2147483647, 4294967295}\n"
-      "IMM[1] UINT32 {1, 2, 4, 8}\n"
-      "IMM[2] UINT32 {16, 32, 64, 128}\n"
-      "IMM[3] UINT32 {1000000, 0, %u, 0}\n" /* for timestamp conversion */
-      "IMM[4] UINT32 {256, 0, 0, 0}\n"
-
-      "AND TEMP[5], CONST[0][0].wwww, IMM[2].xxxx\n"
-      "UIF TEMP[5]\n"
-      /* Check result availability. */
-      "LOAD TEMP[1].x, BUFFER[0], CONST[0][1].xxxx\n"
-      "ISHR TEMP[0].z, TEMP[1].xxxx, IMM[0].yyyy\n"
-      "MOV TEMP[1], TEMP[0].zzzz\n"
-      "NOT TEMP[0].z, TEMP[0].zzzz\n"
-
-      /* Load result if available. */
-      "UIF TEMP[1]\n"
-      "LOAD TEMP[0].xy, BUFFER[0], IMM[0].xxxx\n"
-      "ENDIF\n"
-      "ELSE\n"
-      /* Load previously accumulated result if requested. */
-      "MOV TEMP[0], IMM[0].xxxx\n"
-      "AND TEMP[4], CONST[0][0].wwww, IMM[1].xxxx\n"
-      "UIF TEMP[4]\n"
-      "LOAD TEMP[0].xyz, BUFFER[1], IMM[0].xxxx\n"
-      "ENDIF\n"
-
-      "MOV TEMP[1].x, IMM[0].xxxx\n"
-      "BGNLOOP\n"
-      /* Break if accumulated result so far is not available. */
-      "UIF TEMP[0].zzzz\n"
-      "BRK\n"
-      "ENDIF\n"
-
-      /* Break if result_index >= result_count. */
-      "USGE TEMP[5], TEMP[1].xxxx, CONST[0][0].zzzz\n"
-      "UIF TEMP[5]\n"
-      "BRK\n"
-      "ENDIF\n"
-
-      /* Load fence and check result availability */
-      "UMAD TEMP[5].x, TEMP[1].xxxx, CONST[0][0].yyyy, CONST[0][1].xxxx\n"
-      "LOAD TEMP[5].x, BUFFER[0], TEMP[5].xxxx\n"
-      "ISHR TEMP[0].z, TEMP[5].xxxx, IMM[0].yyyy\n"
-      "NOT TEMP[0].z, TEMP[0].zzzz\n"
-      "UIF TEMP[0].zzzz\n"
-      "BRK\n"
-      "ENDIF\n"
-
-      "MOV TEMP[1].y, IMM[0].xxxx\n"
-      "BGNLOOP\n"
-      /* Load start and end. */
-      "UMUL TEMP[5].x, TEMP[1].xxxx, CONST[0][0].yyyy\n"
-      "UMAD TEMP[5].x, TEMP[1].yyyy, CONST[0][1].yyyy, TEMP[5].xxxx\n"
-      "LOAD TEMP[2].xy, BUFFER[0], TEMP[5].xxxx\n"
-
-      "UADD TEMP[5].y, TEMP[5].xxxx, CONST[0][0].xxxx\n"
-      "LOAD TEMP[3].xy, BUFFER[0], TEMP[5].yyyy\n"
-
-      "U64ADD TEMP[4].xy, TEMP[3], -TEMP[2]\n"
-
-      "AND TEMP[5].z, CONST[0][0].wwww, IMM[4].xxxx\n"
-      "UIF TEMP[5].zzzz\n"
-      /* Load second start/end half-pair and
-       * take the difference
-       */
-      "UADD TEMP[5].xy, TEMP[5], IMM[1].wwww\n"
-      "LOAD TEMP[2].xy, BUFFER[0], TEMP[5].xxxx\n"
-      "LOAD TEMP[3].xy, BUFFER[0], TEMP[5].yyyy\n"
-
-      "U64ADD TEMP[3].xy, TEMP[3], -TEMP[2]\n"
-      "U64ADD TEMP[4].xy, TEMP[4], -TEMP[3]\n"
-      "ENDIF\n"
-
-      "U64ADD TEMP[0].xy, TEMP[0], TEMP[4]\n"
-
-      /* Increment pair index */
-      "UADD TEMP[1].y, TEMP[1].yyyy, IMM[1].xxxx\n"
-      "USGE TEMP[5], TEMP[1].yyyy, CONST[0][1].zzzz\n"
-      "UIF TEMP[5]\n"
-      "BRK\n"
-      "ENDIF\n"
-      "ENDLOOP\n"
-
-      /* Increment result index */
-      "UADD TEMP[1].x, TEMP[1].xxxx, IMM[1].xxxx\n"
-      "ENDLOOP\n"
-      "ENDIF\n"
-
-      "AND TEMP[4], CONST[0][0].wwww, IMM[1].yyyy\n"
-      "UIF TEMP[4]\n"
-      /* Store accumulated data for chaining. */
-      "STORE BUFFER[2].xyz, IMM[0].xxxx, TEMP[0]\n"
-      "ELSE\n"
-      "AND TEMP[4], CONST[0][0].wwww, IMM[1].zzzz\n"
-      "UIF TEMP[4]\n"
-      /* Store result availability. */
-      "NOT TEMP[0].z, TEMP[0]\n"
-      "AND TEMP[0].z, TEMP[0].zzzz, IMM[1].xxxx\n"
-      "STORE BUFFER[2].x, IMM[0].xxxx, TEMP[0].zzzz\n"
-
-      "AND TEMP[4], CONST[0][0].wwww, IMM[2].zzzz\n"
-      "UIF TEMP[4]\n"
-      "STORE BUFFER[2].y, IMM[0].xxxx, IMM[0].xxxx\n"
-      "ENDIF\n"
-      "ELSE\n"
-      /* Store result if it is available. */
-      "NOT TEMP[4], TEMP[0].zzzz\n"
-      "UIF TEMP[4]\n"
-      /* Apply timestamp conversion */
-      "AND TEMP[4], CONST[0][0].wwww, IMM[2].yyyy\n"
-      "UIF TEMP[4]\n"
-      "U64MUL TEMP[0].xy, TEMP[0], IMM[3].xyxy\n"
-      "U64DIV TEMP[0].xy, TEMP[0], IMM[3].zwzw\n"
-      "ENDIF\n"
-
-      /* Convert to boolean */
-      "AND TEMP[4], CONST[0][0].wwww, IMM[1].wwww\n"
-      "UIF TEMP[4]\n"
-      "U64SNE TEMP[0].x, TEMP[0].xyxy, IMM[4].zwzw\n"
-      "AND TEMP[0].x, TEMP[0].xxxx, IMM[1].xxxx\n"
-      "MOV TEMP[0].y, IMM[0].xxxx\n"
-      "ENDIF\n"
-
-      "AND TEMP[4], CONST[0][0].wwww, IMM[2].zzzz\n"
-      "UIF TEMP[4]\n"
-      "STORE BUFFER[2].xy, IMM[0].xxxx, TEMP[0].xyxy\n"
-      "ELSE\n"
-      /* Clamping */
-      "UIF TEMP[0].yyyy\n"
-      "MOV TEMP[0].x, IMM[0].wwww\n"
-      "ENDIF\n"
-
-      "AND TEMP[4], CONST[0][0].wwww, IMM[2].wwww\n"
-      "UIF TEMP[4]\n"
-      "UMIN TEMP[0].x, TEMP[0].xxxx, IMM[0].zzzz\n"
-      "ENDIF\n"
-
-      "STORE BUFFER[2].x, IMM[0].xxxx, TEMP[0].xxxx\n"
-      "ENDIF\n"
-      "ENDIF\n"
-      "ENDIF\n"
-      "ENDIF\n"
-
-      "END\n";
-
-   char text[sizeof(text_tmpl) + 32];
-   struct tgsi_token tokens[1024];
-   struct pipe_compute_state state = {};
-
-   /* Hard code the frequency into the shader so that the backend can
-    * use the full range of optimizations for divide-by-constant.
-    */
-   snprintf(text, sizeof(text), text_tmpl, sctx->screen->info.clock_crystal_freq);
-
-   if (!tgsi_text_translate(text, tokens, ARRAY_SIZE(tokens))) {
-      assert(false);
-      return NULL;
-   }
-
-   state.ir_type = PIPE_SHADER_IR_TGSI;
-   state.prog = tokens;
-
-   return sctx->b.create_compute_state(&sctx->b, &state);
-}
-
 /* Create the compute shader that is used to collect the results of gfx10+
  * shader queries.
  *
-- 
GitLab

