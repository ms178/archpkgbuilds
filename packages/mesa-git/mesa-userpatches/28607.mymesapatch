From 6b32f0de147479efe5e2dd7cca9a92d14128f98e Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Sun, 17 Mar 2024 16:49:53 -0400
Subject: [PATCH 1/9] ac/surface: add radeon_surf::thick_tiling

It's not worth writing a compute shader for copying 3D textures yet.
I have a sophisticated compute shader that will do it properly.
---
 src/amd/common/ac_surface.c | 4 ++++
 src/amd/common/ac_surface.h | 2 ++
 2 files changed, 6 insertions(+)

diff --git a/src/amd/common/ac_surface.c b/src/amd/common/ac_surface.c
index 6e881cf16690a..40d5ba24a01fe 100644
--- a/src/amd/common/ac_surface.c
+++ b/src/amd/common/ac_surface.c
@@ -1506,6 +1506,8 @@ static int gfx6_compute_surface(ADDR_HANDLE addrlib, const struct radeon_info *i
    surf->is_displayable = surf->is_linear || surf->micro_tile_mode == RADEON_MICRO_MODE_DISPLAY ||
                           surf->micro_tile_mode == RADEON_MICRO_MODE_RENDER;
 
+   surf->thick_tiling = AddrSurfInfoOut.blockSlices > 1;
+
    /* The rotated micro tile mode doesn't work if both CMASK and RB+ are
     * used at the same time. This case is not currently expected to occur
     * because we don't use rotated. Enforce this restriction on all chips
@@ -1852,6 +1854,8 @@ static int gfx9_compute_miptree(struct ac_addrlib *addrlib, const struct radeon_
       }
    }
 
+   surf->thick_tiling = out.blockSlices > 1; /* should be 0 for depth and stencil */
+
    if (in->flags.stencil) {
       surf->u.gfx9.zs.stencil_swizzle_mode = in->swizzleMode;
       surf->u.gfx9.zs.stencil_epitch =
diff --git a/src/amd/common/ac_surface.h b/src/amd/common/ac_surface.h
index 83338f3413472..58229ef6f96db 100644
--- a/src/amd/common/ac_surface.h
+++ b/src/amd/common/ac_surface.h
@@ -314,6 +314,8 @@ struct radeon_surf {
    uint8_t has_stencil : 1;
    /* This might be true even if micro_tile_mode isn't displayable or rotated. */
    uint8_t is_displayable : 1;
+   /* Thick tiling means 3D tiles. Use 3D compute workgroups for blits. (4x4x4 works well) */
+   uint8_t thick_tiling : 1;
    uint8_t first_mip_tail_level : 4;
 
    /* These are return values. Some of them can be set by the caller, but
-- 
GitLab


From f2bbf5e04d19ad677798aed8d40cdc15137ca7e0 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Fri, 5 Apr 2024 21:46:25 -0400
Subject: [PATCH 2/9] ac/nir: allow 16-bit results for resinfo

---
 src/amd/common/ac_nir_lower_resinfo.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/src/amd/common/ac_nir_lower_resinfo.c b/src/amd/common/ac_nir_lower_resinfo.c
index 1836eceafcff3..ea81ebbe9c5c6 100644
--- a/src/amd/common/ac_nir_lower_resinfo.c
+++ b/src/amd/common/ac_nir_lower_resinfo.c
@@ -326,6 +326,10 @@ static bool lower_resinfo(nir_builder *b, nir_instr *instr, void *data)
    if (!result)
       return false;
 
+   assert(dst->bit_size == 32 || dst->bit_size == 16);
+   if (dst->bit_size == 16)
+      result = nir_u2u16(b, result);
+
    nir_def_rewrite_uses_after(dst, result, instr);
    nir_instr_remove(instr);
    return true;
-- 
GitLab


From 8cc98d45565157e64db1444104abe256338e04e4 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Fri, 5 Apr 2024 21:47:26 -0400
Subject: [PATCH 3/9] ac/llvm: simplify extracting an element in
 get_image_coords

---
 src/amd/llvm/ac_nir_to_llvm.c | 9 +--------
 1 file changed, 1 insertion(+), 8 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index f553ab92ee26a..65c91a3ec2fde 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -2198,13 +2198,6 @@ static void get_image_coords(struct ac_nir_context *ctx, const nir_intrinsic_ins
                              enum glsl_sampler_dim dim, bool is_array)
 {
    LLVMValueRef src0 = get_src(ctx, instr->src[1]);
-   LLVMValueRef masks[] = {
-      ctx->ac.i32_0,
-      ctx->ac.i32_1,
-      LLVMConstInt(ctx->ac.i32, 2, false),
-      LLVMConstInt(ctx->ac.i32, 3, false),
-   };
-
    int count;
    ASSERTED bool add_frag_pos =
       (dim == GLSL_SAMPLER_DIM_SUBPASS || dim == GLSL_SAMPLER_DIM_SUBPASS_MS);
@@ -2215,7 +2208,7 @@ static void get_image_coords(struct ac_nir_context *ctx, const nir_intrinsic_ins
 
    if (count == 1 && !gfx9_1d) {
       if (instr->src[1].ssa->num_components)
-         args->coords[0] = LLVMBuildExtractElement(ctx->ac.builder, src0, masks[0], "");
+         args->coords[0] = ac_llvm_extract_elem(&ctx->ac, src0, 0);
       else
          args->coords[0] = src0;
    } else {
-- 
GitLab


From 8fc30ca7730bb0a79fda657dc81fbca48a1c34b1 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Fri, 5 Apr 2024 21:48:35 -0400
Subject: [PATCH 4/9] ac/llvm: add support for 16-bit coordinates (A16) for
 image (non-sampler) opcodes

---
 src/amd/llvm/ac_nir_to_llvm.c | 11 +++++++----
 1 file changed, 7 insertions(+), 4 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 65c91a3ec2fde..5be723cae4b62 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -2222,9 +2222,9 @@ static void get_image_coords(struct ac_nir_context *ctx, const nir_intrinsic_ins
       if (gfx9_1d) {
          if (is_array) {
             args->coords[2] = args->coords[1];
-            args->coords[1] = ctx->ac.i32_0;
+            args->coords[1] = LLVMConstInt(LLVMTypeOf(args->coords[0]), 0, 0);
          } else
-            args->coords[1] = ctx->ac.i32_0;
+            args->coords[1] = LLVMConstInt(LLVMTypeOf(args->coords[0]), 0, 0);
          count++;
       }
       if (ctx->ac.gfx_level == GFX9 && dim == GLSL_SAMPLER_DIM_2D && !is_array) {
@@ -2264,7 +2264,8 @@ static void get_image_coords(struct ac_nir_context *ctx, const nir_intrinsic_ins
             }
          }
 
-         args->coords[count] = first_layer;
+         args->coords[count] = LLVMBuildTrunc(ctx->ac.builder, first_layer,
+                                              LLVMTypeOf(args->coords[0]), "");
          count++;
       }
 
@@ -2344,8 +2345,8 @@ static LLVMValueRef visit_image_load(struct ac_nir_context *ctx, const nir_intri
          args.lod = get_src(ctx, instr->src[3]);
       args.dmask = 15;
       args.attributes = access & ACCESS_CAN_REORDER ? AC_ATTR_INVARIANT_LOAD : 0;
-
       args.d16 = instr->def.bit_size == 16;
+      args.a16 = ac_get_elem_bits(&ctx->ac, LLVMTypeOf(args.coords[0])) == 16;
 
       res = ac_build_image_opcode(&ctx->ac, &args);
    }
@@ -2414,6 +2415,7 @@ static void visit_image_store(struct ac_nir_context *ctx, const nir_intrinsic_in
          args.lod = get_src(ctx, instr->src[4]);
       args.dmask = 15;
       args.d16 = ac_get_elem_bits(&ctx->ac, LLVMTypeOf(args.data[0])) == 16;
+      args.a16 = ac_get_elem_bits(&ctx->ac, LLVMTypeOf(args.coords[0])) == 16;
 
       ac_build_image_opcode(&ctx->ac, &args);
    }
@@ -2532,6 +2534,7 @@ static LLVMValueRef visit_image_atomic(struct ac_nir_context *ctx, const nir_int
       args.resource = ctx->abi->load_sampler_desc(ctx->abi, dynamic_index, AC_DESC_IMAGE);
       get_image_coords(ctx, instr, dynamic_index, &args, dim, is_array);
       args.dim = ac_get_image_dim(ctx->ac.gfx_level, dim, is_array);
+      args.a16 = ac_get_elem_bits(&ctx->ac, LLVMTypeOf(args.coords[0])) == 16;
       args.access = ac_get_mem_access_flags(instr);
 
       result = ac_build_image_opcode(&ctx->ac, &args);
-- 
GitLab


From 008cbbc76b93c7c2c65a6d11a4c7b37e55f23b82 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Fri, 5 Apr 2024 21:50:00 -0400
Subject: [PATCH 5/9] ac/llvm: allow image loads to return less than 4
 components, trim DMASK

---
 src/amd/llvm/ac_nir_to_llvm.c | 10 ++++++++--
 1 file changed, 8 insertions(+), 2 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 5be723cae4b62..d6568d275688c 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -2328,7 +2328,7 @@ static LLVMValueRef visit_image_load(struct ac_nir_context *ctx, const nir_intri
       args.opcode = ac_image_load;
       args.resource = ctx->abi->load_sampler_desc(ctx->abi, dynamic_index, AC_DESC_FMASK);
       get_image_coords(ctx, instr, dynamic_index, &args, GLSL_SAMPLER_DIM_2D, is_array);
-      args.dmask = 0xf;
+      args.dmask = 0x1;
       args.dim = is_array ? ac_image_2darray : ac_image_2d;
       args.attributes = AC_ATTR_INVARIANT_LOAD;
       args.a16 = ac_get_elem_bits(&ctx->ac, LLVMTypeOf(args.coords[0])) == 16;
@@ -2343,7 +2343,10 @@ static LLVMValueRef visit_image_load(struct ac_nir_context *ctx, const nir_intri
       args.dim = ac_get_image_dim(ctx->ac.gfx_level, dim, is_array);
       if (!level_zero)
          args.lod = get_src(ctx, instr->src[3]);
-      args.dmask = 15;
+      /* TODO: Fix in LLVM. LLVM doesn't reduce DMASK for D16 if optimization barriers are
+       * present and even if the vector is trimmed before the optimization barriers.
+       */
+      args.dmask = BITFIELD_MASK(instr->def.num_components);
       args.attributes = access & ACCESS_CAN_REORDER ? AC_ATTR_INVARIANT_LOAD : 0;
       args.d16 = instr->def.bit_size == 16;
       args.a16 = ac_get_elem_bits(&ctx->ac, LLVMTypeOf(args.coords[0])) == 16;
@@ -2368,6 +2371,9 @@ static LLVMValueRef visit_image_load(struct ac_nir_context *ctx, const nir_intri
       res = ac_build_gather_values(&ctx->ac, values, 4 + args.tfe);
    }
 
+   if (instr->def.num_components < 4)
+      res = ac_trim_vector(&ctx->ac, res, instr->def.num_components);
+
    return exit_waterfall(ctx, &wctx, res);
 }
 
-- 
GitLab


From 8eee3cde081a76739790949d66f7107ca02c0f25 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Sat, 30 Mar 2024 23:21:16 -0400
Subject: [PATCH 6/9] ac/llvm: remove handling of input and output loads/stores
 that are lowered

There is a lot that we still use.
---
 src/amd/llvm/ac_nir_to_llvm.c                 | 82 ++++---------------
 src/amd/llvm/ac_shader_abi.h                  |  3 +-
 src/gallium/drivers/radeonsi/si_shader_llvm.c |  5 +-
 .../drivers/radeonsi/si_shader_llvm_tess.c    |  5 +-
 4 files changed, 19 insertions(+), 76 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index d6568d275688c..b73a74d554132 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -2125,23 +2125,16 @@ static void visit_store_output(struct ac_nir_context *ctx, nir_intrinsic_instr *
    unsigned writemask = nir_intrinsic_write_mask(instr);
    unsigned component = nir_intrinsic_component(instr);
    LLVMValueRef src = ac_to_float(&ctx->ac, get_src(ctx, instr->src[0]));
+   ASSERTED unsigned bit_size = ac_get_elem_bits(&ctx->ac, LLVMTypeOf(src));
    ASSERTED nir_src offset = *nir_get_io_offset_src(instr);
 
+   /* Non-monolithic PS and also LS before TCS in radeonsi use this to forward outputs to
+    * registers.
+    */
+   assert(bit_size == 16 || bit_size == 32);
    /* No indirect indexing is allowed here. */
    assert(nir_src_is_const(offset) && nir_src_as_uint(offset) == 0);
 
-   switch (ac_get_elem_bits(&ctx->ac, LLVMTypeOf(src))) {
-   case 16:
-   case 32:
-      break;
-   case 64:
-      unreachable("64-bit IO should have been lowered to 32 bits");
-      return;
-   default:
-      unreachable("unhandled store_output bit size");
-      return;
-   }
-
    writemask <<= component;
 
    for (unsigned chan = 0; chan < 8; chan++) {
@@ -2887,50 +2880,26 @@ static LLVMValueRef load_interpolated_input(struct ac_nir_context *ctx, LLVMValu
    return ac_to_integer(&ctx->ac, ac_build_gather_values(&ctx->ac, values, num_components));
 }
 
-static LLVMValueRef visit_load(struct ac_nir_context *ctx, nir_intrinsic_instr *instr,
-                               bool is_output)
+static LLVMValueRef visit_load(struct ac_nir_context *ctx, nir_intrinsic_instr *instr)
 {
    LLVMValueRef values[8];
    LLVMTypeRef dest_type = get_def_type(ctx, &instr->def);
-   LLVMTypeRef component_type;
    unsigned base = nir_intrinsic_base(instr);
    unsigned component = nir_intrinsic_component(instr);
    unsigned count = instr->def.num_components;
-   nir_src *vertex_index_src = nir_get_io_arrayed_index_src(instr);
-   LLVMValueRef vertex_index = vertex_index_src ? get_src(ctx, *vertex_index_src) : NULL;
    nir_src offset = *nir_get_io_offset_src(instr);
-   LLVMValueRef indir_index = NULL;
-
-   switch (instr->def.bit_size) {
-   case 16:
-   case 32:
-      break;
-   case 64:
-      if (ctx->stage != MESA_SHADER_VERTEX || is_output) {
-         unreachable("64-bit IO should have been lowered");
-         return NULL;
-      }
-      break;
-   default:
-      unreachable("unhandled load type");
-      return NULL;
-   }
 
-   if (LLVMGetTypeKind(dest_type) == LLVMVectorTypeKind)
-      component_type = LLVMGetElementType(dest_type);
-   else
-      component_type = dest_type;
-
-   if (nir_src_is_const(offset))
-      assert(nir_src_as_uint(offset) == 0);
-   else
-      indir_index = get_src(ctx, offset);
+   assert(instr->def.bit_size == 16 || instr->def.bit_size == 32);
+   /* No indirect indexing allowed. */
+   assert(nir_src_is_const(offset) && nir_src_as_uint(offset) == 0);
 
+   /* This is used to load TCS inputs from VGPRs in radeonsi. */
    if (ctx->stage == MESA_SHADER_TESS_CTRL) {
+      LLVMTypeRef component_type = LLVMGetTypeKind(dest_type) == LLVMVectorTypeKind ?
+                                      LLVMGetElementType(dest_type) : dest_type;
+
       LLVMValueRef result = ctx->abi->load_tess_varyings(ctx->abi, component_type,
-                                                         vertex_index, indir_index,
-                                                         base, component,
-                                                         count, !is_output);
+                                                         base, component, count);
       if (instr->def.bit_size == 16) {
          result = ac_to_integer(&ctx->ac, result);
          result = LLVMBuildTrunc(ctx->ac.builder, result, dest_type, "");
@@ -2938,22 +2907,6 @@ static LLVMValueRef visit_load(struct ac_nir_context *ctx, nir_intrinsic_instr *
       return LLVMBuildBitCast(ctx->ac.builder, result, dest_type, "");
    }
 
-   /* No indirect indexing is allowed after this point. */
-   assert(!indir_index);
-
-   /* Other non-fragment cases have outputs in temporaries. */
-   if (is_output && (ctx->stage == MESA_SHADER_VERTEX || ctx->stage == MESA_SHADER_TESS_EVAL)) {
-      assert(is_output);
-
-      for (unsigned chan = component; chan < count + component; chan++)
-         values[chan] = LLVMBuildLoad2(ctx->ac.builder, ctx->ac.f32,
-                                       ctx->abi->outputs[base * 4 + chan], "");
-
-      LLVMValueRef result = ac_build_varying_gather_values(&ctx->ac, values, count, component);
-      return LLVMBuildBitCast(ctx->ac.builder, result, dest_type, "");
-   }
-
-   /* Fragment shader inputs. */
    assert(ctx->stage == MESA_SHADER_FRAGMENT);
    unsigned vertex_id = 0; /* P0 */
 
@@ -3205,14 +3158,9 @@ static bool visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_load_input:
    case nir_intrinsic_load_input_vertex:
    case nir_intrinsic_load_per_vertex_input:
-      result = visit_load(ctx, instr, false);
-      break;
-   case nir_intrinsic_load_output:
-   case nir_intrinsic_load_per_vertex_output:
-      result = visit_load(ctx, instr, true);
+      result = visit_load(ctx, instr);
       break;
    case nir_intrinsic_store_output:
-   case nir_intrinsic_store_per_vertex_output:
       visit_store_output(ctx, instr);
       break;
    case nir_intrinsic_load_shared:
diff --git a/src/amd/llvm/ac_shader_abi.h b/src/amd/llvm/ac_shader_abi.h
index 4dee4ad2813a5..88dcf0b5540a8 100644
--- a/src/amd/llvm/ac_shader_abi.h
+++ b/src/amd/llvm/ac_shader_abi.h
@@ -42,9 +42,8 @@ struct ac_shader_abi {
    unsigned fs_input_attr_indices[MAX_VARYING];
 
    LLVMValueRef (*load_tess_varyings)(struct ac_shader_abi *abi, LLVMTypeRef type,
-                                      LLVMValueRef vertex_index, LLVMValueRef param_index,
                                       unsigned driver_location, unsigned component,
-                                      unsigned num_components, bool load_inputs);
+                                      unsigned num_components);
 
    LLVMValueRef (*load_ubo)(struct ac_shader_abi *abi, LLVMValueRef index);
 
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm.c b/src/gallium/drivers/radeonsi/si_shader_llvm.c
index deec16f88e766..6ccfcc31c95ae 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm.c
@@ -731,12 +731,9 @@ static bool si_llvm_translate_nir(struct si_shader_context *ctx, struct si_shade
       ctx->stage == MESA_SHADER_VERTEX && shader->key.ge.as_ls &&
       shader->key.ge.opt.same_patch_vertices;
 
-   bool tcs_need_output =
-      ctx->stage == MESA_SHADER_TESS_CTRL && info->tessfactors_are_def_in_all_invocs;
-
    bool ps_need_output = ctx->stage == MESA_SHADER_FRAGMENT;
 
-   if (ls_need_output || tcs_need_output || ps_need_output) {
+   if (ls_need_output || ps_need_output) {
       for (unsigned i = 0; i < info->num_outputs; i++) {
          LLVMTypeRef type = ctx->ac.f32;
 
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c b/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c
index a585e64d8da37..5f9409dccb2de 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c
@@ -10,14 +10,13 @@
 #include "sid.h"
 
 static LLVMValueRef si_nir_load_tcs_varyings(struct ac_shader_abi *abi, LLVMTypeRef type,
-                                             LLVMValueRef vertex_index, LLVMValueRef param_index,
                                              unsigned driver_location, unsigned component,
-                                             unsigned num_components, bool load_input)
+                                             unsigned num_components)
 {
    struct si_shader_context *ctx = si_shader_context_from_abi(abi);
    struct si_shader_info *info = &ctx->shader->selector->info;
 
-   assert(ctx->shader->key.ge.opt.same_patch_vertices && !param_index);
+   assert(ctx->shader->key.ge.opt.same_patch_vertices);
 
    uint8_t semantic = info->input[driver_location].semantic;
    /* Load the TCS input from a VGPR. */
-- 
GitLab


From 33dfb0f20be4e596d02e5b6c9e1964445a4e4e83 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Sat, 30 Mar 2024 23:32:26 -0400
Subject: [PATCH 7/9] ac/llvm: remove unused fields of ac_shader_abi

---
 src/amd/llvm/ac_shader_abi.h | 7 -------
 1 file changed, 7 deletions(-)

diff --git a/src/amd/llvm/ac_shader_abi.h b/src/amd/llvm/ac_shader_abi.h
index 88dcf0b5540a8..a438192d5f67a 100644
--- a/src/amd/llvm/ac_shader_abi.h
+++ b/src/amd/llvm/ac_shader_abi.h
@@ -38,9 +38,6 @@ struct ac_shader_abi {
    LLVMValueRef tes_rel_patch_id_replaced;
    LLVMValueRef tes_patch_id_replaced;
 
-   /* Varying -> attribute number mapping. Also NIR-only */
-   unsigned fs_input_attr_indices[MAX_VARYING];
-
    LLVMValueRef (*load_tess_varyings)(struct ac_shader_abi *abi, LLVMTypeRef type,
                                       unsigned driver_location, unsigned component,
                                       unsigned num_components);
@@ -84,10 +81,6 @@ struct ac_shader_abi {
    /* Whether to inline the compute dispatch size in user sgprs. */
    bool load_grid_size_from_user_sgpr;
 
-   /* Whether to detect divergent textures/samplers index and apply
-    * waterfall to avoid incorrect rendering. */
-   bool use_waterfall_for_divergent_tex_samplers;
-
    /* Whether to disable anisotropic filtering. */
    bool disable_aniso_single_level;
 };
-- 
GitLab


From 69f2411b81637547e46e2a92da7ab5364ab7a2f2 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Mon, 6 Mar 2023 21:41:12 -0500
Subject: [PATCH 8/9] ac/llvm: simplify the optimization barrier and apply it
 to the whole vector

Use the same code as the pointer type. It works with all types and works
with any vector, but we need to handle i1 and v3i16 as special cases,
otherwise LLVM fails when it sees them. The previous code only extracted
the first component, which is not what we want.
---
 src/amd/llvm/ac_llvm_build.c | 50 ++++++++----------------------------
 1 file changed, 11 insertions(+), 39 deletions(-)

diff --git a/src/amd/llvm/ac_llvm_build.c b/src/amd/llvm/ac_llvm_build.c
index 5d8da90b6f177..66d26406c97aa 100644
--- a/src/amd/llvm/ac_llvm_build.c
+++ b/src/amd/llvm/ac_llvm_build.c
@@ -412,54 +412,26 @@ void ac_build_optimization_barrier(struct ac_llvm_context *ctx, LLVMValueRef *pg
       LLVMTypeRef ftype = LLVMFunctionType(ctx->voidt, NULL, 0, false);
       LLVMValueRef inlineasm = LLVMConstInlineAsm(ftype, code, "", true, false);
       LLVMBuildCall2(builder, ftype, inlineasm, NULL, 0, "");
-   } else if (LLVMTypeOf(*pgpr) == ctx->i32) {
-      /* Simple version for i32 that allows the caller to set LLVM metadata on the call
-       * instruction. */
-      LLVMTypeRef ftype = LLVMFunctionType(ctx->i32, &ctx->i32, 1, false);
-      LLVMValueRef inlineasm = LLVMConstInlineAsm(ftype, code, constraint, true, false);
+   } else {
+      LLVMTypeRef old_type = LLVMTypeOf(*pgpr);
 
-      *pgpr = LLVMBuildCall2(builder, ftype, inlineasm, pgpr, 1, "");
-   } else if (LLVMTypeOf(*pgpr) == ctx->i16) {
-      /* Simple version for i16 that allows the caller to set LLVM metadata on the call
-       * instruction. */
-      LLVMTypeRef ftype = LLVMFunctionType(ctx->i16, &ctx->i16, 1, false);
-      LLVMValueRef inlineasm = LLVMConstInlineAsm(ftype, code, constraint, true, false);
+      if (old_type == ctx->i1)
+         *pgpr = LLVMBuildZExt(builder, *pgpr, ctx->i32, "");
+
+      if (old_type == LLVMVectorType(ctx->i16, 3))
+         *pgpr = ac_build_expand_to_vec4(ctx, *pgpr, 4);
 
-      *pgpr = LLVMBuildCall2(builder, ftype, inlineasm, pgpr, 1, "");
-   } else if (LLVMGetTypeKind(LLVMTypeOf(*pgpr)) == LLVMPointerTypeKind) {
       LLVMTypeRef type = LLVMTypeOf(*pgpr);
       LLVMTypeRef ftype = LLVMFunctionType(type, &type, 1, false);
       LLVMValueRef inlineasm = LLVMConstInlineAsm(ftype, code, constraint, true, false);
 
       *pgpr = LLVMBuildCall2(builder, ftype, inlineasm, pgpr, 1, "");
-   } else {
-      LLVMTypeRef ftype = LLVMFunctionType(ctx->i32, &ctx->i32, 1, false);
-      LLVMValueRef inlineasm = LLVMConstInlineAsm(ftype, code, constraint, true, false);
-      LLVMTypeRef type = LLVMTypeOf(*pgpr);
-      unsigned bitsize = ac_get_elem_bits(ctx, type);
-      LLVMValueRef vgpr = *pgpr;
-      LLVMTypeRef vgpr_type;
-      unsigned vgpr_size;
-      LLVMValueRef vgpr0;
-
-      if (bitsize < 32)
-         vgpr = LLVMBuildZExt(ctx->builder, vgpr, ctx->i32, "");
-
-      vgpr_type = LLVMTypeOf(vgpr);
-      vgpr_size = ac_get_type_size(vgpr_type);
-
-      assert(vgpr_size % 4 == 0);
-
-      vgpr = LLVMBuildBitCast(builder, vgpr, LLVMVectorType(ctx->i32, vgpr_size / 4), "");
-      vgpr0 = LLVMBuildExtractElement(builder, vgpr, ctx->i32_0, "");
-      vgpr0 = LLVMBuildCall2(builder, ftype, inlineasm, &vgpr0, 1, "");
-      vgpr = LLVMBuildInsertElement(builder, vgpr, vgpr0, ctx->i32_0, "");
-      vgpr = LLVMBuildBitCast(builder, vgpr, vgpr_type, "");
 
-      if (bitsize < 32)
-         vgpr = LLVMBuildTrunc(builder, vgpr, type, "");
+      if (old_type == ctx->i1)
+         *pgpr = LLVMBuildTrunc(builder, *pgpr, old_type, "");
 
-      *pgpr = vgpr;
+      if (old_type == LLVMVectorType(ctx->i16, 3))
+         *pgpr = ac_extract_components(ctx, *pgpr, 0, 3);
    }
 }
 
-- 
GitLab


From 8a82afc7c527264d72664d3106cda600d3760e7f Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Sun, 17 Mar 2024 15:11:56 -0400
Subject: [PATCH 9/9] ac: add helper ac_get_ip_type_string to remove
 duplication

---
 src/amd/common/ac_gpu_info.c | 18 +++---------------
 src/amd/common/ac_parse_ib.c | 20 ++++----------------
 src/amd/common/amd_family.c  | 29 +++++++++++++++++++++++++++++
 src/amd/common/amd_family.h  |  3 +++
 src/amd/vulkan/radv_debug.c  |  2 +-
 5 files changed, 40 insertions(+), 32 deletions(-)

diff --git a/src/amd/common/ac_gpu_info.c b/src/amd/common/ac_gpu_info.c
index 82687be7bbd55..b7f80dd5cf032 100644
--- a/src/amd/common/ac_gpu_info.c
+++ b/src/amd/common/ac_gpu_info.c
@@ -1754,22 +1754,10 @@ void ac_print_gpu_info(const struct radeon_info *info, FILE *f)
    fprintf(f, "    pcie_bandwidth = %1.1f GB/s\n", info->pcie_bandwidth_mbps / 1024.0);
    fprintf(f, "    clock_crystal_freq = %i KHz\n", info->clock_crystal_freq);
 
-   const char *ip_string[AMD_NUM_IP_TYPES] = {
-      [AMD_IP_GFX] = "GFX",
-      [AMD_IP_COMPUTE] = "COMP",
-      [AMD_IP_SDMA] = "SDMA",
-      [AMD_IP_UVD] = "UVD",
-      [AMD_IP_VCE] = "VCE",
-      [AMD_IP_UVD_ENC] = "UVD_ENC",
-      [AMD_IP_VCN_DEC] = "VCN_DEC",
-      [AMD_IP_VCN_ENC] = (info->vcn_ip_version >= VCN_4_0_0) ? "VCN" : "VCN_ENC",
-      [AMD_IP_VCN_JPEG] = "VCN_JPG",
-      [AMD_IP_VPE] = "VPE",
-   };
-
    for (unsigned i = 0; i < AMD_NUM_IP_TYPES; i++) {
       if (info->ip[i].num_queues) {
-         fprintf(f, "    IP %-7s %2u.%u \tqueues:%u \talign:%u \tpad_dw:0x%x\n", ip_string[i],
+         fprintf(f, "    IP %-7s %2u.%u \tqueues:%u \talign:%u \tpad_dw:0x%x\n",
+                 ac_get_ip_type_string(info, i),
                  info->ip[i].ver_major, info->ip[i].ver_minor, info->ip[i].num_queues,
                  info->ip[i].ib_alignment, info->ip[i].ib_pad_dw_mask);
       }
@@ -1933,7 +1921,7 @@ void ac_print_gpu_info(const struct radeon_info *info, FILE *f)
    fprintf(f, "    has_tmz_support = %u\n", info->has_tmz_support);
    for (unsigned i = 0; i < AMD_NUM_IP_TYPES; i++) {
       if (info->max_submitted_ibs[i]) {
-         fprintf(f, "    IP %-7s max_submitted_ibs = %u\n", ip_string[i],
+         fprintf(f, "    IP %-7s max_submitted_ibs = %u\n", ac_get_ip_type_string(info, i),
                  info->max_submitted_ibs[i]);
       }
    }
diff --git a/src/amd/common/ac_parse_ib.c b/src/amd/common/ac_parse_ib.c
index 9eea077778dd1..81775a1595055 100644
--- a/src/amd/common/ac_parse_ib.c
+++ b/src/amd/common/ac_parse_ib.c
@@ -973,20 +973,6 @@ void ac_parse_ib_chunk(struct ac_ib_parser *ib)
    }
 }
 
-static const char *ip_name(const enum amd_ip_type ip)
-{
-   switch (ip) {
-   case AMD_IP_GFX:
-      return "GFX";
-   case AMD_IP_COMPUTE:
-      return "COMPUTE";
-   case AMD_IP_SDMA:
-      return "SDMA";
-   default:
-      return "Unknown";
-   }
-}
-
 /**
  * Parse and print an IB into a file.
  *
@@ -1005,9 +991,11 @@ static const char *ip_name(const enum amd_ip_type ip)
  */
 void ac_parse_ib(struct ac_ib_parser *ib, const char *name)
 {
-   fprintf(ib->f, "------------------ %s begin - %s ------------------\n", name, ip_name(ib->ip_type));
+   fprintf(ib->f, "------------------ %s begin - %s ------------------\n", name,
+           ac_get_ip_type_string(NULL, ib->ip_type));
 
    ac_parse_ib_chunk(ib);
 
-   fprintf(ib->f, "------------------- %s end - %s -------------------\n\n", name, ip_name(ib->ip_type));
+   fprintf(ib->f, "------------------- %s end - %s -------------------\n\n", name,
+           ac_get_ip_type_string(NULL, ib->ip_type));
 }
diff --git a/src/amd/common/amd_family.c b/src/amd/common/amd_family.c
index a8f86266b791e..d3ae92e2bd244 100644
--- a/src/amd/common/amd_family.c
+++ b/src/amd/common/amd_family.c
@@ -7,6 +7,7 @@
 #include "amd_family.h"
 #include "addrlib/src/amdgpu_asic_addr.h"
 #include "util/macros.h"
+#include "ac_gpu_info.h"
 
 const char *ac_get_family_name(enum radeon_family family)
 {
@@ -235,3 +236,31 @@ const char *ac_get_llvm_processor_name(enum radeon_family family)
       return "";
    }
 }
+
+const char *ac_get_ip_type_string(const struct radeon_info *info, enum amd_ip_type ip_type)
+{
+   switch (ip_type) {
+   case AMD_IP_GFX:
+      return "GFX";
+   case AMD_IP_COMPUTE:
+      return "COMPUTE";
+   case AMD_IP_SDMA:
+      return "SDMA";
+   case AMD_IP_UVD:
+      return "UVD";
+   case AMD_IP_VCE:
+      return "VCE";
+   case AMD_IP_UVD_ENC:
+      return "UVD_ENC";
+   case AMD_IP_VCN_DEC:
+      return "VCN_DEC";
+   case AMD_IP_VCN_ENC: /* equal to AMD_IP_VCN_UNIFIED */
+      return !info || info->vcn_ip_version >= VCN_4_0_0 ? "VCN" : "VCN_ENC";
+   case AMD_IP_VCN_JPEG:
+      return "VCN_JPEG";
+   case AMD_IP_VPE:
+      return "VPE";
+   default:
+      return "UNKNOWN_IP";
+   }
+}
diff --git a/src/amd/common/amd_family.h b/src/amd/common/amd_family.h
index 39a74626b613d..100bfb5af8175 100644
--- a/src/amd/common/amd_family.h
+++ b/src/amd/common/amd_family.h
@@ -12,6 +12,8 @@
 extern "C" {
 #endif
 
+struct radeon_info;
+
 enum radeon_family
 {
    CHIP_UNKNOWN = 0,
@@ -243,6 +245,7 @@ const char *ac_get_family_name(enum radeon_family family);
 enum amd_gfx_level ac_get_gfx_level(enum radeon_family family);
 unsigned ac_get_family_id(enum radeon_family family);
 const char *ac_get_llvm_processor_name(enum radeon_family family);
+const char *ac_get_ip_type_string(const struct radeon_info *info, enum amd_ip_type ip_type);
 
 #ifdef __cplusplus
 }
diff --git a/src/amd/vulkan/radv_debug.c b/src/amd/vulkan/radv_debug.c
index db17dfb17f617..7b4dbfa1c688f 100644
--- a/src/amd/vulkan/radv_debug.c
+++ b/src/amd/vulkan/radv_debug.c
@@ -480,7 +480,7 @@ radv_dump_queue_state(struct radv_queue *queue, const char *dump_dir, FILE *f)
    enum amd_ip_type ring = radv_queue_ring(queue);
    struct radv_pipeline *pipeline;
 
-   fprintf(f, "AMD_IP_%s:\n", ring == AMD_IP_GFX ? "GFX" : "COMPUTE");
+   fprintf(f, "AMD_IP_%s:\n", ac_get_ip_type_string(&pdev->info, ring));
 
    pipeline = radv_get_saved_pipeline(device, ring);
    if (pipeline) {
-- 
GitLab

