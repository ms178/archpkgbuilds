From 92bda63e1ebb51a1b02ee207668f14f345ed9658 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Thu, 12 Jan 2023 01:17:08 +0100
Subject: [PATCH 2/6] radv: Move pre-computing tess info to
 radv_cmd_buffer_flush_dynamic_state.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/amd/vulkan/radv_cmd_buffer.c | 52 ++++++++++++++------------------
 1 file changed, 23 insertions(+), 29 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index ec46ae2eeaab..a062a055cf68 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -4259,6 +4259,29 @@ radv_cmd_buffer_flush_dynamic_state(struct radv_cmd_buffer *cmd_buffer, bool pip
    if (!states)
       return;
 
+   /* Pre-compute some tessellation info that depend on the number of patch control points when the
+    * bound pipeline declared this state as dynamic.
+    */
+   if (states & RADV_CMD_DIRTY_DYNAMIC_PATCH_CONTROL_POINTS) {
+      const struct radv_physical_device *pdevice = cmd_buffer->device->physical_device;
+      const struct radv_graphics_pipeline *pipeline = cmd_buffer->state.graphics_pipeline;
+      const struct radv_shader *tcs = pipeline->base.shaders[MESA_SHADER_TESS_CTRL];
+      const struct radv_dynamic_state *d = &cmd_buffer->state.dynamic;
+
+      /* Compute the number of patches and emit the context register. */
+      cmd_buffer->state.tess_num_patches = get_tcs_num_patches(
+         d->vk.ts.patch_control_points, tcs->info.tcs.tcs_vertices_out,
+         tcs->info.tcs.num_linked_inputs, tcs->info.tcs.num_linked_outputs,
+         tcs->info.tcs.num_linked_patch_outputs, pdevice->hs.tess_offchip_block_dw_size,
+         pdevice->rad_info.gfx_level, pdevice->rad_info.family);
+
+      /* Compute the LDS size and emit the shader register. */
+      cmd_buffer->state.tess_lds_size = calculate_tess_lds_size(
+         pdevice->rad_info.gfx_level, d->vk.ts.patch_control_points, tcs->info.tcs.tcs_vertices_out,
+         tcs->info.tcs.num_linked_inputs, cmd_buffer->state.tess_num_patches,
+         tcs->info.tcs.num_linked_outputs, tcs->info.tcs.num_linked_patch_outputs);
+   }
+
    if (states & (RADV_CMD_DIRTY_DYNAMIC_VIEWPORT |
                  RADV_CMD_DIRTY_DYNAMIC_DEPTH_CLIP_ENABLE |
                  RADV_CMD_DIRTY_DYNAMIC_DEPTH_CLIP_NEGATIVE_ONE_TO_ONE |
@@ -8616,35 +8639,6 @@ radv_emit_all_graphics_states(struct radv_cmd_buffer *cmd_buffer, const struct r
       }
    }
 
-   /* Pre-compute some tessellation info that depend on the number of patch control points when the
-    * bound pipeline declared this state as dynamic.
-    */
-   if (cmd_buffer->state.graphics_pipeline->dynamic_states & RADV_DYNAMIC_PATCH_CONTROL_POINTS) {
-      uint64_t dynamic_states =
-         cmd_buffer->state.dirty & cmd_buffer->state.emitted_graphics_pipeline->needed_dynamic_state;
-
-      if (dynamic_states & RADV_CMD_DIRTY_DYNAMIC_PATCH_CONTROL_POINTS) {
-         const struct radv_physical_device *pdevice = device->physical_device;
-         const struct radv_graphics_pipeline *pipeline = cmd_buffer->state.graphics_pipeline;
-         const struct radv_shader *tcs = pipeline->base.shaders[MESA_SHADER_TESS_CTRL];
-         const struct radv_dynamic_state *d = &cmd_buffer->state.dynamic;
-
-         /* Compute the number of patches and emit the context register. */
-         cmd_buffer->state.tess_num_patches = get_tcs_num_patches(
-            d->vk.ts.patch_control_points, tcs->info.tcs.tcs_vertices_out,
-            tcs->info.tcs.num_linked_inputs, tcs->info.tcs.num_linked_outputs,
-            tcs->info.tcs.num_linked_patch_outputs, pdevice->hs.tess_offchip_block_dw_size,
-            pdevice->rad_info.gfx_level, pdevice->rad_info.family);
-
-         /* Compute the LDS size and emit the shader register. */
-         cmd_buffer->state.tess_lds_size = calculate_tess_lds_size(
-            pdevice->rad_info.gfx_level, d->vk.ts.patch_control_points,
-            tcs->info.tcs.tcs_vertices_out, tcs->info.tcs.num_linked_inputs,
-            cmd_buffer->state.tess_num_patches, tcs->info.tcs.num_linked_outputs,
-            tcs->info.tcs.num_linked_patch_outputs);
-      }
-   }
-
    radv_cmd_buffer_flush_dynamic_state(cmd_buffer, pipeline_is_dirty);
 
    radv_emit_draw_registers(cmd_buffer, info);
-- 
GitLab


From a8867c5f0f12d6f2872131044b6d8f2049b34e3d Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Mon, 30 Jan 2023 02:11:22 +0100
Subject: [PATCH 3/6] radv: Clear descriptor dirty flags in caller.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/amd/vulkan/radv_cmd_buffer.c | 107 +++++++++++++++----------------
 1 file changed, 52 insertions(+), 55 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index a062a055cf68..79b92ae63d67 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -4846,8 +4846,6 @@ radv_flush_vertex_descriptors(struct radv_cmd_buffer *cmd_buffer)
 
    if (unlikely(cmd_buffer->device->trace_bo))
       radv_save_vertex_descriptors(cmd_buffer, (uintptr_t)vb_ptr);
-
-   cmd_buffer->state.dirty &= ~RADV_CMD_DIRTY_VERTEX_BUFFER;
 }
 
 static void
@@ -4880,71 +4878,67 @@ radv_emit_streamout_buffers(struct radv_cmd_buffer *cmd_buffer, uint64_t va)
 static void
 radv_flush_streamout_descriptors(struct radv_cmd_buffer *cmd_buffer)
 {
-   if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_STREAMOUT_BUFFER) {
-      struct radv_streamout_binding *sb = cmd_buffer->streamout_bindings;
-      struct radv_streamout_state *so = &cmd_buffer->state.streamout;
-      unsigned so_offset;
-      uint64_t desc_va;
-      void *so_ptr;
+   struct radv_streamout_binding *sb = cmd_buffer->streamout_bindings;
+   struct radv_streamout_state *so = &cmd_buffer->state.streamout;
+   unsigned so_offset;
+   uint64_t desc_va;
+   void *so_ptr;
 
-      /* Allocate some descriptor state for streamout buffers. */
-      if (!radv_cmd_buffer_upload_alloc(cmd_buffer, MAX_SO_BUFFERS * 16, &so_offset, &so_ptr))
-         return;
+   /* Allocate some descriptor state for streamout buffers. */
+   if (!radv_cmd_buffer_upload_alloc(cmd_buffer, MAX_SO_BUFFERS * 16, &so_offset, &so_ptr))
+      return;
+
+   for (uint32_t i = 0; i < MAX_SO_BUFFERS; i++) {
+      struct radv_buffer *buffer = sb[i].buffer;
+      uint32_t *desc = &((uint32_t *)so_ptr)[i * 4];
+      uint32_t size = 0;
+      uint64_t va = 0;
 
-      for (uint32_t i = 0; i < MAX_SO_BUFFERS; i++) {
-         struct radv_buffer *buffer = sb[i].buffer;
-         uint32_t *desc = &((uint32_t *)so_ptr)[i * 4];
-         uint32_t size = 0;
-         uint64_t va = 0;
+      if (so->enabled_mask & (1 << i)) {
+         va = radv_buffer_get_va(buffer->bo) + buffer->offset;
 
-         if (so->enabled_mask & (1 << i)) {
-            va = radv_buffer_get_va(buffer->bo) + buffer->offset;
+         va += sb[i].offset;
 
-            va += sb[i].offset;
+         /* Set the descriptor.
+          *
+          * On GFX8, the format must be non-INVALID, otherwise
+          * the buffer will be considered not bound and store
+          * instructions will be no-ops.
+          */
+         size = 0xffffffff;
 
-            /* Set the descriptor.
-             *
-             * On GFX8, the format must be non-INVALID, otherwise
-             * the buffer will be considered not bound and store
-             * instructions will be no-ops.
+         if (cmd_buffer->device->physical_device->use_ngg_streamout) {
+            /* With NGG streamout, the buffer size is used to determine the max emit per buffer
+             * and also acts as a disable bit when it's 0.
              */
-            size = 0xffffffff;
-
-            if (cmd_buffer->device->physical_device->use_ngg_streamout) {
-               /* With NGG streamout, the buffer size is used to determine the max emit per buffer
-                * and also acts as a disable bit when it's 0.
-                */
-               size = radv_is_streamout_enabled(cmd_buffer) ? sb[i].size : 0;
-            }
+            size = radv_is_streamout_enabled(cmd_buffer) ? sb[i].size : 0;
          }
+      }
 
-         uint32_t rsrc_word3 =
-            S_008F0C_DST_SEL_X(V_008F0C_SQ_SEL_X) | S_008F0C_DST_SEL_Y(V_008F0C_SQ_SEL_Y) |
-            S_008F0C_DST_SEL_Z(V_008F0C_SQ_SEL_Z) | S_008F0C_DST_SEL_W(V_008F0C_SQ_SEL_W);
-
-         if (cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX11) {
-            rsrc_word3 |= S_008F0C_FORMAT(V_008F0C_GFX11_FORMAT_32_FLOAT) |
-                          S_008F0C_OOB_SELECT(V_008F0C_OOB_SELECT_RAW);
-         } else if (cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX10) {
-            rsrc_word3 |= S_008F0C_FORMAT(V_008F0C_GFX10_FORMAT_32_FLOAT) |
-                          S_008F0C_OOB_SELECT(V_008F0C_OOB_SELECT_RAW) | S_008F0C_RESOURCE_LEVEL(1);
-         } else {
-            rsrc_word3 |= S_008F0C_DATA_FORMAT(V_008F0C_BUF_DATA_FORMAT_32);
-         }
+      uint32_t rsrc_word3 =
+         S_008F0C_DST_SEL_X(V_008F0C_SQ_SEL_X) | S_008F0C_DST_SEL_Y(V_008F0C_SQ_SEL_Y) |
+         S_008F0C_DST_SEL_Z(V_008F0C_SQ_SEL_Z) | S_008F0C_DST_SEL_W(V_008F0C_SQ_SEL_W);
 
-         desc[0] = va;
-         desc[1] = S_008F04_BASE_ADDRESS_HI(va >> 32);
-         desc[2] = size;
-         desc[3] = rsrc_word3;
+      if (cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX11) {
+         rsrc_word3 |= S_008F0C_FORMAT(V_008F0C_GFX11_FORMAT_32_FLOAT) |
+                       S_008F0C_OOB_SELECT(V_008F0C_OOB_SELECT_RAW);
+      } else if (cmd_buffer->device->physical_device->rad_info.gfx_level >= GFX10) {
+         rsrc_word3 |= S_008F0C_FORMAT(V_008F0C_GFX10_FORMAT_32_FLOAT) |
+                       S_008F0C_OOB_SELECT(V_008F0C_OOB_SELECT_RAW) | S_008F0C_RESOURCE_LEVEL(1);
+      } else {
+         rsrc_word3 |= S_008F0C_DATA_FORMAT(V_008F0C_BUF_DATA_FORMAT_32);
       }
 
-      desc_va = radv_buffer_get_va(cmd_buffer->upload.upload_bo);
-      desc_va += so_offset;
-
-      radv_emit_streamout_buffers(cmd_buffer, desc_va);
+      desc[0] = va;
+      desc[1] = S_008F04_BASE_ADDRESS_HI(va >> 32);
+      desc[2] = size;
+      desc[3] = rsrc_word3;
    }
 
-   cmd_buffer->state.dirty &= ~RADV_CMD_DIRTY_STREAMOUT_BUFFER;
+   desc_va = radv_buffer_get_va(cmd_buffer->upload.upload_bo);
+   desc_va += so_offset;
+
+   radv_emit_streamout_buffers(cmd_buffer, desc_va);
 }
 
 static void
@@ -5041,7 +5035,10 @@ radv_upload_graphics_shader_descriptors(struct radv_cmd_buffer *cmd_buffer)
    if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_VERTEX_BUFFER)
       radv_flush_vertex_descriptors(cmd_buffer);
 
-   radv_flush_streamout_descriptors(cmd_buffer);
+   if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_STREAMOUT_BUFFER)
+      radv_flush_streamout_descriptors(cmd_buffer);
+
+   cmd_buffer->state.dirty &= ~(RADV_CMD_DIRTY_VERTEX_BUFFER | RADV_CMD_DIRTY_STREAMOUT_BUFFER);
 
    VkShaderStageFlags stages = VK_SHADER_STAGE_ALL_GRAPHICS;
    radv_flush_descriptors(cmd_buffer, stages, &pipeline->base, VK_PIPELINE_BIND_POINT_GRAPHICS);
-- 
GitLab


From 7ecbf9df82faf0e82181cdacc39f7b9ba88227d0 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Wed, 25 Jan 2023 18:57:53 +0100
Subject: [PATCH 4/6] radv: Slight refactor to late_scissor_emission.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

There is no need to set context_roll_without_scissor_emitted
when pipeline, rbplus state, or binning state changes,
because radv_need_late_scissor_emission already checks
their dirty flags.

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/amd/vulkan/radv_cmd_buffer.c | 37 ++++++++++++--------------------
 1 file changed, 14 insertions(+), 23 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index 79b92ae63d67..c89da5572256 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -1115,8 +1115,6 @@ radv_emit_sample_locations(struct radv_cmd_buffer *cmd_buffer)
    radeon_set_context_reg_seq(cs, R_028BD4_PA_SC_CENTROID_PRIORITY_0, 2);
    radeon_emit(cs, centroid_priority);
    radeon_emit(cs, centroid_priority >> 32);
-
-   cmd_buffer->state.context_roll_without_scissor_emitted = true;
 }
 
 static void
@@ -1588,8 +1586,6 @@ radv_emit_binning_state(struct radv_cmd_buffer *cmd_buffer)
 
    radeon_set_context_reg(cmd_buffer->cs, R_028C44_PA_SC_BINNER_CNTL_0, pa_sc_binner_cntl_0);
 
-   cmd_buffer->state.context_roll_without_scissor_emitted = true;
-
    cmd_buffer->state.last_pa_sc_binner_cntl_0 = pa_sc_binner_cntl_0;
 }
 
@@ -1800,8 +1796,6 @@ radv_emit_rbplus_state(struct radv_cmd_buffer *cmd_buffer)
       radeon_emit(cmd_buffer->cs, sx_blend_opt_epsilon);
       radeon_emit(cmd_buffer->cs, sx_blend_opt_control);
 
-      cmd_buffer->state.context_roll_without_scissor_emitted = true;
-
       cmd_buffer->state.last_sx_ps_downconvert = sx_ps_downconvert;
       cmd_buffer->state.last_sx_blend_opt_epsilon = sx_blend_opt_epsilon;
       cmd_buffer->state.last_sx_blend_opt_control = sx_blend_opt_control;
@@ -1878,7 +1872,6 @@ radv_emit_graphics_pipeline(struct radv_cmd_buffer *cmd_buffer)
        memcmp(cmd_buffer->state.emitted_graphics_pipeline->base.ctx_cs.buf, pipeline->base.ctx_cs.buf,
               pipeline->base.ctx_cs.cdw * 4)) {
       radeon_emit_array(cmd_buffer->cs, pipeline->base.ctx_cs.buf, pipeline->base.ctx_cs.cdw);
-      cmd_buffer->state.context_roll_without_scissor_emitted = true;
    }
 
    if (device->pbb_allowed) {
@@ -1999,8 +1992,6 @@ static void
 radv_emit_scissor(struct radv_cmd_buffer *cmd_buffer)
 {
    radv_write_scissors(cmd_buffer, cmd_buffer->cs);
-
-   cmd_buffer->state.context_roll_without_scissor_emitted = false;
 }
 
 static void
@@ -8400,21 +8391,17 @@ radv_need_late_scissor_emission(struct radv_cmd_buffer *cmd_buffer,
 {
    struct radv_cmd_state *state = &cmd_buffer->state;
 
-   if (!cmd_buffer->device->physical_device->rad_info.has_gfx9_scissor_bug)
-      return false;
-
    if (cmd_buffer->state.context_roll_without_scissor_emitted || info->strmout_buffer)
       return true;
 
    uint64_t used_states =
       cmd_buffer->state.graphics_pipeline->needed_dynamic_state | ~RADV_CMD_DIRTY_DYNAMIC_ALL;
 
-   /* Index, vertex and streamout buffers don't change context regs, and
-    * pipeline is already handled.
+   /* Index, vertex and streamout buffers don't change context regs.
+    * We assume that any other dirty flag causes context rolls.
     */
    used_states &= ~(RADV_CMD_DIRTY_INDEX_BUFFER | RADV_CMD_DIRTY_VERTEX_BUFFER |
-                    RADV_CMD_DIRTY_DYNAMIC_VERTEX_INPUT | RADV_CMD_DIRTY_STREAMOUT_BUFFER |
-                    RADV_CMD_DIRTY_PIPELINE);
+                    RADV_CMD_DIRTY_DYNAMIC_VERTEX_INPUT | RADV_CMD_DIRTY_STREAMOUT_BUFFER);
 
    if (cmd_buffer->state.dirty & used_states)
       return true;
@@ -8537,7 +8524,6 @@ radv_emit_all_graphics_states(struct radv_cmd_buffer *cmd_buffer, const struct r
                               bool pipeline_is_dirty)
 {
    const struct radv_device *device = cmd_buffer->device;
-   bool late_scissor_emission;
 
    if (cmd_buffer->state.graphics_pipeline->base.shaders[MESA_SHADER_FRAGMENT]->info.ps.has_epilog) {
       struct radv_shader_part *ps_epilog = NULL;
@@ -8567,6 +8553,14 @@ radv_emit_all_graphics_states(struct radv_cmd_buffer *cmd_buffer, const struct r
          radv_emit_ps_epilog_state(cmd_buffer, ps_epilog, pipeline_is_dirty);
    }
 
+   /* Determine whether GFX9 late scissor workaround should be applied based on:
+    * 1. radv_need_late_scissor_emission
+    * 2. any dirty dynamic flags that may cause context rolls
+    */
+   const bool late_scissor_emission =
+      cmd_buffer->device->physical_device->rad_info.has_gfx9_scissor_bug
+      ? radv_need_late_scissor_emission(cmd_buffer, info) : false;
+
    if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_RBPLUS)
       radv_emit_rbplus_state(cmd_buffer);
 
@@ -8590,11 +8584,6 @@ radv_emit_all_graphics_states(struct radv_cmd_buffer *cmd_buffer, const struct r
    if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_PIPELINE)
       radv_emit_graphics_pipeline(cmd_buffer);
 
-   /* This should be before the cmd_buffer->state.dirty is cleared
-    * (excluding RADV_CMD_DIRTY_PIPELINE) and after
-    * cmd_buffer->state.context_roll_without_scissor_emitted is set. */
-   late_scissor_emission = radv_need_late_scissor_emission(cmd_buffer, info);
-
    if (cmd_buffer->state.dirty & RADV_CMD_DIRTY_FRAMEBUFFER)
       radv_emit_framebuffer_state(cmd_buffer);
 
@@ -8640,8 +8629,10 @@ radv_emit_all_graphics_states(struct radv_cmd_buffer *cmd_buffer, const struct r
 
    radv_emit_draw_registers(cmd_buffer, info);
 
-   if (late_scissor_emission)
+   if (unlikely(late_scissor_emission)) {
       radv_emit_scissor(cmd_buffer);
+      cmd_buffer->state.context_roll_without_scissor_emitted = false;
+   }
 }
 
 /* MUST inline this function to avoid massive perf loss in drawoverhead */
-- 
GitLab
