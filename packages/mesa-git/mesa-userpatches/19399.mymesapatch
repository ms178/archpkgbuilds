From 1fe5e2ff9e9f1d4cde36ba15060252d1f7435206 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Sat, 29 Oct 2022 17:25:00 -0400
Subject: [PATCH 1/3] nir: add nir_lower_subdword_ubo_loads to lower 8/16-bit
 UBO loads to 32 bits

---
 src/compiler/nir/meson.build                |  1 +
 src/compiler/nir/nir.h                      |  1 +
 src/compiler/nir/nir_lower_subdword_loads.c | 88 +++++++++++++++++++++
 3 files changed, 90 insertions(+)
 create mode 100644 src/compiler/nir/nir_lower_subdword_loads.c

diff --git a/src/compiler/nir/meson.build b/src/compiler/nir/meson.build
index f1a1879f6d2b..837bb972db32 100644
--- a/src/compiler/nir/meson.build
+++ b/src/compiler/nir/meson.build
@@ -199,6 +199,7 @@ files_libnir = files(
   'nir_lower_shader_calls.c',
   'nir_lower_single_sampled.c',
   'nir_lower_ssbo.c',
+  'nir_lower_subdword_loads.c',
   'nir_lower_subgroups.c',
   'nir_lower_system_values.c',
   'nir_lower_task_shader.c',
diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index af5fbfb6f555..3a851886f135 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -5768,6 +5768,7 @@ nir_function_impl *nir_shader_get_preamble(nir_shader *shader);
 
 bool nir_lower_point_smooth(nir_shader *shader);
 bool nir_lower_poly_line_smooth(nir_shader *shader, unsigned num_smooth_aa_sample);
+bool nir_lower_subdword_ubo_loads(nir_shader *nir);
 
 #include "nir_inline_helpers.h"
 
diff --git a/src/compiler/nir/nir_lower_subdword_loads.c b/src/compiler/nir/nir_lower_subdword_loads.c
new file mode 100644
index 000000000000..0bd06b6d8bf8
--- /dev/null
+++ b/src/compiler/nir/nir_lower_subdword_loads.c
@@ -0,0 +1,88 @@
+/*
+ * Copyright Â© 2022 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ */
+
+/* Convert 8-bit and 16-bit UBO loads to 32 bits. This is for drivers that
+ * don't support non-32-bit UBO loads.
+ *
+ * The pass expects UBO loads to be scalar. Run these two passes before this:
+ * - nir_lower_io_to_scalar(nir_var_mem_ubo)
+ * - nir_opt_constant_folding
+ *
+ */
+
+#include "nir_builder.h"
+#include "util/u_math.h"
+
+static bool
+lower_subdword_loads(nir_builder *b, nir_instr *instr, void *data)
+{
+   if (instr->type != nir_instr_type_intrinsic)
+      return false;
+
+   nir_intrinsic_instr *intr = nir_instr_as_intrinsic(instr);
+   if (intr->intrinsic != nir_intrinsic_load_ubo)
+      return false;
+
+   unsigned size = intr->dest.ssa.bit_size / 8;
+   if (size != 1 && size != 2)
+      return false;
+
+   /* All 8-bit and 16-bit loads should be scalarized before this pass. */
+   assert(intr->dest.ssa.num_components == 1);
+
+   nir_src *src_offset = nir_get_io_offset_src(intr);
+   nir_ssa_def *result = NULL;
+
+   nir_ssa_def *offset = nir_ssa_for_src(b, *src_offset, 1);
+
+   b->cursor = nir_before_instr(instr);
+
+   /* Round down the offset to a dword. */
+   nir_instr_rewrite_src_ssa(instr, src_offset, nir_iand_imm(b, offset, ~0x3));
+   nir_intrinsic_set_align_offset(intr, nir_intrinsic_align_offset(intr) & ~0x3);
+   intr->dest.ssa.bit_size = 32;
+
+   b->cursor = nir_after_instr(instr);
+
+   /* Bitcast to the subdword type. */
+   if (size == 1)
+      result = nir_unpack_32_4x8(b, &intr->dest.ssa);
+   else if (size == 2)
+      result = nir_unpack_32_2x16(b, &intr->dest.ssa);
+
+   /* Extract the byte or word from the loaded vector. */
+   nir_ssa_def *comp = nir_ushr_imm(b, nir_iand_imm(b, offset, 0x3),
+                                    size == 2 ? 1 : 0);
+   result = nir_vector_extract(b, result, comp);
+
+   nir_ssa_def_rewrite_uses_after(&intr->dest.ssa, result, result->parent_instr);
+   return true;
+}
+
+bool
+nir_lower_subdword_ubo_loads(nir_shader *nir)
+{
+   return nir_shader_instructions_pass(nir, lower_subdword_loads,
+                                       nir_metadata_dominance |
+                                       nir_metadata_block_index, NULL);
+}
-- 
GitLab


From 36c29f3bcefbcd2ffe6367cb37285c7f9f3363fb Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Sat, 29 Oct 2022 17:28:43 -0400
Subject: [PATCH 2/3] nir: return progress from nir_lower_io_to_scalar

oversight?
---
 src/compiler/nir/nir.h                    |  2 +-
 src/compiler/nir/nir_lower_io_to_scalar.c | 12 ++++++------
 2 files changed, 7 insertions(+), 7 deletions(-)

diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index 3a851886f135..1b73c3c29853 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -4913,7 +4913,7 @@ bool nir_lower_phis_to_scalar(nir_shader *shader, bool lower_all);
 void nir_lower_io_arrays_to_elements(nir_shader *producer, nir_shader *consumer);
 void nir_lower_io_arrays_to_elements_no_indirects(nir_shader *shader,
                                                   bool outputs_only);
-void nir_lower_io_to_scalar(nir_shader *shader, nir_variable_mode mask);
+bool nir_lower_io_to_scalar(nir_shader *shader, nir_variable_mode mask);
 bool nir_lower_io_to_scalar_early(nir_shader *shader, nir_variable_mode mask);
 bool nir_lower_io_to_vector(nir_shader *shader, nir_variable_mode mask);
 bool nir_vectorize_tess_levels(nir_shader *shader);
diff --git a/src/compiler/nir/nir_lower_io_to_scalar.c b/src/compiler/nir/nir_lower_io_to_scalar.c
index ff2c9f07fea4..94f4565dbd9f 100644
--- a/src/compiler/nir/nir_lower_io_to_scalar.c
+++ b/src/compiler/nir/nir_lower_io_to_scalar.c
@@ -268,14 +268,14 @@ nir_lower_io_to_scalar_instr(nir_builder *b, nir_instr *instr, void *data)
    return false;
 }
 
-void
+bool
 nir_lower_io_to_scalar(nir_shader *shader, nir_variable_mode mask)
 {
-   nir_shader_instructions_pass(shader,
-                                nir_lower_io_to_scalar_instr,
-                                nir_metadata_block_index |
-                                nir_metadata_dominance,
-                                &mask);
+   return nir_shader_instructions_pass(shader,
+                                       nir_lower_io_to_scalar_instr,
+                                       nir_metadata_block_index |
+                                       nir_metadata_dominance,
+                                       &mask);
 }
 
 static nir_variable **
-- 
GitLab


From 9999255923fffd7f28a08e2a03ddf7dce22636e9 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Sat, 29 Oct 2022 17:29:37 -0400
Subject: [PATCH 3/3] ac/llvm: replace broken 8-bit and 16-bit UBO load
 lowering with the new NIR pass

---
 src/amd/llvm/ac_nir_to_llvm.c                | 15 +++------------
 src/amd/vulkan/radv_pipeline.c               |  7 +++++++
 src/gallium/drivers/radeonsi/si_shader_nir.c |  4 ++++
 3 files changed, 14 insertions(+), 12 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 69dc14c3cad0..16c027115ca2 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -2307,16 +2307,14 @@ static LLVMValueRef visit_load_ubo_buffer(struct ac_nir_context *ctx, nir_intrin
    LLVMValueRef offset = get_src(ctx, instr->src[1]);
    int num_components = instr->num_components;
 
+   assert(instr->dest.ssa.bit_size >= 32);
+
    if (ctx->abi->load_ubo)
       rsrc = ctx->abi->load_ubo(ctx->abi, rsrc);
 
-   /* Convert to a scalar 32-bit load. */
+   /* Convert to a 32-bit load. */
    if (instr->dest.ssa.bit_size == 64)
       num_components *= 2;
-   else if (instr->dest.ssa.bit_size == 16)
-      num_components = DIV_ROUND_UP(num_components, 2);
-   else if (instr->dest.ssa.bit_size == 8)
-      num_components = DIV_ROUND_UP(num_components, 4);
 
    ret =
       ac_build_buffer_load(&ctx->ac, rsrc, num_components, NULL, offset, NULL,
@@ -2326,15 +2324,8 @@ static LLVMValueRef visit_load_ubo_buffer(struct ac_nir_context *ctx, nir_intrin
    if (instr->dest.ssa.bit_size == 64) {
       ret = LLVMBuildBitCast(ctx->ac.builder, ret,
                              LLVMVectorType(ctx->ac.i64, num_components / 2), "");
-   } else if (instr->dest.ssa.bit_size == 16) {
-      ret = LLVMBuildBitCast(ctx->ac.builder, ret,
-                             LLVMVectorType(ctx->ac.i16, num_components * 2), "");
-   } else if (instr->dest.ssa.bit_size == 8) {
-      ret = LLVMBuildBitCast(ctx->ac.builder, ret,
-                             LLVMVectorType(ctx->ac.i8, num_components * 4), "");
    }
 
-   ret = ac_trim_vector(&ctx->ac, ret, instr->num_components);
    ret = LLVMBuildBitCast(ctx->ac.builder, ret, get_def_type(ctx, &instr->dest.ssa), "");
 
    return exit_waterfall(ctx, &wctx, ret);
diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index 689e75a7cae4..4cdbfcb3c6b6 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -3801,6 +3801,13 @@ radv_postprocess_nir(struct radv_pipeline *pipeline,
    /* Wave and workgroup size should already be filled. */
    assert(stage->info.wave_size && stage->info.workgroup_size);
 
+   /* TODO: enable this for ACO */
+   if (radv_use_llvm_for_stage(device, stage->stage)) {
+      NIR_PASS(_, stage->nir, nir_lower_io_to_scalar, nir_var_mem_ubo);
+      NIR_PASS(_, stage->nir, nir_opt_constant_folding);
+      NIR_PASS(_, stage->nir, nir_lower_subdword_ubo_loads);
+   }
+
    if (stage->stage == MESA_SHADER_FRAGMENT) {
       NIR_PASS(_, stage->nir, nir_opt_cse);
       NIR_PASS(_, stage->nir, radv_lower_fs_intrinsics, stage, pipeline_key);
diff --git a/src/gallium/drivers/radeonsi/si_shader_nir.c b/src/gallium/drivers/radeonsi/si_shader_nir.c
index 047224132409..e8f78153c348 100644
--- a/src/gallium/drivers/radeonsi/si_shader_nir.c
+++ b/src/gallium/drivers/radeonsi/si_shader_nir.c
@@ -342,6 +342,10 @@ char *si_finalize_nir(struct pipe_screen *screen, void *nirptr)
 
    nir_lower_io_passes(nir);
 
+   NIR_PASS_V(nir, nir_lower_io_to_scalar, nir_var_mem_ubo);
+   NIR_PASS_V(nir, nir_opt_constant_folding);
+   NIR_PASS_V(nir, nir_lower_subdword_ubo_loads);
+
    NIR_PASS_V(nir, nir_lower_explicit_io, nir_var_mem_shared, nir_address_format_32bit_offset);
 
    /* Remove dead derefs, so that we can remove uniforms. */
-- 
GitLab

