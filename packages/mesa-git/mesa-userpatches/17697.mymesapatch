From 89bc61afffd099916c3d5a95ad4ac76e1e23477e Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Thu, 21 Jul 2022 19:23:38 +0100
Subject: [PATCH 1/4] aco: fix LdsBranchVmemWARHazard with 2+ branch chains

For example, "DS -> branch -> VMEM -> branch -> DS".

fossil-db (navi10):
Totals from 639 (0.40% of 161220) affected shaders:
Instrs: 629090 -> 628254 (-0.13%); split: -0.19%, +0.06%
CodeSize: 3410164 -> 3406748 (-0.10%); split: -0.14%, +0.04%
Latency: 7834755 -> 7821011 (-0.18%); split: -0.70%, +0.52%
InvThroughput: 1369698 -> 1374495 (+0.35%); split: -0.12%, +0.47%

A lot of the fossil-db changes are noise.
threekingdoms.8db138826c386a62.1.foz/0b222ed175eebad0 is an example of a
shader that actually has this issue.

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
Fixes: c037ba1bb7a ("aco/gfx10: Mitigate LdsBranchVmemWARHazard.")
---
 src/amd/compiler/aco_insert_NOPs.cpp | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/src/amd/compiler/aco_insert_NOPs.cpp b/src/amd/compiler/aco_insert_NOPs.cpp
index b05238685246..6d07813b7363 100644
--- a/src/amd/compiler/aco_insert_NOPs.cpp
+++ b/src/amd/compiler/aco_insert_NOPs.cpp
@@ -787,6 +787,9 @@ handle_instruction_gfx10(State& state, NOP_ctx_gfx10& ctx, aco_ptr<Instruction>&
       wait->definitions[0] = Definition(sgpr_null, s1);
       wait->imm = 0;
       new_instructions.emplace_back(std::move(wait));
+
+      ctx.has_VMEM = instr->isVMEM() || instr->isGlobal() || instr->isScratch();
+      ctx.has_DS = instr->isDS();
    }
 
    /* NSAToVMEMBug
-- 
GitLab


From 1fd6557eaf709b048bd83d1476133f7643643091 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Thu, 21 Jul 2022 19:24:46 +0100
Subject: [PATCH 2/4] aco: set has_VMEM,has_DS=false after a branch

fossil-db (navi10):
Totals from 161 (0.10% of 161220) affected shaders:
Instrs: 206726 -> 207179 (+0.22%); split: -0.02%, +0.24%
CodeSize: 1114152 -> 1116032 (+0.17%); split: -0.01%, +0.18%
Latency: 2119380 -> 2147403 (+1.32%); split: -0.16%, +1.48%
InvThroughput: 462960 -> 461922 (-0.22%); split: -0.42%, +0.19%

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/aco_insert_NOPs.cpp | 5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/src/amd/compiler/aco_insert_NOPs.cpp b/src/amd/compiler/aco_insert_NOPs.cpp
index 6d07813b7363..10a6a8a9960d 100644
--- a/src/amd/compiler/aco_insert_NOPs.cpp
+++ b/src/amd/compiler/aco_insert_NOPs.cpp
@@ -770,8 +770,9 @@ handle_instruction_gfx10(State& state, NOP_ctx_gfx10& ctx, aco_ptr<Instruction>&
       /* Mitigation for VMEM is needed only if there was already a branch after */
       ctx.has_VMEM = ctx.has_branch_after_VMEM;
    } else if (instr_is_branch(instr)) {
-      ctx.has_branch_after_VMEM = ctx.has_VMEM;
-      ctx.has_branch_after_DS = ctx.has_DS;
+      ctx.has_branch_after_VMEM |= ctx.has_VMEM;
+      ctx.has_branch_after_DS |= ctx.has_DS;
+      ctx.has_VMEM = ctx.has_DS = false;
    } else if (instr->opcode == aco_opcode::s_waitcnt_vscnt) {
       /* Only s_waitcnt_vscnt can mitigate the hazard */
       const SOPK_instruction& sopk = instr->sopk();
-- 
GitLab


From fcadfcf5414ef2c1772e1f47df64d5ddbc88bb08 Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Thu, 21 Jul 2022 19:59:54 +0100
Subject: [PATCH 3/4] aco: only add vscnt wait when visiting VMEM/DS

This prevents issues where we insert a s_waitcnt_vscnt(0) at the start of
a block or very end of the shader because we're joining two blocks (for
example, one with has_VMEM=true and the other with
has_branch_after_DS=true).

fossil-db (navi10):
Totals from 2441 (1.51% of 161220) affected shaders:
Instrs: 1383964 -> 1384094 (+0.01%); split: -0.07%, +0.08%
CodeSize: 7438212 -> 7438760 (+0.01%); split: -0.05%, +0.06%
Latency: 13780665 -> 13679664 (-0.73%); split: -1.53%, +0.80%
InvThroughput: 2950835 -> 2921511 (-0.99%); split: -1.06%, +0.07%

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/aco_insert_NOPs.cpp | 31 +++++++++-------------------
 1 file changed, 10 insertions(+), 21 deletions(-)

diff --git a/src/amd/compiler/aco_insert_NOPs.cpp b/src/amd/compiler/aco_insert_NOPs.cpp
index 10a6a8a9960d..5284b2c75138 100644
--- a/src/amd/compiler/aco_insert_NOPs.cpp
+++ b/src/amd/compiler/aco_insert_NOPs.cpp
@@ -637,6 +637,8 @@ handle_instruction_gfx10(State& state, NOP_ctx_gfx10& ctx, aco_ptr<Instruction>&
 {
    // TODO: s_dcache_inv needs to be in it's own group on GFX10
 
+   Builder bld(state.program, &new_instructions);
+
    /* VMEMtoScalarWriteHazard
     * Handle EXEC/M0/SGPR write following a VMEM instruction without a VALU or "waitcnt vmcnt(0)"
     * in-between.
@@ -760,15 +762,15 @@ handle_instruction_gfx10(State& state, NOP_ctx_gfx10& ctx, aco_ptr<Instruction>&
     * Handle VMEM/GLOBAL/SCRATCH->branch->DS and DS->branch->VMEM/GLOBAL/SCRATCH patterns.
     */
    if (instr->isVMEM() || instr->isGlobal() || instr->isScratch()) {
+      if (ctx.has_branch_after_DS)
+         bld.sopk(aco_opcode::s_waitcnt_vscnt, Definition(sgpr_null, s1), 0);
+      ctx.has_branch_after_VMEM = ctx.has_branch_after_DS = ctx.has_DS = false;
       ctx.has_VMEM = true;
-      ctx.has_branch_after_VMEM = false;
-      /* Mitigation for DS is needed only if there was already a branch after */
-      ctx.has_DS = ctx.has_branch_after_DS;
    } else if (instr->isDS()) {
+      if (ctx.has_branch_after_VMEM)
+         bld.sopk(aco_opcode::s_waitcnt_vscnt, Definition(sgpr_null, s1), 0);
+      ctx.has_branch_after_VMEM = ctx.has_branch_after_DS = ctx.has_VMEM = false;
       ctx.has_DS = true;
-      ctx.has_branch_after_DS = false;
-      /* Mitigation for VMEM is needed only if there was already a branch after */
-      ctx.has_VMEM = ctx.has_branch_after_VMEM;
    } else if (instr_is_branch(instr)) {
       ctx.has_branch_after_VMEM |= ctx.has_VMEM;
       ctx.has_branch_after_DS |= ctx.has_DS;
@@ -779,19 +781,6 @@ handle_instruction_gfx10(State& state, NOP_ctx_gfx10& ctx, aco_ptr<Instruction>&
       if (sopk.definitions[0].physReg() == sgpr_null && sopk.imm == 0)
          ctx.has_VMEM = ctx.has_branch_after_VMEM = ctx.has_DS = ctx.has_branch_after_DS = false;
    }
-   if ((ctx.has_VMEM && ctx.has_branch_after_DS) || (ctx.has_DS && ctx.has_branch_after_VMEM)) {
-      ctx.has_VMEM = ctx.has_branch_after_VMEM = ctx.has_DS = ctx.has_branch_after_DS = false;
-
-      /* Insert s_waitcnt_vscnt to mitigate the problem */
-      aco_ptr<SOPK_instruction> wait{
-         create_instruction<SOPK_instruction>(aco_opcode::s_waitcnt_vscnt, Format::SOPK, 0, 1)};
-      wait->definitions[0] = Definition(sgpr_null, s1);
-      wait->imm = 0;
-      new_instructions.emplace_back(std::move(wait));
-
-      ctx.has_VMEM = instr->isVMEM() || instr->isGlobal() || instr->isScratch();
-      ctx.has_DS = instr->isDS();
-   }
 
    /* NSAToVMEMBug
     * Handles NSA MIMG (4 or more dwords) immediately followed by MUBUF/MTBUF (with offset[2:1] !=
@@ -805,7 +794,7 @@ handle_instruction_gfx10(State& state, NOP_ctx_gfx10& ctx, aco_ptr<Instruction>&
       if (instr->isMUBUF() || instr->isMTBUF()) {
          uint32_t offset = instr->isMUBUF() ? instr->mubuf().offset : instr->mtbuf().offset;
          if (offset & 6)
-            Builder(state.program, &new_instructions).sopp(aco_opcode::s_nop, -1, 0);
+            bld.sopp(aco_opcode::s_nop, -1, 0);
       }
    }
 
@@ -817,7 +806,7 @@ handle_instruction_gfx10(State& state, NOP_ctx_gfx10& ctx, aco_ptr<Instruction>&
    } else if (ctx.has_writelane) {
       ctx.has_writelane = false;
       if (instr->isMIMG() && get_mimg_nsa_dwords(instr.get()) > 0)
-         Builder(state.program, &new_instructions).sopp(aco_opcode::s_nop, -1, 0);
+         bld.sopp(aco_opcode::s_nop, -1, 0);
    }
 }
 
-- 
GitLab


From 5b56879bc10953246875c2c64e2e13cd1795856a Mon Sep 17 00:00:00 2001
From: Rhys Perry <pendingchaos02@gmail.com>
Date: Wed, 13 Jul 2022 19:37:27 +0100
Subject: [PATCH 4/4] aco: improve VcmpxPermlaneHazard workaround

According to LLVM, we only need to care about VOPC which writes exec.

No fossil-db changes.

Signed-off-by: Rhys Perry <pendingchaos02@gmail.com>
---
 src/amd/compiler/README-ISA.md       |  3 +--
 src/amd/compiler/aco_insert_NOPs.cpp | 26 ++++++++++++++------------
 2 files changed, 15 insertions(+), 14 deletions(-)

diff --git a/src/amd/compiler/README-ISA.md b/src/amd/compiler/README-ISA.md
index b49e4d050830..594da9925cb0 100644
--- a/src/amd/compiler/README-ISA.md
+++ b/src/amd/compiler/README-ISA.md
@@ -251,8 +251,7 @@ ACO doesn't use FLAT load/store on GFX10, so is unaffected.
 ### VcmpxPermlaneHazard
 
 Triggered by:
-Any permlane instruction that follows any VOPC instruction.
-Confirmed by AMD devs that despite the name, this doesn't only affect v_cmpx.
+Any permlane instruction that follows any VOPC instruction which writes exec.
 
 Mitigated by: any VALU instruction except `v_nop`.
 
diff --git a/src/amd/compiler/aco_insert_NOPs.cpp b/src/amd/compiler/aco_insert_NOPs.cpp
index 5284b2c75138..dab408e9badf 100644
--- a/src/amd/compiler/aco_insert_NOPs.cpp
+++ b/src/amd/compiler/aco_insert_NOPs.cpp
@@ -150,7 +150,7 @@ struct NOP_ctx_gfx6 {
 };
 
 struct NOP_ctx_gfx10 {
-   bool has_VOPC = false;
+   bool has_VOPC_write_exec = false;
    bool has_nonVALU_exec_read = false;
    bool has_VMEM = false;
    bool has_branch_after_VMEM = false;
@@ -163,7 +163,7 @@ struct NOP_ctx_gfx10 {
 
    void join(const NOP_ctx_gfx10& other)
    {
-      has_VOPC |= other.has_VOPC;
+      has_VOPC_write_exec |= other.has_VOPC_write_exec;
       has_nonVALU_exec_read |= other.has_nonVALU_exec_read;
       has_VMEM |= other.has_VMEM;
       has_branch_after_VMEM |= other.has_branch_after_VMEM;
@@ -177,9 +177,10 @@ struct NOP_ctx_gfx10 {
 
    bool operator==(const NOP_ctx_gfx10& other)
    {
-      return has_VOPC == other.has_VOPC && has_nonVALU_exec_read == other.has_nonVALU_exec_read &&
-             has_VMEM == other.has_VMEM && has_branch_after_VMEM == other.has_branch_after_VMEM &&
-             has_DS == other.has_DS && has_branch_after_DS == other.has_branch_after_DS &&
+      return has_VOPC_write_exec == other.has_VOPC_write_exec &&
+             has_nonVALU_exec_read == other.has_nonVALU_exec_read && has_VMEM == other.has_VMEM &&
+             has_branch_after_VMEM == other.has_branch_after_VMEM && has_DS == other.has_DS &&
+             has_branch_after_DS == other.has_branch_after_DS &&
              has_NSA_MIMG == other.has_NSA_MIMG && has_writelane == other.has_writelane &&
              sgprs_read_by_VMEM == other.sgprs_read_by_VMEM &&
              sgprs_read_by_SMEM == other.sgprs_read_by_SMEM;
@@ -679,13 +680,14 @@ handle_instruction_gfx10(State& state, NOP_ctx_gfx10& ctx, aco_ptr<Instruction>&
    }
 
    /* VcmpxPermlaneHazard
-    * Handle any permlane following a VOPC instruction, insert v_mov between them.
+    * Handle any permlane following a VOPC instruction writing exec, insert v_mov between them.
     */
-   if (instr->isVOPC()) {
-      ctx.has_VOPC = true;
-   } else if (ctx.has_VOPC && (instr->opcode == aco_opcode::v_permlane16_b32 ||
-                               instr->opcode == aco_opcode::v_permlanex16_b32)) {
-      ctx.has_VOPC = false;
+   if (instr->isVOPC() && instr->definitions[0].physReg() == exec) {
+      /* we only need to check definitions[0] because since GFX10 v_cmpx only writes one dest */
+      ctx.has_VOPC_write_exec = true;
+   } else if (ctx.has_VOPC_write_exec && (instr->opcode == aco_opcode::v_permlane16_b32 ||
+                                          instr->opcode == aco_opcode::v_permlanex16_b32)) {
+      ctx.has_VOPC_write_exec = false;
 
       /* v_nop would be discarded by SQ, so use v_mov with the first operand of the permlane */
       aco_ptr<VOP1_instruction> v_mov{
@@ -694,7 +696,7 @@ handle_instruction_gfx10(State& state, NOP_ctx_gfx10& ctx, aco_ptr<Instruction>&
       v_mov->operands[0] = Operand(instr->operands[0].physReg(), v1);
       new_instructions.emplace_back(std::move(v_mov));
    } else if (instr->isVALU() && instr->opcode != aco_opcode::v_nop) {
-      ctx.has_VOPC = false;
+      ctx.has_VOPC_write_exec = false;
    }
 
    /* VcmpxExecWARHazard
-- 
GitLab

