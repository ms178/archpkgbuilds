From a277ce7198e829babbe5316808897230439027ea Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Mon, 3 Jul 2023 11:36:41 +0200
Subject: [PATCH 1/3] nir: Add option to lower local invocation id y, z to
 subgroup id.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/compiler/nir/nir.h                 |  1 +
 src/compiler/nir/nir_lower_subgroups.c | 47 ++++++++++++++++++++++++--
 2 files changed, 46 insertions(+), 2 deletions(-)

diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index dc47e920deb0e..f13b4c0358907 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -5424,6 +5424,7 @@ typedef struct nir_lower_subgroups_options {
    bool lower_read_invocation_to_cond:1;
    bool lower_rotate_to_shuffle:1;
    bool lower_ballot_bit_count_to_mbcnt_amd:1;
+   bool lower_cs_local_id_yz_to_subgroup_id : 1;
 } nir_lower_subgroups_options;
 
 bool nir_lower_subgroups(nir_shader *shader,
diff --git a/src/compiler/nir/nir_lower_subgroups.c b/src/compiler/nir/nir_lower_subgroups.c
index a393a0869e43b..30a4651d05427 100644
--- a/src/compiler/nir/nir_lower_subgroups.c
+++ b/src/compiler/nir/nir_lower_subgroups.c
@@ -516,8 +516,8 @@ build_subgroup_mask(nir_builder *b,
     * in all cases.  The other components will also get the correct value in
     * case (1) if we just use the rule in case (2), so we'll get the correct
     * result if we just follow (2) and then replace the first component with
-    * "result". 
-    */ 
+    * "result".
+    */
    nir_const_value min_idx[4];
    for (unsigned i = 0; i < options->ballot_components; i++)
       min_idx[i] = nir_const_value_for_int(i * options->ballot_bit_size, 32);
@@ -865,6 +865,49 @@ lower_subgroups_instr(nir_builder *b, nir_instr *instr, void *_options)
       }
       break;
 
+   case nir_intrinsic_load_local_invocation_id:
+      if (!b->shader->info.workgroup_size_variable &&
+          !(b->shader->info.stage == MESA_SHADER_COMPUTE &&
+            b->shader->info.cs.derivative_group == DERIVATIVE_GROUP_QUADS) &&
+          options->lower_cs_local_id_yz_to_subgroup_id &&
+          b->shader->info.workgroup_size[0] % options->subgroup_size == 0 &&
+          util_is_power_of_two_nonzero(options->subgroup_size) &&
+          util_is_power_of_two_nonzero(b->shader->info.workgroup_size[0]) &&
+          util_is_power_of_two_nonzero(b->shader->info.workgroup_size[1])) {
+         /* Replace Y and Z components of local invocation ID
+          * by a formula based on the subgroup ID.
+          * This is beneficial for the following reasons:
+          * 1. Allows the use of scalar registers on HW that has them
+          * 2. No need to initialize vector registers for Y and Z components
+          */
+         nir_ssa_def *id_x = nir_channel(b, &intrin->dest.ssa, 0);
+         nir_ssa_def *id_y, *id_z;
+
+         if (b->shader->info.workgroup_size[2] == 1 &&
+             b->shader->info.workgroup_size[1] == 1) {
+            id_y = id_z = nir_imm_int(b, 0);
+         } else {
+            nir_ssa_def *subgroup_id = nir_load_subgroup_id(b);
+            nir_ssa_def *s =
+               nir_udiv_imm(b, subgroup_id,
+                            b->shader->info.workgroup_size[0] / options->subgroup_size);
+
+            if (b->shader->info.workgroup_size[2] == 1) {
+               id_y = s;
+               id_z = nir_imm_int(b, 0);
+            } else if (b->shader->info.workgroup_size[1] == 1) {
+               id_y = nir_imm_int(b, 0);
+               id_z = s;
+            } else {
+               id_y = nir_umod_imm(b, s, b->shader->info.workgroup_size[1]);
+               id_z = nir_udiv_imm(b, s, b->shader->info.workgroup_size[1]);
+            }
+         }
+
+         return nir_vec3(b, id_x, id_y, id_z);
+      }
+      break;
+
    default:
       break;
    }
-- 
GitLab


From 7841be2bca502294ebb7acd7f98fd905164b1ee8 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Mon, 3 Jul 2023 12:39:04 +0200
Subject: [PATCH 2/3] radv: Use lower_cs_local_id_yz_to_subgroup_id.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/amd/vulkan/radv_shader.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/src/amd/vulkan/radv_shader.c b/src/amd/vulkan/radv_shader.c
index 9c09299d4a5c2..d886506bcba6e 100644
--- a/src/amd/vulkan/radv_shader.c
+++ b/src/amd/vulkan/radv_shader.c
@@ -629,6 +629,7 @@ radv_shader_spirv_to_nir(struct radv_device *device, const struct radv_shader_st
                .lower_quad_broadcast_dynamic_to_const = gfx7minus,
                .lower_shuffle_to_swizzle_amd = 1,
                .lower_ballot_bit_count_to_mbcnt_amd = 1,
+               .lower_cs_local_id_yz_to_subgroup_id = 1,
             });
 
    NIR_PASS(_, nir, nir_lower_load_const_to_scalar);
-- 
GitLab


From bba5c7b5c3a8da77654d6514ceebf8576e0b2fcd Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Mon, 3 Jul 2023 17:08:21 +0200
Subject: [PATCH 3/3] nir/opt_algebraic: Add various bitfield extract patterns.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/compiler/nir/nir_opt_algebraic.py | 30 ++++++++++++++++
 src/compiler/nir/nir_search_helpers.h | 51 +++++++++++++++++++++++++++
 2 files changed, 81 insertions(+)

diff --git a/src/compiler/nir/nir_opt_algebraic.py b/src/compiler/nir/nir_opt_algebraic.py
index 374ddb681260d..b8f7b62bfd830 100644
--- a/src/compiler/nir/nir_opt_algebraic.py
+++ b/src/compiler/nir/nir_opt_algebraic.py
@@ -475,7 +475,37 @@ for size, mask in ((8, 0xff), (16, 0xffff), (32, 0xffffffff), (64, 0xfffffffffff
        (('ushr', ('ishl', a_sz, '#b'), b), ('iand', a, ('ushr', mask, b))),
     ])
 
+# Collapses ubfe(ubfe(a, b, c), d, e) when b, c, d, e are constants.
+def ubfe_ubfe(a, b, c, d, e):
+    inner_offset = ('iand', b, 0x1f)
+    inner_bits = ('umin', ('iand', c, 0x1f), ('isub', 32, inner_offset))
+    outer_offset = ('iand', d, 0x1f)
+    outer_bits = ('iand', e, 0x1f)
+
+    offset = ('iadd', inner_offset, outer_offset)
+    bits = ('umin', outer_bits, ('imin', ('isub', inner_bits, outer_offset), 0))
+    collapsed = ('ubfe', a, offset, bits)
+    offset_out_of_range = ('ilt', 31, offset)
+    bits_out_of_range = ('ige', outer_offset, inner_bits)
+
+    # This will be constant-folded to either 0 or the collapsed ubfe,
+    # whose offset and bits operands will also be constant folded.
+    return ('bcsel', ('ior', offset_out_of_range, bits_out_of_range), 0, collapsed)
+
 optimizations.extend([
+    # Create bitfield extract from right-shift + and pattern.
+    (('iand@32', ('ushr@32', a, b), '#c(is_const_bitmask)'),
+     ('ubfe', a, b, ('bit_count', c)),
+     'options->lower_bitfield_extract'),
+
+    # Collapse two bitfield extracts with constant operands into a single one.
+    (('ubfe', ('ubfe', a, '#b', '#c'), '#d', '#e'),
+     ubfe_ubfe(a, b, c, d, e)),
+
+    # Collapse non-zero right-shift into bitfield extract.
+    (('ushr@32', ('ubfe', a, '#b', '#c'), '#d(is_5lsb_not_zero)'),
+     ubfe_ubfe(a, b, c, d, ('isub', 32, ('iand', d, 0x1f)))),
+
     (('iand', ('ishl', 'a@32', '#b(is_first_5_bits_uge_2)'), -4), ('ishl', a, b)),
     (('iand', ('imul', a, '#b(is_unsigned_multiple_of_4)'), -4), ('imul', a, b)),
 ])
diff --git a/src/compiler/nir/nir_search_helpers.h b/src/compiler/nir/nir_search_helpers.h
index a9d19963a7a19..a6b6800f6ae8c 100644
--- a/src/compiler/nir/nir_search_helpers.h
+++ b/src/compiler/nir/nir_search_helpers.h
@@ -574,6 +574,57 @@ is_lower_half_negative_one(UNUSED struct hash_table *ht, const nir_alu_instr *in
    return true;
 }
 
+/**
+ * Returns whether an operand is a constant bit-mask, meaning that it
+ * only has consecutive 1 bits starting from the LSB.
+ * Numbers whose MSB is 1 are excluded because they are not useful
+ * for the optimizations where this function is used.
+ */
+static inline bool
+is_const_bitmask(UNUSED struct hash_table *ht, const nir_alu_instr *instr,
+                 unsigned src, unsigned num_components,
+                 const uint8_t *swizzle)
+{
+   if (nir_src_as_const_value(instr->src[src].src) == NULL)
+      return false;
+
+   for (unsigned i = 0; i < num_components; i++) {
+      if (!instr->src[src].src.is_ssa)
+         return false;
+
+      const unsigned bit_size = instr->src[src].src.ssa->bit_size;
+      const uint64_t c = nir_src_comp_as_uint(instr->src[src].src, swizzle[i]);
+      const unsigned num_bits = util_bitcount64(c);
+      if (c != BITFIELD64_MASK(num_bits) || num_bits == bit_size)
+         return false;
+   }
+
+   return true;
+}
+
+/**
+ * Returns whether the 5 LSBs of an operand are non-zero.
+ */
+static inline bool
+is_5lsb_not_zero(UNUSED struct hash_table *ht, const nir_alu_instr *instr,
+                 unsigned src, unsigned num_components,
+                 const uint8_t *swizzle)
+{
+   if (nir_src_as_const_value(instr->src[src].src) == NULL)
+      return false;
+
+   for (unsigned i = 0; i < num_components; i++) {
+      if (!instr->src[src].src.is_ssa)
+         return false;
+
+      const uint64_t c = nir_src_comp_as_uint(instr->src[src].src, swizzle[i]);
+      if ((c & 0x1f) == 0)
+         return false;
+   }
+
+   return true;
+}
+
 static inline bool
 no_signed_wrap(const nir_alu_instr *instr)
 {
-- 
GitLab

