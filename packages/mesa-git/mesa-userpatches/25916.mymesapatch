From 47196245369aeeb8c175e1ca583fb5f38a202119 Mon Sep 17 00:00:00 2001
From: Faith Ekstrand <faith.ekstrand@collabora.com>
Date: Thu, 26 Oct 2023 08:51:57 -0500
Subject: [PATCH 1/6] nir: Add a typedef for the nir_lower_io type size
 callback

---
 src/compiler/nir/nir.h          | 22 +++++++++++++++++-----
 src/compiler/nir/nir_lower_io.c | 10 +++++-----
 2 files changed, 22 insertions(+), 10 deletions(-)

diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index 16be72b7376d9..85ad3f454a37e 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -5020,10 +5020,6 @@ void nir_gather_types(nir_function_impl *impl,
                       BITSET_WORD *float_types,
                       BITSET_WORD *int_types);
 
-void nir_assign_var_locations(nir_shader *shader, nir_variable_mode mode,
-                              unsigned *size,
-                              int (*type_size)(const struct glsl_type *, bool));
-
 /* Some helpers to do very simple linking */
 bool nir_remove_unused_varyings(nir_shader *producer, nir_shader *consumer);
 bool nir_remove_unused_io_vars(nir_shader *shader, nir_variable_mode mode,
@@ -5068,6 +5064,22 @@ nir_linked_io_var_info
 nir_assign_linked_io_var_locations(nir_shader *producer,
                                    nir_shader *consumer);
 
+/** Returns the size of a type
+ *
+ * The value returned by this callback is potentially modified by the
+ * following flags:
+ *
+ *  - is_bindless:  The variable has the bindless flag set and that texture
+ *    and sampler types take actual size.  For input/output variable, this is
+ *    always true.
+ */
+typedef int (*nir_lower_io_type_size_cb)(const struct glsl_type *,
+                                         bool is_bindless);
+
+void nir_assign_var_locations(nir_shader *shader, nir_variable_mode mode,
+                              unsigned *size,
+                              nir_lower_io_type_size_cb type_size);
+
 typedef enum {
    /* If set, this causes all 64-bit IO operations to be lowered on-the-fly
     * to 32-bit operations.  This is only valid for nir_var_shader_in/out
@@ -5100,7 +5112,7 @@ typedef enum {
 } nir_lower_io_options;
 bool nir_lower_io(nir_shader *shader,
                   nir_variable_mode modes,
-                  int (*type_size)(const struct glsl_type *, bool),
+                  nir_lower_io_type_size_cb type_size,
                   nir_lower_io_options);
 
 bool nir_io_add_const_offset_to_base(nir_shader *nir, nir_variable_mode modes);
diff --git a/src/compiler/nir/nir_lower_io.c b/src/compiler/nir/nir_lower_io.c
index d2bca8ad7d3c1..63b8f0c8d7a23 100644
--- a/src/compiler/nir/nir_lower_io.c
+++ b/src/compiler/nir/nir_lower_io.c
@@ -36,7 +36,7 @@
 struct lower_io_state {
    void *dead_ctx;
    nir_builder builder;
-   int (*type_size)(const struct glsl_type *type, bool);
+   nir_lower_io_type_size_cb type_size;
    nir_variable_mode modes;
    nir_lower_io_options options;
 };
@@ -105,7 +105,7 @@ task_payload_atomic_for_deref(nir_intrinsic_op deref_op)
 void
 nir_assign_var_locations(nir_shader *shader, nir_variable_mode mode,
                          unsigned *size,
-                         int (*type_size)(const struct glsl_type *, bool))
+                         nir_lower_io_type_size_cb type_size)
 {
    unsigned location = 0;
 
@@ -198,7 +198,7 @@ get_number_of_slots(struct lower_io_state *state,
 static nir_def *
 get_io_offset(nir_builder *b, nir_deref_instr *deref,
               nir_def **array_index,
-              int (*type_size)(const struct glsl_type *, bool),
+              nir_lower_io_type_size_cb type_size,
               unsigned *component, bool bts)
 {
    nir_deref_path path;
@@ -752,7 +752,7 @@ nir_lower_io_block(nir_block *block,
 static bool
 nir_lower_io_impl(nir_function_impl *impl,
                   nir_variable_mode modes,
-                  int (*type_size)(const struct glsl_type *, bool),
+                  nir_lower_io_type_size_cb type_size,
                   nir_lower_io_options options)
 {
    struct lower_io_state state;
@@ -790,7 +790,7 @@ nir_lower_io_impl(nir_function_impl *impl,
  */
 bool
 nir_lower_io(nir_shader *shader, nir_variable_mode modes,
-             int (*type_size)(const struct glsl_type *, bool),
+             nir_lower_io_type_size_cb type_size,
              nir_lower_io_options options)
 {
    bool progress = false;
-- 
GitLab


From 5d8cda480c17b0e850c7d602e299b198198a2854 Mon Sep 17 00:00:00 2001
From: Faith Ekstrand <faith.ekstrand@collabora.com>
Date: Thu, 26 Oct 2023 13:44:40 -0500
Subject: [PATCH 2/6] nir: Add a shared lower_io type size callback which
 returns vec4s

This is what most drivers want most of the time and it's what gallium
expects.  Most drivers have a type_size function which is a tiny wrapper
like this one in ir3:

    int
    ir3_glsl_type_size(const struct glsl_type *type, bool bindless)
    {
        glsl_count_attribute_slots(type, false);
    }

This provides a common helper which pretty much does that.  The only
difference is that the new helper does ignore images/samplers when
bindless is false so it's safe to use for uniforms, attributes, and
varyings.
---
 src/amd/vulkan/nir/radv_nir_lower_io.c             | 12 +++---------
 src/broadcom/compiler/vir.c                        | 12 ++----------
 src/broadcom/vulkan/v3dv_pipeline.c                |  8 +-------
 src/compiler/nir/nir.h                             |  2 ++
 src/compiler/nir/nir_lower_io.c                    | 14 +++++++-------
 src/freedreno/ir3/ir3_nir.c                        | 12 +++++++++---
 src/freedreno/ir3/ir3_shader.c                     |  6 ------
 src/freedreno/ir3/ir3_shader.h                     |  2 --
 src/gallium/auxiliary/nir/nir_to_tgsi.c            |  8 +-------
 src/gallium/drivers/etnaviv/etnaviv_compiler_nir.c | 10 ++--------
 src/gallium/drivers/freedreno/a2xx/fd2_program.c   | 10 ++--------
 src/gallium/drivers/freedreno/ir3/ir3_cmdline.c    | 14 +++++++-------
 src/gallium/drivers/lima/lima_program.c            | 12 ++++--------
 src/gallium/drivers/r300/compiler/nir_to_rc.c      |  8 +-------
 src/gallium/drivers/r600/sfn/sfn_nir.cpp           |  8 +-------
 src/gallium/drivers/v3d/v3d_program.c              |  8 +-------
 src/gallium/drivers/vc4/vc4_program.c              |  8 +-------
 src/gallium/drivers/zink/zink_compiler.c           | 10 ++--------
 src/imagination/rogue/rogue_nir.c                  |  7 +------
 src/microsoft/compiler/nir_to_dxil.c               |  8 +-------
 src/nouveau/codegen/nv50_ir_from_nir.cpp           |  8 +-------
 src/panfrost/compiler/bifrost_compile.c            |  8 +-------
 src/panfrost/midgard/midgard_compile.c             |  8 +-------
 23 files changed, 51 insertions(+), 152 deletions(-)

diff --git a/src/amd/vulkan/nir/radv_nir_lower_io.c b/src/amd/vulkan/nir/radv_nir_lower_io.c
index bc5ecfe41e9b0..74b5bb10b8e50 100644
--- a/src/amd/vulkan/nir/radv_nir_lower_io.c
+++ b/src/amd/vulkan/nir/radv_nir_lower_io.c
@@ -30,12 +30,6 @@
 #include "radv_private.h"
 #include "radv_shader.h"
 
-static int
-type_size_vec4(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 void
 radv_nir_lower_io_to_scalar_early(nir_shader *nir, nir_variable_mode mask)
 {
@@ -80,10 +74,10 @@ radv_nir_lower_io(struct radv_device *device, nir_shader *nir)
    }
 
    if (nir->info.stage == MESA_SHADER_VERTEX) {
-      NIR_PASS(_, nir, nir_lower_io, nir_var_shader_in, type_size_vec4, 0);
-      NIR_PASS(_, nir, nir_lower_io, nir_var_shader_out, type_size_vec4, nir_lower_io_lower_64bit_to_32);
+      NIR_PASS(_, nir, nir_lower_io, nir_var_shader_in, nir_io_type_size_vec4, 0);
+      NIR_PASS(_, nir, nir_lower_io, nir_var_shader_out, nir_io_type_size_vec4, nir_lower_io_lower_64bit_to_32);
    } else {
-      NIR_PASS(_, nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out, type_size_vec4,
+      NIR_PASS(_, nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out, nir_io_type_size_vec4,
                nir_lower_io_lower_64bit_to_32);
    }
 
diff --git a/src/broadcom/compiler/vir.c b/src/broadcom/compiler/vir.c
index 8c536b8fbcc12..8f0a6ddafa38a 100644
--- a/src/broadcom/compiler/vir.c
+++ b/src/broadcom/compiler/vir.c
@@ -616,12 +616,6 @@ vir_compile_init(const struct v3d_compiler *compiler,
         return c;
 }
 
-static int
-type_size_vec4(const struct glsl_type *type, bool bindless)
-{
-        return glsl_count_attribute_slots(type, false);
-}
-
 static enum nir_lower_tex_packing
 lower_tex_packing_cb(const nir_tex_instr *tex, const void *data)
 {
@@ -954,8 +948,7 @@ v3d_nir_lower_vs_early(struct v3d_compile *c)
                 NIR_PASS(_, c->s, nir_lower_point_size, 1.0f, 0.0f);
 
         NIR_PASS(_, c->s, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-                 type_size_vec4,
-                 (nir_lower_io_options)0);
+                 nir_io_type_size_vec4, (nir_lower_io_options)0);
         /* clean up nir_lower_io's deref_var remains and do a constant folding pass
          * on the code it generated.
          */
@@ -988,8 +981,7 @@ v3d_nir_lower_gs_early(struct v3d_compile *c)
                 NIR_PASS(_, c->s, nir_lower_point_size, 1.0f, 0.0f);
 
         NIR_PASS(_, c->s, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-                 type_size_vec4,
-                 (nir_lower_io_options)0);
+                 nir_io_type_size_vec4, (nir_lower_io_options)0);
         /* clean up nir_lower_io's deref_var remains and do a constant folding pass
          * on the code it generated.
          */
diff --git a/src/broadcom/vulkan/v3dv_pipeline.c b/src/broadcom/vulkan/v3dv_pipeline.c
index 3b182951efe4f..b9548d3cdd637 100644
--- a/src/broadcom/vulkan/v3dv_pipeline.c
+++ b/src/broadcom/vulkan/v3dv_pipeline.c
@@ -393,12 +393,6 @@ shader_module_compile_to_nir(struct v3dv_device *device,
    return nir;
 }
 
-static int
-type_size_vec4(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 /* FIXME: the number of parameters for this method is somewhat big. Perhaps
  * rethink.
  */
@@ -934,7 +928,7 @@ lower_fs_io(nir_shader *nir)
                                MESA_SHADER_FRAGMENT);
 
    NIR_PASS(_, nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-            type_size_vec4, 0);
+            nir_io_type_size_vec4, 0);
 }
 
 static void
diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index 85ad3f454a37e..6448578066895 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -5076,6 +5076,8 @@ nir_assign_linked_io_var_locations(nir_shader *producer,
 typedef int (*nir_lower_io_type_size_cb)(const struct glsl_type *,
                                          bool is_bindless);
 
+int nir_io_type_size_vec4(const struct glsl_type *, bool is_bindless);
+
 void nir_assign_var_locations(nir_shader *shader, nir_variable_mode mode,
                               unsigned *size,
                               nir_lower_io_type_size_cb type_size);
diff --git a/src/compiler/nir/nir_lower_io.c b/src/compiler/nir/nir_lower_io.c
index 63b8f0c8d7a23..aac84df348f56 100644
--- a/src/compiler/nir/nir_lower_io.c
+++ b/src/compiler/nir/nir_lower_io.c
@@ -33,6 +33,12 @@
 
 #include "util/u_math.h"
 
+int
+nir_io_type_size_vec4(const struct glsl_type *type, bool is_bindless)
+{
+   return glsl_count_vec4_slots(type, false, is_bindless);
+}
+
 struct lower_io_state {
    void *dead_ctx;
    nir_builder builder;
@@ -3143,12 +3149,6 @@ nir_io_add_intrinsic_xfb_info(nir_shader *nir)
    return progress;
 }
 
-static int
-type_size_vec4(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 /**
  * This runs all compiler passes needed to lower IO, lower indirect IO access,
  * set transform feedback info in IO intrinsics, and clean up the IR.
@@ -3202,7 +3202,7 @@ nir_lower_io_passes(nir_shader *nir, bool renumber_vs_inputs)
    }
 
    NIR_PASS_V(nir, nir_lower_io, nir_var_shader_out | nir_var_shader_in,
-              type_size_vec4, nir_lower_io_lower_64bit_to_32);
+              nir_io_type_size_vec4, nir_lower_io_lower_64bit_to_32);
 
    /* nir_io_add_const_offset_to_base needs actual constants. */
    NIR_PASS_V(nir, nir_opt_constant_folding);
diff --git a/src/freedreno/ir3/ir3_nir.c b/src/freedreno/ir3/ir3_nir.c
index 21b3576ec7be8..6ed436c830930 100644
--- a/src/freedreno/ir3/ir3_nir.c
+++ b/src/freedreno/ir3/ir3_nir.c
@@ -327,6 +327,12 @@ ir3_nir_lower_array_sampler(nir_shader *shader)
       nir_metadata_block_index | nir_metadata_dominance, NULL);
 }
 
+static int
+amul_type_size_vec4(const struct glsl_type *type, bool _unused)
+{
+   return glsl_count_attribute_slots(type, false);
+}
+
 void
 ir3_finalize_nir(struct ir3_compiler *compiler, nir_shader *s)
 {
@@ -357,7 +363,7 @@ ir3_finalize_nir(struct ir3_compiler *compiler, nir_shader *s)
       NIR_PASS_V(s, ir3_nir_lower_gs);
 
    NIR_PASS_V(s, nir_lower_frexp);
-   NIR_PASS_V(s, nir_lower_amul, ir3_glsl_type_size);
+   NIR_PASS_V(s, nir_lower_amul, amul_type_size_vec4);
 
    OPT_V(s, nir_lower_wrmasks, should_split_wrmask, s);
 
@@ -473,7 +479,7 @@ ir3_nir_post_finalize(struct ir3_shader *shader)
    MESA_TRACE_FUNC();
 
    NIR_PASS_V(s, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-              ir3_glsl_type_size, nir_lower_io_lower_64bit_to_32);
+              nir_io_type_size_vec4, nir_lower_io_lower_64bit_to_32);
 
    if (s->info.stage == MESA_SHADER_FRAGMENT) {
       /* NOTE: lower load_barycentric_at_sample first, since it
@@ -752,7 +758,7 @@ ir3_nir_lower_variant(struct ir3_shader_variant *so, nir_shader *s)
 
    progress |= OPT(s, ir3_nir_lower_preamble, so);
 
-   OPT_V(s, nir_lower_amul, ir3_glsl_type_size);
+   OPT_V(s, nir_lower_amul, amul_type_size_vec4);
 
    /* UBO offset lowering has to come after we've decided what will
     * be left as load_ubo
diff --git a/src/freedreno/ir3/ir3_shader.c b/src/freedreno/ir3/ir3_shader.c
index d4c64e242cb8f..ed21c12e1f6ca 100644
--- a/src/freedreno/ir3/ir3_shader.c
+++ b/src/freedreno/ir3/ir3_shader.c
@@ -42,12 +42,6 @@
 
 #include "disasm.h"
 
-int
-ir3_glsl_type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 /* wrapper for ir3_assemble() which does some info fixup based on
  * shader state.  Non-static since used by ir3_cmdline too.
  */
diff --git a/src/freedreno/ir3/ir3_shader.h b/src/freedreno/ir3/ir3_shader.h
index d2686fcb10420..f000d2b4a4f91 100644
--- a/src/freedreno/ir3/ir3_shader.h
+++ b/src/freedreno/ir3/ir3_shader.h
@@ -991,8 +991,6 @@ void ir3_shader_destroy(struct ir3_shader *shader);
 void ir3_shader_disasm(struct ir3_shader_variant *so, uint32_t *bin, FILE *out);
 uint64_t ir3_shader_outputs(const struct ir3_shader *so);
 
-int ir3_glsl_type_size(const struct glsl_type *type, bool bindless);
-
 /*
  * Helper/util:
  */
diff --git a/src/gallium/auxiliary/nir/nir_to_tgsi.c b/src/gallium/auxiliary/nir/nir_to_tgsi.c
index 4cf7fbc20c481..bce2efee902d6 100644
--- a/src/gallium/auxiliary/nir/nir_to_tgsi.c
+++ b/src/gallium/auxiliary/nir/nir_to_tgsi.c
@@ -3206,12 +3206,6 @@ ntt_emit_impl(struct ntt_compile *c, nir_function_impl *impl)
 
 }
 
-static int
-type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 /* Allow vectorizing of ALU instructions, but avoid vectorizing past what we
  * can handle for 64-bit values in TGSI.
  */
@@ -3908,7 +3902,7 @@ const void *nir_to_tgsi_options(struct nir_shader *s,
    }
 
    NIR_PASS_V(s, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-              type_size, (nir_lower_io_options)0);
+              nir_io_type_size_vec4, (nir_lower_io_options)0);
 
    nir_to_tgsi_lower_txp(s);
    NIR_PASS_V(s, nir_to_tgsi_lower_tex);
diff --git a/src/gallium/drivers/etnaviv/etnaviv_compiler_nir.c b/src/gallium/drivers/etnaviv/etnaviv_compiler_nir.c
index 9c821625fe6db..78d9e378d01df 100644
--- a/src/gallium/drivers/etnaviv/etnaviv_compiler_nir.c
+++ b/src/gallium/drivers/etnaviv/etnaviv_compiler_nir.c
@@ -174,12 +174,6 @@ etna_optimize_loop(nir_shader *s)
    while (progress);
 }
 
-static int
-etna_glsl_type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 static void
 copy_uniform_state_to_shader(struct etna_shader_variant *sobj, uint64_t *consts, unsigned count)
 {
@@ -1164,8 +1158,8 @@ etna_compile_shader(struct etna_shader_variant *v)
       assert(sf->num_reg == count);
    }
 
-   NIR_PASS_V(s, nir_lower_io, nir_var_shader_in | nir_var_uniform, etna_glsl_type_size,
-            (nir_lower_io_options)0);
+   NIR_PASS_V(s, nir_lower_io, nir_var_shader_in | nir_var_uniform,
+              nir_io_type_size_vec4, (nir_lower_io_options)0);
 
    NIR_PASS_V(s, nir_lower_vars_to_ssa);
    NIR_PASS_V(s, nir_lower_indirect_derefs, nir_var_all, UINT32_MAX);
diff --git a/src/gallium/drivers/freedreno/a2xx/fd2_program.c b/src/gallium/drivers/freedreno/a2xx/fd2_program.c
index d60ab8c6795d2..74ea33ae792a7 100644
--- a/src/gallium/drivers/freedreno/a2xx/fd2_program.c
+++ b/src/gallium/drivers/freedreno/a2xx/fd2_program.c
@@ -83,12 +83,6 @@ emit(struct fd_ringbuffer *ring, gl_shader_stage type,
       OUT_RING(ring, info->dwords[i]);
 }
 
-static int
-ir2_glsl_type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 static void *
 fd2_fp_state_create(struct pipe_context *pctx,
                     const struct pipe_shader_state *cso)
@@ -102,7 +96,7 @@ fd2_fp_state_create(struct pipe_context *pctx,
                 : tgsi_to_nir(cso->tokens, pctx->screen, false);
 
    NIR_PASS_V(so->nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-              ir2_glsl_type_size, (nir_lower_io_options)0);
+              nir_io_type_size_vec4, (nir_lower_io_options)0);
 
    if (ir2_optimize_nir(so->nir, true))
       goto fail;
@@ -140,7 +134,7 @@ fd2_vp_state_create(struct pipe_context *pctx,
                 : tgsi_to_nir(cso->tokens, pctx->screen, false);
 
    NIR_PASS_V(so->nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-              ir2_glsl_type_size, (nir_lower_io_options)0);
+              nir_io_type_size_vec4, (nir_lower_io_options)0);
 
    if (ir2_optimize_nir(so->nir, true))
       goto fail;
diff --git a/src/gallium/drivers/freedreno/ir3/ir3_cmdline.c b/src/gallium/drivers/freedreno/ir3/ir3_cmdline.c
index 497a44b147a3e..e11fc30e89e30 100644
--- a/src/gallium/drivers/freedreno/ir3/ir3_cmdline.c
+++ b/src/gallium/drivers/freedreno/ir3/ir3_cmdline.c
@@ -148,23 +148,23 @@ load_glsl(unsigned num_files, char *const *files, gl_shader_stage stage)
    switch (stage) {
    case MESA_SHADER_VERTEX:
       nir_assign_var_locations(nir, nir_var_shader_in, &nir->num_inputs,
-                               ir3_glsl_type_size);
+                               nir_io_type_size_vec4);
 
       /* Re-lower global vars, to deal with any dead VS inputs. */
       NIR_PASS_V(nir, nir_lower_global_vars_to_local);
 
       sort_varyings(nir, nir_var_shader_out);
       nir_assign_var_locations(nir, nir_var_shader_out, &nir->num_outputs,
-                               ir3_glsl_type_size);
+                               nir_io_type_size_vec4);
       fixup_varying_slots(nir, nir_var_shader_out);
       break;
    case MESA_SHADER_FRAGMENT:
       sort_varyings(nir, nir_var_shader_in);
       nir_assign_var_locations(nir, nir_var_shader_in, &nir->num_inputs,
-                               ir3_glsl_type_size);
+                               nir_io_type_size_vec4);
       fixup_varying_slots(nir, nir_var_shader_in);
       nir_assign_var_locations(nir, nir_var_shader_out, &nir->num_outputs,
-                               ir3_glsl_type_size);
+                               nir_io_type_size_vec4);
       break;
    case MESA_SHADER_COMPUTE:
    case MESA_SHADER_KERNEL:
@@ -174,7 +174,7 @@ load_glsl(unsigned num_files, char *const *files, gl_shader_stage stage)
    }
 
    nir_assign_var_locations(nir, nir_var_uniform, &nir->num_uniforms,
-                            ir3_glsl_type_size);
+                            nir_io_type_size_vec4);
 
    NIR_PASS_V(nir, nir_lower_system_values);
    NIR_PASS_V(nir, nir_lower_compute_system_values, NULL);
@@ -182,7 +182,7 @@ load_glsl(unsigned num_files, char *const *files, gl_shader_stage stage)
    NIR_PASS_V(nir, nir_lower_frexp);
    NIR_PASS_V(nir, nir_lower_io,
               nir_var_shader_in | nir_var_shader_out | nir_var_uniform,
-              ir3_glsl_type_size, (nir_lower_io_options)0);
+              nir_io_type_size_vec4, (nir_lower_io_options)0);
    NIR_PASS_V(nir, gl_nir_lower_samplers, prog);
 
    return nir;
@@ -399,7 +399,7 @@ main(int argc, char **argv)
       nir = load_spirv(filenames[0], spirv_entry, stage);
 
       NIR_PASS_V(nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-                 ir3_glsl_type_size, (nir_lower_io_options)0);
+                 nir_io_type_size_vec4, (nir_lower_io_options)0);
 
       /* TODO do this somewhere else */
       nir_lower_int64(nir);
diff --git a/src/gallium/drivers/lima/lima_program.c b/src/gallium/drivers/lima/lima_program.c
index e670524899228..b768a16d6f705 100644
--- a/src/gallium/drivers/lima/lima_program.c
+++ b/src/gallium/drivers/lima/lima_program.c
@@ -104,12 +104,6 @@ lima_program_get_compiler_options(enum pipe_shader_type shader)
    }
 }
 
-static int
-type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 void
 lima_program_optimize_vs_nir(struct nir_shader *s)
 {
@@ -118,7 +112,8 @@ lima_program_optimize_vs_nir(struct nir_shader *s)
    NIR_PASS_V(s, nir_lower_viewport_transform);
    NIR_PASS_V(s, nir_lower_point_size, 1.0f, 100.0f);
    NIR_PASS_V(s, nir_lower_io,
-	      nir_var_shader_in | nir_var_shader_out, type_size, 0);
+	      nir_var_shader_in | nir_var_shader_out,
+              nir_io_type_size_vec4, 0);
    NIR_PASS_V(s, nir_lower_load_const_to_scalar);
    NIR_PASS_V(s, lima_nir_lower_uniform_to_scalar);
    NIR_PASS_V(s, nir_lower_io_to_scalar,
@@ -226,7 +221,8 @@ lima_program_optimize_fs_nir(struct nir_shader *s,
 
    NIR_PASS_V(s, nir_lower_fragcoord_wtrans);
    NIR_PASS_V(s, nir_lower_io,
-	      nir_var_shader_in | nir_var_shader_out, type_size, 0);
+	      nir_var_shader_in | nir_var_shader_out,
+              nir_io_type_size_vec4, 0);
    NIR_PASS_V(s, nir_lower_tex, tex_options);
    NIR_PASS_V(s, lima_nir_lower_txp);
 
diff --git a/src/gallium/drivers/r300/compiler/nir_to_rc.c b/src/gallium/drivers/r300/compiler/nir_to_rc.c
index 0fda015ced04e..bfca04002807e 100644
--- a/src/gallium/drivers/r300/compiler/nir_to_rc.c
+++ b/src/gallium/drivers/r300/compiler/nir_to_rc.c
@@ -2157,12 +2157,6 @@ ntr_emit_impl(struct ntr_compile *c, nir_function_impl *impl)
 
 }
 
-static int
-type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 /* Allow vectorizing of ALU instructions.
  */
 static uint8_t
@@ -2389,7 +2383,7 @@ const void *nir_to_rc_options(struct nir_shader *s,
    }
 
    NIR_PASS_V(s, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-              type_size, (nir_lower_io_options)0);
+              nir_io_type_size_vec4, (nir_lower_io_options)0);
 
    nir_to_rc_lower_txp(s);
    NIR_PASS_V(s, nir_to_rc_lower_tex);
diff --git a/src/gallium/drivers/r600/sfn/sfn_nir.cpp b/src/gallium/drivers/r600/sfn/sfn_nir.cpp
index d03116c60235f..6bd98f7f937c6 100644
--- a/src/gallium/drivers/r600/sfn/sfn_nir.cpp
+++ b/src/gallium/drivers/r600/sfn/sfn_nir.cpp
@@ -468,12 +468,6 @@ using r600::r600_lower_fs_out_to_vector;
 using r600::r600_lower_scratch_addresses;
 using r600::r600_lower_ubo_to_align16;
 
-int
-r600_glsl_type_size(const struct glsl_type *type, bool is_bindless)
-{
-   return glsl_count_vec4_slots(type, false, is_bindless);
-}
-
 void
 r600_get_natural_size_align_bytes(const struct glsl_type *type,
                                   unsigned *size,
@@ -802,7 +796,7 @@ r600_shader_from_nir(struct r600_context *rctx,
    NIR_PASS_V(sh,
               nir_lower_io,
               io_modes,
-              r600_glsl_type_size,
+              nir_io_type_size_vec4,
               nir_lower_io_lower_64bit_to_32);
 
    if (sh->info.stage == MESA_SHADER_FRAGMENT)
diff --git a/src/gallium/drivers/v3d/v3d_program.c b/src/gallium/drivers/v3d/v3d_program.c
index 89fee012ddd96..9ffe092b7cf05 100644
--- a/src/gallium/drivers/v3d/v3d_program.c
+++ b/src/gallium/drivers/v3d/v3d_program.c
@@ -183,12 +183,6 @@ v3d_set_transform_feedback_outputs(struct v3d_uncompiled_shader *so,
         memcpy(so->tf_outputs, slots, sizeof(*slots) * slot_count);
 }
 
-static int
-type_size(const struct glsl_type *type, bool bindless)
-{
-        return glsl_count_attribute_slots(type, false);
-}
-
 static void
 precompile_all_outputs(nir_shader *s,
                        struct v3d_varying_slot *outputs,
@@ -368,7 +362,7 @@ v3d_uncompiled_shader_create(struct pipe_context *pctx,
             s->info.stage != MESA_SHADER_GEOMETRY) {
                 NIR_PASS(_, s, nir_lower_io,
                          nir_var_shader_in | nir_var_shader_out,
-                         type_size, (nir_lower_io_options)0);
+                         nir_io_type_size_vec4, (nir_lower_io_options)0);
         }
 
         NIR_PASS(_, s, nir_normalize_cubemap_coords);
diff --git a/src/gallium/drivers/vc4/vc4_program.c b/src/gallium/drivers/vc4/vc4_program.c
index 46f16e445c516..be526e2227ee9 100644
--- a/src/gallium/drivers/vc4/vc4_program.c
+++ b/src/gallium/drivers/vc4/vc4_program.c
@@ -48,12 +48,6 @@ static struct vc4_compiled_shader *
 vc4_get_compiled_shader(struct vc4_context *vc4, enum qstage stage,
                         struct vc4_key *key);
 
-static int
-type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 static void
 resize_qreg_array(struct vc4_compile *c,
                   struct qreg **regs,
@@ -2531,7 +2525,7 @@ vc4_shader_state_create(struct pipe_context *pctx,
 
         NIR_PASS_V(s, nir_lower_io,
                    nir_var_shader_in | nir_var_shader_out | nir_var_uniform,
-                   type_size, (nir_lower_io_options)0);
+                   nir_io_type_size_vec4, (nir_lower_io_options)0);
 
         NIR_PASS_V(s, nir_normalize_cubemap_coords);
 
diff --git a/src/gallium/drivers/zink/zink_compiler.c b/src/gallium/drivers/zink/zink_compiler.c
index 014b6cccdd7bb..f155d64e1778a 100644
--- a/src/gallium/drivers/zink/zink_compiler.c
+++ b/src/gallium/drivers/zink/zink_compiler.c
@@ -5283,12 +5283,6 @@ eliminate_io_wrmasks_instr(const nir_instr *instr, const void *data)
    return false;
 }
 
-static int
-zink_type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 static nir_mem_access_size_align
 mem_access_size_align_cb(nir_intrinsic_op intrin, uint8_t bytes,
                          uint8_t bit_size, uint32_t align,
@@ -5345,10 +5339,10 @@ zink_shader_create(struct zink_screen *screen, struct nir_shader *nir)
       NIR_PASS_V(nir, nir_split_var_copies);
       NIR_PASS_V(nir, nir_lower_var_copies);
    }
-   NIR_PASS_V(nir, nir_lower_io, nir_var_shader_out, zink_type_size, lower_io_flags);
+   NIR_PASS_V(nir, nir_lower_io, nir_var_shader_out, nir_io_type_size_vec4, lower_io_flags);
    if (nir->info.stage == MESA_SHADER_VERTEX)
       lower_io_flags |= nir_lower_io_lower_64bit_to_32;
-   NIR_PASS_V(nir, nir_lower_io, nir_var_shader_in, zink_type_size, lower_io_flags);
+   NIR_PASS_V(nir, nir_lower_io, nir_var_shader_in, nir_io_type_size_vec4, lower_io_flags);
    nir->info.io_lowered = true;
 
    if (nir->info.stage == MESA_SHADER_KERNEL) {
diff --git a/src/imagination/rogue/rogue_nir.c b/src/imagination/rogue/rogue_nir.c
index ecbf4547e2dfd..4999ac7c7b818 100644
--- a/src/imagination/rogue/rogue_nir.c
+++ b/src/imagination/rogue/rogue_nir.c
@@ -48,11 +48,6 @@ static const nir_shader_compiler_options nir_options = {
    .fuse_ffma32 = true,
 };
 
-static int rogue_glsl_type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 /**
  * \brief Applies optimizations and passes required to lower the NIR shader into
  * a form suitable for lowering to Rogue IR.
@@ -84,7 +79,7 @@ static void rogue_nir_passes(struct rogue_build_ctx *ctx,
    NIR_PASS_V(nir,
               nir_lower_io,
               nir_var_shader_in | nir_var_shader_out,
-              rogue_glsl_type_size,
+              nir_io_type_size_vec4,
               (nir_lower_io_options)0);
 
    /* Load inputs to scalars (single registers later). */
diff --git a/src/microsoft/compiler/nir_to_dxil.c b/src/microsoft/compiler/nir_to_dxil.c
index 97537fea53470..09f9ea14403c4 100644
--- a/src/microsoft/compiler/nir_to_dxil.c
+++ b/src/microsoft/compiler/nir_to_dxil.c
@@ -6418,12 +6418,6 @@ allocate_sysvalues(struct ntd_context *ctx)
    return true;
 }
 
-static int
-type_size_vec4(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 static const unsigned dxil_validator_min_capable_version = DXIL_VALIDATOR_1_4;
 static const unsigned dxil_validator_max_capable_version = DXIL_VALIDATOR_1_7;
 static const unsigned dxil_min_shader_model = SHADER_MODEL_6_0;
@@ -6511,7 +6505,7 @@ nir_to_dxil(struct nir_shader *s, const struct nir_to_dxil_options *opts,
    NIR_PASS_V(s, dxil_nir_lower_fquantize2f16);
    NIR_PASS_V(s, nir_lower_frexp);
    NIR_PASS_V(s, nir_lower_flrp, 16 | 32 | 64, true);
-   NIR_PASS_V(s, nir_lower_io, nir_var_shader_in | nir_var_shader_out, type_size_vec4, nir_lower_io_lower_64bit_to_32);
+   NIR_PASS_V(s, nir_lower_io, nir_var_shader_in | nir_var_shader_out, nir_io_type_size_vec4, nir_lower_io_lower_64bit_to_32);
    NIR_PASS_V(s, dxil_nir_ensure_position_writes);
    NIR_PASS_V(s, dxil_nir_lower_system_values);
    NIR_PASS_V(s, nir_lower_io_to_scalar, nir_var_shader_in | nir_var_system_value | nir_var_shader_out, NULL, NULL);
diff --git a/src/nouveau/codegen/nv50_ir_from_nir.cpp b/src/nouveau/codegen/nv50_ir_from_nir.cpp
index 9bdc45b9ccedc..e39a42d8665b2 100644
--- a/src/nouveau/codegen/nv50_ir_from_nir.cpp
+++ b/src/nouveau/codegen/nv50_ir_from_nir.cpp
@@ -43,12 +43,6 @@ namespace {
 
 using namespace nv50_ir;
 
-int
-type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 static void
 function_temp_type_info(const struct glsl_type *type, unsigned *size, unsigned *align)
 {
@@ -3277,7 +3271,7 @@ Converter::run()
    NIR_PASS_V(nir, nir_lower_vars_to_ssa);
 
    NIR_PASS_V(nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-              type_size, (nir_lower_io_options)0);
+              nir_io_type_size_vec4, (nir_lower_io_options)0);
 
    NIR_PASS_V(nir, nir_lower_subgroups, &subgroup_options);
 
diff --git a/src/panfrost/compiler/bifrost_compile.c b/src/panfrost/compiler/bifrost_compile.c
index 72c65cb8d5ce6..92c7061311a84 100644
--- a/src/panfrost/compiler/bifrost_compile.c
+++ b/src/panfrost/compiler/bifrost_compile.c
@@ -4141,12 +4141,6 @@ va_print_stats(bi_context *ctx, unsigned size)
                           ctx->fills);
 }
 
-static int
-glsl_type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 /* Split stores to memory. We don't split stores to vertex outputs, since
  * nir_lower_io_to_temporaries will ensure there's only a single write.
  */
@@ -4665,7 +4659,7 @@ bifrost_preprocess_nir(nir_shader *nir, unsigned gpu_id)
    NIR_PASS_V(nir, nir_lower_var_copies);
    NIR_PASS_V(nir, nir_lower_vars_to_ssa);
    NIR_PASS_V(nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-              glsl_type_size, 0);
+              nir_io_type_size_vec4, 0);
 
    /* nir_lower[_explicit]_io is lazy and emits mul+add chains even for
     * offsets it could figure out are constant.  Do some constant folding
diff --git a/src/panfrost/midgard/midgard_compile.c b/src/panfrost/midgard/midgard_compile.c
index f4f2ba4f5c4b0..e5d5bcafd917c 100644
--- a/src/panfrost/midgard/midgard_compile.c
+++ b/src/panfrost/midgard/midgard_compile.c
@@ -205,12 +205,6 @@ attach_constants(compiler_context *ctx, midgard_instruction *ins,
    memcpy(&ins->constants, constants, 16);
 }
 
-static int
-glsl_type_size(const struct glsl_type *type, bool bindless)
-{
-   return glsl_count_attribute_slots(type, false);
-}
-
 static bool
 midgard_nir_lower_global_load_instr(nir_builder *b, nir_intrinsic_instr *intr,
                                     void *data)
@@ -348,7 +342,7 @@ midgard_preprocess_nir(nir_shader *nir, unsigned gpu_id)
    NIR_PASS_V(nir, nir_lower_vars_to_ssa);
 
    NIR_PASS_V(nir, nir_lower_io, nir_var_shader_in | nir_var_shader_out,
-              glsl_type_size, 0);
+              nir_io_type_size_vec4, 0);
 
    if (nir->info.stage == MESA_SHADER_VERTEX) {
       /* nir_lower[_explicit]_io is lazy and emits mul+add chains even
-- 
GitLab


From a7bba2c96406b1767fbafd6385b182dc1d73f6c7 Mon Sep 17 00:00:00 2001
From: Faith Ekstrand <faith.ekstrand@collabora.com>
Date: Thu, 26 Oct 2023 15:58:12 -0500
Subject: [PATCH 3/6] nir/lower_io: Handle per-vertex I/O in
 assign_var_locations

Previously, it assigned enough I/O space for each vertex to have its own
locations but this isn't what any drivers actually want.  This commit
solves this and also adds a helper which gets the size of a variable
which we can share with the nir_lower_io() helpers.
---
 src/compiler/nir/nir_lower_io.c | 34 +++++++++++++++++++--------------
 1 file changed, 20 insertions(+), 14 deletions(-)

diff --git a/src/compiler/nir/nir_lower_io.c b/src/compiler/nir/nir_lower_io.c
index aac84df348f56..8d56494671b59 100644
--- a/src/compiler/nir/nir_lower_io.c
+++ b/src/compiler/nir/nir_lower_io.c
@@ -108,6 +108,21 @@ task_payload_atomic_for_deref(nir_intrinsic_op deref_op)
    }
 }
 
+static int
+variable_size(const nir_variable *var, gl_shader_stage stage,
+              nir_lower_io_type_size_cb type_size)
+{
+   const struct glsl_type *type = var->type;
+   if (nir_is_arrayed_io(var, stage))
+      type = glsl_get_array_element(type);
+
+   bool bindless = var->data.mode == nir_var_shader_in ||
+                   var->data.mode == nir_var_shader_out ||
+                   var->data.bindless;
+
+   return type_size(type, bindless);
+}
+
 void
 nir_assign_var_locations(nir_shader *shader, nir_variable_mode mode,
                          unsigned *size,
@@ -117,10 +132,7 @@ nir_assign_var_locations(nir_shader *shader, nir_variable_mode mode,
 
    nir_foreach_variable_with_modes(var, shader, mode) {
       var->data.driver_location = location;
-      bool bindless_type_size = var->data.mode == nir_var_shader_in ||
-                                var->data.mode == nir_var_shader_out ||
-                                var->data.bindless;
-      location += type_size(var->type, bindless_type_size);
+      location += variable_size(var, shader->info.stage, type_size);
    }
 
    *size = location;
@@ -322,11 +334,8 @@ emit_load(struct lower_io_state *state,
 
    nir_intrinsic_set_base(load, var->data.driver_location);
    if (nir_intrinsic_has_range(load)) {
-      const struct glsl_type *type = var->type;
-      if (array_index)
-         type = glsl_get_array_element(type);
-      unsigned var_size = state->type_size(type, var->data.bindless);
-      nir_intrinsic_set_range(load, var_size);
+      nir_intrinsic_set_range(load, variable_size(var, nir->info.stage,
+                                                  state->type_size));
    }
 
    if (mode == nir_var_shader_in || mode == nir_var_shader_out)
@@ -451,12 +460,9 @@ emit_store(struct lower_io_state *state, nir_def *data,
 
    store->src[0] = nir_src_for_ssa(data);
 
-   const struct glsl_type *type = var->type;
-   if (array_index)
-      type = glsl_get_array_element(type);
-   unsigned var_size = state->type_size(type, var->data.bindless);
    nir_intrinsic_set_base(store, var->data.driver_location);
-   nir_intrinsic_set_range(store, var_size);
+   nir_intrinsic_set_range(store, variable_size(var, b->shader->info.stage,
+                                                state->type_size));
    nir_intrinsic_set_component(store, component);
    nir_intrinsic_set_src_type(store, src_type);
 
-- 
GitLab


From 0ca0afd040fd38ee73d0fce11c932e0467419f32 Mon Sep 17 00:00:00 2001
From: Faith Ekstrand <faith.ekstrand@collabora.com>
Date: Thu, 26 Oct 2023 08:52:43 -0500
Subject: [PATCH 4/6] nir/lower_io: Support indirect vec components and compact
 arrays

The tricky part here is to tease out the type_size differences between a
scalar (or array of scalar) variable and a component of a vector.  For
things which are trying to work in terms of GL or Vulkan locations, a
scalar takes up a whole vec4 whenever it's by itself or in a struct or
array.  A component of a vector or a single scalar within a compact
array, however, only take the size of a single scalar.  This adds a
"compact" bool to the type_size callback to allow us to tease out this
difference.

Most drivers should not see a functional change from this because we
only ever set compact when we are handling an array deref of a vector or
when we have an indirect access to clip distance or tess levels.  All
the drivers in the tree today already lower all that away.

Most of this commit is just churning all the drivers to add the new bool
and assert that it's false in most cases.
---
 src/compiler/nir/nir.h                    | 11 ++++-
 src/compiler/nir/nir_lower_io.c           | 52 ++++++++++++++++-------
 src/intel/compiler/brw_mesh.cpp           |  3 +-
 src/intel/compiler/brw_nir.h              | 12 +++---
 src/intel/compiler/brw_vec4_visitor.cpp   | 10 ++---
 src/mesa/state_tracker/st_glsl_to_nir.cpp |  7 ++-
 6 files changed, 65 insertions(+), 30 deletions(-)

diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index 6448578066895..766028ca8e74b 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -5072,11 +5072,18 @@ nir_assign_linked_io_var_locations(nir_shader *producer,
  *  - is_bindless:  The variable has the bindless flag set and that texture
  *    and sampler types take actual size.  For input/output variable, this is
  *    always true.
+ *
+ *  - compact:  In this case, scalar types should not be expanded to whole
+ *    vectors.  This is set for compact variables (such as clip distances and
+ *    tessellation factors) and for array derefs of vectors.
  */
 typedef int (*nir_lower_io_type_size_cb)(const struct glsl_type *,
-                                         bool is_bindless);
+                                         bool is_bindless,
+                                         bool is_compact);
 
-int nir_io_type_size_vec4(const struct glsl_type *, bool is_bindless);
+int nir_io_type_size_vec4(const struct glsl_type *,
+                          bool is_bindless,
+                          bool is_compact);
 
 void nir_assign_var_locations(nir_shader *shader, nir_variable_mode mode,
                               unsigned *size,
diff --git a/src/compiler/nir/nir_lower_io.c b/src/compiler/nir/nir_lower_io.c
index 8d56494671b59..0d303cad28516 100644
--- a/src/compiler/nir/nir_lower_io.c
+++ b/src/compiler/nir/nir_lower_io.c
@@ -34,9 +34,16 @@
 #include "util/u_math.h"
 
 int
-nir_io_type_size_vec4(const struct glsl_type *type, bool is_bindless)
+nir_io_type_size_vec4(const struct glsl_type *type,
+                      bool is_bindless,
+                      bool is_compact)
 {
-   return glsl_count_vec4_slots(type, false, is_bindless);
+   if (is_compact) {
+      unsigned dw = glsl_count_dword_slots(type, is_bindless);
+      return DIV_ROUND_UP(dw, 4);
+   } else {
+      return glsl_count_vec4_slots(type, false, is_bindless);
+   }
 }
 
 struct lower_io_state {
@@ -120,7 +127,7 @@ variable_size(const nir_variable *var, gl_shader_stage stage,
                    var->data.mode == nir_var_shader_out ||
                    var->data.bindless;
 
-   return type_size(type, bindless);
+   return type_size(type, bindless, var->data.compact);
 }
 
 void
@@ -209,7 +216,7 @@ get_number_of_slots(struct lower_io_state *state,
        !nir_is_arrayed_io(var, state->builder.shader->info.stage))
       return 1;
 
-   return state->type_size(type, var->data.bindless) /
+   return state->type_size(type, var->data.bindless, false) /
           (uses_high_dvec2_semantic(state, var) ? 2 : 1);
 }
 
@@ -234,16 +241,26 @@ get_io_offset(nir_builder *b, nir_deref_instr *deref,
       p++;
    }
 
-   if (path.path[0]->var->data.compact) {
+   nir_variable *var = path.path[0]->var;
+   if (var->data.compact) {
       assert((*p)->deref_type == nir_deref_type_array);
       assert(glsl_type_is_scalar((*p)->type));
 
-      /* We always lower indirect dereferences for "compact" array vars. */
-      const unsigned index = nir_src_as_uint((*p)->arr.index);
-      const unsigned total_offset = *component + index;
-      const unsigned slot_offset = total_offset / 4;
-      *component = total_offset % 4;
-      return nir_imm_int(b, type_size(glsl_vec4_type(), bts) * slot_offset);
+      if (nir_src_is_const((*p)->arr.index)) {
+         /* For compact array vars, if we have a constant index, we can lower
+          * to a component which will work on any hardware which can handle
+          * partial vector read/writes to I/O even if it can't handle
+          * indirects on individual components.  For this lowering, we work in
+          * terms of dwords until we need to actually return a size.
+          */
+         const unsigned index = nir_src_as_uint((*p)->arr.index);
+         const unsigned total_offset = *component + index;
+         const unsigned slot_offset = total_offset / 4;
+         *component = total_offset % 4;
+
+         const unsigned slot_size = type_size(glsl_vec4_type(), bts, false);
+         return nir_imm_int(b, slot_size * slot_offset);
+      }
    }
 
    /* Just emit code and let constant-folding go to town */
@@ -251,7 +268,9 @@ get_io_offset(nir_builder *b, nir_deref_instr *deref,
 
    for (; *p; p++) {
       if ((*p)->deref_type == nir_deref_type_array) {
-         unsigned size = type_size((*p)->type, bts);
+         nir_deref_instr *parent = *(p - 1);
+         bool compact = var->data.compact || glsl_type_is_vector(parent->type);
+         unsigned size = type_size((*p)->type, bts, compact);
 
          nir_def *mul =
             nir_amul_imm(b, (*p)->arr.index.ssa, size);
@@ -263,7 +282,8 @@ get_io_offset(nir_builder *b, nir_deref_instr *deref,
 
          unsigned field_offset = 0;
          for (unsigned i = 0; i < (*p)->strct.index; i++) {
-            field_offset += type_size(glsl_get_struct_field(parent->type, i), bts);
+            field_offset += type_size(glsl_get_struct_field(parent->type, i),
+                                      bts, false);
          }
          offset = nir_iadd_imm(b, offset, field_offset);
       } else {
@@ -392,7 +412,8 @@ lower_load(nir_intrinsic_instr *intrin, struct lower_io_state *state,
       if (use_high_dvec2_semantic)
          offset = nir_ushr_imm(b, offset, 1);
 
-      const unsigned slot_size = state->type_size(glsl_dvec_type(2), false);
+      const unsigned slot_size =
+         state->type_size(glsl_dvec_type(2), false, false);
 
       nir_def *comp64[4];
       assert(component == 0 || component == 2);
@@ -515,7 +536,8 @@ lower_store(nir_intrinsic_instr *intrin, struct lower_io_state *state,
                                            nir_lower_io_lower_64bit_to_32_new)))) {
       nir_builder *b = &state->builder;
 
-      const unsigned slot_size = state->type_size(glsl_dvec_type(2), false);
+      const unsigned slot_size =
+         state->type_size(glsl_dvec_type(2), false, false);
 
       assert(component == 0 || component == 2);
       unsigned src_comp = 0;
diff --git a/src/intel/compiler/brw_mesh.cpp b/src/intel/compiler/brw_mesh.cpp
index e2cd61a93397c..b187568d13c16 100644
--- a/src/intel/compiler/brw_mesh.cpp
+++ b/src/intel/compiler/brw_mesh.cpp
@@ -76,7 +76,8 @@ brw_nir_lower_load_uniforms(nir_shader *nir)
 }
 
 static inline int
-type_size_scalar_dwords(const struct glsl_type *type, bool bindless)
+type_size_scalar_dwords(const struct glsl_type *type,
+                        bool bindless, bool compact)
 {
    return glsl_count_dword_slots(type, bindless);
 }
diff --git a/src/intel/compiler/brw_nir.h b/src/intel/compiler/brw_nir.h
index 505e14740aa06..6e1d0d3857de9 100644
--- a/src/intel/compiler/brw_nir.h
+++ b/src/intel/compiler/brw_nir.h
@@ -33,19 +33,21 @@
 extern "C" {
 #endif
 
-int type_size_vec4(const struct glsl_type *type, bool bindless);
-int type_size_dvec4(const struct glsl_type *type, bool bindless);
+int type_size_vec4(const struct glsl_type *type, bool bindless, bool compact);
+int type_size_dvec4(const struct glsl_type *type, bool bindless, bool compact);
 
 static inline int
-type_size_scalar_bytes(const struct glsl_type *type, bool bindless)
+type_size_scalar_bytes(const struct glsl_type *type,
+                       bool bindless, bool compact)
 {
    return glsl_count_dword_slots(type, bindless) * 4;
 }
 
 static inline int
-type_size_vec4_bytes(const struct glsl_type *type, bool bindless)
+type_size_vec4_bytes(const struct glsl_type *type,
+                     bool bindless, bool compact)
 {
-   return type_size_vec4(type, bindless) * 16;
+   return type_size_vec4(type, bindless, compact) * 16;
 }
 
 /* Flags set in the instr->pass_flags field by i965 analysis passes */
diff --git a/src/intel/compiler/brw_vec4_visitor.cpp b/src/intel/compiler/brw_vec4_visitor.cpp
index 54866dcb868e5..b2f1fff0e4a9a 100644
--- a/src/intel/compiler/brw_vec4_visitor.cpp
+++ b/src/intel/compiler/brw_vec4_visitor.cpp
@@ -640,7 +640,7 @@ type_size_xvec4(const struct glsl_type *type, bool as_vec4, bool bindless)
  * store a particular type.
  */
 extern "C" int
-type_size_vec4(const struct glsl_type *type, bool bindless)
+type_size_vec4(const struct glsl_type *type, bool bindless, bool compact)
 {
    return type_size_xvec4(type, true, bindless);
 }
@@ -665,7 +665,7 @@ type_size_vec4(const struct glsl_type *type, bool bindless)
  * type fits in one or two vec4 slots.
  */
 extern "C" int
-type_size_dvec4(const struct glsl_type *type, bool bindless)
+type_size_dvec4(const struct glsl_type *type, bool bindless, bool compact)
 {
    return type_size_xvec4(type, false, bindless);
 }
@@ -675,7 +675,7 @@ src_reg::src_reg(class vec4_visitor *v, const struct glsl_type *type)
    init();
 
    this->file = VGRF;
-   this->nr = v->alloc.allocate(type_size_vec4(type, false));
+   this->nr = v->alloc.allocate(type_size_vec4(type, false, false));
 
    if (type->is_array() || type->is_struct()) {
       this->swizzle = BRW_SWIZZLE_NOOP;
@@ -693,7 +693,7 @@ src_reg::src_reg(class vec4_visitor *v, const struct glsl_type *type, int size)
    init();
 
    this->file = VGRF;
-   this->nr = v->alloc.allocate(type_size_vec4(type, false) * size);
+   this->nr = v->alloc.allocate(type_size_vec4(type, false, false) * size);
 
    this->swizzle = BRW_SWIZZLE_NOOP;
 
@@ -705,7 +705,7 @@ dst_reg::dst_reg(class vec4_visitor *v, const struct glsl_type *type)
    init();
 
    this->file = VGRF;
-   this->nr = v->alloc.allocate(type_size_vec4(type, false));
+   this->nr = v->alloc.allocate(type_size_vec4(type, false, false));
 
    if (type->is_array() || type->is_struct()) {
       this->writemask = WRITEMASK_XYZW;
diff --git a/src/mesa/state_tracker/st_glsl_to_nir.cpp b/src/mesa/state_tracker/st_glsl_to_nir.cpp
index 0255b0cca9044..87d5a6d20b261 100644
--- a/src/mesa/state_tracker/st_glsl_to_nir.cpp
+++ b/src/mesa/state_tracker/st_glsl_to_nir.cpp
@@ -818,14 +818,17 @@ st_nir_lower_samplers(struct pipe_screen *screen, nir_shader *nir,
 }
 
 static int
-st_packed_uniforms_type_size(const struct glsl_type *type, bool bindless)
+st_packed_uniforms_type_size(const struct glsl_type *type,
+                             bool bindless, bool compact)
 {
    return glsl_count_dword_slots(type, bindless);
 }
 
 static int
-st_unpacked_uniforms_type_size(const struct glsl_type *type, bool bindless)
+st_unpacked_uniforms_type_size(const struct glsl_type *type,
+                               bool bindless, bool compact)
 {
+   assert(!compact);
    return glsl_count_vec4_slots(type, false, bindless);
 }
 
-- 
GitLab


From ac2e2b215ab846b4cac7008a663b997da417dfa9 Mon Sep 17 00:00:00 2001
From: Faith Ekstrand <faith.ekstrand@collabora.com>
Date: Fri, 27 Oct 2023 09:49:27 -0500
Subject: [PATCH 5/6] mesa,anv,hasvk,turnip,lvp: Call
 nir_lower_array_deref_of_vec for TCS outputs

TCS outputs can have array derefs of vectors.  We don't have them today
because spirv_to_nir emits a read-select-write pattern.  However, this
is racy if the output is being written from multiple invocations.  We'll
change that in the next but first we need to prep all the tess-capable
drivers.  RADV already invokes nir_lower_array_deref_of_vec in
radv_nir_lower_io_to_scalar_early so it's fine.  The other drivers,
however, need to call the NIR pass.

Notably missing from this list is NVK.  I plan to handle this directly
in the NVK compiler as all I/O is scalar there and we can do indirects
on vectors just fine.
---
 src/compiler/nir/nir.h                        |  1 +
 src/freedreno/vulkan/tu_shader.cc             | 11 +++++++++++
 src/gallium/frontends/lavapipe/lvp_pipeline.c | 16 +++++++++++++++-
 src/intel/vulkan/anv_pipeline.c               | 11 +++++++++++
 src/intel/vulkan_hasvk/anv_pipeline.c         | 11 +++++++++++
 src/mesa/main/glspirv.c                       | 11 +++++++++++
 6 files changed, 60 insertions(+), 1 deletion(-)

diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index 766028ca8e74b..30868c446733e 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -4991,6 +4991,7 @@ typedef enum {
    nir_lower_direct_array_deref_of_vec_store = (1 << 2),
    nir_lower_indirect_array_deref_of_vec_store = (1 << 3),
 } nir_lower_array_deref_of_vec_options;
+MESA_DEFINE_CPP_ENUM_BITFIELD_OPERATORS(nir_lower_array_deref_of_vec_options)
 
 bool nir_lower_array_deref_of_vec(nir_shader *shader, nir_variable_mode modes,
                                   nir_lower_array_deref_of_vec_options options);
diff --git a/src/freedreno/vulkan/tu_shader.cc b/src/freedreno/vulkan/tu_shader.cc
index 2179a64f8e926..ba86116d00e01 100644
--- a/src/freedreno/vulkan/tu_shader.cc
+++ b/src/freedreno/vulkan/tu_shader.cc
@@ -99,6 +99,17 @@ tu_spirv_to_nir(struct tu_device *dev,
       nir_print_shader(nir, stderr);
    }
 
+   if (stage == MESA_SHADER_TESS_CTRL) {
+      /* Tessellation control shaders may have array derefs of vectors on
+       * outputs and compilers may not be able to handle those.
+       */
+      NIR_PASS_V(nir, nir_lower_array_deref_of_vec, nir_var_shader_out,
+                 nir_lower_direct_array_deref_of_vec_load |
+                 nir_lower_indirect_array_deref_of_vec_load |
+                 nir_lower_direct_array_deref_of_vec_store |
+                 nir_lower_indirect_array_deref_of_vec_store);
+   }
+
    const struct nir_lower_sysvals_to_varyings_options sysvals_to_varyings = {
       .point_coord = true,
    };
diff --git a/src/gallium/frontends/lavapipe/lvp_pipeline.c b/src/gallium/frontends/lavapipe/lvp_pipeline.c
index 0f9b000e2f376..2b243d7b7bfc6 100644
--- a/src/gallium/frontends/lavapipe/lvp_pipeline.c
+++ b/src/gallium/frontends/lavapipe/lvp_pipeline.c
@@ -355,7 +355,21 @@ compile_spirv(struct lvp_device *pdevice, const VkPipelineShaderStageCreateInfo
    result = vk_pipeline_shader_stage_to_nir(&pdevice->vk, sinfo,
                                             &spirv_options, pdevice->physical_device->drv_options[stage],
                                             NULL, nir);
-   return result;
+   if (result != VK_SUCCESS)
+      return result;
+
+   if (stage == MESA_SHADER_TESS_CTRL) {
+      /* Tessellation control shaders may have array derefs of vectors on
+       * outputs and compilers may not be able to handle those.
+       */
+      NIR_PASS_V(*nir, nir_lower_array_deref_of_vec, nir_var_shader_out,
+                 nir_lower_direct_array_deref_of_vec_load |
+                 nir_lower_indirect_array_deref_of_vec_load |
+                 nir_lower_direct_array_deref_of_vec_store |
+                 nir_lower_indirect_array_deref_of_vec_store);
+   }
+
+   return VK_SUCCESS;
 }
 
 static bool
diff --git a/src/intel/vulkan/anv_pipeline.c b/src/intel/vulkan/anv_pipeline.c
index 52f97aec3125c..5d355abb2cb29 100644
--- a/src/intel/vulkan/anv_pipeline.c
+++ b/src/intel/vulkan/anv_pipeline.c
@@ -239,6 +239,17 @@ anv_shader_stage_to_nir(struct anv_device *device,
    NIR_PASS_V(nir, nir_lower_io_to_temporaries,
               nir_shader_get_entrypoint(nir), true, false);
 
+   if (stage == MESA_SHADER_TESS_CTRL) {
+      /* Tessellation control shaders may have array derefs of vectors on
+       * outputs and our compiler can't handle those.
+       */
+      NIR_PASS(_, nir, nir_lower_array_deref_of_vec, nir_var_shader_out,
+               nir_lower_direct_array_deref_of_vec_load |
+               nir_lower_indirect_array_deref_of_vec_load |
+               nir_lower_direct_array_deref_of_vec_store |
+               nir_lower_indirect_array_deref_of_vec_store);
+   }
+
    return nir;
 }
 
diff --git a/src/intel/vulkan_hasvk/anv_pipeline.c b/src/intel/vulkan_hasvk/anv_pipeline.c
index 6df9c3f79ff1c..9b3dc048cc8ef 100644
--- a/src/intel/vulkan_hasvk/anv_pipeline.c
+++ b/src/intel/vulkan_hasvk/anv_pipeline.c
@@ -144,6 +144,17 @@ anv_shader_stage_to_nir(struct anv_device *device,
    NIR_PASS_V(nir, nir_lower_io_to_temporaries,
               nir_shader_get_entrypoint(nir), true, false);
 
+   if (stage == MESA_SHADER_TESS_CTRL) {
+      /* Tessellation control shaders may have array derefs of vectors on
+       * outputs and our compiler can't handle those.
+       */
+      NIR_PASS(_, nir, nir_lower_array_deref_of_vec, nir_var_shader_out,
+               nir_lower_direct_array_deref_of_vec_load |
+               nir_lower_indirect_array_deref_of_vec_load |
+               nir_lower_direct_array_deref_of_vec_store |
+               nir_lower_indirect_array_deref_of_vec_store);
+   }
+
    const struct nir_lower_sysvals_to_varyings_options sysvals_to_varyings = {
       .point_coord = true,
    };
diff --git a/src/mesa/main/glspirv.c b/src/mesa/main/glspirv.c
index 73e4abc20d7c0..65047618b69e8 100644
--- a/src/mesa/main/glspirv.c
+++ b/src/mesa/main/glspirv.c
@@ -331,6 +331,17 @@ _mesa_spirv_to_nir(struct gl_context *ctx,
    NIR_PASS_V(nir, nir_split_var_copies);
    NIR_PASS_V(nir, nir_split_per_member_structs);
 
+   if (stage == MESA_SHADER_TESS_CTRL) {
+      /* Tessellation control shaders may have array derefs of vectors on
+       * outputs and compilers may not be able to handle those.
+       */
+      NIR_PASS_V(nir, nir_lower_array_deref_of_vec, nir_var_shader_out,
+                 nir_lower_direct_array_deref_of_vec_load |
+                 nir_lower_indirect_array_deref_of_vec_load |
+                 nir_lower_direct_array_deref_of_vec_store |
+                 nir_lower_indirect_array_deref_of_vec_store);
+   }
+
    if (nir->info.stage == MESA_SHADER_VERTEX)
       nir_remap_dual_slot_attributes(nir, &linked_shader->Program->DualSlotInputs);
 
-- 
GitLab


From 3f5f327da5fb9a7ac0ce42f88d527182a7008569 Mon Sep 17 00:00:00 2001
From: Faith Ekstrand <faith.ekstrand@collabora.com>
Date: Wed, 25 Oct 2023 16:38:11 -0500
Subject: [PATCH 6/6] spirv: Properly handle cross-invocation TCS output access

This makes spirv_to_nir stop emitting read-select-write patterns for TCS
outputs and instead just do an array deref of the vector.
---
 src/compiler/spirv/vtn_variables.c | 5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/src/compiler/spirv/vtn_variables.c b/src/compiler/spirv/vtn_variables.c
index d00e3d785fdaf..ac3548c157a04 100644
--- a/src/compiler/spirv/vtn_variables.c
+++ b/src/compiler/spirv/vtn_variables.c
@@ -187,8 +187,9 @@ static bool
 vtn_mode_is_cross_invocation(struct vtn_builder *b,
                              enum vtn_variable_mode mode)
 {
-   /* TODO: add TCS here once nir_remove_unused_io_vars() can handle vector indexing. */
-   bool cross_invocation_outputs = b->shader->info.stage == MESA_SHADER_MESH;
+   bool cross_invocation_outputs =
+      b->shader->info.stage == MESA_SHADER_TESS_CTRL ||
+      b->shader->info.stage == MESA_SHADER_MESH;
    return mode == vtn_variable_mode_ssbo ||
           mode == vtn_variable_mode_ubo ||
           mode == vtn_variable_mode_phys_ssbo ||
-- 
GitLab

