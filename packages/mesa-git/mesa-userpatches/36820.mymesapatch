From e37a926ed1b719f3671d68de68035a390b706908 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Sat, 9 Aug 2025 06:43:13 +0200
Subject: [PATCH 1/5] radv: Add comment to document CP DMA prefetch

Background info about the prefetch:
On GPUs where CP DMA uses L2, it loads binaries to L2.
On GPUs that have MALL (infinity cache), it loads binaries to MALL.
---
 src/amd/vulkan/radv_cp_dma.c | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/src/amd/vulkan/radv_cp_dma.c b/src/amd/vulkan/radv_cp_dma.c
index 2deee13b73a7e..5ee2029ed8a79 100644
--- a/src/amd/vulkan/radv_cp_dma.c
+++ b/src/amd/vulkan/radv_cp_dma.c
@@ -132,6 +132,14 @@ radv_emit_cp_dma(struct radv_cmd_buffer *cmd_buffer, uint64_t dst_va, uint64_t s
       radv_cmd_buffer_trace_emit(cmd_buffer);
 }
 
+/* Emit a CP DMA prefetch.
+ * This is useful for warming up caches before draw commands,
+ * for example we use it to load shader binaries and VBO descriptors.
+ *
+ * On GPUs where CP DMA uses L2, it loads binaries into L2.
+ * On GPUs that have MALL (infinity cache), it loads binaries into MALL.
+ * (On GPUs where CP DMA can't use L2 and there is no MALL, this does nothing)
+ */
 void
 radv_cs_cp_dma_prefetch(const struct radv_device *device, struct radv_cmd_stream *cs, uint64_t va, unsigned size,
                         bool predicating)
-- 
GitLab


From 14f88b6cbffa8d662f4457f79cfb2f8315389696 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Sat, 9 Aug 2025 06:44:09 +0200
Subject: [PATCH 2/5] radv: Flush L2 before CP DMA copy/fill when CP DMA
 doesn't use L2

In case the source or destination were previously written
through L2, we need to writeback L2 to avoid the CP DMA accessing
stale data.

However, as the CP DMA doesn't write L2 either, an invalidation
is also needed to make sure other clients don't access stale data
when they read it through L2 after the CP DMA is complete.

Doing an invalidation before the CP DMA operation should take
care of both.

Additionally, radv_src_access_flush also invalidates L2 before
the copied data can be read.

Cc: mesa-stable
---
 src/amd/vulkan/radv_cp_dma.c | 16 ++++++++++------
 1 file changed, 10 insertions(+), 6 deletions(-)

diff --git a/src/amd/vulkan/radv_cp_dma.c b/src/amd/vulkan/radv_cp_dma.c
index 5ee2029ed8a79..e2e0be30b8e7b 100644
--- a/src/amd/vulkan/radv_cp_dma.c
+++ b/src/amd/vulkan/radv_cp_dma.c
@@ -240,6 +240,11 @@ radv_cp_dma_copy_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t src_va, uin
    uint64_t main_src_va, main_dest_va;
    uint64_t skipped_size = 0, realign_size = 0;
 
+   if (!(pdev->info.cp_dma_use_L2 && pdev->info.gfx_level >= GFX9)) {
+      /* Invalidate L2 in case "src_va" or "dest_va" were previously written through L2. */
+      cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_INV_L2;
+   }
+
    /* Assume that we are not going to sync after the last DMA operation. */
    cmd_buffer->state.dma_is_busy = true;
 
@@ -304,9 +309,6 @@ radv_cp_dma_copy_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t src_va, uin
    }
    if (realign_size)
       radv_cp_dma_realign_engine(cmd_buffer, realign_size);
-
-   if (pdev->info.cp_sdma_ge_use_system_memory_scope)
-      cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_INV_L2;
 }
 
 void
@@ -318,6 +320,11 @@ radv_cp_dma_fill_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t va, uint64_
    if (!size)
       return;
 
+   if (!(pdev->info.cp_dma_use_L2 && pdev->info.gfx_level >= GFX9)) {
+      /* Invalidate L2 in case "va" was previously written through L2. */
+      cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_INV_L2;
+   }
+
    assert(va % 4 == 0 && size % 4 == 0);
 
    enum amd_gfx_level gfx_level = pdev->info.gfx_level;
@@ -347,9 +354,6 @@ radv_cp_dma_fill_memory(struct radv_cmd_buffer *cmd_buffer, uint64_t va, uint64_
       size -= byte_count;
       va += byte_count;
    }
-
-   if (pdev->info.cp_sdma_ge_use_system_memory_scope)
-      cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_INV_L2;
 }
 
 void
-- 
GitLab


From 3768aaeb37b7701c2e82284805b69c50fe11df69 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Fri, 29 Aug 2025 09:42:35 +0200
Subject: [PATCH 3/5] radv: Add L2 flush after subpass clear with CP DMA if
 necessary

In case of a subpass clear, the driver is responsible for
implicitly flushing caches before the first draw.

We forgot about this because it's a really rare edge case,
as most of the time the subpass clear is done using compute.
Also the flush is not needed on all GPUs.

Cc: mesa-stable
---
 src/amd/vulkan/meta/radv_meta_buffer.c | 6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/src/amd/vulkan/meta/radv_meta_buffer.c b/src/amd/vulkan/meta/radv_meta_buffer.c
index 66fd17ab937fa..6b5f257dfa874 100644
--- a/src/amd/vulkan/meta/radv_meta_buffer.c
+++ b/src/amd/vulkan/meta/radv_meta_buffer.c
@@ -298,9 +298,13 @@ radv_fill_memory_internal(struct radv_cmd_buffer *cmd_buffer, const struct radv_
       flush_bits = RADV_CMD_FLAG_CS_PARTIAL_FLUSH | RADV_CMD_FLAG_INV_VCACHE |
                    radv_src_access_flush(cmd_buffer, VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
                                          VK_ACCESS_2_SHADER_WRITE_BIT, 0, image, NULL);
-   } else if (size)
+   } else if (size) {
       radv_cp_dma_fill_memory(cmd_buffer, va, size, value);
 
+      flush_bits = radv_src_access_flush(cmd_buffer, VK_PIPELINE_STAGE_2_TRANSFER_BIT,
+                                         VK_ACCESS_2_TRANSFER_WRITE_BIT, 0, image, NULL);
+   }
+
    return flush_bits;
 }
 
-- 
GitLab


From 50a0f42bb5a32080cce709b20b62b94607c3b296 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Mon, 1 Sep 2025 14:49:14 +0200
Subject: [PATCH 4/5] radv: Flush after resetting query pool when necessary

It may be necessary to flush it even when using the CP DMA
code path.

The pending_reset_query	field already keeps track of whether a
reset query pool is pending, so	there is no need to also check
that it	took the compute code path.

Cc: mesa-stable
---
 src/amd/vulkan/radv_query.c | 12 ++----------
 1 file changed, 2 insertions(+), 10 deletions(-)

diff --git a/src/amd/vulkan/radv_query.c b/src/amd/vulkan/radv_query.c
index 5687dcbaf9b73..1e21453e8a651 100644
--- a/src/amd/vulkan/radv_query.c
+++ b/src/amd/vulkan/radv_query.c
@@ -2452,14 +2452,7 @@ static void
 emit_query_flush(struct radv_cmd_buffer *cmd_buffer, struct radv_query_pool *pool)
 {
    if (cmd_buffer->pending_reset_query) {
-      if (pool->size >= RADV_BUFFER_OPS_CS_THRESHOLD) {
-         /* Only need to flush caches if the query pool size is
-          * large enough to be reset using the compute shader
-          * path. Small pools don't need any cache flushes
-          * because we use a CP dma clear.
-          */
-         radv_emit_cache_flush(cmd_buffer);
-      }
+      radv_emit_cache_flush(cmd_buffer);
    }
 }
 
@@ -2497,7 +2490,7 @@ radv_CmdCopyQueryPoolResults(VkCommandBuffer commandBuffer, VkQueryPool queryPoo
     *  previous uses of vkCmdResetQueryPool in the same queue, without any
     *  additional synchronization."
     *
-    * So, we have to flush the caches if the compute shader path was used.
+    * So, we have to flush the caches if necessary.
     */
    emit_query_flush(cmd_buffer, pool);
 
@@ -2562,7 +2555,6 @@ radv_CmdResetQueryPool(VkCommandBuffer commandBuffer, VkQueryPool queryPool, uin
    }
 
    if (flush_bits) {
-      /* Only need to flush caches for the compute shader path. */
       cmd_buffer->pending_reset_query = true;
       cmd_buffer->state.flush_bits |= flush_bits;
    }
-- 
GitLab


From badc2e337506d6f4f5ba1911de579cda246cd8fb Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Thu, 7 Aug 2025 09:04:34 +0200
Subject: [PATCH 5/5] radv: Add L2 flush for indirect and index buffer reads

Indirect buffers are read through L2 on GFX9-11 but not other hw.
The render condition should work the same way as indirect buffers.
Index buffers are read through L2 on GFX8-11 but not other hw.

For reference, see the following RadeonSI functions:
si_memory_barrier
si_draw
si_launch_grid
si_render_condition

Cc: mesa-stable
---
 src/amd/vulkan/radv_cmd_buffer.c | 14 +++++++++++++-
 1 file changed, 13 insertions(+), 1 deletion(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index 1153af624425f..37c3a3f409303 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -7234,14 +7234,26 @@ radv_dst_access_flush(struct radv_cmd_buffer *cmd_buffer, VkPipelineStageFlags2
          flush_bits |= RADV_CMD_FLAG_INV_SCACHE;
       }
 
+      /* Indirect buffers and conditional rendering predicate are
+       * read through L2 on GFX9-GFX11.5, but not other hw.
+       */
+      if (pdev->info.gfx_level <= GFX8 || pdev->info.cp_sdma_ge_use_system_memory_scope)
+         flush_bits |= RADV_CMD_FLAG_WB_L2;
+
       /* Ensure the DGC meta shader can read the commands. */
       if (device->vk.enabled_features.deviceGeneratedCommands) {
          flush_bits |= RADV_CMD_FLAG_INV_SCACHE | RADV_CMD_FLAG_INV_VCACHE;
-         if (pdev->info.gfx_level < GFX9)
+         if (pdev->info.gfx_level <= GFX8 || pdev->info.cp_sdma_ge_use_system_memory_scope)
             flush_bits |= RADV_CMD_FLAG_INV_L2;
       }
    }
 
+   if (dst_flags & VK_ACCESS_2_INDEX_READ_BIT) {
+      /* GFX8-GFX11.5 reads index buffers through L2, so they don't need this. */
+      if (pdev->info.gfx_level <= GFX7 || pdev->info.cp_sdma_ge_use_system_memory_scope)
+         flush_bits |= RADV_CMD_FLAG_WB_L2;
+   }
+
    if (dst_flags & VK_ACCESS_2_UNIFORM_READ_BIT)
       flush_bits |= RADV_CMD_FLAG_INV_VCACHE | RADV_CMD_FLAG_INV_SCACHE;
 
-- 
GitLab

