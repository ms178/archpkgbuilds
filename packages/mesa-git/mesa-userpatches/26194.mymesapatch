From 94102c2f7f382869488fade71b0b03eedd94b3e1 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Fri, 10 Feb 2023 12:52:17 +0100
Subject: [PATCH 1/9] aco: pass live_vars to live_var_analysis rather than
 using it as constructor

In order to use aco::monotonic_buffer_resource, we must not use copy-assignments.
---
 src/amd/compiler/aco_interface.cpp         |  2 +-
 src/amd/compiler/aco_ir.h                  |  2 +-
 src/amd/compiler/aco_live_var_analysis.cpp | 21 +++++++++------------
 src/amd/compiler/aco_lower_to_cssa.cpp     |  2 +-
 src/amd/compiler/aco_spill.cpp             |  2 +-
 src/amd/compiler/aco_validate.cpp          |  3 ++-
 src/amd/compiler/tests/helpers.cpp         |  3 ++-
 7 files changed, 17 insertions(+), 18 deletions(-)

diff --git a/src/amd/compiler/aco_interface.cpp b/src/amd/compiler/aco_interface.cpp
index 7e418caaa55f2..5f17149b2b878 100644
--- a/src/amd/compiler/aco_interface.cpp
+++ b/src/amd/compiler/aco_interface.cpp
@@ -146,7 +146,7 @@ aco_postprocess_shader(const struct aco_compiler_options* options,
       validate(program.get());
 
       /* spilling and scheduling */
-      live_vars = aco::live_var_analysis(program.get());
+      live_var_analysis(program.get(), live_vars);
       if (program->collect_statistics)
          aco::collect_presched_stats(program.get());
       aco::spill(program.get(), live_vars);
diff --git a/src/amd/compiler/aco_ir.h b/src/amd/compiler/aco_ir.h
index 8ee4caeed47c1..185fd89691832 100644
--- a/src/amd/compiler/aco_ir.h
+++ b/src/amd/compiler/aco_ir.h
@@ -2212,7 +2212,7 @@ void select_ps_prolog(Program* program, void* pinfo, ac_shader_config* config,
 void lower_phis(Program* program);
 void calc_min_waves(Program* program);
 void update_vgpr_sgpr_demand(Program* program, const RegisterDemand new_demand);
-live live_var_analysis(Program* program);
+void live_var_analysis(Program* program, live& live);
 std::vector<uint16_t> dead_code_analysis(Program* program);
 void dominator_tree(Program* program);
 void insert_exec_mask(Program* program);
diff --git a/src/amd/compiler/aco_live_var_analysis.cpp b/src/amd/compiler/aco_live_var_analysis.cpp
index f894dd31b746a..154e2eb9db780 100644
--- a/src/amd/compiler/aco_live_var_analysis.cpp
+++ b/src/amd/compiler/aco_live_var_analysis.cpp
@@ -473,12 +473,12 @@ update_vgpr_sgpr_demand(Program* program, const RegisterDemand new_demand)
    }
 }
 
-live
-live_var_analysis(Program* program)
+void
+live_var_analysis(Program* program, live& live)
 {
-   live result;
-   result.live_out.resize(program->blocks.size());
-   result.register_demand.resize(program->blocks.size());
+   live.live_out.clear();
+   live.live_out.resize(program->blocks.size());
+   live.register_demand.resize(program->blocks.size());
    unsigned worklist = program->blocks.size();
    std::vector<PhiInfo> phi_info(program->blocks.size());
    RegisterDemand new_demand;
@@ -489,19 +489,18 @@ live_var_analysis(Program* program)
     * program->blocks vector */
    while (worklist) {
       unsigned block_idx = --worklist;
-      process_live_temps_per_block(program, result, &program->blocks[block_idx], worklist,
-                                   phi_info);
+      process_live_temps_per_block(program, live, &program->blocks[block_idx], worklist, phi_info);
    }
 
    /* Handle branches: we will insert copies created for linear phis just before the branch. */
    for (Block& block : program->blocks) {
-      result.register_demand[block.index].back().sgpr += phi_info[block.index].linear_phi_defs;
-      result.register_demand[block.index].back().sgpr -= phi_info[block.index].linear_phi_ops;
+      live.register_demand[block.index].back().sgpr += phi_info[block.index].linear_phi_defs;
+      live.register_demand[block.index].back().sgpr -= phi_info[block.index].linear_phi_ops;
 
       /* update block's register demand */
       if (program->progress < CompilationProgress::after_ra) {
          block.register_demand = RegisterDemand();
-         for (RegisterDemand& demand : result.register_demand[block.index])
+         for (RegisterDemand& demand : live.register_demand[block.index])
             block.register_demand.update(demand);
       }
 
@@ -511,8 +510,6 @@ live_var_analysis(Program* program)
    /* calculate the program's register demand and number of waves */
    if (program->progress < CompilationProgress::after_ra)
       update_vgpr_sgpr_demand(program, new_demand);
-
-   return result;
 }
 
 } // namespace aco
diff --git a/src/amd/compiler/aco_lower_to_cssa.cpp b/src/amd/compiler/aco_lower_to_cssa.cpp
index 3c509ee2f811c..b1fa02cb9b410 100644
--- a/src/amd/compiler/aco_lower_to_cssa.cpp
+++ b/src/amd/compiler/aco_lower_to_cssa.cpp
@@ -533,6 +533,6 @@ lower_to_cssa(Program* program, live& live_vars)
    emit_parallelcopies(ctx);
 
    /* update live variable information */
-   live_vars = live_var_analysis(program);
+   live_var_analysis(program, live_vars);
 }
 } // namespace aco
diff --git a/src/amd/compiler/aco_spill.cpp b/src/amd/compiler/aco_spill.cpp
index 2f9e4b0421f67..b05ef08d4255d 100644
--- a/src/amd/compiler/aco_spill.cpp
+++ b/src/amd/compiler/aco_spill.cpp
@@ -1972,7 +1972,7 @@ spill(Program* program, live& live_vars)
    assign_spill_slots(ctx, extra_vgprs);
 
    /* update live variable information */
-   live_vars = live_var_analysis(program);
+   live_var_analysis(program, live_vars);
 
    assert(program->num_waves > 0);
 }
diff --git a/src/amd/compiler/aco_validate.cpp b/src/amd/compiler/aco_validate.cpp
index b952c56d4d4cb..613cd98c78bd0 100644
--- a/src/amd/compiler/aco_validate.cpp
+++ b/src/amd/compiler/aco_validate.cpp
@@ -1217,7 +1217,8 @@ validate_ra(Program* program)
       return false;
 
    bool err = false;
-   aco::live live_vars = aco::live_var_analysis(program);
+   aco::live live_vars;
+   aco::live_var_analysis(program, live_vars);
    std::vector<std::vector<Temp>> phi_sgpr_ops(program->blocks.size());
    uint16_t sgpr_limit = get_addr_sgpr_from_waves(program, program->num_waves);
 
diff --git a/src/amd/compiler/tests/helpers.cpp b/src/amd/compiler/tests/helpers.cpp
index b4b52617fa6c6..9d4ea8a9808a2 100644
--- a/src/amd/compiler/tests/helpers.cpp
+++ b/src/amd/compiler/tests/helpers.cpp
@@ -210,7 +210,8 @@ finish_ra_test(ra_test_policy policy, bool lower)
    }
 
    program->workgroup_size = program->wave_size;
-   aco::live live_vars = aco::live_var_analysis(program.get());
+   aco::live live_vars;
+   aco::live_var_analysis(program.get(), live_vars);
    aco::register_allocation(program.get(), live_vars, policy);
 
    if (aco::validate_ra(program.get())) {
-- 
GitLab


From d9ad1b7028321b3a86392c1b67eebe146a8e7119 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Fri, 10 Feb 2023 13:25:28 +0100
Subject: [PATCH 2/9] aco: pass live_vars to reindex_ssa()

in order to be able to use aco::monotonic_buffer_resource for IDSet
---
 src/amd/compiler/aco_ir.h              | 16 ++++++++--------
 src/amd/compiler/aco_lower_to_cssa.cpp |  2 +-
 src/amd/compiler/aco_reindex_ssa.cpp   |  8 ++++----
 3 files changed, 13 insertions(+), 13 deletions(-)

diff --git a/src/amd/compiler/aco_ir.h b/src/amd/compiler/aco_ir.h
index 185fd89691832..33be5df272fb0 100644
--- a/src/amd/compiler/aco_ir.h
+++ b/src/amd/compiler/aco_ir.h
@@ -2067,6 +2067,13 @@ enum class CompilationProgress {
    after_ra,
 };
 
+struct live {
+   /* live temps out per block */
+   std::vector<IDSet> live_out;
+   /* register demand (sgpr/vgpr) per instruction per block */
+   std::vector<std::vector<RegisterDemand>> register_demand;
+};
+
 class Program final {
 public:
    aco::monotonic_buffer_resource m{65536};
@@ -2140,7 +2147,7 @@ public:
    uint32_t peekAllocationId() { return allocationID; }
 
    friend void reindex_ssa(Program* program);
-   friend void reindex_ssa(Program* program, std::vector<IDSet>& live_out);
+   friend void reindex_ssa(Program* program, live& live_vars);
 
    Block* create_and_insert_block()
    {
@@ -2163,13 +2170,6 @@ private:
    uint32_t allocationID = 1;
 };
 
-struct live {
-   /* live temps out per block */
-   std::vector<IDSet> live_out;
-   /* register demand (sgpr/vgpr) per instruction per block */
-   std::vector<std::vector<RegisterDemand>> register_demand;
-};
-
 struct ra_test_policy {
    /* Force RA to always use its pessimistic fallback algorithm */
    bool skip_optimistic_path = false;
diff --git a/src/amd/compiler/aco_lower_to_cssa.cpp b/src/amd/compiler/aco_lower_to_cssa.cpp
index b1fa02cb9b410..b15a56442466e 100644
--- a/src/amd/compiler/aco_lower_to_cssa.cpp
+++ b/src/amd/compiler/aco_lower_to_cssa.cpp
@@ -527,7 +527,7 @@ emit_parallelcopies(cssa_ctx& ctx)
 void
 lower_to_cssa(Program* program, live& live_vars)
 {
-   reindex_ssa(program, live_vars.live_out);
+   reindex_ssa(program, live_vars);
    cssa_ctx ctx = {program, live_vars.live_out};
    collect_parallelcopies(ctx);
    emit_parallelcopies(ctx);
diff --git a/src/amd/compiler/aco_reindex_ssa.cpp b/src/amd/compiler/aco_reindex_ssa.cpp
index 47653f8b6d3fe..b4b33a312f695 100644
--- a/src/amd/compiler/aco_reindex_ssa.cpp
+++ b/src/amd/compiler/aco_reindex_ssa.cpp
@@ -95,9 +95,9 @@ reindex_program(idx_ctx& ctx, Program* program)
 }
 
 void
-update_live_out(idx_ctx& ctx, std::vector<IDSet>& live_out)
+update_live_out(idx_ctx& ctx, live& live_vars)
 {
-   for (IDSet& set : live_out) {
+   for (IDSet& set : live_vars.live_out) {
       IDSet new_set;
       for (uint32_t id : set)
          new_set.insert(ctx.renames[id]);
@@ -117,11 +117,11 @@ reindex_ssa(Program* program)
 }
 
 void
-reindex_ssa(Program* program, std::vector<IDSet>& live_out)
+reindex_ssa(Program* program, live& live_vars)
 {
    idx_ctx ctx;
    reindex_program(ctx, program);
-   update_live_out(ctx, live_out);
+   update_live_out(ctx, live_vars);
 
    program->allocationID = program->temp_rc.size();
 }
-- 
GitLab


From 931807d352d981c4e7a64e62c3177174dbf7e766 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Fri, 10 Feb 2023 13:55:09 +0100
Subject: [PATCH 3/9] aco: make aco::monotonic_buffer_resource declaration
 visible for aco::IDSet

---
 src/amd/compiler/aco_util.h | 318 ++++++++++++++++++------------------
 1 file changed, 159 insertions(+), 159 deletions(-)

diff --git a/src/amd/compiler/aco_util.h b/src/amd/compiler/aco_util.h
index 9659f5a98f623..44212f8ca2080 100644
--- a/src/amd/compiler/aco_util.h
+++ b/src/amd/compiler/aco_util.h
@@ -237,6 +237,165 @@ private:
    size_type length{0}; //!> Size of the span
 };
 
+/*
+ * Light-weight memory resource which allows to sequentially allocate from
+ * a buffer. Both, the release() method and the destructor release all managed
+ * memory.
+ *
+ * The memory resource is not thread-safe.
+ * This class mimics std::pmr::monotonic_buffer_resource
+ */
+class monotonic_buffer_resource final {
+public:
+   explicit monotonic_buffer_resource(size_t size = initial_size)
+   {
+      /* The size parameter refers to the total size of the buffer.
+       * The usable data_size is size - sizeof(Buffer).
+       */
+      size = MAX2(size, minimum_size);
+      buffer = (Buffer*)malloc(size);
+      buffer->next = nullptr;
+      buffer->data_size = size - sizeof(Buffer);
+      buffer->current_idx = 0;
+   }
+
+   ~monotonic_buffer_resource()
+   {
+      release();
+      free(buffer);
+   }
+
+   /* Delete copy-constructor and -assignment to avoid double free() */
+   monotonic_buffer_resource(const monotonic_buffer_resource&) = delete;
+   monotonic_buffer_resource& operator=(const monotonic_buffer_resource&) = delete;
+
+   void* allocate(size_t size, size_t alignment)
+   {
+      buffer->current_idx = align(buffer->current_idx, alignment);
+      if (buffer->current_idx + size <= buffer->data_size) {
+         uint8_t* ptr = &buffer->data[buffer->current_idx];
+         buffer->current_idx += size;
+         return ptr;
+      }
+
+      /* create new larger buffer */
+      uint32_t total_size = buffer->data_size + sizeof(Buffer);
+      do {
+         total_size *= 2;
+      } while (total_size - sizeof(Buffer) < size);
+      Buffer* next = buffer;
+      buffer = (Buffer*)malloc(total_size);
+      buffer->next = next;
+      buffer->data_size = total_size - sizeof(Buffer);
+      buffer->current_idx = 0;
+
+      return allocate(size, alignment);
+   }
+
+   void release()
+   {
+      while (buffer->next) {
+         Buffer* next = buffer->next;
+         free(buffer);
+         buffer = next;
+      }
+      buffer->current_idx = 0;
+   }
+
+   bool operator==(const monotonic_buffer_resource& other) { return buffer == other.buffer; }
+
+private:
+   struct Buffer {
+      Buffer* next;
+      uint32_t current_idx;
+      uint32_t data_size;
+      uint8_t data[];
+   };
+
+   Buffer* buffer;
+   static constexpr size_t initial_size = 4096;
+   static constexpr size_t minimum_size = 128;
+   static_assert(minimum_size > sizeof(Buffer));
+};
+
+/*
+ * Small memory allocator which wraps monotonic_buffer_resource
+ * in order to implement <allocator_traits>.
+ *
+ * This class mimics std::pmr::polymorphic_allocator with monotonic_buffer_resource
+ * as memory resource. The advantage of this specialization is the absence of
+ * virtual function calls and the propagation on swap, copy- and move assignment.
+ */
+template <typename T> class monotonic_allocator {
+public:
+   monotonic_allocator() = delete;
+   monotonic_allocator(monotonic_buffer_resource& m) : memory_resource(m) {}
+   template <typename U>
+   explicit monotonic_allocator(const monotonic_allocator<U>& rhs)
+       : memory_resource(rhs.memory_resource)
+   {}
+
+   /* Memory Allocation */
+   T* allocate(size_t size)
+   {
+      uint32_t bytes = sizeof(T) * size;
+      return (T*)memory_resource.get().allocate(bytes, alignof(T));
+   }
+
+   /* Memory will be freed on destruction of memory_resource */
+   void deallocate(T* ptr, size_t size) {}
+
+   /* Implement <allocator_traits> */
+   using value_type = T;
+   template <class U> struct rebind {
+      using other = monotonic_allocator<U>;
+   };
+
+   typedef std::true_type propagate_on_container_copy_assignment;
+   typedef std::true_type propagate_on_container_move_assignment;
+   typedef std::true_type propagate_on_container_swap;
+
+   template <typename> friend class monotonic_allocator;
+   template <typename X, typename Y>
+   friend bool operator==(monotonic_allocator<X> const& a, monotonic_allocator<Y> const& b);
+   template <typename X, typename Y>
+   friend bool operator!=(monotonic_allocator<X> const& a, monotonic_allocator<Y> const& b);
+
+private:
+   std::reference_wrapper<monotonic_buffer_resource> memory_resource;
+};
+
+/* Necessary for <allocator_traits>. */
+template <typename X, typename Y>
+inline bool
+operator==(monotonic_allocator<X> const& a, monotonic_allocator<Y> const& b)
+{
+   return a.memory_resource.get() == b.memory_resource.get();
+}
+template <typename X, typename Y>
+inline bool
+operator!=(monotonic_allocator<X> const& a, monotonic_allocator<Y> const& b)
+{
+   return !(a == b);
+}
+
+/*
+ * aco::map - alias for std::map with monotonic_allocator
+ *
+ * This template specialization mimics std::pmr::map.
+ */
+template <class Key, class T, class Compare = std::less<Key>>
+using map = std::map<Key, T, Compare, aco::monotonic_allocator<std::pair<const Key, T>>>;
+
+/*
+ * aco::unordered_map - alias for std::unordered_map with monotonic_allocator
+ *
+ * This template specialization mimics std::pmr::unordered_map.
+ */
+template <class Key, class T, class Hash = std::hash<Key>, class Pred = std::equal_to<Key>>
+using unordered_map =
+   std::unordered_map<Key, T, Hash, Pred, aco::monotonic_allocator<std::pair<const Key, T>>>;
+
 /*
  * Cache-friendly set of 32-bit IDs with fast insert/erase/lookup and
  * the ability to efficiently iterate over contained elements.
@@ -431,165 +590,6 @@ IDSet::Iterator::operator*() const
    return id;
 }
 
-/*
- * Light-weight memory resource which allows to sequentially allocate from
- * a buffer. Both, the release() method and the destructor release all managed
- * memory.
- *
- * The memory resource is not thread-safe.
- * This class mimics std::pmr::monotonic_buffer_resource
- */
-class monotonic_buffer_resource final {
-public:
-   explicit monotonic_buffer_resource(size_t size = initial_size)
-   {
-      /* The size parameter refers to the total size of the buffer.
-       * The usable data_size is size - sizeof(Buffer).
-       */
-      size = MAX2(size, minimum_size);
-      buffer = (Buffer*)malloc(size);
-      buffer->next = nullptr;
-      buffer->data_size = size - sizeof(Buffer);
-      buffer->current_idx = 0;
-   }
-
-   ~monotonic_buffer_resource()
-   {
-      release();
-      free(buffer);
-   }
-
-   /* Delete copy-constructor and -assignment to avoid double free() */
-   monotonic_buffer_resource(const monotonic_buffer_resource&) = delete;
-   monotonic_buffer_resource& operator=(const monotonic_buffer_resource&) = delete;
-
-   void* allocate(size_t size, size_t alignment)
-   {
-      buffer->current_idx = align(buffer->current_idx, alignment);
-      if (buffer->current_idx + size <= buffer->data_size) {
-         uint8_t* ptr = &buffer->data[buffer->current_idx];
-         buffer->current_idx += size;
-         return ptr;
-      }
-
-      /* create new larger buffer */
-      uint32_t total_size = buffer->data_size + sizeof(Buffer);
-      do {
-         total_size *= 2;
-      } while (total_size - sizeof(Buffer) < size);
-      Buffer* next = buffer;
-      buffer = (Buffer*)malloc(total_size);
-      buffer->next = next;
-      buffer->data_size = total_size - sizeof(Buffer);
-      buffer->current_idx = 0;
-
-      return allocate(size, alignment);
-   }
-
-   void release()
-   {
-      while (buffer->next) {
-         Buffer* next = buffer->next;
-         free(buffer);
-         buffer = next;
-      }
-      buffer->current_idx = 0;
-   }
-
-   bool operator==(const monotonic_buffer_resource& other) { return buffer == other.buffer; }
-
-private:
-   struct Buffer {
-      Buffer* next;
-      uint32_t current_idx;
-      uint32_t data_size;
-      uint8_t data[];
-   };
-
-   Buffer* buffer;
-   static constexpr size_t initial_size = 4096;
-   static constexpr size_t minimum_size = 128;
-   static_assert(minimum_size > sizeof(Buffer));
-};
-
-/*
- * Small memory allocator which wraps monotonic_buffer_resource
- * in order to implement <allocator_traits>.
- *
- * This class mimics std::pmr::polymorphic_allocator with monotonic_buffer_resource
- * as memory resource. The advantage of this specialization is the absence of
- * virtual function calls and the propagation on swap, copy- and move assignment.
- */
-template <typename T> class monotonic_allocator {
-public:
-   monotonic_allocator() = delete;
-   monotonic_allocator(monotonic_buffer_resource& m) : memory_resource(m) {}
-   template <typename U>
-   explicit monotonic_allocator(const monotonic_allocator<U>& rhs)
-       : memory_resource(rhs.memory_resource)
-   {}
-
-   /* Memory Allocation */
-   T* allocate(size_t size)
-   {
-      uint32_t bytes = sizeof(T) * size;
-      return (T*)memory_resource.get().allocate(bytes, alignof(T));
-   }
-
-   /* Memory will be freed on destruction of memory_resource */
-   void deallocate(T* ptr, size_t size) {}
-
-   /* Implement <allocator_traits> */
-   using value_type = T;
-   template <class U> struct rebind {
-      using other = monotonic_allocator<U>;
-   };
-
-   typedef std::true_type propagate_on_container_copy_assignment;
-   typedef std::true_type propagate_on_container_move_assignment;
-   typedef std::true_type propagate_on_container_swap;
-
-   template <typename> friend class monotonic_allocator;
-   template <typename X, typename Y>
-   friend bool operator==(monotonic_allocator<X> const& a, monotonic_allocator<Y> const& b);
-   template <typename X, typename Y>
-   friend bool operator!=(monotonic_allocator<X> const& a, monotonic_allocator<Y> const& b);
-
-private:
-   std::reference_wrapper<monotonic_buffer_resource> memory_resource;
-};
-
-/* Necessary for <allocator_traits>. */
-template <typename X, typename Y>
-inline bool
-operator==(monotonic_allocator<X> const& a, monotonic_allocator<Y> const& b)
-{
-   return a.memory_resource.get() == b.memory_resource.get();
-}
-template <typename X, typename Y>
-inline bool
-operator!=(monotonic_allocator<X> const& a, monotonic_allocator<Y> const& b)
-{
-   return !(a == b);
-}
-
-/*
- * aco::map - alias for std::map with monotonic_allocator
- *
- * This template specialization mimics std::pmr::map.
- */
-template <class Key, class T, class Compare = std::less<Key>>
-using map = std::map<Key, T, Compare, aco::monotonic_allocator<std::pair<const Key, T>>>;
-
-/*
- * aco::unordered_map - alias for std::unordered_map with monotonic_allocator
- *
- * This template specialization mimics std::pmr::unordered_map.
- */
-template <class Key, class T, class Hash = std::hash<Key>, class Pred = std::equal_to<Key>>
-using unordered_map =
-   std::unordered_map<Key, T, Hash, Pred, aco::monotonic_allocator<std::pair<const Key, T>>>;
-
 /*
  * Helper class for a integer/bool (access_type) packed into
  * a bigger integer (data_type) with an offset and size.
-- 
GitLab


From 8df4fa807a29101ad2b8e6c7c661f2090fe915aa Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Fri, 10 Feb 2023 14:03:11 +0100
Subject: [PATCH 4/9] aco: use aco::monotonic_allocator for IDSet

---
 src/amd/compiler/aco_ir.h                  | 1 +
 src/amd/compiler/aco_live_var_analysis.cpp | 3 ++-
 src/amd/compiler/aco_reindex_ssa.cpp       | 2 +-
 src/amd/compiler/aco_util.h                | 6 ++++--
 4 files changed, 8 insertions(+), 4 deletions(-)

diff --git a/src/amd/compiler/aco_ir.h b/src/amd/compiler/aco_ir.h
index 33be5df272fb0..2e29d367f4296 100644
--- a/src/amd/compiler/aco_ir.h
+++ b/src/amd/compiler/aco_ir.h
@@ -2068,6 +2068,7 @@ enum class CompilationProgress {
 };
 
 struct live {
+   monotonic_buffer_resource memory;
    /* live temps out per block */
    std::vector<IDSet> live_out;
    /* register demand (sgpr/vgpr) per instruction per block */
diff --git a/src/amd/compiler/aco_live_var_analysis.cpp b/src/amd/compiler/aco_live_var_analysis.cpp
index 154e2eb9db780..bce2551f50727 100644
--- a/src/amd/compiler/aco_live_var_analysis.cpp
+++ b/src/amd/compiler/aco_live_var_analysis.cpp
@@ -477,7 +477,8 @@ void
 live_var_analysis(Program* program, live& live)
 {
    live.live_out.clear();
-   live.live_out.resize(program->blocks.size());
+   live.memory.release();
+   live.live_out.resize(program->blocks.size(), IDSet(live.memory));
    live.register_demand.resize(program->blocks.size());
    unsigned worklist = program->blocks.size();
    std::vector<PhiInfo> phi_info(program->blocks.size());
diff --git a/src/amd/compiler/aco_reindex_ssa.cpp b/src/amd/compiler/aco_reindex_ssa.cpp
index b4b33a312f695..88138879918f9 100644
--- a/src/amd/compiler/aco_reindex_ssa.cpp
+++ b/src/amd/compiler/aco_reindex_ssa.cpp
@@ -98,7 +98,7 @@ void
 update_live_out(idx_ctx& ctx, live& live_vars)
 {
    for (IDSet& set : live_vars.live_out) {
-      IDSet new_set;
+      IDSet new_set(live_vars.memory);
       for (uint32_t id : set)
          new_set.insert(ctx.renames[id]);
       set = new_set;
diff --git a/src/amd/compiler/aco_util.h b/src/amd/compiler/aco_util.h
index 44212f8ca2080..b58f2660c0459 100644
--- a/src/amd/compiler/aco_util.h
+++ b/src/amd/compiler/aco_util.h
@@ -412,7 +412,7 @@ struct IDSet {
 
    struct Iterator {
       const IDSet* set;
-      std::map<uint32_t, block_t>::const_iterator block;
+      aco::map<uint32_t, block_t>::const_iterator block;
       uint32_t id;
 
       Iterator& operator++();
@@ -529,6 +529,8 @@ struct IDSet {
 
    bool empty() const { return !size(); }
 
+   explicit IDSet(monotonic_buffer_resource& m) : words(m) {}
+
 private:
    static uint32_t get_first_set(const block_t& words)
    {
@@ -539,7 +541,7 @@ private:
       return UINT32_MAX;
    }
 
-   std::map<uint32_t, block_t> words;
+   aco::map<uint32_t, block_t> words;
 };
 
 inline IDSet::Iterator&
-- 
GitLab


From 1d6cf55145c0fc6684f17563e77b5d0c88049eae Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Fri, 10 Nov 2023 11:35:43 +0100
Subject: [PATCH 5/9] aco/live_var_analysis: refactor using ctx struct

---
 src/amd/compiler/aco_live_var_analysis.cpp | 72 ++++++++++++----------
 1 file changed, 41 insertions(+), 31 deletions(-)

diff --git a/src/amd/compiler/aco_live_var_analysis.cpp b/src/amd/compiler/aco_live_var_analysis.cpp
index bce2551f50727..b2dc69b21758f 100644
--- a/src/amd/compiler/aco_live_var_analysis.cpp
+++ b/src/amd/compiler/aco_live_var_analysis.cpp
@@ -109,6 +109,13 @@ struct PhiInfo {
    uint16_t linear_phi_defs = 0;
 };
 
+struct live_ctx {
+   Program* program;
+   live& lives;
+   std::vector<PhiInfo> phi_info;
+   unsigned worklist;
+};
+
 bool
 instr_needs_vcc(Instruction* instr)
 {
@@ -125,19 +132,18 @@ instr_needs_vcc(Instruction* instr)
 }
 
 void
-process_live_temps_per_block(Program* program, live& lives, Block* block, unsigned& worklist,
-                             std::vector<PhiInfo>& phi_info)
+process_live_temps_per_block(live_ctx& ctx, Block* block)
 {
-   std::vector<RegisterDemand>& register_demand = lives.register_demand[block->index];
+   std::vector<RegisterDemand>& register_demand = ctx.lives.register_demand[block->index];
    RegisterDemand new_demand;
 
    register_demand.resize(block->instructions.size());
-   IDSet live = lives.live_out[block->index];
+   IDSet live = ctx.lives.live_out[block->index];
 
    /* initialize register demand */
    for (unsigned t : live)
-      new_demand += Temp(t, program->temp_rc[t]);
-   new_demand.sgpr -= phi_info[block->index].logical_phi_sgpr_ops;
+      new_demand += Temp(t, ctx.program->temp_rc[t]);
+   new_demand.sgpr -= ctx.phi_info[block->index].logical_phi_sgpr_ops;
 
    /* traverse the instructions backwards */
    int idx;
@@ -146,7 +152,7 @@ process_live_temps_per_block(Program* program, live& lives, Block* block, unsign
       if (is_phi(insn))
          break;
 
-      program->needs_vcc |= instr_needs_vcc(insn);
+      ctx.program->needs_vcc |= instr_needs_vcc(insn);
       register_demand[idx] = RegisterDemand(new_demand.vgpr, new_demand.sgpr);
 
       /* KILL */
@@ -155,7 +161,7 @@ process_live_temps_per_block(Program* program, live& lives, Block* block, unsign
             continue;
          }
          if (definition.isFixed() && definition.physReg() == vcc)
-            program->needs_vcc = true;
+            ctx.program->needs_vcc = true;
 
          const Temp temp = definition.getTemp();
          const size_t n = live.erase(temp.id());
@@ -171,7 +177,7 @@ process_live_temps_per_block(Program* program, live& lives, Block* block, unsign
 
       /* GEN */
       if (insn->opcode == aco_opcode::p_logical_end) {
-         new_demand.sgpr += phi_info[block->index].logical_phi_sgpr_ops;
+         new_demand.sgpr += ctx.phi_info[block->index].logical_phi_sgpr_ops;
       } else {
          /* we need to do this in a separate loop because the next one can
           * setKill() for several operands at once and we don't want to
@@ -184,7 +190,7 @@ process_live_temps_per_block(Program* program, live& lives, Block* block, unsign
             if (!operand.isTemp())
                continue;
             if (operand.isFixed() && operand.physReg() == vcc)
-               program->needs_vcc = true;
+               ctx.program->needs_vcc = true;
             const Temp temp = operand.getTemp();
             const bool inserted = live.insert(temp.id()).second;
             if (inserted) {
@@ -225,7 +231,7 @@ process_live_temps_per_block(Program* program, live& lives, Block* block, unsign
       }
       Definition& definition = insn->definitions[0];
       if (definition.isFixed() && definition.physReg() == vcc)
-         program->needs_vcc = true;
+         ctx.program->needs_vcc = true;
       const Temp temp = definition.getTemp();
       const size_t n = live.erase(temp.id());
 
@@ -243,7 +249,7 @@ process_live_temps_per_block(Program* program, live& lives, Block* block, unsign
    }
 
    for (unsigned pred_idx : block->linear_preds)
-      phi_info[pred_idx].linear_phi_defs = linear_phi_defs;
+      ctx.phi_info[pred_idx].linear_phi_defs = linear_phi_defs;
 
    /* now, we need to merge the live-ins into the live-out sets */
    bool fast_merge =
@@ -257,24 +263,24 @@ process_live_temps_per_block(Program* program, live& lives, Block* block, unsign
 
    if (fast_merge) {
       for (unsigned pred_idx : block->linear_preds) {
-         if (lives.live_out[pred_idx].insert(live))
-            worklist = std::max(worklist, pred_idx + 1);
+         if (ctx.lives.live_out[pred_idx].insert(live))
+            ctx.worklist = std::max(ctx.worklist, pred_idx + 1);
       }
    } else {
       for (unsigned t : live) {
-         RegClass rc = program->temp_rc[t];
+         RegClass rc = ctx.program->temp_rc[t];
          std::vector<unsigned>& preds = rc.is_linear() ? block->linear_preds : block->logical_preds;
 
 #ifndef NDEBUG
          if (preds.empty())
-            aco_err(program, "Temporary never defined or are defined after use: %%%d in BB%d", t,
-                    block->index);
+            aco_err(ctx.program, "Temporary never defined or are defined after use: %%%d in BB%d",
+                    t, block->index);
 #endif
 
          for (unsigned pred_idx : preds) {
-            auto it = lives.live_out[pred_idx].insert(t);
+            auto it = ctx.lives.live_out[pred_idx].insert(t);
             if (it.second)
-               worklist = std::max(worklist, pred_idx + 1);
+               ctx.worklist = std::max(ctx.worklist, pred_idx + 1);
          }
       }
    }
@@ -292,16 +298,16 @@ process_live_temps_per_block(Program* program, live& lives, Block* block, unsign
          if (!operand.isTemp())
             continue;
          if (operand.isFixed() && operand.physReg() == vcc)
-            program->needs_vcc = true;
+            ctx.program->needs_vcc = true;
          /* check if we changed an already processed block */
-         const bool inserted = lives.live_out[preds[i]].insert(operand.tempId()).second;
+         const bool inserted = ctx.lives.live_out[preds[i]].insert(operand.tempId()).second;
          if (inserted) {
-            worklist = std::max(worklist, preds[i] + 1);
+            ctx.worklist = std::max(ctx.worklist, preds[i] + 1);
             if (insn->opcode == aco_opcode::p_phi && operand.getTemp().type() == RegType::sgpr) {
-               phi_info[preds[i]].logical_phi_sgpr_ops += operand.size();
+               ctx.phi_info[preds[i]].logical_phi_sgpr_ops += operand.size();
             } else if (insn->opcode == aco_opcode::p_linear_phi) {
                assert(operand.getTemp().type() == RegType::sgpr);
-               phi_info[preds[i]].linear_phi_ops += operand.size();
+               ctx.phi_info[preds[i]].linear_phi_ops += operand.size();
             }
          }
 
@@ -480,23 +486,27 @@ live_var_analysis(Program* program, live& live)
    live.memory.release();
    live.live_out.resize(program->blocks.size(), IDSet(live.memory));
    live.register_demand.resize(program->blocks.size());
-   unsigned worklist = program->blocks.size();
-   std::vector<PhiInfo> phi_info(program->blocks.size());
+   live_ctx ctx{
+      program,
+      live,
+      std::vector<PhiInfo>(program->blocks.size()),
+      unsigned(program->blocks.size()),
+   };
    RegisterDemand new_demand;
 
    program->needs_vcc = program->gfx_level >= GFX10;
 
    /* this implementation assumes that the block idx corresponds to the block's position in
     * program->blocks vector */
-   while (worklist) {
-      unsigned block_idx = --worklist;
-      process_live_temps_per_block(program, live, &program->blocks[block_idx], worklist, phi_info);
+   while (ctx.worklist) {
+      unsigned block_idx = --ctx.worklist;
+      process_live_temps_per_block(ctx, &program->blocks[block_idx]);
    }
 
    /* Handle branches: we will insert copies created for linear phis just before the branch. */
    for (Block& block : program->blocks) {
-      live.register_demand[block.index].back().sgpr += phi_info[block.index].linear_phi_defs;
-      live.register_demand[block.index].back().sgpr -= phi_info[block.index].linear_phi_ops;
+      live.register_demand[block.index].back().sgpr += ctx.phi_info[block.index].linear_phi_defs;
+      live.register_demand[block.index].back().sgpr -= ctx.phi_info[block.index].linear_phi_ops;
 
       /* update block's register demand */
       if (program->progress < CompilationProgress::after_ra) {
-- 
GitLab


From c2ece8a7629507c3bfb0be127a359970fa718bd0 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Tue, 14 Nov 2023 16:57:16 +0100
Subject: [PATCH 6/9] aco/live_var_analysis: handle phis separately

---
 src/amd/compiler/aco_live_var_analysis.cpp | 94 ++++++++++++++--------
 1 file changed, 61 insertions(+), 33 deletions(-)

diff --git a/src/amd/compiler/aco_live_var_analysis.cpp b/src/amd/compiler/aco_live_var_analysis.cpp
index b2dc69b21758f..4465bb4aecd24 100644
--- a/src/amd/compiler/aco_live_var_analysis.cpp
+++ b/src/amd/compiler/aco_live_var_analysis.cpp
@@ -131,6 +131,31 @@ instr_needs_vcc(Instruction* instr)
    return false;
 }
 
+void
+handle_phi_operands(live_ctx& ctx)
+{
+   for (Block& block : ctx.program->blocks) {
+      for (aco_ptr<Instruction>& phi : block.instructions) {
+         if (!is_phi(phi))
+            break;
+
+         /* Directly insert into the predecessors' live-out set. */
+         std::vector<unsigned>& preds =
+            phi->opcode == aco_opcode::p_phi ? block.logical_preds : block.linear_preds;
+
+         for (unsigned i = 0; i < preds.size(); ++i) {
+            Operand& operand = phi->operands[i];
+            if (!operand.isTemp())
+               continue;
+            if (operand.isFixed() && operand.physReg() == vcc)
+               ctx.program->needs_vcc = true;
+
+            ctx.lives.live_out[preds[i]].insert(operand.tempId());
+         }
+      }
+   }
+}
+
 void
 process_live_temps_per_block(live_ctx& ctx, Block* block)
 {
@@ -248,8 +273,40 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
       phi_idx--;
    }
 
-   for (unsigned pred_idx : block->linear_preds)
+   for (unsigned pred_idx : block->linear_preds) {
       ctx.phi_info[pred_idx].linear_phi_defs = linear_phi_defs;
+      ctx.phi_info[pred_idx].linear_phi_ops = 0;
+   }
+   for (unsigned pred_idx : block->logical_preds) {
+      ctx.phi_info[pred_idx].logical_phi_sgpr_ops = 0;
+   }
+
+   /* handle phi operands */
+   phi_idx = idx;
+   while (phi_idx >= 0) {
+      Instruction* insn = block->instructions[phi_idx].get();
+      assert(is_phi(insn));
+
+      std::vector<unsigned>& preds =
+         insn->opcode == aco_opcode::p_phi ? block->logical_preds : block->linear_preds;
+      for (unsigned i = 0; i < preds.size(); ++i) {
+         Operand& operand = insn->operands[i];
+         if (!operand.isTemp())
+            continue;
+
+         const bool kill = !live.count(operand.tempId());
+         operand.setKill(kill);
+         if (kill) {
+            if (insn->opcode == aco_opcode::p_phi && operand.getTemp().type() == RegType::sgpr) {
+               ctx.phi_info[preds[i]].logical_phi_sgpr_ops += operand.size();
+            } else if (insn->opcode == aco_opcode::p_linear_phi) {
+               assert(operand.getTemp().type() == RegType::sgpr);
+               ctx.phi_info[preds[i]].linear_phi_ops += operand.size();
+            }
+         }
+      }
+      phi_idx--;
+   }
 
    /* now, we need to merge the live-ins into the live-out sets */
    bool fast_merge =
@@ -285,38 +342,6 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
       }
    }
 
-   /* handle phi operands */
-   phi_idx = idx;
-   while (phi_idx >= 0) {
-      Instruction* insn = block->instructions[phi_idx].get();
-      assert(is_phi(insn));
-      /* directly insert into the predecessors live-out set */
-      std::vector<unsigned>& preds =
-         insn->opcode == aco_opcode::p_phi ? block->logical_preds : block->linear_preds;
-      for (unsigned i = 0; i < preds.size(); ++i) {
-         Operand& operand = insn->operands[i];
-         if (!operand.isTemp())
-            continue;
-         if (operand.isFixed() && operand.physReg() == vcc)
-            ctx.program->needs_vcc = true;
-         /* check if we changed an already processed block */
-         const bool inserted = ctx.lives.live_out[preds[i]].insert(operand.tempId()).second;
-         if (inserted) {
-            ctx.worklist = std::max(ctx.worklist, preds[i] + 1);
-            if (insn->opcode == aco_opcode::p_phi && operand.getTemp().type() == RegType::sgpr) {
-               ctx.phi_info[preds[i]].logical_phi_sgpr_ops += operand.size();
-            } else if (insn->opcode == aco_opcode::p_linear_phi) {
-               assert(operand.getTemp().type() == RegType::sgpr);
-               ctx.phi_info[preds[i]].linear_phi_ops += operand.size();
-            }
-         }
-
-         /* set if the operand is killed by this (or another) phi instruction */
-         operand.setKill(!live.count(operand.tempId()));
-      }
-      phi_idx--;
-   }
-
    assert(!block->linear_preds.empty() || (new_demand == RegisterDemand() && live.empty()));
 }
 
@@ -496,6 +521,9 @@ live_var_analysis(Program* program, live& live)
 
    program->needs_vcc = program->gfx_level >= GFX10;
 
+   /* First, insert all phi operands into live-out sets of the predecessors. */
+   handle_phi_operands(ctx);
+
    /* this implementation assumes that the block idx corresponds to the block's position in
     * program->blocks vector */
    while (ctx.worklist) {
-- 
GitLab


From aa78968591a52bd9ceff7bb44dc9a5052e4b9dd1 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Tue, 9 Jan 2024 15:40:18 +0100
Subject: [PATCH 7/9] aco/live_var_analysis: apply logical_phi_sgpr_ops after
 live var analysis

---
 src/amd/compiler/aco_live_var_analysis.cpp | 21 ++++++++++++++-------
 1 file changed, 14 insertions(+), 7 deletions(-)

diff --git a/src/amd/compiler/aco_live_var_analysis.cpp b/src/amd/compiler/aco_live_var_analysis.cpp
index 4465bb4aecd24..50fa32daa3100 100644
--- a/src/amd/compiler/aco_live_var_analysis.cpp
+++ b/src/amd/compiler/aco_live_var_analysis.cpp
@@ -168,7 +168,6 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
    /* initialize register demand */
    for (unsigned t : live)
       new_demand += Temp(t, ctx.program->temp_rc[t]);
-   new_demand.sgpr -= ctx.phi_info[block->index].logical_phi_sgpr_ops;
 
    /* traverse the instructions backwards */
    int idx;
@@ -201,9 +200,7 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
       }
 
       /* GEN */
-      if (insn->opcode == aco_opcode::p_logical_end) {
-         new_demand.sgpr += ctx.phi_info[block->index].logical_phi_sgpr_ops;
-      } else {
+      {
          /* we need to do this in a separate loop because the next one can
           * setKill() for several operands at once and we don't want to
           * overwrite that in a later iteration */
@@ -531,10 +528,20 @@ live_var_analysis(Program* program, live& live)
       process_live_temps_per_block(ctx, &program->blocks[block_idx]);
    }
 
-   /* Handle branches: we will insert copies created for linear phis just before the branch. */
+   /* Handle branches: We will insert copies created for linear phis just before the branch.
+    * SGPR->VGPR copies for logical phis happen just before p_logical_end.
+    */
    for (Block& block : program->blocks) {
-      live.register_demand[block.index].back().sgpr += ctx.phi_info[block.index].linear_phi_defs;
-      live.register_demand[block.index].back().sgpr -= ctx.phi_info[block.index].linear_phi_ops;
+      std::vector<RegisterDemand>& reg_demand = live.register_demand[block.index];
+      reg_demand.back().sgpr += ctx.phi_info[block.index].linear_phi_defs;
+      reg_demand.back().sgpr -= ctx.phi_info[block.index].linear_phi_ops;
+      if (ctx.phi_info[block.index].logical_phi_sgpr_ops) {
+         for (int i = block.instructions.size() - 1; i >= 0; i--) {
+            reg_demand[i].sgpr -= ctx.phi_info[block.index].logical_phi_sgpr_ops;
+            if (block.instructions[i]->opcode == aco_opcode::p_logical_end)
+               break;
+         }
+      }
 
       /* update block's register demand */
       if (program->progress < CompilationProgress::after_ra) {
-- 
GitLab


From b7cb96d05340a1440a4cc1d727f0773ca59ad348 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Tue, 14 Nov 2023 17:45:11 +0100
Subject: [PATCH 8/9] aco/live_var_analysis: simplify phi-handling

---
 src/amd/compiler/aco_live_var_analysis.cpp | 127 +++++++++------------
 1 file changed, 52 insertions(+), 75 deletions(-)

diff --git a/src/amd/compiler/aco_live_var_analysis.cpp b/src/amd/compiler/aco_live_var_analysis.cpp
index 50fa32daa3100..680a4ab98f06f 100644
--- a/src/amd/compiler/aco_live_var_analysis.cpp
+++ b/src/amd/compiler/aco_live_var_analysis.cpp
@@ -156,6 +156,49 @@ handle_phi_operands(live_ctx& ctx)
    }
 }
 
+void
+procsss_phi_reg_changes(live_ctx& ctx, Block* block, IDSet& live)
+{
+   for (unsigned pred_idx : block->linear_preds)
+      ctx.phi_info[pred_idx].linear_phi_ops = 0;
+   for (unsigned pred_idx : block->logical_preds)
+      ctx.phi_info[pred_idx].logical_phi_sgpr_ops = 0;
+   uint16_t linear_phi_defs = 0;
+
+   for (unsigned j = 0; j < block->instructions.size(); j++) {
+      Instruction* insn = block->instructions[j].get();
+      if (!is_phi(insn))
+         break;
+
+      std::vector<unsigned>& preds =
+         insn->opcode == aco_opcode::p_phi ? block->logical_preds : block->linear_preds;
+      for (unsigned i = 0; i < preds.size(); ++i) {
+         Operand& operand = insn->operands[i];
+         if (!operand.isTemp())
+            continue;
+
+         const bool kill = !live.count(operand.tempId());
+         operand.setKill(kill);
+         if (kill) {
+            if (insn->opcode == aco_opcode::p_phi && operand.getTemp().type() == RegType::sgpr) {
+               ctx.phi_info[preds[i]].logical_phi_sgpr_ops += operand.size();
+            } else if (insn->opcode == aco_opcode::p_linear_phi) {
+               assert(operand.getTemp().type() == RegType::sgpr);
+               ctx.phi_info[preds[i]].linear_phi_ops += operand.size();
+            }
+         }
+      }
+
+      if (insn->opcode == aco_opcode::p_linear_phi && insn->definitions[0].isTemp()) {
+         assert(insn->definitions[0].getTemp().type() == RegType::sgpr);
+         linear_phi_defs += insn->definitions[0].size();
+      }
+   }
+
+   for (unsigned pred_idx : block->linear_preds)
+      ctx.phi_info[pred_idx].linear_phi_defs = linear_phi_defs;
+}
+
 void
 process_live_temps_per_block(live_ctx& ctx, Block* block)
 {
@@ -173,8 +216,6 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
    int idx;
    for (idx = block->instructions.size() - 1; idx >= 0; idx--) {
       Instruction* insn = block->instructions[idx].get();
-      if (is_phi(insn))
-         break;
 
       ctx.program->needs_vcc |= instr_needs_vcc(insn);
       register_demand[idx] = RegisterDemand(new_demand.vgpr, new_demand.sgpr);
@@ -190,17 +231,17 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
          const Temp temp = definition.getTemp();
          const size_t n = live.erase(temp.id());
 
-         if (n) {
-            new_demand -= temp;
-            definition.setKill(false);
-         } else {
-            register_demand[idx] += temp;
-            definition.setKill(true);
+         if (!is_phi(insn)) {
+            if (n)
+               new_demand -= temp;
+            else
+               register_demand[idx] += temp;
          }
+         definition.setKill(!n);
       }
 
       /* GEN */
-      {
+      if (!is_phi(insn)) {
          /* we need to do this in a separate loop because the next one can
           * setKill() for several operands at once and we don't want to
           * overwrite that in a later iteration */
@@ -238,72 +279,8 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
       }
    }
 
-   /* handle phi definitions */
-   uint16_t linear_phi_defs = 0;
-   int phi_idx = idx;
-   while (phi_idx >= 0) {
-      register_demand[phi_idx] = new_demand;
-      Instruction* insn = block->instructions[phi_idx].get();
-
-      assert(is_phi(insn) && insn->definitions.size() == 1);
-      if (!insn->definitions[0].isTemp()) {
-         assert(insn->definitions[0].isFixed() && insn->definitions[0].physReg() == exec);
-         phi_idx--;
-         continue;
-      }
-      Definition& definition = insn->definitions[0];
-      if (definition.isFixed() && definition.physReg() == vcc)
-         ctx.program->needs_vcc = true;
-      const Temp temp = definition.getTemp();
-      const size_t n = live.erase(temp.id());
-
-      if (n)
-         definition.setKill(false);
-      else
-         definition.setKill(true);
-
-      if (insn->opcode == aco_opcode::p_linear_phi) {
-         assert(definition.getTemp().type() == RegType::sgpr);
-         linear_phi_defs += definition.size();
-      }
-
-      phi_idx--;
-   }
-
-   for (unsigned pred_idx : block->linear_preds) {
-      ctx.phi_info[pred_idx].linear_phi_defs = linear_phi_defs;
-      ctx.phi_info[pred_idx].linear_phi_ops = 0;
-   }
-   for (unsigned pred_idx : block->logical_preds) {
-      ctx.phi_info[pred_idx].logical_phi_sgpr_ops = 0;
-   }
-
-   /* handle phi operands */
-   phi_idx = idx;
-   while (phi_idx >= 0) {
-      Instruction* insn = block->instructions[phi_idx].get();
-      assert(is_phi(insn));
-
-      std::vector<unsigned>& preds =
-         insn->opcode == aco_opcode::p_phi ? block->logical_preds : block->linear_preds;
-      for (unsigned i = 0; i < preds.size(); ++i) {
-         Operand& operand = insn->operands[i];
-         if (!operand.isTemp())
-            continue;
-
-         const bool kill = !live.count(operand.tempId());
-         operand.setKill(kill);
-         if (kill) {
-            if (insn->opcode == aco_opcode::p_phi && operand.getTemp().type() == RegType::sgpr) {
-               ctx.phi_info[preds[i]].logical_phi_sgpr_ops += operand.size();
-            } else if (insn->opcode == aco_opcode::p_linear_phi) {
-               assert(operand.getTemp().type() == RegType::sgpr);
-               ctx.phi_info[preds[i]].linear_phi_ops += operand.size();
-            }
-         }
-      }
-      phi_idx--;
-   }
+   /* Handle phis: fixup final register demand calculations */
+   procsss_phi_reg_changes(ctx, block, live);
 
    /* now, we need to merge the live-ins into the live-out sets */
    bool fast_merge =
-- 
GitLab


From cc244042e99da9891dd622bf7ce3b74ef0136edd Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Daniel=20Sch=C3=BCrmann?= <daniel@schuermann.dev>
Date: Mon, 13 Nov 2023 10:01:29 +0100
Subject: [PATCH 9/9] aco/live_var_analysis: insert loop live variables into
 the entire loop at once

For reducible CFGs it holds that
- If a variable is live-in at the header of a loop then
  it is live at all nodes inside the loop.

We use property to directly insert the live-out variables into all blocks of the loop.
---
 src/amd/compiler/aco_live_var_analysis.cpp | 157 +++++++++++++++++----
 1 file changed, 127 insertions(+), 30 deletions(-)

diff --git a/src/amd/compiler/aco_live_var_analysis.cpp b/src/amd/compiler/aco_live_var_analysis.cpp
index 680a4ab98f06f..36331a0040332 100644
--- a/src/amd/compiler/aco_live_var_analysis.cpp
+++ b/src/amd/compiler/aco_live_var_analysis.cpp
@@ -113,7 +113,8 @@ struct live_ctx {
    Program* program;
    live& lives;
    std::vector<PhiInfo> phi_info;
-   unsigned worklist;
+   std::vector<bool> live_out_complete;
+   std::vector<bool> reg_demand_complete;
 };
 
 bool
@@ -159,10 +160,6 @@ handle_phi_operands(live_ctx& ctx)
 void
 procsss_phi_reg_changes(live_ctx& ctx, Block* block, IDSet& live)
 {
-   for (unsigned pred_idx : block->linear_preds)
-      ctx.phi_info[pred_idx].linear_phi_ops = 0;
-   for (unsigned pred_idx : block->logical_preds)
-      ctx.phi_info[pred_idx].logical_phi_sgpr_ops = 0;
    uint16_t linear_phi_defs = 0;
 
    for (unsigned j = 0; j < block->instructions.size(); j++) {
@@ -199,6 +196,78 @@ procsss_phi_reg_changes(live_ctx& ctx, Block* block, IDSet& live)
       ctx.phi_info[pred_idx].linear_phi_defs = linear_phi_defs;
 }
 
+/* For reducible CFGs it holds that
+ * - If a variable is live-in at the header of a loop then
+ *   it is live at all nodes inside the loop.
+ *
+ * We use this property to directly insert the live-out variables into all
+ * blocks of the loop.
+ */
+void
+insert_loop_lives(live_ctx& ctx, Block* loop_header, IDSet& live)
+{
+   unsigned loop_header_idx = loop_header->index;
+
+   /* Insert into preheader */
+   ctx.lives.live_out[loop_header_idx - 1].insert(live);
+   ctx.live_out_complete[loop_header_idx - 1] = true;
+
+   std::vector<uint32_t> logical_blocks = { loop_header_idx };
+   std::vector<uint32_t> linear_blocks;
+
+   while (!logical_blocks.empty()) {
+      unsigned block_idx = logical_blocks.back();
+      logical_blocks.pop_back();
+      if (ctx.live_out_complete[block_idx])
+         continue;
+
+      ctx.lives.live_out[block_idx].insert(live);
+      ctx.live_out_complete[block_idx] = true;
+
+      const Block& block = ctx.program->blocks[block_idx];
+      for (const unsigned pred : block.logical_preds) {
+         if (!ctx.live_out_complete[pred])
+            logical_blocks.emplace_back(pred);
+      }
+      for (const unsigned pred : block.linear_preds)
+         if (!ctx.live_out_complete[pred])
+            linear_blocks.emplace_back(pred);
+   }
+
+   while (!linear_blocks.empty() && ctx.live_out_complete[linear_blocks.back()])
+      linear_blocks.pop_back();
+
+   if (!linear_blocks.empty()) {
+      IDSet linear_set = IDSet(ctx.lives.memory);
+      for (unsigned id : live) {
+         if (ctx.program->temp_rc[id].is_linear())
+            linear_set.insert(id);
+      }
+
+      while (!linear_blocks.empty()) {
+         unsigned block_idx = linear_blocks.back();
+         linear_blocks.pop_back();
+         if (ctx.live_out_complete[block_idx])
+            continue;
+
+         ctx.lives.live_out[block_idx].insert(linear_set);
+         ctx.live_out_complete[block_idx] = true;
+
+         const Block& block = ctx.program->blocks[block_idx];
+         for (unsigned pred : block.linear_preds)
+            if (!ctx.live_out_complete[pred])
+               linear_blocks.emplace_back(pred);
+      }
+   }
+
+   unsigned loop_exit_idx = loop_header->linear_preds.back() + 1;
+   assert(ctx.program->blocks[loop_exit_idx].kind & block_kind_loop_exit);
+   const bool live_out_complete = ctx.reg_demand_complete[loop_exit_idx];
+   std::fill(std::next(ctx.live_out_complete.begin(), loop_header_idx),
+             std::next(ctx.live_out_complete.begin(), loop_exit_idx), live_out_complete);
+   ctx.live_out_complete[loop_header_idx - 1] = false;
+}
+
 void
 process_live_temps_per_block(live_ctx& ctx, Block* block)
 {
@@ -209,8 +278,17 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
    IDSet live = ctx.lives.live_out[block->index];
 
    /* initialize register demand */
-   for (unsigned t : live)
-      new_demand += Temp(t, ctx.program->temp_rc[t]);
+   const bool live_out_complete = ctx.live_out_complete[block->index];
+   const bool update_reg_demand =
+      live_out_complete || std::all_of(block->linear_succs.begin(), block->linear_succs.end(),
+                                       [&](unsigned succ) { return ctx.live_out_complete[succ]; });
+   if (update_reg_demand) {
+      for (unsigned t : live)
+         new_demand += Temp(t, ctx.program->temp_rc[t]);
+
+      ctx.live_out_complete[block->index] = true;
+      ctx.reg_demand_complete[block->index] = true;
+   }
 
    /* traverse the instructions backwards */
    int idx;
@@ -279,8 +357,10 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
       }
    }
 
-   /* Handle phis: fixup final register demand calculations */
-   procsss_phi_reg_changes(ctx, block, live);
+   if (update_reg_demand) {
+      /* Handle phis: fixup final register demand calculations */
+      procsss_phi_reg_changes(ctx, block, live);
+   }
 
    /* now, we need to merge the live-ins into the live-out sets */
    bool fast_merge =
@@ -292,11 +372,13 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
       fast_merge = false; /* we might have errors */
 #endif
 
-   if (fast_merge) {
-      for (unsigned pred_idx : block->linear_preds) {
-         if (ctx.lives.live_out[pred_idx].insert(live))
-            ctx.worklist = std::max(ctx.worklist, pred_idx + 1);
-      }
+   if (live_out_complete) {
+      /* Live-out have been inserted in a previous iteration. */
+   } else if (block->kind & block_kind_loop_header && block->linear_preds.size() > 1) {
+      insert_loop_lives(ctx, block, live);
+   } else if (fast_merge) {
+      for (unsigned pred_idx : block->linear_preds)
+         ctx.lives.live_out[pred_idx].insert(live);
    } else {
       for (unsigned t : live) {
          RegClass rc = ctx.program->temp_rc[t];
@@ -308,11 +390,8 @@ process_live_temps_per_block(live_ctx& ctx, Block* block)
                     t, block->index);
 #endif
 
-         for (unsigned pred_idx : preds) {
-            auto it = ctx.lives.live_out[pred_idx].insert(t);
-            if (it.second)
-               ctx.worklist = std::max(ctx.worklist, pred_idx + 1);
-         }
+         for (unsigned pred_idx : preds)
+            ctx.lives.live_out[pred_idx].insert(t);
       }
    }
 
@@ -481,6 +560,12 @@ update_vgpr_sgpr_demand(Program* program, const RegisterDemand new_demand)
 void
 live_var_analysis(Program* program, live& live)
 {
+   /* This algorithm implements 'Liveness Sets On Reducible Graphs' from
+    * "Computing Liveness Sets for SSA-Form Programs" by F. Brandner et al.
+    *
+    * Note, that this implementation assumes that the block idx corresponds to the
+    * block's position in program->blocks vector.
+    */
    live.live_out.clear();
    live.memory.release();
    live.live_out.resize(program->blocks.size(), IDSet(live.memory));
@@ -489,26 +574,38 @@ live_var_analysis(Program* program, live& live)
       program,
       live,
       std::vector<PhiInfo>(program->blocks.size()),
-      unsigned(program->blocks.size()),
+      std::vector<bool>(program->blocks.size()),
+      std::vector<bool>(program->blocks.size()),
    };
-   RegisterDemand new_demand;
 
    program->needs_vcc = program->gfx_level >= GFX10;
 
    /* First, insert all phi operands into live-out sets of the predecessors. */
    handle_phi_operands(ctx);
 
-   /* this implementation assumes that the block idx corresponds to the block's position in
-    * program->blocks vector */
-   while (ctx.worklist) {
-      unsigned block_idx = --ctx.worklist;
-      process_live_temps_per_block(ctx, &program->blocks[block_idx]);
+   /* Second, calculate complete live-out sets of all blocks by
+    * - computing partial liveness sets using postorder traversal.
+    * - propagating live variables withing loop bodies.
+    */
+   for (int i = program->blocks.size() - 1; i >= 0; i--)
+      process_live_temps_per_block(ctx, &program->blocks[i]);
+
+   /* Third, calculate register demand within loop bodies. */
+   for (int i = program->blocks.size() - 1; i >= 0; i--) {
+      assert(ctx.live_out_complete[i]);
+      if (!ctx.reg_demand_complete[i])
+         process_live_temps_per_block(ctx, &program->blocks[i]);
    }
 
-   /* Handle branches: We will insert copies created for linear phis just before the branch.
-    * SGPR->VGPR copies for logical phis happen just before p_logical_end.
-    */
+   /* Final register demand calculation. */
+   RegisterDemand new_demand;
    for (Block& block : program->blocks) {
+
+      /* Handle branches: Fixup the register demand changes caused by phis.
+       *
+       * We will insert copies created for linear phis just before the branch.
+       * SGPR->VGPR copies for logical phis happen just before p_logical_end.
+       */
       std::vector<RegisterDemand>& reg_demand = live.register_demand[block.index];
       reg_demand.back().sgpr += ctx.phi_info[block.index].linear_phi_defs;
       reg_demand.back().sgpr -= ctx.phi_info[block.index].linear_phi_ops;
@@ -520,7 +617,7 @@ live_var_analysis(Program* program, live& live)
          }
       }
 
-      /* update block's register demand */
+      /* Update block's register demand */
       if (program->progress < CompilationProgress::after_ra) {
          block.register_demand = RegisterDemand();
          for (RegisterDemand& demand : live.register_demand[block.index])
-- 
GitLab

