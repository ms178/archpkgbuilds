From 55a4b801fb8a9f9d8f71d523dfe8a4e39b2592fa Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Sat, 6 Aug 2022 11:58:50 +0200
Subject: [PATCH 1/3] aco/optimizer_postRA: Don't optimize deleted or dead
 instructions.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/amd/compiler/aco_optimizer_postRA.cpp | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/src/amd/compiler/aco_optimizer_postRA.cpp b/src/amd/compiler/aco_optimizer_postRA.cpp
index 726cff40a0c9..0335dd7feb6a 100644
--- a/src/amd/compiler/aco_optimizer_postRA.cpp
+++ b/src/amd/compiler/aco_optimizer_postRA.cpp
@@ -450,6 +450,10 @@ try_combine_dpp(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
 void
 process_instruction(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
 {
+   /* Don't optimize instructions which are already deleted or dead. */
+   if (!instr || is_dead(ctx.uses, instr.get()))
+      return;
+
    try_apply_branch_vcc(ctx, instr);
 
    try_optimize_scc_nocompare(ctx, instr);
-- 
GitLab


From 3cf7797e4b80186bdb482fc2877b42d62f67f308 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Wed, 23 Mar 2022 18:45:36 +0100
Subject: [PATCH 2/3] aco: Support s_cselect_b64 in SCC no-compare
 optimization.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Totals from 67536 (52.49% of 128653) affected shaders:
CodeSize: 241979756 -> 241439532 (-0.22%)
Instrs: 45617999 -> 45482943 (-0.30%)
Latency: 383839969 -> 383769343 (-0.02%)
InvThroughput: 66171558 -> 66169045 (-0.00%); split: -0.00%, +0.00%

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/amd/compiler/aco_optimizer_postRA.cpp | 9 ++++++---
 1 file changed, 6 insertions(+), 3 deletions(-)

diff --git a/src/amd/compiler/aco_optimizer_postRA.cpp b/src/amd/compiler/aco_optimizer_postRA.cpp
index 0335dd7feb6a..5e5963e3f1c2 100644
--- a/src/amd/compiler/aco_optimizer_postRA.cpp
+++ b/src/amd/compiler/aco_optimizer_postRA.cpp
@@ -327,11 +327,13 @@ try_optimize_scc_nocompare(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
             : aco_opcode::s_cmp_lg_u32;
    } else if ((instr->format == Format::PSEUDO_BRANCH && instr->operands.size() == 1 &&
                instr->operands[0].physReg() == scc) ||
-              instr->opcode == aco_opcode::s_cselect_b32) {
+              instr->opcode == aco_opcode::s_cselect_b32 ||
+              instr->opcode == aco_opcode::s_cselect_b64) {
 
       /* For cselect, operand 2 is the SCC condition */
       unsigned scc_op_idx = 0;
-      if (instr->opcode == aco_opcode::s_cselect_b32) {
+      if (instr->opcode == aco_opcode::s_cselect_b32 ||
+          instr->opcode == aco_opcode::s_cselect_b64) {
          scc_op_idx = 2;
       }
 
@@ -359,7 +361,8 @@ try_optimize_scc_nocompare(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
          if (instr->format == Format::PSEUDO_BRANCH)
             instr->opcode = instr->opcode == aco_opcode::p_cbranch_z ? aco_opcode::p_cbranch_nz
                                                                      : aco_opcode::p_cbranch_z;
-         else if (instr->opcode == aco_opcode::s_cselect_b32)
+         else if (instr->opcode == aco_opcode::s_cselect_b32 ||
+                  instr->opcode == aco_opcode::s_cselect_b64)
             std::swap(instr->operands[0], instr->operands[1]);
          else
             unreachable(
-- 
GitLab


From 6e74e6597ead70da8fbfdb22670cedd4768c5d76 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Wed, 13 Apr 2022 19:29:30 +0200
Subject: [PATCH 3/3] aco: Improve SCC nocompare optimization when SCC is
 clobbered.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

When SCC is clobbered between s_cmp and its operand's writer,
the current optimization that eliminates s_cmp won't kick in.

However, when s_cmp is the only user of its operand temporary,
it is possible to "pull down" the instruction that wrote the operand.

Totals from 66886 (51.99% of 128653) affected shaders:
CodeSize: 234808084 -> 234496440 (-0.13%)
Instrs: 44246098 -> 44168187 (-0.18%)
Latency: 362686563 -> 362655169 (-0.01%); split: -0.01%, +0.00%
InvThroughput: 62534929 -> 62533363 (-0.00%); split: -0.00%, +0.00%

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/amd/compiler/aco_optimizer_postRA.cpp     | 65 ++++++++++++++++++-
 .../compiler/tests/test_optimizer_postRA.cpp  | 19 ++++++
 2 files changed, 81 insertions(+), 3 deletions(-)

diff --git a/src/amd/compiler/aco_optimizer_postRA.cpp b/src/amd/compiler/aco_optimizer_postRA.cpp
index 5e5963e3f1c2..6a7cd0dc8d61 100644
--- a/src/amd/compiler/aco_optimizer_postRA.cpp
+++ b/src/amd/compiler/aco_optimizer_postRA.cpp
@@ -267,10 +267,9 @@ try_optimize_scc_nocompare(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
       if (ctx.uses[instr->operands[0].tempId()] > 1)
          return;
 
-      /* Make sure both SCC and Operand 0 are written by the same instruction. */
+      /* Find the writer instruction of Operand 0. */
       Idx wr_idx = last_writer_idx(ctx, instr->operands[0]);
-      Idx sccwr_idx = last_writer_idx(ctx, scc, s1);
-      if (!wr_idx.found() || wr_idx != sccwr_idx)
+      if (!wr_idx.found())
          return;
 
       Instruction* wr_instr = ctx.get(wr_idx);
@@ -313,6 +312,66 @@ try_optimize_scc_nocompare(pr_opt_ctx& ctx, aco_ptr<Instruction>& instr)
       default: return;
       }
 
+      /* Check whether both SCC and Operand 0 are written by the same instruction. */
+      Idx sccwr_idx = last_writer_idx(ctx, scc, s1);
+      if (wr_idx != sccwr_idx) {
+         /* Check whether the current instruction is the only user of its first operand. */
+         if (ctx.uses[wr_instr->definitions[1].tempId()] ||
+             ctx.uses[wr_instr->definitions[0].tempId()] > 1)
+            return;
+
+         /* Only process SOP1 and SOP2 instructions in this manner. */
+         if (wr_instr->format != Format::SOP2 && wr_instr->format != Format::SOP1)
+            return;
+
+         /* Check whether the operands of the writer are clobbered. */
+         for (const Operand& op : wr_instr->operands) {
+            if (!op.isConstant() && is_clobbered_since(ctx, op, wr_idx))
+               return;
+         }
+
+         aco_opcode pulled_opcode = wr_instr->opcode;
+         if (instr->opcode == aco_opcode::s_cmp_eq_u32 ||
+             instr->opcode == aco_opcode::s_cmp_eq_i32 ||
+             instr->opcode == aco_opcode::s_cmp_eq_u64) {
+            /* We need to invert the opcode when s_cmp_eq is used. */
+            switch (wr_instr->opcode) {
+            case aco_opcode::s_and_b32: pulled_opcode = aco_opcode::s_nand_b32; break;
+            case aco_opcode::s_and_b64: pulled_opcode = aco_opcode::s_nand_b64; break;
+            case aco_opcode::s_or_b32: pulled_opcode = aco_opcode::s_nor_b32; break;
+            case aco_opcode::s_or_b64: pulled_opcode = aco_opcode::s_nor_b64; break;
+            case aco_opcode::s_xor_b32: pulled_opcode = aco_opcode::s_xnor_b32; break;
+            case aco_opcode::s_xor_b64: pulled_opcode = aco_opcode::s_xnor_b64; break;
+            case aco_opcode::s_nor_b32: pulled_opcode = aco_opcode::s_or_b32; break;
+            case aco_opcode::s_nor_b64: pulled_opcode = aco_opcode::s_or_b64; break;
+            case aco_opcode::s_xnor_b32: pulled_opcode = aco_opcode::s_xor_b32; break;
+            case aco_opcode::s_xnor_b64: pulled_opcode = aco_opcode::s_xor_b64; break;
+            case aco_opcode::s_nand_b32: pulled_opcode = aco_opcode::s_and_b32; break;
+            case aco_opcode::s_nand_b64: pulled_opcode = aco_opcode::s_and_b64; break;
+            default:
+               /* No suitable opcode is found, don't do the optimization. */
+               return;
+            }
+         }
+
+         Definition scc_def = instr->definitions[0];
+         ctx.uses[wr_instr->definitions[0].tempId()]--;
+
+         /* Copy the writer instruction, but use SCC from the current instr.
+          * This means that the original instruction will be eliminated.
+          */
+         if (wr_instr->format == Format::SOP2) {
+            instr.reset(create_instruction<SOP2_instruction>(pulled_opcode, Format::SOP2, 2, 2));
+            instr->operands[1] = wr_instr->operands[1];
+         } else if (wr_instr->format == Format::SOP1) {
+            instr.reset(create_instruction<SOP1_instruction>(pulled_opcode, Format::SOP1, 1, 2));
+         }
+         instr->definitions[0] = wr_instr->definitions[0];
+         instr->definitions[1] = scc_def;
+         instr->operands[0] = wr_instr->operands[0];
+         return;
+      }
+
       /* Use the SCC def from wr_instr */
       ctx.uses[instr->operands[0].tempId()]--;
       instr->operands[0] = Operand(wr_instr->definitions[1].getTemp(), scc);
diff --git a/src/amd/compiler/tests/test_optimizer_postRA.cpp b/src/amd/compiler/tests/test_optimizer_postRA.cpp
index 468a24cdb51a..da566932a49a 100644
--- a/src/amd/compiler/tests/test_optimizer_postRA.cpp
+++ b/src/amd/compiler/tests/test_optimizer_postRA.cpp
@@ -240,6 +240,25 @@ BEGIN_TEST(optimizer_postRA.scc_nocmp_opt)
 
     //; del d, e, f, g, h, x
 
+    {
+       /* SCC is overwritten in between, optimize by pulling down */
+
+       //! s1: %h:s[3], s1: %x:scc = s_add_u32 %a:s[0], 1
+       //! s1: %d:s[2], s1: %e:scc = s_bfe_u32 %a:s[0], 0x40018
+       //! s2: %f:vcc = p_cbranch_z %g:scc
+       //! p_unit_test 5, %f:vcc, %h:s[3]
+       auto salu = bld.sop2(aco_opcode::s_bfe_u32, bld.def(s1, reg_s2), bld.def(s1, scc), op_in_0,
+                            Operand::c32(0x40018u));
+       auto ovrw = bld.sop2(aco_opcode::s_add_u32, bld.def(s1, reg_s3), bld.def(s1, scc), op_in_0,
+                            Operand::c32(1u));
+       auto scmp = bld.sopc(aco_opcode::s_cmp_lg_u32, bld.def(s1, scc), Operand(salu, reg_s2),
+                            Operand::zero());
+       auto br = bld.branch(aco_opcode::p_cbranch_z, bld.def(s2, vcc), bld.scc(scmp));
+       writeout(5, Operand(br, vcc), Operand(ovrw, reg_s3));
+    }
+
+    //; del d, e, f, g, h, x
+
     {
         //! s1: %d:s[2], s1: %e:scc = s_bfe_u32 %a:s[0], 0x40018
         //! s1: %f:s[4] = s_cselect_b32 %z:s[6], %a:s[0], %e:scc
-- 
GitLab

