From b5e01ac5290e73bac7148432d292ecdf3c3504e8 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Tue, 19 Jul 2022 01:23:44 -0400
Subject: [PATCH 01/10] nir: add nir_intrinsic_image_samples_identical

radeonsi will use it

Reviewed-by: Jason Ekstrand <jason.ekstrand@collabora.com>
---
 src/amd/llvm/ac_nir_to_llvm.c                      | 1 +
 src/compiler/glsl/gl_nir_lower_images.c            | 1 +
 src/compiler/glsl/gl_nir_lower_samplers_as_deref.c | 1 +
 src/compiler/nir/nir_divergence_analysis.c         | 7 +++++++
 src/compiler/nir/nir_group_loads.c                 | 3 +++
 src/compiler/nir/nir_intrinsics.py                 | 2 ++
 src/compiler/nir/nir_lower_non_uniform_access.c    | 3 +++
 src/compiler/nir/nir_opt_access.c                  | 2 ++
 src/compiler/nir/nir_opt_preamble.c                | 1 +
 9 files changed, 21 insertions(+)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 5fb48ca33248..a29d7d91eef9 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -3845,6 +3845,7 @@ static void visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
       break;
    case nir_intrinsic_image_deref_load:
    case nir_intrinsic_image_deref_sparse_load:
+   case nir_intrinsic_image_deref_samples_identical:
       result = visit_image_load(ctx, instr, false);
       break;
    case nir_intrinsic_bindless_image_store:
diff --git a/src/compiler/glsl/gl_nir_lower_images.c b/src/compiler/glsl/gl_nir_lower_images.c
index fde996051cea..09b00947f4aa 100644
--- a/src/compiler/glsl/gl_nir_lower_images.c
+++ b/src/compiler/glsl/gl_nir_lower_images.c
@@ -78,6 +78,7 @@ lower_impl(nir_builder *b, nir_instr *instr, bool bindless_only)
    case nir_intrinsic_image_deref_load:
    case nir_intrinsic_image_deref_samples:
    case nir_intrinsic_image_deref_size:
+   case nir_intrinsic_image_deref_samples_identical:
    case nir_intrinsic_image_deref_store: {
       deref = nir_src_as_deref(intrinsic->src[0]);
       var = nir_deref_instr_get_variable(deref);
diff --git a/src/compiler/glsl/gl_nir_lower_samplers_as_deref.c b/src/compiler/glsl/gl_nir_lower_samplers_as_deref.c
index a6f72d77f6c3..d4a808749cf8 100644
--- a/src/compiler/glsl/gl_nir_lower_samplers_as_deref.c
+++ b/src/compiler/glsl/gl_nir_lower_samplers_as_deref.c
@@ -328,6 +328,7 @@ lower_intrinsic(nir_intrinsic_instr *instr,
        instr->intrinsic == nir_intrinsic_image_deref_atomic_comp_swap ||
        instr->intrinsic == nir_intrinsic_image_deref_atomic_fadd ||
        instr->intrinsic == nir_intrinsic_image_deref_size ||
+       instr->intrinsic == nir_intrinsic_image_deref_samples_identical ||
        instr->intrinsic == nir_intrinsic_image_deref_samples) {
 
       b->cursor = nir_before_instr(&instr->instr);
diff --git a/src/compiler/nir/nir_divergence_analysis.c b/src/compiler/nir/nir_divergence_analysis.c
index ca634d6e1c2a..4365b126c60d 100644
--- a/src/compiler/nir/nir_divergence_analysis.c
+++ b/src/compiler/nir/nir_divergence_analysis.c
@@ -323,6 +323,13 @@ visit_intrinsic(nir_shader *shader, nir_intrinsic_instr *instr)
       is_divergent = instr->src[0].ssa->divergent && (nir_intrinsic_access(instr) & ACCESS_NON_UNIFORM);
       break;
 
+   case nir_intrinsic_image_samples_identical:
+   case nir_intrinsic_image_deref_samples_identical:
+   case nir_intrinsic_bindless_image_samples_identical:
+      is_divergent = (instr->src[0].ssa->divergent && (nir_intrinsic_access(instr) & ACCESS_NON_UNIFORM)) ||
+                     instr->src[1].ssa->divergent;
+      break;
+
    case nir_intrinsic_image_load:
    case nir_intrinsic_image_deref_load:
    case nir_intrinsic_bindless_image_load:
diff --git a/src/compiler/nir/nir_group_loads.c b/src/compiler/nir/nir_group_loads.c
index b9da5c325fb2..b45f9f320bb1 100644
--- a/src/compiler/nir/nir_group_loads.c
+++ b/src/compiler/nir/nir_group_loads.c
@@ -83,6 +83,9 @@ get_intrinsic_resource(nir_intrinsic_instr *intr)
    case nir_intrinsic_image_sparse_load:
    case nir_intrinsic_image_deref_sparse_load:
    /* Group image_size too because it has the same latency as cache hits. */
+   case nir_intrinsic_image_samples_identical:
+   case nir_intrinsic_image_deref_samples_identical:
+   case nir_intrinsic_bindless_image_samples_identical:
    case nir_intrinsic_image_size:
    case nir_intrinsic_image_deref_size:
    case nir_intrinsic_bindless_image_load:
diff --git a/src/compiler/nir/nir_intrinsics.py b/src/compiler/nir/nir_intrinsics.py
index 3a8c64998519..caff6f794024 100644
--- a/src/compiler/nir/nir_intrinsics.py
+++ b/src/compiler/nir/nir_intrinsics.py
@@ -649,6 +649,8 @@ image("size",    dest_comp=0, src_comp=[1], flags=[CAN_ELIMINATE, CAN_REORDER])
 image("samples", dest_comp=1, flags=[CAN_ELIMINATE, CAN_REORDER])
 image("atomic_inc_wrap",  src_comp=[4, 1, 1], dest_comp=1)
 image("atomic_dec_wrap",  src_comp=[4, 1, 1], dest_comp=1)
+# This returns true if all samples within the pixel have equal color values.
+image("samples_identical", dest_comp=1, src_comp=[4], flags=[CAN_ELIMINATE])
 # CL-specific format queries
 image("format", dest_comp=1, flags=[CAN_ELIMINATE, CAN_REORDER])
 image("order", dest_comp=1, flags=[CAN_ELIMINATE, CAN_REORDER])
diff --git a/src/compiler/nir/nir_lower_non_uniform_access.c b/src/compiler/nir/nir_lower_non_uniform_access.c
index fbdd37204349..02ad2a6ade15 100644
--- a/src/compiler/nir/nir_lower_non_uniform_access.c
+++ b/src/compiler/nir/nir_lower_non_uniform_access.c
@@ -272,6 +272,7 @@ nir_lower_non_uniform_access_impl(nir_function_impl *impl,
             case nir_intrinsic_image_atomic_fmax:
             case nir_intrinsic_image_size:
             case nir_intrinsic_image_samples:
+            case nir_intrinsic_image_samples_identical:
             case nir_intrinsic_bindless_image_load:
             case nir_intrinsic_bindless_image_sparse_load:
             case nir_intrinsic_bindless_image_store:
@@ -290,6 +291,7 @@ nir_lower_non_uniform_access_impl(nir_function_impl *impl,
             case nir_intrinsic_bindless_image_atomic_fmax:
             case nir_intrinsic_bindless_image_size:
             case nir_intrinsic_bindless_image_samples:
+            case nir_intrinsic_bindless_image_samples_identical:
             case nir_intrinsic_image_deref_load:
             case nir_intrinsic_image_deref_sparse_load:
             case nir_intrinsic_image_deref_store:
@@ -308,6 +310,7 @@ nir_lower_non_uniform_access_impl(nir_function_impl *impl,
             case nir_intrinsic_image_deref_atomic_fmax:
             case nir_intrinsic_image_deref_size:
             case nir_intrinsic_image_deref_samples:
+            case nir_intrinsic_image_deref_samples_identical:
                if ((options->types & nir_lower_non_uniform_image_access) &&
                    lower_non_uniform_access_intrin(options, &b, intrin, 0))
                   progress = true;
diff --git a/src/compiler/nir/nir_opt_access.c b/src/compiler/nir/nir_opt_access.c
index 14e49eedfe9d..3d4fce2db249 100644
--- a/src/compiler/nir/nir_opt_access.c
+++ b/src/compiler/nir/nir_opt_access.c
@@ -97,6 +97,7 @@ gather_intrinsic(struct access_state *state, nir_intrinsic_instr *instr)
    case nir_intrinsic_image_deref_atomic_fadd:
    case nir_intrinsic_image_deref_atomic_fmin:
    case nir_intrinsic_image_deref_atomic_fmax:
+   case nir_intrinsic_image_deref_samples_identical:
       var = nir_intrinsic_get_var(instr, 0);
       read = instr->intrinsic != nir_intrinsic_image_deref_store;
       write = instr->intrinsic != nir_intrinsic_image_deref_load &&
@@ -139,6 +140,7 @@ gather_intrinsic(struct access_state *state, nir_intrinsic_instr *instr)
    case nir_intrinsic_bindless_image_atomic_fadd:
    case nir_intrinsic_bindless_image_atomic_fmin:
    case nir_intrinsic_bindless_image_atomic_fmax:
+   case nir_intrinsic_bindless_image_samples_identical:
       read = instr->intrinsic != nir_intrinsic_bindless_image_store;
       write = instr->intrinsic != nir_intrinsic_bindless_image_load &&
               instr->intrinsic != nir_intrinsic_bindless_image_sparse_load;
diff --git a/src/compiler/nir/nir_opt_preamble.c b/src/compiler/nir/nir_opt_preamble.c
index 0a9224de15ff..174021ed6838 100644
--- a/src/compiler/nir/nir_opt_preamble.c
+++ b/src/compiler/nir/nir_opt_preamble.c
@@ -197,6 +197,7 @@ can_move_intrinsic(nir_intrinsic_instr *instr, opt_preamble_ctx *ctx)
     * sources can be moved.
     */
    case nir_intrinsic_image_load:
+   case nir_intrinsic_image_samples_identical:
    case nir_intrinsic_bindless_image_load:
    case nir_intrinsic_load_ssbo:
    case nir_intrinsic_load_ssbo_ir3:
-- 
GitLab


From 1586736e414f80d1ff309da0d5f5d00cbe7377f9 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Wed, 20 Jul 2022 07:55:04 -0400
Subject: [PATCH 02/10] nir: add nir_intrinsic_image_descriptor_amd

This returns the AMD shader resource descriptor.

Reviewed-by: Jason Ekstrand <jason.ekstrand@collabora.com>
---
 src/compiler/glsl/gl_nir_lower_images.c            | 1 +
 src/compiler/glsl/gl_nir_lower_samplers_as_deref.c | 1 +
 src/compiler/nir/nir_divergence_analysis.c         | 3 +++
 src/compiler/nir/nir_intrinsics.py                 | 3 +++
 4 files changed, 8 insertions(+)

diff --git a/src/compiler/glsl/gl_nir_lower_images.c b/src/compiler/glsl/gl_nir_lower_images.c
index 09b00947f4aa..a1d50f45a81c 100644
--- a/src/compiler/glsl/gl_nir_lower_images.c
+++ b/src/compiler/glsl/gl_nir_lower_images.c
@@ -79,6 +79,7 @@ lower_impl(nir_builder *b, nir_instr *instr, bool bindless_only)
    case nir_intrinsic_image_deref_samples:
    case nir_intrinsic_image_deref_size:
    case nir_intrinsic_image_deref_samples_identical:
+   case nir_intrinsic_image_deref_descriptor_amd:
    case nir_intrinsic_image_deref_store: {
       deref = nir_src_as_deref(intrinsic->src[0]);
       var = nir_deref_instr_get_variable(deref);
diff --git a/src/compiler/glsl/gl_nir_lower_samplers_as_deref.c b/src/compiler/glsl/gl_nir_lower_samplers_as_deref.c
index d4a808749cf8..99622c189fff 100644
--- a/src/compiler/glsl/gl_nir_lower_samplers_as_deref.c
+++ b/src/compiler/glsl/gl_nir_lower_samplers_as_deref.c
@@ -329,6 +329,7 @@ lower_intrinsic(nir_intrinsic_instr *instr,
        instr->intrinsic == nir_intrinsic_image_deref_atomic_fadd ||
        instr->intrinsic == nir_intrinsic_image_deref_size ||
        instr->intrinsic == nir_intrinsic_image_deref_samples_identical ||
+       instr->intrinsic == nir_intrinsic_image_deref_descriptor_amd ||
        instr->intrinsic == nir_intrinsic_image_deref_samples) {
 
       b->cursor = nir_before_instr(&instr->instr);
diff --git a/src/compiler/nir/nir_divergence_analysis.c b/src/compiler/nir/nir_divergence_analysis.c
index 4365b126c60d..2dcce508259e 100644
--- a/src/compiler/nir/nir_divergence_analysis.c
+++ b/src/compiler/nir/nir_divergence_analysis.c
@@ -372,6 +372,9 @@ visit_intrinsic(nir_shader *shader, nir_intrinsic_instr *instr)
    case nir_intrinsic_image_size:
    case nir_intrinsic_image_deref_size:
    case nir_intrinsic_bindless_image_size:
+   case nir_intrinsic_image_descriptor_amd:
+   case nir_intrinsic_image_deref_descriptor_amd:
+   case nir_intrinsic_bindless_image_descriptor_amd:
    case nir_intrinsic_copy_deref:
    case nir_intrinsic_vulkan_resource_index:
    case nir_intrinsic_vulkan_resource_reindex:
diff --git a/src/compiler/nir/nir_intrinsics.py b/src/compiler/nir/nir_intrinsics.py
index caff6f794024..3741b8b06e14 100644
--- a/src/compiler/nir/nir_intrinsics.py
+++ b/src/compiler/nir/nir_intrinsics.py
@@ -651,6 +651,9 @@ image("atomic_inc_wrap",  src_comp=[4, 1, 1], dest_comp=1)
 image("atomic_dec_wrap",  src_comp=[4, 1, 1], dest_comp=1)
 # This returns true if all samples within the pixel have equal color values.
 image("samples_identical", dest_comp=1, src_comp=[4], flags=[CAN_ELIMINATE])
+# Non-uniform access is not lowered for image_descriptor_amd.
+# dest_comp can be either 4 (buffer) or 8 (image).
+image("descriptor_amd", dest_comp=0, src_comp=[], flags=[CAN_ELIMINATE, CAN_REORDER])
 # CL-specific format queries
 image("format", dest_comp=1, flags=[CAN_ELIMINATE, CAN_REORDER])
 image("order", dest_comp=1, flags=[CAN_ELIMINATE, CAN_REORDER])
-- 
GitLab


From f1d78814ef240fbeebbec2f1b9d25c7f00a97e02 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Wed, 20 Jul 2022 22:55:04 -0400
Subject: [PATCH 03/10] nir: add nir_texop_descriptor_amd

AMD will use it to emulate resinfo.

Reviewed-by: Jason Ekstrand <jason.ekstrand@collabora.com>
---
 src/compiler/nir/nir.c            | 5 +++++
 src/compiler/nir/nir.h            | 1 +
 src/compiler/spirv/spirv_to_nir.c | 5 +++++
 3 files changed, 11 insertions(+)

diff --git a/src/compiler/nir/nir.c b/src/compiler/nir/nir.c
index 0f181e891206..1e749911e34f 100644
--- a/src/compiler/nir/nir.c
+++ b/src/compiler/nir/nir.c
@@ -3215,6 +3215,7 @@ nir_tex_instr_need_sampler(const nir_tex_instr *instr)
    case nir_texop_query_levels:
    case nir_texop_texture_samples:
    case nir_texop_samples_identical:
+   case nir_texop_descriptor_amd:
       return false;
    default:
       return true;
@@ -3260,6 +3261,9 @@ nir_tex_instr_result_size(const nir_tex_instr *instr)
    case nir_texop_fragment_mask_fetch_amd:
       return 1;
 
+   case nir_texop_descriptor_amd:
+      return instr->sampler_dim == GLSL_SAMPLER_DIM_BUF ? 4 : 8;
+
    default:
       if (instr->is_shadow && instr->is_new_style_shadow)
          return 1;
@@ -3276,6 +3280,7 @@ nir_tex_instr_is_query(const nir_tex_instr *instr)
    case nir_texop_lod:
    case nir_texop_texture_samples:
    case nir_texop_query_levels:
+   case nir_texop_descriptor_amd:
       return true;
    case nir_texop_tex:
    case nir_texop_txb:
diff --git a/src/compiler/nir/nir.h b/src/compiler/nir/nir.h
index 9cc5efb3317d..0584f86fab1d 100644
--- a/src/compiler/nir/nir.h
+++ b/src/compiler/nir/nir.h
@@ -2154,6 +2154,7 @@ typedef enum {
    nir_texop_tex_prefetch,       /**< Regular texture look-up, eligible for pre-dispatch */
    nir_texop_fragment_fetch_amd,      /**< Multisample fragment color texture fetch */
    nir_texop_fragment_mask_fetch_amd, /**< Multisample fragment mask texture fetch */
+   nir_texop_descriptor_amd,     /**< Returns a buffer or image descriptor. */
 } nir_texop;
 
 /** Represents a texture instruction */
diff --git a/src/compiler/spirv/spirv_to_nir.c b/src/compiler/spirv/spirv_to_nir.c
index 7c10c9729cf5..6e0b54dd2467 100644
--- a/src/compiler/spirv/spirv_to_nir.c
+++ b/src/compiler/spirv/spirv_to_nir.c
@@ -2826,8 +2826,13 @@ vtn_handle_texture(struct vtn_builder *b, SpvOp opcode,
       break;
    case nir_texop_txf_ms_mcs_intel:
       vtn_fail("unexpected nir_texop_txf_ms_mcs");
+      break;
    case nir_texop_tex_prefetch:
       vtn_fail("unexpected nir_texop_tex_prefetch");
+      break;
+   case nir_texop_descriptor_amd:
+      vtn_fail("unexpected nir_texop_descriptor_amd");
+      break;
    }
 
    unsigned idx = 4;
-- 
GitLab


From 2bc802a025bcc4a96685bd0bd56bc6aa1e2d3586 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 21 Jul 2022 09:31:38 -0400
Subject: [PATCH 04/10] nir: add shader_info::uses_resource_info_query for txs,
 levels, samples, etc.

AMD will use this to execute a lowering pass conditionally.

Reviewed-by: Jason Ekstrand <jason.ekstrand@collabora.com>
---
 src/compiler/nir/nir_gather_info.c | 15 +++++++++++++++
 src/compiler/shader_info.h         |  3 +++
 2 files changed, 18 insertions(+)

diff --git a/src/compiler/nir/nir_gather_info.c b/src/compiler/nir/nir_gather_info.c
index c19fe07a1bd5..d1086d86d3ef 100644
--- a/src/compiler/nir/nir_gather_info.c
+++ b/src/compiler/nir/nir_gather_info.c
@@ -836,6 +836,14 @@ gather_intrinsic_info(nir_intrinsic_instr *instr, nir_shader *shader,
    default:
       if (nir_intrinsic_writes_external_memory(instr))
          shader->info.writes_memory = true;
+
+      if (instr->intrinsic == nir_intrinsic_image_size ||
+          instr->intrinsic == nir_intrinsic_image_samples ||
+          instr->intrinsic == nir_intrinsic_image_deref_size ||
+          instr->intrinsic == nir_intrinsic_image_deref_samples ||
+          instr->intrinsic == nir_intrinsic_bindless_image_size ||
+          instr->intrinsic == nir_intrinsic_bindless_image_samples)
+         shader->info.uses_resource_info_query = true;
       break;
    }
 }
@@ -851,6 +859,11 @@ gather_tex_info(nir_tex_instr *instr, nir_shader *shader)
    case nir_texop_tg4:
       shader->info.uses_texture_gather = true;
       break;
+   case nir_texop_txs:
+   case nir_texop_query_levels:
+   case nir_texop_texture_samples:
+      shader->info.uses_resource_info_query = true;
+      break;
    default:
       break;
    }
@@ -962,6 +975,8 @@ nir_shader_gather_info(nir_shader *shader, nir_function_impl *entrypoint)
    shader->info.patch_inputs_read_indirectly = 0;
    shader->info.patch_outputs_accessed_indirectly = 0;
 
+   shader->info.uses_resource_info_query = false;
+
    if (shader->info.stage == MESA_SHADER_VERTEX) {
       shader->info.vs.double_inputs = 0;
    }
diff --git a/src/compiler/shader_info.h b/src/compiler/shader_info.h
index 9229c3016897..b8c0e8f2aa99 100644
--- a/src/compiler/shader_info.h
+++ b/src/compiler/shader_info.h
@@ -254,6 +254,9 @@ typedef struct shader_info {
    /* Whether or not this shader ever uses textureGather() */
    bool uses_texture_gather:1;
 
+   /* Whether texture size, levels, or samples is queried. */
+   bool uses_resource_info_query:1;
+
    /**
     * True if this shader uses the fddx/fddy opcodes.
     *
-- 
GitLab


From 250771d874591e4b2be09babef62e58e31f60102 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Tue, 19 Jul 2022 02:08:33 -0400
Subject: [PATCH 05/10] ac/llvm: implement
 nir_intrinsic_image_deref_samples_identical

---
 src/amd/llvm/ac_nir_to_llvm.c | 19 ++++++++++++++++++-
 1 file changed, 18 insertions(+), 1 deletion(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index a29d7d91eef9..757812426898 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -2491,7 +2491,7 @@ static void get_image_coords(struct ac_nir_context *ctx, const nir_intrinsic_ins
       LLVMConstInt(ctx->ac.i32, 2, false),
       LLVMConstInt(ctx->ac.i32, 3, false),
    };
-   LLVMValueRef sample_index = ac_llvm_extract_elem(&ctx->ac, get_src(ctx, instr->src[2]), 0);
+   LLVMValueRef sample_index = NULL;
 
    int count;
    ASSERTED bool add_frag_pos =
@@ -2515,6 +2515,7 @@ static void get_image_coords(struct ac_nir_context *ctx, const nir_intrinsic_ins
       else
          fmask_load_address[2] = NULL;
 
+      sample_index = ac_llvm_extract_elem(&ctx->ac, get_src(ctx, instr->src[2]), 0);
       sample_index = adjust_sample_index_using_fmask(
          &ctx->ac, fmask_load_address[0], fmask_load_address[1], fmask_load_address[2],
          sample_index, get_image_descriptor(ctx, instr, dynamic_desc_index, AC_DESC_FMASK, false));
@@ -2558,6 +2559,8 @@ static void get_image_coords(struct ac_nir_context *ctx, const nir_intrinsic_ins
       }
 
       if (is_ms) {
+         if (!sample_index)
+            sample_index = ac_llvm_extract_elem(&ctx->ac, get_src(ctx, instr->src[2]), 0);
          args->coords[count] = sample_index;
          count++;
       }
@@ -2626,6 +2629,20 @@ static LLVMValueRef visit_image_load(struct ac_nir_context *ctx, const nir_intri
 
       res = ac_trim_vector(&ctx->ac, res, instr->dest.ssa.num_components);
       res = ac_to_integer(&ctx->ac, res);
+   } else if (instr->intrinsic == nir_intrinsic_image_deref_samples_identical) {
+      assert(ctx->ac.gfx_level < GFX11);
+
+      args.opcode = ac_image_load;
+      args.resource = get_image_descriptor(ctx, instr, dynamic_index, AC_DESC_FMASK, false);
+      get_image_coords(ctx, instr, dynamic_index, &args, GLSL_SAMPLER_DIM_2D, is_array);
+      args.dmask = 0xf;
+      args.dim = is_array ? ac_image_2darray : ac_image_2d;
+      args.attributes = AC_FUNC_ATTR_READNONE;
+      args.a16 = ac_get_elem_bits(&ctx->ac, LLVMTypeOf(args.coords[0])) == 16;
+
+      res = ac_build_image_opcode(&ctx->ac, &args);
+      res = LLVMBuildExtractElement(ctx->ac.builder, res, ctx->ac.i32_0, "");
+      res = LLVMBuildICmp(ctx->ac.builder, LLVMIntEQ, res, ctx->ac.i32_0, "");
    } else {
       bool level_zero = nir_src_is_const(instr->src[3]) && nir_src_as_uint(instr->src[3]) == 0;
 
-- 
GitLab


From 9debd3ed769ef8d389f88e60debded50bce6fc63 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Wed, 20 Jul 2022 07:55:11 -0400
Subject: [PATCH 06/10] ac/llvm: implement
 nir_intrinsic_image_deref_descriptor_amd

---
 src/amd/llvm/ac_nir_to_llvm.c | 32 ++++++++++++++++++++++++++++++++
 1 file changed, 32 insertions(+)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 757812426898..37ae0e84b44f 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -2979,6 +2979,32 @@ static LLVMValueRef visit_image_size(struct ac_nir_context *ctx, const nir_intri
    return exit_waterfall(ctx, &wctx, res);
 }
 
+static LLVMValueRef visit_image_descriptor(struct ac_nir_context *ctx,
+                                           const nir_intrinsic_instr *instr,
+                                           bool bindless)
+{
+   enum glsl_sampler_dim dim;
+
+   if (bindless) {
+      dim = nir_intrinsic_image_dim(instr);
+   } else {
+      const struct glsl_type *type = get_image_deref(instr)->type;
+      dim = glsl_get_sampler_dim(type);
+   }
+
+   nir_deref_instr *deref_instr = NULL;
+   if (instr->src[0].ssa->parent_instr->type == nir_instr_type_deref)
+      deref_instr = nir_instr_as_deref(instr->src[0].ssa->parent_instr);
+
+   LLVMValueRef dynamic_index = get_sampler_desc_index(ctx, deref_instr, &instr->instr, true);
+
+   if (dim == GLSL_SAMPLER_DIM_BUF) {
+      return get_image_descriptor(ctx, instr, dynamic_index, AC_DESC_BUFFER, false);
+   } else {
+      return get_image_descriptor(ctx, instr, dynamic_index, AC_DESC_IMAGE, false);
+   }
+}
+
 static void emit_discard(struct ac_nir_context *ctx, const nir_intrinsic_instr *instr)
 {
    LLVMValueRef cond;
@@ -3907,6 +3933,12 @@ static void visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_image_deref_size:
       result = visit_image_size(ctx, instr, false);
       break;
+   case nir_intrinsic_image_deref_descriptor_amd:
+      result = visit_image_descriptor(ctx, instr, false);
+      break;
+   case nir_intrinsic_bindless_image_descriptor_amd:
+      result = visit_image_descriptor(ctx, instr, true);
+      break;
    case nir_intrinsic_shader_clock:
       result = ac_build_shader_clock(&ctx->ac, nir_intrinsic_memory_scope(instr));
       break;
-- 
GitLab


From 337c6a45f5abec4cbd585006a8302bc15389cc2b Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Wed, 20 Jul 2022 22:56:23 -0400
Subject: [PATCH 07/10] ac/llvm: implement nir_texop_descriptor_amd

---
 src/amd/llvm/ac_nir_to_llvm.c | 20 ++++++++++++++------
 1 file changed, 14 insertions(+), 6 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 37ae0e84b44f..0437a2070d20 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -4564,7 +4564,8 @@ static LLVMValueRef sici_fix_sampler_aniso(struct ac_nir_context *ctx, LLVMValue
 
 static void tex_fetch_ptrs(struct ac_nir_context *ctx, nir_tex_instr *instr,
                            struct waterfall_context *wctx, LLVMValueRef *res_ptr,
-                           LLVMValueRef *samp_ptr, LLVMValueRef *fmask_ptr)
+                           LLVMValueRef *samp_ptr, LLVMValueRef *fmask_ptr,
+                           bool divergent)
 {
    LLVMValueRef texture_dynamic_handle = NULL;
    LLVMValueRef sampler_dynamic_handle = NULL;
@@ -4633,10 +4634,10 @@ static void tex_fetch_ptrs(struct ac_nir_context *ctx, nir_tex_instr *instr,
    if (texture_dynamic_handle) {
       /* descriptor handles given through nir_tex_src_{texture,sampler}_handle */
       if (instr->texture_non_uniform)
-         texture_dynamic_handle = enter_waterfall(ctx, &wctx[0], texture_dynamic_handle, true);
+         texture_dynamic_handle = enter_waterfall(ctx, &wctx[0], texture_dynamic_handle, divergent);
 
       if (instr->sampler_non_uniform)
-         sampler_dynamic_handle = enter_waterfall(ctx, &wctx[1], sampler_dynamic_handle, true);
+         sampler_dynamic_handle = enter_waterfall(ctx, &wctx[1], sampler_dynamic_handle, divergent);
 
       *res_ptr = ctx->abi->load_sampler_desc(ctx->abi, 0, 0, 0, texture_dynamic_handle,
                                              main_descriptor, false, false, true);
@@ -4666,11 +4667,11 @@ static void tex_fetch_ptrs(struct ac_nir_context *ctx, nir_tex_instr *instr,
     */
    if (instr->texture_non_uniform ||
        (ctx->abi->use_waterfall_for_divergent_tex_samplers && texture_deref_instr->dest.ssa.divergent))
-      texture_dynamic_index = enter_waterfall(ctx, wctx + 0, texture_dynamic_index, true);
+      texture_dynamic_index = enter_waterfall(ctx, wctx + 0, texture_dynamic_index, divergent);
 
    if (instr->sampler_non_uniform ||
        (ctx->abi->use_waterfall_for_divergent_tex_samplers && sampler_deref_instr->dest.ssa.divergent))
-      sampler_dynamic_index = enter_waterfall(ctx, wctx + 1, sampler_dynamic_index, true);
+      sampler_dynamic_index = enter_waterfall(ctx, wctx + 1, sampler_dynamic_index, divergent);
 
    *res_ptr = get_sampler_desc(ctx, texture_deref_instr, main_descriptor, &instr->instr,
                                texture_dynamic_index, false, false);
@@ -4704,7 +4705,14 @@ static void visit_tex(struct ac_nir_context *ctx, nir_tex_instr *instr)
    unsigned offset_src = 0;
    struct waterfall_context wctx[2] = {{{0}}};
 
-   tex_fetch_ptrs(ctx, instr, wctx, &args.resource, &args.sampler, &fmask_ptr);
+   /* Don't use the waterfall loop when returning a descriptor. */
+   tex_fetch_ptrs(ctx, instr, wctx, &args.resource, &args.sampler, &fmask_ptr,
+                  instr->op != nir_texop_descriptor_amd);
+
+   if (instr->op == nir_texop_descriptor_amd) {
+      result = args.resource;
+      goto write_result;
+   }
 
    for (unsigned i = 0; i < instr->num_srcs; i++) {
       switch (instr->src[i].src_type) {
-- 
GitLab


From d5ba3052b0b0fd6af19c399ff8e295287de9ec45 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Wed, 20 Jul 2022 11:23:26 -0400
Subject: [PATCH 08/10] ac/nir: add ac_nir_lower_resinfo

Emulating image_get_resinfo should be faster than using the hw.
---
 src/amd/common/ac_nir.h               |   2 +
 src/amd/common/ac_nir_lower_resinfo.c | 316 ++++++++++++++++++++++++++
 src/amd/common/meson.build            |   1 +
 3 files changed, 319 insertions(+)
 create mode 100644 src/amd/common/ac_nir_lower_resinfo.c

diff --git a/src/amd/common/ac_nir.h b/src/amd/common/ac_nir.h
index 601f48ca0ffb..9a9b39d0ddc9 100644
--- a/src/amd/common/ac_nir.h
+++ b/src/amd/common/ac_nir.h
@@ -166,6 +166,8 @@ ac_nir_cull_triangle(nir_builder *b,
 bool
 ac_nir_lower_global_access(nir_shader *shader);
 
+bool ac_nir_lower_resinfo(nir_shader *nir, enum amd_gfx_level gfx_level);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/src/amd/common/ac_nir_lower_resinfo.c b/src/amd/common/ac_nir_lower_resinfo.c
new file mode 100644
index 000000000000..93b138780455
--- /dev/null
+++ b/src/amd/common/ac_nir_lower_resinfo.c
@@ -0,0 +1,316 @@
+/*
+ * Copyright Â© 2022 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ */
+
+/* Implement query_size, query_levels, and query_samples by extracting the information from
+ * descriptors. This is expected to be faster than image_resinfo.
+ */
+
+#include "ac_nir.h"
+#include "nir_builder.h"
+#include "amdgfxregs.h"
+
+static nir_ssa_def *get_field(nir_builder *b, nir_ssa_def *desc, unsigned index, unsigned mask)
+{
+   return nir_ubfe_imm(b, nir_channel(b, desc, index), ffs(mask) - 1, util_bitcount(mask));
+}
+
+static nir_ssa_def *handle_null_desc(nir_builder *b, nir_ssa_def *desc, nir_ssa_def *value)
+{
+   nir_ssa_def *is_null = nir_ieq_imm(b, nir_channel(b, desc, 1), 0);
+   return nir_bcsel(b, is_null, nir_imm_int(b, 0), value);
+}
+
+static nir_ssa_def *query_samples(nir_builder *b, nir_ssa_def *desc, enum glsl_sampler_dim dim)
+{
+   nir_ssa_def *samples;
+
+   if (dim == GLSL_SAMPLER_DIM_MS) {
+      /* LAST_LEVEL contains log2(num_samples). */
+      samples = get_field(b, desc, 3, ~C_00A00C_LAST_LEVEL);
+      samples = nir_ishl(b, nir_imm_int(b, 1), samples);
+   } else {
+      samples = nir_imm_int(b, 1);
+   }
+
+   return handle_null_desc(b, desc, samples);
+}
+
+static nir_ssa_def *query_levels(nir_builder *b, nir_ssa_def *desc)
+{
+   nir_ssa_def *base_level = get_field(b, desc, 3, ~C_00A00C_BASE_LEVEL);
+   nir_ssa_def *last_level = get_field(b, desc, 3, ~C_00A00C_LAST_LEVEL);
+
+   nir_ssa_def *levels = nir_iadd_imm(b, nir_isub(b, last_level, base_level), 1);
+
+   return handle_null_desc(b, desc, levels);
+}
+
+static nir_ssa_def *
+lower_query_size(nir_builder *b, nir_ssa_def *desc, nir_src *lod,
+                 enum glsl_sampler_dim dim, bool is_array, enum amd_gfx_level gfx_level)
+{
+   if (dim == GLSL_SAMPLER_DIM_BUF) {
+      nir_ssa_def *size = nir_channel(b, desc, 2);
+
+      if (gfx_level == GFX8) {
+         /* On GFX8, the descriptor contains the size in bytes,
+          * but TXQ must return the size in elements.
+          * The stride is always non-zero for resources using TXQ.
+          * Divide the size by the stride.
+          */
+         size = nir_udiv(b, size, get_field(b, desc, 1, ~C_008F04_STRIDE));
+      }
+      return size;
+   }
+
+   /* Cube textures return (width, width) instead of (width, height). */
+   bool has_height = dim != GLSL_SAMPLER_DIM_1D && dim != GLSL_SAMPLER_DIM_CUBE;
+   bool has_depth = dim == GLSL_SAMPLER_DIM_3D;
+   nir_ssa_def *width, *height = NULL, *layers = NULL, *base_array = NULL, *last_array = NULL;
+   nir_ssa_def *depth = NULL;
+
+   /* Get the width, height, depth, layers. */
+   if (gfx_level >= GFX10) {
+      nir_ssa_def *width_lo = get_field(b, desc, 1, ~C_00A004_WIDTH_LO);
+      nir_ssa_def *width_hi = get_field(b, desc, 2, ~C_00A008_WIDTH_HI);
+
+      width = nir_ior(b, width_lo, nir_ishl_imm(b, width_hi, 2));
+      if (has_height)
+         height = get_field(b, desc, 2, ~C_00A008_HEIGHT);
+      if (has_depth)
+         depth = get_field(b, desc, 4, ~C_00A010_DEPTH);
+
+      if (is_array) {
+         last_array = get_field(b, desc, 4, ~C_00A010_DEPTH);
+         base_array = get_field(b, desc, 4, ~C_00A010_BASE_ARRAY);
+      }
+   } else {
+      width = get_field(b, desc, 2, ~C_008F18_WIDTH);
+      if (has_height)
+         height = get_field(b, desc, 2, ~C_008F18_HEIGHT);
+      if (has_depth)
+         depth = get_field(b, desc, 4, ~C_008F20_DEPTH);
+
+      if (is_array) {
+         base_array = get_field(b, desc, 5, ~C_008F24_BASE_ARRAY);
+
+         if (gfx_level == GFX9) {
+            last_array = get_field(b, desc, 4, ~C_008F20_DEPTH);
+         } else {
+            last_array = get_field(b, desc, 5, ~C_008F24_LAST_ARRAY);
+         }
+      }
+   }
+
+   /* All values are off by 1. */
+   width = nir_iadd_imm(b, width, 1);
+   if (has_height)
+      height = nir_iadd_imm(b, height, 1);
+   if (has_depth)
+      depth = nir_iadd_imm(b, depth, 1);
+
+   if (is_array) {
+      layers = nir_isub(b, last_array, base_array);
+      layers = nir_iadd_imm(b, layers, 1);
+   }
+
+   /* Minify the dimensions according to base_level + lod. */
+   if (dim != GLSL_SAMPLER_DIM_MS && dim != GLSL_SAMPLER_DIM_RECT) {
+      nir_ssa_def *base_level = get_field(b, desc, 3, ~C_00A00C_BASE_LEVEL);
+      nir_ssa_def *level = lod ? nir_iadd(b, base_level, lod->ssa) : base_level;
+
+      width = nir_ushr(b, width, level);
+      width = nir_umax(b, width, nir_imm_int(b, 1));
+      if (has_height) {
+         height = nir_ushr(b, height, level);
+         height = nir_umax(b, height, nir_imm_int(b, 1));
+      }
+      if (has_depth) {
+         depth = nir_ushr(b, depth, level);
+         depth = nir_umax(b, depth, nir_imm_int(b, 1));
+      }
+   }
+
+   nir_ssa_def *result = NULL;
+
+   /* Construct the result. */
+   switch (dim) {
+   case GLSL_SAMPLER_DIM_1D:
+      result = is_array ? nir_vec2(b, width, layers) : width;
+      break;
+   case GLSL_SAMPLER_DIM_CUBE:
+      result = is_array ? nir_vec3(b, width, width, layers) : nir_vec2(b, width, width);
+      break;
+   case GLSL_SAMPLER_DIM_2D:
+   case GLSL_SAMPLER_DIM_MS:
+   case GLSL_SAMPLER_DIM_RECT:
+      result = is_array ? nir_vec3(b, width, height, layers) : nir_vec2(b, width, height);
+      break;
+   case GLSL_SAMPLER_DIM_3D:
+      result = nir_vec3(b, width, height, depth);
+      break;
+   default:
+      unreachable("invalid sampler dim");
+   }
+
+   return handle_null_desc(b, desc, result);
+}
+
+static bool lower_resinfo(nir_builder *b, nir_instr *instr, void *data)
+{
+   enum amd_gfx_level gfx_level = *(enum amd_gfx_level*)data;
+   nir_ssa_def *result = NULL, *dst = NULL;
+
+   if (instr->type == nir_instr_type_intrinsic) {
+      nir_intrinsic_instr *intr = nir_instr_as_intrinsic(instr);
+      const struct glsl_type *type;
+      enum glsl_sampler_dim dim;
+      bool is_array;
+      nir_ssa_def *desc = NULL;
+
+      dst = &intr->dest.ssa;
+      b->cursor = nir_before_instr(instr);
+
+      switch (intr->intrinsic) {
+      case nir_intrinsic_image_size:
+      case nir_intrinsic_image_samples:
+         dim = nir_intrinsic_image_dim(intr);
+         is_array = nir_intrinsic_image_array(intr);
+         desc = nir_image_descriptor_amd(b, dim == GLSL_SAMPLER_DIM_BUF ? 4 : 8,
+                                         32, intr->src[0].ssa);
+         break;
+
+      case nir_intrinsic_image_deref_size:
+      case nir_intrinsic_image_deref_samples:
+         type = nir_instr_as_deref(intr->src[0].ssa->parent_instr)->type;
+         dim = glsl_get_sampler_dim(type);
+         is_array = glsl_sampler_type_is_array(type);
+         desc = nir_image_deref_descriptor_amd(b, dim == GLSL_SAMPLER_DIM_BUF ? 4 : 8,
+                                               32, intr->src[0].ssa);
+         break;
+
+      case nir_intrinsic_bindless_image_size:
+      case nir_intrinsic_bindless_image_samples:
+         dim = nir_intrinsic_image_dim(intr);
+         is_array = nir_intrinsic_image_array(intr);
+         desc = nir_bindless_image_descriptor_amd(b, dim == GLSL_SAMPLER_DIM_BUF ? 4 : 8,
+                                                  32, intr->src[0].ssa);
+         break;
+
+      default:
+         return false;
+      }
+
+      switch (intr->intrinsic) {
+      case nir_intrinsic_image_size:
+      case nir_intrinsic_image_deref_size:
+      case nir_intrinsic_bindless_image_size:
+         result = lower_query_size(b, desc, NULL, dim, is_array, gfx_level);
+         break;
+
+      case nir_intrinsic_image_samples:
+      case nir_intrinsic_image_deref_samples:
+      case nir_intrinsic_bindless_image_samples:
+         result = query_samples(b, desc, dim);
+         break;
+
+      default:
+         assert(!desc);
+         return false;
+      }
+   } else if (instr->type == nir_instr_type_tex) {
+      nir_tex_instr *tex = nir_instr_as_tex(instr);
+      nir_tex_instr *new_tex;
+      nir_ssa_def *desc = NULL;
+      nir_src *lod = NULL;
+
+      dst = &tex->dest.ssa;
+      b->cursor = nir_before_instr(instr);
+
+      switch (tex->op) {
+      case nir_texop_txs:
+      case nir_texop_query_levels:
+      case nir_texop_texture_samples:
+         for (unsigned i = 0; i < tex->num_srcs; i++) {
+            switch (tex->src[i].src_type) {
+            case nir_tex_src_texture_deref:
+            case nir_tex_src_texture_handle:
+               new_tex = nir_tex_instr_create(b->shader, 1);
+               new_tex->op = nir_texop_descriptor_amd;
+               new_tex->sampler_dim = tex->sampler_dim;
+               new_tex->is_array = tex->is_array;
+               new_tex->texture_index = tex->texture_index;
+               new_tex->sampler_index = tex->sampler_index;
+               new_tex->dest_type = nir_type_int32;
+               nir_src_copy(&new_tex->src[0].src, &tex->src[i].src);
+               new_tex->src[0].src_type = tex->src[i].src_type;
+               nir_ssa_dest_init(&new_tex->instr, &new_tex->dest,
+                                 nir_tex_instr_dest_size(new_tex), 32, NULL);
+               nir_builder_instr_insert(b, &new_tex->instr);
+               desc = &new_tex->dest.ssa;
+               break;
+
+            case nir_tex_src_lod:
+               lod = &tex->src[i].src;
+               break;
+
+            default:;
+            }
+         }
+
+         switch (tex->op) {
+         case nir_texop_txs:
+            result = lower_query_size(b, desc, lod, tex->sampler_dim, tex->is_array,
+                                      gfx_level);
+            break;
+         case nir_texop_query_levels:
+            result = query_levels(b, desc);
+            break;
+         case nir_texop_texture_samples:
+            result = query_samples(b, desc, tex->sampler_dim);
+            break;
+         default:
+            unreachable("shouldn't get here");
+         }
+         break;
+
+      default:
+         return false;
+      }
+   }
+
+   if (!result)
+      return false;
+
+   nir_ssa_def_rewrite_uses_after(dst, result, instr);
+   nir_instr_remove(instr);
+   return true;
+}
+
+bool ac_nir_lower_resinfo(nir_shader *nir, enum amd_gfx_level gfx_level)
+{
+   return nir_shader_instructions_pass(nir, lower_resinfo,
+                                       nir_metadata_dominance |
+                                       nir_metadata_block_index,
+                                       &gfx_level);
+}
diff --git a/src/amd/common/meson.build b/src/amd/common/meson.build
index 0b511b534a07..1d72ce7f0f1a 100644
--- a/src/amd/common/meson.build
+++ b/src/amd/common/meson.build
@@ -96,6 +96,7 @@ amd_common_files = files(
   'ac_nir_cull.c',
   'ac_nir_lower_esgs_io_to_mem.c',
   'ac_nir_lower_global_access.c',
+  'ac_nir_lower_resinfo.c',
   'ac_nir_lower_taskmesh_io_to_mem.c',
   'ac_nir_lower_tess_io_to_mem.c',
   'ac_nir_lower_ngg.c',
-- 
GitLab


From 4b3c3ce9ea0bc5c4ee18bc45b8df9ffbab547a74 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Thu, 21 Jul 2022 09:48:29 -0400
Subject: [PATCH 09/10] radeonsi,radv: run ac_nir_lower_resinfo

Emulating image_get_resinfo should be faster than using the hw.
---
 src/amd/vulkan/radv_pipeline.c           | 4 ++++
 src/gallium/drivers/radeonsi/si_shader.c | 3 +++
 2 files changed, 7 insertions(+)

diff --git a/src/amd/vulkan/radv_pipeline.c b/src/amd/vulkan/radv_pipeline.c
index d6a24f5a9921..353ae9241d0f 100644
--- a/src/amd/vulkan/radv_pipeline.c
+++ b/src/amd/vulkan/radv_pipeline.c
@@ -4857,6 +4857,10 @@ radv_create_shaders(struct radv_pipeline *pipeline, struct radv_pipeline_layout
          if (lowered_ngg)
             radv_lower_ngg(device, &stages[i], pipeline_key);
 
+         if (radv_use_llvm_for_stage(device, i) &&
+             stages[i].nir->info.uses_resource_info_query)
+            NIR_PASS(_, stages[i].nir, ac_nir_lower_resinfo, device->physical_device->rad_info.gfx_level);
+
          NIR_PASS(_, stages[i].nir, ac_nir_lower_global_access);
          NIR_PASS_V(stages[i].nir, radv_nir_lower_abi, device->physical_device->rad_info.gfx_level,
                     &stages[i].info, &stages[i].args, pipeline_key,
diff --git a/src/gallium/drivers/radeonsi/si_shader.c b/src/gallium/drivers/radeonsi/si_shader.c
index 531fc60ca95b..6a62f324c437 100644
--- a/src/gallium/drivers/radeonsi/si_shader.c
+++ b/src/gallium/drivers/radeonsi/si_shader.c
@@ -1607,6 +1607,9 @@ struct nir_shader *si_get_nir_shader(struct si_shader *shader, bool *free_nir,
    if (sel->stage <= MESA_SHADER_GEOMETRY)
       NIR_PASS(progress, nir, si_nir_kill_outputs, key);
 
+   if (nir->info.uses_resource_info_query)
+      NIR_PASS(progress, nir, ac_nir_lower_resinfo, sel->screen->info.gfx_level);
+
    bool inline_uniforms = false;
    uint32_t *inlined_uniform_values;
    si_get_inline_uniform_state((union si_shader_key*)key, sel->pipe_shader_type,
-- 
GitLab


From 5e6aea9423ba10283c51c3afc2e134b089afd294 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Sun, 17 Jul 2022 12:35:42 -0400
Subject: [PATCH 10/10] ac/llvm: remove all resinfo code now that it's lowered

---
 src/amd/llvm/ac_nir_to_llvm.c | 165 ++--------------------------------
 1 file changed, 7 insertions(+), 158 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 0437a2070d20..354843d56b29 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -1406,27 +1406,6 @@ static void visit_load_const(struct ac_nir_context *ctx, const nir_load_const_in
    ctx->ssa_defs[instr->def.index] = value;
 }
 
-static LLVMValueRef get_buffer_size(struct ac_nir_context *ctx, LLVMValueRef descriptor,
-                                    bool in_elements)
-{
-   LLVMValueRef size =
-      LLVMBuildExtractElement(ctx->ac.builder, descriptor, LLVMConstInt(ctx->ac.i32, 2, false), "");
-
-   /* GFX8 only */
-   if (ctx->ac.gfx_level == GFX8 && in_elements) {
-      /* On GFX8, the descriptor contains the size in bytes,
-       * but TXQ must return the size in elements.
-       * The stride is always non-zero for resources using TXQ.
-       */
-      LLVMValueRef stride = LLVMBuildExtractElement(ctx->ac.builder, descriptor, ctx->ac.i32_1, "");
-      stride = LLVMBuildLShr(ctx->ac.builder, stride, LLVMConstInt(ctx->ac.i32, 16, false), "");
-      stride = LLVMBuildAnd(ctx->ac.builder, stride, LLVMConstInt(ctx->ac.i32, 0x3fff, false), "");
-
-      size = LLVMBuildUDiv(ctx->ac.builder, size, stride, "");
-   }
-   return size;
-}
-
 /* Gather4 should follow the same rules as bilinear filtering, but the hardware
  * incorrectly forces nearest filtering if the texture format is integer.
  * The only effect it has on Gather4, which always returns 4 texels for
@@ -1604,10 +1583,8 @@ static LLVMValueRef build_tex_intrinsic(struct ac_nir_context *ctx, const nir_te
       break;
    case nir_texop_txs:
    case nir_texop_query_levels:
-      args->opcode = ac_image_get_resinfo;
-      if (!args->lod)
-         args->lod = ctx->ac.i32_0;
-      args->level_zero = false;
+   case nir_texop_texture_samples:
+      assert(!"should have been lowered");
       break;
    case nir_texop_tex:
       if (ctx->stage != MESA_SHADER_FRAGMENT &&
@@ -1770,7 +1747,7 @@ static LLVMValueRef visit_get_ssbo_size(struct ac_nir_context *ctx,
 {
    bool non_uniform = nir_intrinsic_access(instr) & ACCESS_NON_UNIFORM;
    LLVMValueRef rsrc = ctx->abi->load_ssbo(ctx->abi, get_src(ctx, instr->src[0]), false, non_uniform);
-   return get_buffer_size(ctx, rsrc, false);
+   return LLVMBuildExtractElement(ctx->ac.builder, rsrc, LLVMConstInt(ctx->ac.i32, 2, false), "");
 }
 
 static LLVMValueRef extract_vector_range(struct ac_llvm_context *ctx, LLVMValueRef src,
@@ -2911,74 +2888,6 @@ static LLVMValueRef visit_image_atomic(struct ac_nir_context *ctx, const nir_int
    return result;
 }
 
-static LLVMValueRef visit_image_samples(struct ac_nir_context *ctx, nir_intrinsic_instr *instr)
-{
-   struct waterfall_context wctx;
-   LLVMValueRef dynamic_index = enter_waterfall_image(ctx, &wctx, instr);
-   LLVMValueRef rsrc = get_image_descriptor(ctx, instr, dynamic_index, AC_DESC_IMAGE, false);
-
-   LLVMValueRef ret = ac_build_image_get_sample_count(&ctx->ac, rsrc);
-   if (ctx->abi->robust_buffer_access) {
-      LLVMValueRef dword1, is_null_descriptor;
-
-      /* Extract the second dword of the descriptor, if it's
-       * all zero, then it's a null descriptor.
-       */
-      dword1 =
-         LLVMBuildExtractElement(ctx->ac.builder, rsrc, LLVMConstInt(ctx->ac.i32, 1, false), "");
-      is_null_descriptor = LLVMBuildICmp(ctx->ac.builder, LLVMIntEQ, dword1,
-                                         LLVMConstInt(ctx->ac.i32, 0, false), "");
-      ret = LLVMBuildSelect(ctx->ac.builder, is_null_descriptor, ctx->ac.i32_0, ret, "");
-   }
-
-   return exit_waterfall(ctx, &wctx, ret);
-}
-
-static LLVMValueRef visit_image_size(struct ac_nir_context *ctx, const nir_intrinsic_instr *instr,
-                                     bool bindless)
-{
-   LLVMValueRef res;
-
-   enum glsl_sampler_dim dim;
-   bool is_array;
-   if (bindless) {
-      dim = nir_intrinsic_image_dim(instr);
-      is_array = nir_intrinsic_image_array(instr);
-   } else {
-      const struct glsl_type *type = get_image_deref(instr)->type;
-      dim = glsl_get_sampler_dim(type);
-      is_array = glsl_sampler_type_is_array(type);
-   }
-
-   struct waterfall_context wctx;
-   LLVMValueRef dynamic_index = enter_waterfall_image(ctx, &wctx, instr);
-
-   if (dim == GLSL_SAMPLER_DIM_BUF) {
-      res = get_buffer_size(
-         ctx, get_image_descriptor(ctx, instr, dynamic_index, AC_DESC_BUFFER, false), true);
-   } else {
-
-      struct ac_image_args args = {0};
-
-      args.dim = ac_get_image_dim(ctx->ac.gfx_level, dim, is_array);
-      args.dmask = 0xf;
-      args.resource = get_image_descriptor(ctx, instr, dynamic_index, AC_DESC_IMAGE, false);
-      args.opcode = ac_image_get_resinfo;
-      assert(nir_src_as_uint(instr->src[1]) == 0);
-      args.lod = ctx->ac.i32_0;
-      args.attributes = AC_FUNC_ATTR_READNONE;
-
-      res = ac_build_image_opcode(&ctx->ac, &args);
-
-      if (ctx->ac.gfx_level == GFX9 && dim == GLSL_SAMPLER_DIM_1D && is_array) {
-         LLVMValueRef two = LLVMConstInt(ctx->ac.i32, 2, false);
-         LLVMValueRef layers = LLVMBuildExtractElement(ctx->ac.builder, res, two, "");
-         res = LLVMBuildInsertElement(ctx->ac.builder, res, layers, ctx->ac.i32_1, "");
-      }
-   }
-   return exit_waterfall(ctx, &wctx, res);
-}
-
 static LLVMValueRef visit_image_descriptor(struct ac_nir_context *ctx,
                                            const nir_intrinsic_instr *instr,
                                            bool bindless)
@@ -3878,10 +3787,6 @@ static void visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_store_shared2_amd:
       visit_store_shared2_amd(ctx, instr);
       break;
-   case nir_intrinsic_bindless_image_samples:
-   case nir_intrinsic_image_deref_samples:
-      result = visit_image_samples(ctx, instr);
-      break;
    case nir_intrinsic_bindless_image_load:
    case nir_intrinsic_bindless_image_sparse_load:
       result = visit_image_load(ctx, instr, true);
@@ -3927,12 +3832,6 @@ static void visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_image_deref_atomic_fmax:
       result = visit_image_atomic(ctx, instr, false);
       break;
-   case nir_intrinsic_bindless_image_size:
-      result = visit_image_size(ctx, instr, true);
-      break;
-   case nir_intrinsic_image_deref_size:
-      result = visit_image_size(ctx, instr, false);
-      break;
    case nir_intrinsic_image_deref_descriptor_amd:
       result = visit_image_descriptor(ctx, instr, false);
       break;
@@ -4770,48 +4669,6 @@ static void visit_tex(struct ac_nir_context *ctx, nir_tex_instr *instr)
       }
    }
 
-   if (instr->op == nir_texop_txs && instr->sampler_dim == GLSL_SAMPLER_DIM_BUF) {
-      result = get_buffer_size(ctx, args.resource, true);
-      goto write_result;
-   }
-
-   if (instr->op == nir_texop_texture_samples) {
-      LLVMValueRef res, samples, is_msaa;
-      LLVMValueRef default_sample;
-
-      res = LLVMBuildBitCast(ctx->ac.builder, args.resource, ctx->ac.v8i32, "");
-      samples =
-         LLVMBuildExtractElement(ctx->ac.builder, res, LLVMConstInt(ctx->ac.i32, 3, false), "");
-      is_msaa = LLVMBuildLShr(ctx->ac.builder, samples, LLVMConstInt(ctx->ac.i32, 28, false), "");
-      is_msaa = LLVMBuildAnd(ctx->ac.builder, is_msaa, LLVMConstInt(ctx->ac.i32, 0xe, false), "");
-      is_msaa = LLVMBuildICmp(ctx->ac.builder, LLVMIntEQ, is_msaa,
-                              LLVMConstInt(ctx->ac.i32, 0xe, false), "");
-
-      samples = LLVMBuildLShr(ctx->ac.builder, samples, LLVMConstInt(ctx->ac.i32, 16, false), "");
-      samples = LLVMBuildAnd(ctx->ac.builder, samples, LLVMConstInt(ctx->ac.i32, 0xf, false), "");
-      samples = LLVMBuildShl(ctx->ac.builder, ctx->ac.i32_1, samples, "");
-
-      if (ctx->abi->robust_buffer_access) {
-         LLVMValueRef dword1, is_null_descriptor;
-
-         /* Extract the second dword of the descriptor, if it's
-          * all zero, then it's a null descriptor.
-          */
-         dword1 =
-            LLVMBuildExtractElement(ctx->ac.builder, res, LLVMConstInt(ctx->ac.i32, 1, false), "");
-         is_null_descriptor = LLVMBuildICmp(ctx->ac.builder, LLVMIntEQ, dword1,
-                                            LLVMConstInt(ctx->ac.i32, 0, false), "");
-         default_sample =
-            LLVMBuildSelect(ctx->ac.builder, is_null_descriptor, ctx->ac.i32_0, ctx->ac.i32_1, "");
-      } else {
-         default_sample = ctx->ac.i32_1;
-      }
-
-      samples = LLVMBuildSelect(ctx->ac.builder, is_msaa, samples, default_sample, "");
-      result = samples;
-      goto write_result;
-   }
-
    if (args.offset && instr->op != nir_texop_txf && instr->op != nir_texop_txf_ms) {
       LLVMValueRef offset[3], pack;
       for (unsigned chan = 0; chan < 3; ++chan)
@@ -4950,7 +4807,7 @@ static void visit_tex(struct ac_nir_context *ctx, nir_tex_instr *instr)
    if (ctx->ac.gfx_level < GFX11 &&
        (instr->sampler_dim == GLSL_SAMPLER_DIM_SUBPASS_MS ||
         instr->sampler_dim == GLSL_SAMPLER_DIM_MS) &&
-       instr->op != nir_texop_txs && instr->op != nir_texop_fragment_fetch_amd &&
+       instr->op != nir_texop_fragment_fetch_amd &&
        instr->op != nir_texop_fragment_mask_fetch_amd) {
       unsigned sample_chan = instr->is_array ? 3 : 2;
       args.coords[sample_chan] = adjust_sample_index_using_fmask(
@@ -5022,18 +4879,10 @@ static void visit_tex(struct ac_nir_context *ctx, nir_tex_instr *instr)
       result = ac_trim_vector(&ctx->ac, result, 4);
    }
 
-   if (instr->op == nir_texop_query_levels)
-      result =
-         LLVMBuildExtractElement(ctx->ac.builder, result, LLVMConstInt(ctx->ac.i32, 3, false), "");
-   else if (instr->is_shadow && instr->is_new_style_shadow && instr->op != nir_texop_txs &&
-            instr->op != nir_texop_lod && instr->op != nir_texop_tg4)
+   if (instr->is_shadow && instr->is_new_style_shadow &&
+       instr->op != nir_texop_lod && instr->op != nir_texop_tg4)
       result = LLVMBuildExtractElement(ctx->ac.builder, result, ctx->ac.i32_0, "");
-   else if (ctx->ac.gfx_level == GFX9 && instr->op == nir_texop_txs &&
-              instr->sampler_dim == GLSL_SAMPLER_DIM_1D && instr->is_array) {
-      LLVMValueRef two = LLVMConstInt(ctx->ac.i32, 2, false);
-      LLVMValueRef layers = LLVMBuildExtractElement(ctx->ac.builder, result, two, "");
-      result = LLVMBuildInsertElement(ctx->ac.builder, result, layers, ctx->ac.i32_1, "");
-   } else if (instr->op == nir_texop_fragment_mask_fetch_amd) {
+   else if (instr->op == nir_texop_fragment_mask_fetch_amd) {
       /* Use 0x76543210 if the image doesn't have FMASK. */
       LLVMValueRef tmp = LLVMBuildBitCast(ctx->ac.builder, args.resource, ctx->ac.v8i32, "");
       tmp = LLVMBuildExtractElement(ctx->ac.builder, tmp, ctx->ac.i32_1, "");
-- 
GitLab

