From 6b3a349755c8c7ecbaca73562058adcd2acf949e Mon Sep 17 00:00:00 2001
From: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date: Thu, 26 Oct 2023 16:36:11 +0200
Subject: [PATCH 1/5] radv: add a helper to determine if it's possible to
 preprocess DGC

Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/vulkan/radv_cmd_buffer.c              |  2 +-
 .../vulkan/radv_device_generated_commands.c   | 58 +++++++++++--------
 src/amd/vulkan/radv_private.h                 |  5 +-
 3 files changed, 37 insertions(+), 28 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index 20908dae425e..bf2970243444 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -9545,7 +9545,7 @@ radv_CmdExecuteGeneratedCommandsNV(VkCommandBuffer commandBuffer, VkBool32 isPre
       cmd_buffer->state.predicating = true;
    }
 
-   if (!layout->use_preprocess) {
+   if (!radv_dgc_can_preprocess(layout)) {
       radv_prepare_dgc(cmd_buffer, pGeneratedCommandsInfo);
 
       cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_CS_PARTIAL_FLUSH | RADV_CMD_FLAG_INV_VCACHE | RADV_CMD_FLAG_INV_L2;
diff --git a/src/amd/vulkan/radv_device_generated_commands.c b/src/amd/vulkan/radv_device_generated_commands.c
index bb8748601ba8..7405dcd74a54 100644
--- a/src/amd/vulkan/radv_device_generated_commands.c
+++ b/src/amd/vulkan/radv_device_generated_commands.c
@@ -1286,6 +1286,7 @@ radv_CreateIndirectCommandsLayoutNV(VkDevice _device, const VkIndirectCommandsLa
 
    vk_object_base_init(&device->vk, &layout->base, VK_OBJECT_TYPE_INDIRECT_COMMANDS_LAYOUT_NV);
 
+   layout->flags = pCreateInfo->flags;
    layout->pipeline_bind_point = pCreateInfo->pipelineBindPoint;
    layout->input_stride = pCreateInfo->pStreamStrides[0];
    layout->token_count = pCreateInfo->tokenCount;
@@ -1337,30 +1338,6 @@ radv_CreateIndirectCommandsLayoutNV(VkDevice _device, const VkIndirectCommandsLa
    if (!layout->indexed)
       layout->binds_index_buffer = false;
 
-   layout->use_preprocess = pCreateInfo->flags & VK_INDIRECT_COMMANDS_LAYOUT_USAGE_EXPLICIT_PREPROCESS_BIT_NV;
-
-   /* From the Vulkan spec (1.3.269, chapter 32):
-    * "The bound descriptor sets and push constants that will be used with indirect command generation for the compute
-    * piplines must already be specified at the time of preprocessing commands with vkCmdPreprocessGeneratedCommandsNV.
-    * They must not change until the execution of indirect commands is submitted with vkCmdExecuteGeneratedCommandsNV."
-    *
-    * So we can always preprocess compute layouts.
-    */
-   if (layout->pipeline_bind_point != VK_PIPELINE_BIND_POINT_COMPUTE) {
-      /* We embed the index buffer extent in indirect draw packets, but that isn't available at preprocess time. */
-      if (layout->indexed && !layout->binds_index_buffer)
-         layout->use_preprocess = false;
-
-      /* VBO binding (in particular partial VBO binding) uses some draw state which we don't generate at preprocess time
-       * yet. */
-      if (layout->bind_vbo_mask)
-         layout->use_preprocess = false;
-
-      /* In preprocess we use the non-overridden push constants from the draw state for now. */
-      if (layout->push_constant_mask)
-         layout->use_preprocess = false;
-   }
-
    *pIndirectCommandsLayout = radv_indirect_command_layout_to_handle(layout);
    return VK_SUCCESS;
 }
@@ -1415,6 +1392,37 @@ radv_use_dgc_predication(struct radv_cmd_buffer *cmd_buffer, const VkGeneratedCo
    return cmd_buffer->qf == RADV_QUEUE_GENERAL && seq_count_buffer && !cmd_buffer->state.predicating;
 }
 
+bool
+radv_dgc_can_preprocess(const struct radv_indirect_command_layout *layout)
+{
+   if (!(layout->flags & VK_INDIRECT_COMMANDS_LAYOUT_USAGE_EXPLICIT_PREPROCESS_BIT_NV))
+      return false;
+
+   /* From the Vulkan spec (1.3.269, chapter 32):
+    * "The bound descriptor sets and push constants that will be used with indirect command generation for the compute
+    * piplines must already be specified at the time of preprocessing commands with vkCmdPreprocessGeneratedCommandsNV.
+    * They must not change until the execution of indirect commands is submitted with vkCmdExecuteGeneratedCommandsNV."
+    *
+    * So we can always preprocess compute layouts.
+    */
+   if (layout->pipeline_bind_point != VK_PIPELINE_BIND_POINT_COMPUTE) {
+      /* We embed the index buffer extent in indirect draw packets, but that isn't available at preprocess time. */
+      if (layout->indexed && !layout->binds_index_buffer)
+         return false;
+
+      /* VBO binding (in particular partial VBO binding) uses some draw state which we don't generate at preprocess time
+       * yet. */
+      if (layout->bind_vbo_mask)
+         return false;
+
+      /* In preprocess we use the non-overridden push constants from the draw state for now. */
+      if (layout->push_constant_mask)
+         return false;
+   }
+
+   return true;
+}
+
 VKAPI_ATTR void VKAPI_CALL
 radv_CmdPreprocessGeneratedCommandsNV(VkCommandBuffer commandBuffer,
                                       const VkGeneratedCommandsInfoNV *pGeneratedCommandsInfo)
@@ -1422,7 +1430,7 @@ radv_CmdPreprocessGeneratedCommandsNV(VkCommandBuffer commandBuffer,
    VK_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, commandBuffer);
    VK_FROM_HANDLE(radv_indirect_command_layout, layout, pGeneratedCommandsInfo->indirectCommandsLayout);
 
-   if (!layout->use_preprocess)
+   if (!radv_dgc_can_preprocess(layout))
       return;
 
    const bool use_predication = radv_use_dgc_predication(cmd_buffer, pGeneratedCommandsInfo);
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index ccfb15494010..b16ff97e22b1 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -3233,6 +3233,7 @@ void radv_sqtt_emit_relocated_shaders(struct radv_cmd_buffer *cmd_buffer, struct
 struct radv_indirect_command_layout {
    struct vk_object_base base;
 
+   VkIndirectCommandsLayoutUsageFlagsNV flags;
    VkPipelineBindPoint pipeline_bind_point;
 
    uint32_t input_stride;
@@ -3257,8 +3258,6 @@ struct radv_indirect_command_layout {
    uint32_t ibo_type_32;
    uint32_t ibo_type_8;
 
-   bool use_preprocess;
-
    VkIndirectCommandsLayoutTokenNV tokens[0];
 };
 
@@ -3268,6 +3267,8 @@ bool radv_use_dgc_predication(struct radv_cmd_buffer *cmd_buffer,
                               const VkGeneratedCommandsInfoNV *pGeneratedCommandsInfo);
 void radv_prepare_dgc(struct radv_cmd_buffer *cmd_buffer, const VkGeneratedCommandsInfoNV *pGeneratedCommandsInfo);
 
+bool radv_dgc_can_preprocess(const struct radv_indirect_command_layout *layout);
+
 static inline uint32_t
 si_conv_prim_to_gs_out(uint32_t topology, bool is_ngg)
 {
-- 
GitLab


From fc768e02bc94535b11a0f6888bf4ff9ec590c3cd Mon Sep 17 00:00:00 2001
From: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date: Fri, 27 Oct 2023 10:12:27 +0200
Subject: [PATCH 2/5] radv: pass the raw inline push constant SGPR to the DGC
 shader

This will be used to emit individual packets for preprocess graphics
support.

Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 .../vulkan/radv_device_generated_commands.c   | 29 ++++++++++---------
 1 file changed, 15 insertions(+), 14 deletions(-)

diff --git a/src/amd/vulkan/radv_device_generated_commands.c b/src/amd/vulkan/radv_device_generated_commands.c
index 7405dcd74a54..566f8023e1bb 100644
--- a/src/amd/vulkan/radv_device_generated_commands.c
+++ b/src/amd/vulkan/radv_device_generated_commands.c
@@ -725,9 +725,9 @@ dgc_emit_push_constant(nir_builder *b, struct dgc_cmdbuf *cs, nir_def *stream_bu
 
    nir_def *param_buf = radv_meta_load_descriptor(b, 0, DGC_DESC_PARAMS);
    nir_def *param_offset = nir_imul_imm(b, vbo_cnt, 24);
-   nir_def *param_offset_offset = nir_iadd_imm(b, param_offset, MESA_VULKAN_SHADER_STAGES * 12);
+   nir_def *param_offset_offset = nir_iadd_imm(b, param_offset, MESA_VULKAN_SHADER_STAGES * 16);
    nir_def *param_const_offset =
-      nir_iadd_imm(b, param_offset, MAX_PUSH_CONSTANTS_SIZE + MESA_VULKAN_SHADER_STAGES * 12);
+      nir_iadd_imm(b, param_offset, MAX_PUSH_CONSTANTS_SIZE + MESA_VULKAN_SHADER_STAGES * 16);
    nir_push_loop(b);
    {
       nir_def *cur_idx = nir_load_var(b, idx);
@@ -779,10 +779,10 @@ dgc_emit_push_constant(nir_builder *b, struct dgc_cmdbuf *cs, nir_def *stream_bu
       nir_pop_if(b, NULL);
 
       nir_def *reg_info =
-         nir_load_ssbo(b, 3, 32, param_buf, nir_iadd(b, param_offset, nir_imul_imm(b, cur_shader_idx, 12)));
-      nir_def *upload_sgpr = nir_ubfe_imm(b, nir_channel(b, reg_info, 0), 0, 16);
-      nir_def *inline_sgpr = nir_ubfe_imm(b, nir_channel(b, reg_info, 0), 16, 16);
+         nir_load_ssbo(b, 4, 32, param_buf, nir_iadd(b, param_offset, nir_imul_imm(b, cur_shader_idx, 16)));
+      nir_def *upload_sgpr = nir_channel(b, reg_info, 0);
       nir_def *inline_mask = nir_pack_64_2x32(b, nir_channels(b, reg_info, 0x6));
+      nir_def *inline_sgpr = nir_channel(b, reg_info, 3);
 
       nir_push_if(b, nir_ine_imm(b, upload_sgpr, 0));
       {
@@ -798,7 +798,8 @@ dgc_emit_push_constant(nir_builder *b, struct dgc_cmdbuf *cs, nir_def *stream_bu
          nir_def *inline_len = nir_bit_count(b, inline_mask);
          nir_store_var(b, idx, nir_imm_int(b, 0), 0x1);
 
-         nir_def *pkt[2] = {nir_pkt3(b, PKT3_SET_SH_REG, inline_len), inline_sgpr};
+         nir_def *pkt[2] = {nir_pkt3(b, PKT3_SET_SH_REG, inline_len),
+                            nir_ushr_imm(b, nir_isub(b, inline_sgpr, nir_imm_int(b, SI_SH_REG_OFFSET)), 2)};
 
          dgc_emit(b, cs, nir_vec(b, pkt, 2));
 
@@ -1587,7 +1588,7 @@ radv_prepare_dgc(struct radv_cmd_buffer *cmd_buffer, const VkGeneratedCommandsIn
                                     .use_preamble = radv_dgc_use_preamble(pGeneratedCommandsInfo)};
 
    upload_size = pipeline->push_constant_size + 16 * pipeline->dynamic_offset_count +
-                 sizeof(layout->push_constant_offsets) + ARRAY_SIZE(pipeline->shaders) * 12;
+                 sizeof(layout->push_constant_offsets) + ARRAY_SIZE(pipeline->shaders) * 16;
    if (!layout->push_constant_mask)
       upload_size = 0;
 
@@ -1601,7 +1602,7 @@ radv_prepare_dgc(struct radv_cmd_buffer *cmd_buffer, const VkGeneratedCommandsIn
 
    if (layout->push_constant_mask) {
       uint32_t *desc = upload_data;
-      upload_data = (char *)upload_data + ARRAY_SIZE(pipeline->shaders) * 12;
+      upload_data = (char *)upload_data + ARRAY_SIZE(pipeline->shaders) * 16;
 
       unsigned idx = 0;
       for (unsigned i = 0; i < ARRAY_SIZE(pipeline->shaders); ++i) {
@@ -1625,13 +1626,13 @@ radv_prepare_dgc(struct radv_cmd_buffer *cmd_buffer, const VkGeneratedCommandsIn
             }
 
             if (locs->shader_data[AC_UD_INLINE_PUSH_CONSTANTS].sgpr_idx >= 0) {
-               inline_sgpr = (shader->info.user_data_0 + 4 * locs->shader_data[AC_UD_INLINE_PUSH_CONSTANTS].sgpr_idx -
-                              SI_SH_REG_OFFSET) >>
-                             2;
-               desc[idx * 3 + 1] = pipeline->shaders[i]->info.inline_push_constant_mask;
-               desc[idx * 3 + 2] = pipeline->shaders[i]->info.inline_push_constant_mask >> 32;
+               inline_sgpr = shader->info.user_data_0 + 4 * locs->shader_data[AC_UD_INLINE_PUSH_CONSTANTS].sgpr_idx;
+
+               desc[idx * 4 + 1] = pipeline->shaders[i]->info.inline_push_constant_mask;
+               desc[idx * 4 + 2] = pipeline->shaders[i]->info.inline_push_constant_mask >> 32;
+               desc[idx * 4 + 3] = inline_sgpr;
             }
-            desc[idx * 3] = upload_sgpr | (inline_sgpr << 16);
+            desc[idx * 4] = upload_sgpr;
             ++idx;
          }
       }
-- 
GitLab


From 9e068049884c9587f7cd794974f74b57d37be8bd Mon Sep 17 00:00:00 2001
From: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date: Fri, 27 Oct 2023 10:15:33 +0200
Subject: [PATCH 3/5] radv: emit individual SET_SH_REG for inlined push
 constants with DGC

This should allow to preprocess if everything is inlined.

Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 .../vulkan/radv_device_generated_commands.c   | 19 +++++++++++++------
 1 file changed, 13 insertions(+), 6 deletions(-)

diff --git a/src/amd/vulkan/radv_device_generated_commands.c b/src/amd/vulkan/radv_device_generated_commands.c
index 566f8023e1bb..27aaaa3c3749 100644
--- a/src/amd/vulkan/radv_device_generated_commands.c
+++ b/src/amd/vulkan/radv_device_generated_commands.c
@@ -118,7 +118,7 @@ radv_get_sequence_size(const struct radv_indirect_command_layout *layout, struct
          }
          if (locs->shader_data[AC_UD_INLINE_PUSH_CONSTANTS].sgpr_idx >= 0)
             /* One PKT3_SET_SH_REG writing all inline push constants. */
-            *cmd_size += (2 + locs->shader_data[AC_UD_INLINE_PUSH_CONSTANTS].num_sgprs) * 4;
+            *cmd_size += (3 * locs->shader_data[AC_UD_INLINE_PUSH_CONSTANTS].num_sgprs) * 4;
       }
       if (need_copy)
          *upload_size += align(pipeline->push_constant_size + 16 * pipeline->dynamic_offset_count, 16);
@@ -798,10 +798,8 @@ dgc_emit_push_constant(nir_builder *b, struct dgc_cmdbuf *cs, nir_def *stream_bu
          nir_def *inline_len = nir_bit_count(b, inline_mask);
          nir_store_var(b, idx, nir_imm_int(b, 0), 0x1);
 
-         nir_def *pkt[2] = {nir_pkt3(b, PKT3_SET_SH_REG, inline_len),
-                            nir_ushr_imm(b, nir_isub(b, inline_sgpr, nir_imm_int(b, SI_SH_REG_OFFSET)), 2)};
-
-         dgc_emit(b, cs, nir_vec(b, pkt, 2));
+         nir_variable *pc_idx = nir_variable_create(b->shader, nir_var_shader_temp, glsl_uint_type(), "pc_idx");
+         nir_store_var(b, pc_idx, nir_imm_int(b, 0), 0x1);
 
          nir_push_loop(b);
          {
@@ -842,9 +840,18 @@ dgc_emit_push_constant(nir_builder *b, struct dgc_cmdbuf *cs, nir_def *stream_bu
             }
             nir_pop_if(b, NULL);
 
-            dgc_emit(b, cs, nir_load_var(b, data));
+            nir_def *pkt[3] = {
+               nir_imm_int(b, PKT3(PKT3_SET_SH_REG, 1, 0)),
+               nir_ushr_imm(b,
+                            nir_isub(b, nir_iadd(b, inline_sgpr, nir_imul_imm(b, nir_load_var(b, pc_idx), 4)),
+                                     nir_imm_int(b, SI_SH_REG_OFFSET)),
+                            2),
+               nir_load_var(b, data)};
+
+            dgc_emit(b, cs, nir_vec(b, pkt, 3));
 
             nir_store_var(b, idx, nir_iadd_imm(b, cur_idx, 1), 0x1);
+            nir_store_var(b, pc_idx, nir_iadd_imm(b, nir_load_var(b, pc_idx), 1), 0x1);
          }
          nir_pop_loop(b, NULL);
       }
-- 
GitLab


From cd2d475acbce12450ce2f6f9b645b1f0d2d85370 Mon Sep 17 00:00:00 2001
From: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date: Fri, 27 Oct 2023 10:39:28 +0200
Subject: [PATCH 4/5] radv: optimize emitting inlined push constants with DGC

With DGC, push constants can be set from the cmdbuf (CmdPushConstants())
or from the indirect layout. Instead of always emitting inlined push
constants from the DGC shader, just update the ones that come from the
indirect layout and rely on cmdbuf updates for the other ones.

With that, it should be possible to preprocess push constants with
graphics when all can be inlined in shaders.

Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 .../vulkan/radv_device_generated_commands.c   | 30 +++++++------------
 1 file changed, 11 insertions(+), 19 deletions(-)

diff --git a/src/amd/vulkan/radv_device_generated_commands.c b/src/amd/vulkan/radv_device_generated_commands.c
index 27aaaa3c3749..9b2f043b1771 100644
--- a/src/amd/vulkan/radv_device_generated_commands.c
+++ b/src/amd/vulkan/radv_device_generated_commands.c
@@ -118,7 +118,7 @@ radv_get_sequence_size(const struct radv_indirect_command_layout *layout, struct
          }
          if (locs->shader_data[AC_UD_INLINE_PUSH_CONSTANTS].sgpr_idx >= 0)
             /* One PKT3_SET_SH_REG writing all inline push constants. */
-            *cmd_size += (3 * locs->shader_data[AC_UD_INLINE_PUSH_CONSTANTS].num_sgprs) * 4;
+            *cmd_size += (3 * util_bitcount64(layout->push_constant_mask)) * 4;
       }
       if (need_copy)
          *upload_size += align(pipeline->push_constant_size + 16 * pipeline->dynamic_offset_count, 16);
@@ -795,7 +795,6 @@ dgc_emit_push_constant(nir_builder *b, struct dgc_cmdbuf *cs, nir_def *stream_bu
 
       nir_push_if(b, nir_ine_imm(b, inline_sgpr, 0));
       {
-         nir_def *inline_len = nir_bit_count(b, inline_mask);
          nir_store_var(b, idx, nir_imm_int(b, 0), 0x1);
 
          nir_variable *pc_idx = nir_variable_create(b->shader, nir_var_shader_temp, glsl_uint_type(), "pc_idx");
@@ -830,25 +829,18 @@ dgc_emit_push_constant(nir_builder *b, struct dgc_cmdbuf *cs, nir_def *stream_bu
                   nir_load_ssbo(b, 1, 32, param_buf, nir_iadd(b, param_offset_offset, nir_ishl_imm(b, cur_idx, 2)));
                nir_def *new_data = nir_load_ssbo(b, 1, 32, stream_buf, nir_iadd(b, stream_base, stream_offset));
                nir_store_var(b, data, new_data, 0x1);
-            }
-            nir_push_else(b, NULL);
-            {
-               nir_store_var(
-                  b, data,
-                  nir_load_ssbo(b, 1, 32, param_buf, nir_iadd(b, param_const_offset, nir_ishl_imm(b, cur_idx, 2))),
-                  0x1);
-            }
-            nir_pop_if(b, NULL);
 
-            nir_def *pkt[3] = {
-               nir_imm_int(b, PKT3(PKT3_SET_SH_REG, 1, 0)),
-               nir_ushr_imm(b,
-                            nir_isub(b, nir_iadd(b, inline_sgpr, nir_imul_imm(b, nir_load_var(b, pc_idx), 4)),
-                                     nir_imm_int(b, SI_SH_REG_OFFSET)),
-                            2),
-               nir_load_var(b, data)};
+               nir_def *pkt[3] = {
+                  nir_imm_int(b, PKT3(PKT3_SET_SH_REG, 1, 0)),
+                  nir_ushr_imm(b,
+                               nir_isub(b, nir_iadd(b, inline_sgpr, nir_imul_imm(b, nir_load_var(b, pc_idx), 4)),
+                                        nir_imm_int(b, SI_SH_REG_OFFSET)),
+                               2),
+                  nir_load_var(b, data)};
 
-            dgc_emit(b, cs, nir_vec(b, pkt, 3));
+               dgc_emit(b, cs, nir_vec(b, pkt, 3));
+            }
+            nir_pop_if(b, NULL);
 
             nir_store_var(b, idx, nir_iadd_imm(b, cur_idx, 1), 0x1);
             nir_store_var(b, pc_idx, nir_iadd_imm(b, nir_load_var(b, pc_idx), 1), 0x1);
-- 
GitLab


From 07ad5e5f1debb59923997b63f57435eddf4c964e Mon Sep 17 00:00:00 2001
From: Samuel Pitoiset <samuel.pitoiset@gmail.com>
Date: Fri, 27 Oct 2023 10:54:14 +0200
Subject: [PATCH 5/5] radv: enable DGC preprocessing when all push constants
 are inlined

It's not possible when they aren't all inlined because they need to be
copied to the upload BO and the DGC shader also copies the ones that
come from the indirect layout.

Signed-off-by: Samuel Pitoiset <samuel.pitoiset@gmail.com>
---
 src/amd/vulkan/radv_cmd_buffer.c              |  2 +-
 .../vulkan/radv_device_generated_commands.c   | 28 ++++++++++++++++---
 src/amd/vulkan/radv_private.h                 |  2 +-
 3 files changed, 26 insertions(+), 6 deletions(-)

diff --git a/src/amd/vulkan/radv_cmd_buffer.c b/src/amd/vulkan/radv_cmd_buffer.c
index bf2970243444..640cb7be967b 100644
--- a/src/amd/vulkan/radv_cmd_buffer.c
+++ b/src/amd/vulkan/radv_cmd_buffer.c
@@ -9545,7 +9545,7 @@ radv_CmdExecuteGeneratedCommandsNV(VkCommandBuffer commandBuffer, VkBool32 isPre
       cmd_buffer->state.predicating = true;
    }
 
-   if (!radv_dgc_can_preprocess(layout)) {
+   if (!radv_dgc_can_preprocess(layout, pipeline)) {
       radv_prepare_dgc(cmd_buffer, pGeneratedCommandsInfo);
 
       cmd_buffer->state.flush_bits |= RADV_CMD_FLAG_CS_PARTIAL_FLUSH | RADV_CMD_FLAG_INV_VCACHE | RADV_CMD_FLAG_INV_L2;
diff --git a/src/amd/vulkan/radv_device_generated_commands.c b/src/amd/vulkan/radv_device_generated_commands.c
index 9b2f043b1771..bcb8e506be5d 100644
--- a/src/amd/vulkan/radv_device_generated_commands.c
+++ b/src/amd/vulkan/radv_device_generated_commands.c
@@ -1392,8 +1392,25 @@ radv_use_dgc_predication(struct radv_cmd_buffer *cmd_buffer, const VkGeneratedCo
    return cmd_buffer->qf == RADV_QUEUE_GENERAL && seq_count_buffer && !cmd_buffer->state.predicating;
 }
 
+static bool
+radv_dgc_need_push_constants_copy(const struct radv_pipeline *pipeline)
+{
+   for (unsigned i = 0; i < ARRAY_SIZE(pipeline->shaders); ++i) {
+      const struct radv_shader *shader = pipeline->shaders[i];
+
+      if (!shader)
+         continue;
+
+      const struct radv_userdata_locations *locs = &shader->info.user_sgprs_locs;
+      if (locs->shader_data[AC_UD_PUSH_CONSTANTS].sgpr_idx >= 0)
+         return true;
+   }
+
+   return false;
+}
+
 bool
-radv_dgc_can_preprocess(const struct radv_indirect_command_layout *layout)
+radv_dgc_can_preprocess(const struct radv_indirect_command_layout *layout, struct radv_pipeline *pipeline)
 {
    if (!(layout->flags & VK_INDIRECT_COMMANDS_LAYOUT_USAGE_EXPLICIT_PREPROCESS_BIT_NV))
       return false;
@@ -1415,8 +1432,10 @@ radv_dgc_can_preprocess(const struct radv_indirect_command_layout *layout)
       if (layout->bind_vbo_mask)
          return false;
 
-      /* In preprocess we use the non-overridden push constants from the draw state for now. */
-      if (layout->push_constant_mask)
+      /* Do not preprocess when all push constants can't be inlined because they need to be copied
+       * to the upload BO.
+       */
+      if (layout->push_constant_mask && radv_dgc_need_push_constants_copy(pipeline))
          return false;
    }
 
@@ -1429,8 +1448,9 @@ radv_CmdPreprocessGeneratedCommandsNV(VkCommandBuffer commandBuffer,
 {
    VK_FROM_HANDLE(radv_cmd_buffer, cmd_buffer, commandBuffer);
    VK_FROM_HANDLE(radv_indirect_command_layout, layout, pGeneratedCommandsInfo->indirectCommandsLayout);
+   VK_FROM_HANDLE(radv_pipeline, pipeline, pGeneratedCommandsInfo->pipeline);
 
-   if (!radv_dgc_can_preprocess(layout))
+   if (!radv_dgc_can_preprocess(layout, pipeline))
       return;
 
    const bool use_predication = radv_use_dgc_predication(cmd_buffer, pGeneratedCommandsInfo);
diff --git a/src/amd/vulkan/radv_private.h b/src/amd/vulkan/radv_private.h
index b16ff97e22b1..e6ed8c764d68 100644
--- a/src/amd/vulkan/radv_private.h
+++ b/src/amd/vulkan/radv_private.h
@@ -3267,7 +3267,7 @@ bool radv_use_dgc_predication(struct radv_cmd_buffer *cmd_buffer,
                               const VkGeneratedCommandsInfoNV *pGeneratedCommandsInfo);
 void radv_prepare_dgc(struct radv_cmd_buffer *cmd_buffer, const VkGeneratedCommandsInfoNV *pGeneratedCommandsInfo);
 
-bool radv_dgc_can_preprocess(const struct radv_indirect_command_layout *layout);
+bool radv_dgc_can_preprocess(const struct radv_indirect_command_layout *layout, struct radv_pipeline *pipeline);
 
 static inline uint32_t
 si_conv_prim_to_gs_out(uint32_t topology, bool is_ngg)
-- 
GitLab

