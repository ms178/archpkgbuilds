--- a/src/amd/compiler/aco_insert_NOPs.cpp	2025-06-27 20:25:53.353185796 +0200
+++ b/src/amd/compiler/aco_insert_NOPs.cpp	2025-06-27 20:35:41.054060312 +0200
@@ -25,95 +25,73 @@ struct State {
 };
 
 struct NOP_ctx_gfx6 {
-   void join(const NOP_ctx_gfx6& other)
-   {
-      set_vskip_mode_then_vector =
-         MAX2(set_vskip_mode_then_vector, other.set_vskip_mode_then_vector);
-      valu_wr_vcc_then_div_fmas = MAX2(valu_wr_vcc_then_div_fmas, other.valu_wr_vcc_then_div_fmas);
-      salu_wr_m0_then_gds_msg_ttrace =
-         MAX2(salu_wr_m0_then_gds_msg_ttrace, other.salu_wr_m0_then_gds_msg_ttrace);
-      valu_wr_exec_then_dpp = MAX2(valu_wr_exec_then_dpp, other.valu_wr_exec_then_dpp);
-      salu_wr_m0_then_lds = MAX2(salu_wr_m0_then_lds, other.salu_wr_m0_then_lds);
-      salu_wr_m0_then_moverel = MAX2(salu_wr_m0_then_moverel, other.salu_wr_m0_then_moverel);
-      setreg_then_getsetreg = MAX2(setreg_then_getsetreg, other.setreg_then_getsetreg);
-      vmem_store_then_wr_data |= other.vmem_store_then_wr_data;
-      smem_clause |= other.smem_clause;
-      smem_write |= other.smem_write;
-      for (unsigned i = 0; i < BITSET_WORDS(128); i++) {
-         smem_clause_read_write[i] |= other.smem_clause_read_write[i];
-         smem_clause_write[i] |= other.smem_clause_write[i];
+   void join(const NOP_ctx_gfx6& o) {
+      set_vskip_mode_then_vector = MAX2(set_vskip_mode_then_vector, o.set_vskip_mode_then_vector);
+      valu_wr_vcc_then_div_fmas = MAX2(valu_wr_vcc_then_div_fmas, o.valu_wr_vcc_then_div_fmas);
+      salu_wr_m0_then_gds_msg_ttrace = MAX2(salu_wr_m0_then_gds_msg_ttrace, o.salu_wr_m0_then_gds_msg_ttrace);
+      valu_wr_exec_then_dpp = MAX2(valu_wr_exec_then_dpp, o.valu_wr_exec_then_dpp);
+      salu_wr_m0_then_lds = MAX2(salu_wr_m0_then_lds, o.salu_wr_m0_then_lds);
+      salu_wr_m0_then_moverel = MAX2(salu_wr_m0_then_moverel, o.salu_wr_m0_then_moverel);
+      setreg_then_getsetreg = MAX2(setreg_then_getsetreg, o.setreg_then_getsetreg);
+      vcc_wr_then_branch = MAX2(vcc_wr_then_branch, o.vcc_wr_then_branch);
+
+      vmem_store_then_wr_data |= o.vmem_store_then_wr_data;
+
+      smem_clause |= o.smem_clause;
+      smem_write |= o.smem_write;
+
+      for (unsigned i = 0; i < BITSET_WORDS(128); ++i) {
+         smem_clause_read_write[i] |= o.smem_clause_read_write[i];
+         smem_clause_write[i] |= o.smem_clause_write[i];
       }
    }
 
-   bool operator==(const NOP_ctx_gfx6& other)
-   {
-      return set_vskip_mode_then_vector == other.set_vskip_mode_then_vector &&
-             valu_wr_vcc_then_div_fmas == other.valu_wr_vcc_then_div_fmas &&
-             vmem_store_then_wr_data == other.vmem_store_then_wr_data &&
-             salu_wr_m0_then_gds_msg_ttrace == other.salu_wr_m0_then_gds_msg_ttrace &&
-             valu_wr_exec_then_dpp == other.valu_wr_exec_then_dpp &&
-             salu_wr_m0_then_lds == other.salu_wr_m0_then_lds &&
-             salu_wr_m0_then_moverel == other.salu_wr_m0_then_moverel &&
-             setreg_then_getsetreg == other.setreg_then_getsetreg &&
-             smem_clause == other.smem_clause && smem_write == other.smem_write &&
-             BITSET_EQUAL(smem_clause_read_write, other.smem_clause_read_write) &&
-             BITSET_EQUAL(smem_clause_write, other.smem_clause_write);
-   }
-
-   void add_wait_states(unsigned amount)
-   {
-      if ((set_vskip_mode_then_vector -= amount) < 0)
-         set_vskip_mode_then_vector = 0;
-
-      if ((valu_wr_vcc_then_div_fmas -= amount) < 0)
-         valu_wr_vcc_then_div_fmas = 0;
-
-      if ((salu_wr_m0_then_gds_msg_ttrace -= amount) < 0)
-         salu_wr_m0_then_gds_msg_ttrace = 0;
-
-      if ((valu_wr_exec_then_dpp -= amount) < 0)
-         valu_wr_exec_then_dpp = 0;
-
-      if ((salu_wr_m0_then_lds -= amount) < 0)
-         salu_wr_m0_then_lds = 0;
-
-      if ((salu_wr_m0_then_moverel -= amount) < 0)
-         salu_wr_m0_then_moverel = 0;
-
-      if ((setreg_then_getsetreg -= amount) < 0)
-         setreg_then_getsetreg = 0;
+   bool operator==(const NOP_ctx_gfx6& o) const {
+      return set_vskip_mode_then_vector == o.set_vskip_mode_then_vector &&
+             valu_wr_vcc_then_div_fmas == o.valu_wr_vcc_then_div_fmas &&
+             salu_wr_m0_then_gds_msg_ttrace == o.salu_wr_m0_then_gds_msg_ttrace &&
+             valu_wr_exec_then_dpp == o.valu_wr_exec_then_dpp &&
+             salu_wr_m0_then_lds == o.salu_wr_m0_then_lds &&
+             salu_wr_m0_then_moverel == o.salu_wr_m0_then_moverel &&
+             setreg_then_getsetreg == o.setreg_then_getsetreg &&
+             vcc_wr_then_branch == o.vcc_wr_then_branch &&
+             vmem_store_then_wr_data == o.vmem_store_then_wr_data &&
+             smem_clause == o.smem_clause &&
+             smem_write == o.smem_write &&
+             BITSET_EQUAL(smem_clause_read_write, o.smem_clause_read_write) &&
+             BITSET_EQUAL(smem_clause_write, o.smem_clause_write);
+   }
+
+   void add_wait_states(unsigned amount) {
+      /* saturating decrement helper – keeps signedness well-defined */
+      auto saturating_sub = [amount](int8_t& ctr) noexcept {
+         ctr = (ctr > static_cast<int8_t>(amount)) ? static_cast<int8_t>(ctr - amount) : 0;
+      };
+
+      saturating_sub(set_vskip_mode_then_vector);
+      saturating_sub(valu_wr_vcc_then_div_fmas);
+      saturating_sub(salu_wr_m0_then_gds_msg_ttrace);
+      saturating_sub(valu_wr_exec_then_dpp);
+      saturating_sub(salu_wr_m0_then_lds);
+      saturating_sub(salu_wr_m0_then_moverel);
+      saturating_sub(setreg_then_getsetreg);
+      saturating_sub(vcc_wr_then_branch);
 
       vmem_store_then_wr_data.reset();
    }
 
-   /* setting MODE.vskip and then any vector op requires 2 wait states */
-   int8_t set_vskip_mode_then_vector = 0;
-
-   /* VALU writing VCC followed by v_div_fmas require 4 wait states */
-   int8_t valu_wr_vcc_then_div_fmas = 0;
-
-   /* SALU writing M0 followed by GDS, s_sendmsg or s_ttrace_data requires 1 wait state */
-   int8_t salu_wr_m0_then_gds_msg_ttrace = 0;
-
-   /* VALU writing EXEC followed by DPP requires 5 wait states */
-   int8_t valu_wr_exec_then_dpp = 0;
-
-   /* SALU writing M0 followed by some LDS instructions requires 1 wait state on GFX10 */
-   int8_t salu_wr_m0_then_lds = 0;
+   int8_t set_vskip_mode_then_vector = 0;     /* MODE.vskip → vector op  (2) */
+   int8_t valu_wr_vcc_then_div_fmas = 0;      /* VALU→VCC  → v_div_fmas  (4) */
+   int8_t salu_wr_m0_then_gds_msg_ttrace = 0; /* M0 write  → GDS/sendmsg (1) */
+   int8_t valu_wr_exec_then_dpp = 0;          /* VALU→EXEC → DPP         (5) */
+   int8_t salu_wr_m0_then_lds = 0;            /* GFX9+ M0 write → LDS    (1) */
+   int8_t salu_wr_m0_then_moverel = 0;        /* GFX9   M0 write → moverel(1)*/
+   int8_t setreg_then_getsetreg = 0;          /* s_setreg → s_get/setreg (2) */
+   int8_t vcc_wr_then_branch = 0;             /* NEW: SALU→VCC → branch  (2) */
+   uint8_t current_vskip = 0;
 
-   /* SALU writing M0 followed by s_moverel requires 1 wait state on GFX9 */
-   int8_t salu_wr_m0_then_moverel = 0;
-
-   /* s_setreg followed by a s_getreg/s_setreg of the same register needs 2 wait states
-    * currently we don't look at the actual register */
-   int8_t setreg_then_getsetreg = 0;
-
-   /* some memory instructions writing >64bit followed by a instructions
-    * writing the VGPRs holding the writedata requires 1 wait state */
    std::bitset<256> vmem_store_then_wr_data;
 
-   /* we break up SMEM clauses that contain stores or overwrite an
-    * operand/definition of another instruction in the clause */
    bool smem_clause = false;
    bool smem_write = false;
    BITSET_DECLARE(smem_clause_read_write, 128) = {0};
@@ -208,15 +186,21 @@ template <int Max> struct RegCounterMap
 
    void update(uint16_t reg, int idx)
    {
-      int16_t val = base - idx;
-      for (entry& e : list) {
-         if (e.reg == reg) {
-            e.val = MAX2(e.val, val);
-            return;
+         int16_t val = base - idx;
+         uint32_t key = reg & 0x7F;
+
+         /* fast path: already present */
+         if (present.test(key)) {
+               for (entry& e : list) {
+                     if (e.reg == reg) {
+                           e.val = MAX2(e.val, val);
+                           return;
+                     }
+               }
          }
-      }
-      list.push_back(entry{reg, val});
-      present.set(reg & 0x7F);
+         /* slow path: insert */
+         list.push_back(entry{reg, val});
+         present.set(key);
    }
 
    bool operator==(const RegCounterMap& other) const
@@ -322,9 +306,25 @@ get_wait_states(aco_ptr<Instruction>& in
 }
 
 bool
-regs_intersect(PhysReg a_reg, unsigned a_size, PhysReg b_reg, unsigned b_size)
+regs_intersect(PhysReg a_reg, unsigned a_size,
+               PhysReg b_reg, unsigned b_size)
 {
-   return a_reg > b_reg ? (a_reg - b_reg < b_size) : (b_reg - a_reg < a_size);
+      if (a_reg > b_reg) [[likely]]
+            return a_reg - b_reg < b_size;
+      else
+            return b_reg - a_reg < a_size;
+}
+
+static inline bool
+is_vcc_branch(const aco_ptr<Instruction>& instr)
+{
+      switch (instr->opcode) {
+            case aco_opcode::s_cbranch_vccz:
+            case aco_opcode::s_cbranch_vccnz:
+                  return true;
+            default:
+                  return false;
+      }
 }
 
 template <typename GlobalState, typename BlockState,
@@ -383,35 +383,49 @@ struct HandleRawHazardBlockState {
 };
 
 template <bool Valu, bool Vintrp, bool Salu>
-bool
+static bool
 handle_raw_hazard_instr(HandleRawHazardGlobalState& global_state,
-                        HandleRawHazardBlockState& block_state, aco_ptr<Instruction>& pred)
+                        HandleRawHazardBlockState&  block_state,
+                        aco_ptr<Instruction>&       pred)
 {
-   unsigned mask_size = util_last_bit(block_state.mask);
+   const unsigned mask_size = util_last_bit(block_state.mask);
 
-   uint32_t writemask = 0;
-   for (Definition& def : pred->definitions) {
-      if (regs_intersect(global_state.reg, mask_size, def.physReg(), def.size())) {
-         unsigned start = def.physReg() > global_state.reg ? def.physReg() - global_state.reg : 0;
-         unsigned end = MIN2(mask_size, start + def.size());
-         writemask |= u_bit_consecutive(start, end - start);
+   uint32_t writemask = 0u;
+   for (const Definition& def : pred->definitions) {
+      if (regs_intersect(global_state.reg, mask_size,
+                         def.physReg(), def.size()))
+      {
+         const unsigned start = (def.physReg() > global_state.reg) ?
+                                (def.physReg() - global_state.reg) : 0u;
+         const unsigned end   = std::min(mask_size, start + def.size());
+         writemask           |= u_bit_consecutive(start, end - start);
       }
    }
 
-   bool is_hazard = writemask != 0 && ((pred->isVALU() && Valu) || (pred->isVINTRP() && Vintrp) ||
-                                       (pred->isSALU() && Salu));
-   if (is_hazard) {
-      global_state.nops_needed = MAX2(global_state.nops_needed, block_state.nops_needed);
-      return true;
-   }
+   const bool relevant_pred =
+      ((pred->isVALU()   && Valu)   ||
+       (pred->isVINTRP() && Vintrp) ||
+       (pred->isSALU()   && Salu));
+
+   /* RAW hazard found – record and stop. */
+   if (writemask && relevant_pred) {
+      global_state.nops_needed =
+         std::max(global_state.nops_needed, block_state.nops_needed);
+      return true;                               /* EARLY-EXIT on conflict  */
+   }
+
+   /* age the counters for wait-states already consumed by this pred */
+   block_state.mask         &= ~writemask;
+   block_state.nops_needed   = std::max(
+                                 block_state.nops_needed -
+                                 static_cast<int>(get_wait_states(pred)), 0);
 
-   block_state.mask &= ~writemask;
-   block_state.nops_needed = MAX2(block_state.nops_needed - get_wait_states(pred), 0);
-
-   if (block_state.mask == 0)
-      block_state.nops_needed = 0;
+   /* If nothing left to cover OR we already satisfied wait distance – done */
+   if (block_state.mask == 0u || block_state.nops_needed == 0)
+      return true;
 
-   return block_state.nops_needed == 0;
+   /* continue walking */
+   return false;
 }
 
 template <bool Valu, bool Vintrp, bool Salu>
@@ -476,53 +490,104 @@ test_bitset_range(BITSET_WORD* words, un
  *
  * SMEM clauses are only present on GFX8+, and only matter when XNACK is set.
  */
-void
-handle_smem_clause_hazards(Program* program, NOP_ctx_gfx6& ctx, aco_ptr<Instruction>& instr,
-                           int* NOPs)
+static void
+handle_smem_clause_hazards(Program*                program,
+                           NOP_ctx_gfx6&           ctx,
+                           aco_ptr<Instruction>&   instr,
+                           int*                    NOPs)
 {
-   /* break off from previous SMEM clause if needed */
-   if (!*NOPs & (ctx.smem_clause || ctx.smem_write)) {
-      /* Don't allow clauses with store instructions since the clause's
-       * instructions may use the same address. */
-      if (ctx.smem_write || instr->definitions.empty() ||
-          instr_info.is_atomic[(unsigned)instr->opcode]) {
-         *NOPs = 1;
-      } else if (program->dev.xnack_enabled) {
-         for (Operand op : instr->operands) {
-            if (!op.isConstant() &&
-                test_bitset_range(ctx.smem_clause_write, op.physReg(), op.size())) {
-               *NOPs = 1;
-               break;
+      if (!program->dev.xnack_enabled) return;
+      assert(NOPs && "caller must pass valid pointer");
+
+      /* Break an outstanding clause only if we *both* currently do not emit
+       * another NOP already *and* we are still inside a clause.               */
+      if (!*NOPs && (ctx.smem_clause || ctx.smem_write)) {         /* fixed “&&”→“&&” */
+            /* Clause must not contain stores or atomics. */
+            if (ctx.smem_write || instr->definitions.empty() ||
+                  instr_info.is_atomic[static_cast<unsigned>(instr->opcode)])
+            {
+                  *NOPs = 1;
             }
-         }
+            /* With XNACK the clause may replay out of order – ensure no RAW. */
+            else if (program->dev.xnack_enabled) {
+                  for (const Operand& op : instr->operands) {
+                        if (!op.isConstant() &&
+                              test_bitset_range(ctx.smem_clause_write, op.physReg(), op.size()))
+                        {
+                              *NOPs = 1;
+                              break;
+                        }
+                  }
+
+                  if (!*NOPs) {
+                        const Definition& def = instr->definitions[0];
+                        if (test_bitset_range(ctx.smem_clause_read_write,
+                              def.physReg(), def.size()))
+                              *NOPs = 1;
+                  }
+            }
+      }
+}
 
-         Definition def = instr->definitions[0];
-         if (!*NOPs && test_bitset_range(ctx.smem_clause_read_write, def.physReg(), def.size()))
-            *NOPs = 1;
+static bool has_intervening_valu(State& state, Block* start_block) {
+      std::stack<Block*> blocks_to_check;
+      std::set<unsigned> visited;
+      blocks_to_check.push(start_block);
+
+      while (!blocks_to_check.empty()) {
+            Block* block = blocks_to_check.top();
+            blocks_to_check.pop();
+
+            if (visited.count(block->index)) continue;
+            visited.insert(block->index);
+
+            // Search backwards for VALU instructions
+            for (auto it = block->instructions.rbegin(); it != block->instructions.rend(); ++it) {
+                  if ((*it)->isVALU()) return true;
+                  if (is_vcc_branch(*it)) break; // Stop at previous branch
+            }
+
+            // Add linear predecessors (to handle loop/control flow)
+            for (unsigned pred : block->linear_preds) {
+                  blocks_to_check.push(&state.program->blocks[pred]);
+            }
       }
-   }
+      return false;
 }
 
-/* TODO: we don't handle accessing VCC using the actual SGPR instead of using the alias */
-void
-handle_instruction_gfx6(State& state, NOP_ctx_gfx6& ctx, aco_ptr<Instruction>& instr,
+static void
+handle_instruction_gfx6(State&                             state,
+                        NOP_ctx_gfx6&                      ctx,
+                        aco_ptr<Instruction>&              instr,
                         std::vector<aco_ptr<Instruction>>& new_instructions)
 {
-   /* check hazards */
+   /* --------------------------------------------------------------------
+    *  1.  Determine required wait-states *before* @instr
+    * ------------------------------------------------------------------ */
    int NOPs = 0;
 
+   /* SALU→VCC→branch hazard (Vega = 1 wait-state) */
+   if (is_vcc_branch(instr)) {
+         if (state.program->gfx_level == GFX9) {
+               // Skip NOP if there's a VALU between SALU→VCC and branch
+               if (!has_intervening_valu(state, state.block)) {
+                     NOPs = std::max(NOPs, static_cast<int>(ctx.vcc_wr_then_branch));
+               }
+         } else {
+               NOPs = std::max(NOPs, static_cast<int>(ctx.vcc_wr_then_branch));
+         }
+   }
+
+   /* -------------------------  SMEM hazards  --------------------------- */
    if (instr->isSMEM()) {
       if (state.program->gfx_level == GFX6) {
-         /* A read of an SGPR by SMRD instruction requires 4 wait states
-          * when the SGPR was written by a VALU instruction. According to LLVM,
-          * there is also an undocumented hardware behavior when the buffer
-          * descriptor is written by a SALU instruction */
-         for (unsigned i = 0; i < instr->operands.size(); i++) {
-            Operand op = instr->operands[i];
+         /* VALU/SALU → SMRD RAW hazards (4 wait-states). */
+         for (unsigned i = 0; i < instr->operands.size(); ++i) {
+            const Operand& op = instr->operands[i];
             if (op.isConstant())
                continue;
 
-            bool is_buffer_desc = i == 0 && op.size() > 2;
+            const bool is_buffer_desc = (i == 0) && op.size() > 2;
             if (is_buffer_desc)
                handle_valu_salu_then_read_hazard(state, &NOPs, 4, op);
             else
@@ -530,98 +595,161 @@ handle_instruction_gfx6(State& state, NO
          }
       }
 
+      /* SMEM-clause hazards (replay/XNACK etc.). */
       handle_smem_clause_hazards(state.program, ctx, instr, &NOPs);
-   } else if (instr->isSALU()) {
-      if (instr->opcode == aco_opcode::s_setreg_b32 ||
-          instr->opcode == aco_opcode::s_setreg_imm32_b32 ||
-          instr->opcode == aco_opcode::s_getreg_b32) {
-         NOPs = MAX2(NOPs, ctx.setreg_then_getsetreg);
+   }
+
+   /* -------------------------  SALU hazards  --------------------------- */
+   else if (instr->isSALU()) {
+      if (instr->opcode == aco_opcode::s_setreg_b32         ||
+          instr->opcode == aco_opcode::s_setreg_imm32_b32   ||
+          instr->opcode == aco_opcode::s_getreg_b32)
+      {
+         NOPs = std::max(NOPs, static_cast<int>(ctx.setreg_then_getsetreg));
       }
 
-      if (state.program->gfx_level == GFX9) {
-         if (instr->opcode == aco_opcode::s_movrels_b32 ||
-             instr->opcode == aco_opcode::s_movrels_b64 ||
-             instr->opcode == aco_opcode::s_movreld_b32 ||
-             instr->opcode == aco_opcode::s_movreld_b64) {
-            NOPs = MAX2(NOPs, ctx.salu_wr_m0_then_moverel);
-         }
+      if (state.program->gfx_level == GFX9 &&
+          (instr->opcode == aco_opcode::s_movrels_b32 ||
+           instr->opcode == aco_opcode::s_movrels_b64 ||
+           instr->opcode == aco_opcode::s_movreld_b32 ||
+           instr->opcode == aco_opcode::s_movreld_b64))
+      {
+         NOPs = std::max(NOPs, static_cast<int>(ctx.salu_wr_m0_then_moverel));
+      }
+
+      if (instr->opcode == aco_opcode::s_sendmsg ||
+          instr->opcode == aco_opcode::s_ttracedata)
+      {
+         NOPs = std::max(NOPs,
+                         static_cast<int>(ctx.salu_wr_m0_then_gds_msg_ttrace));
       }
+   }
+
+   /* -------------------------  DS / GDS hazards  ----------------------- */
+   else if (instr->isDS() && instr->ds().gds) {
+      NOPs = std::max(NOPs,
+                      static_cast<int>(ctx.salu_wr_m0_then_gds_msg_ttrace));
+   }
 
-      if (instr->opcode == aco_opcode::s_sendmsg || instr->opcode == aco_opcode::s_ttracedata)
-         NOPs = MAX2(NOPs, ctx.salu_wr_m0_then_gds_msg_ttrace);
-   } else if (instr->isDS() && instr->ds().gds) {
-      NOPs = MAX2(NOPs, ctx.salu_wr_m0_then_gds_msg_ttrace);
-   } else if (instr->isVALU() || instr->isVINTRP()) {
+   /* -------------------------  VALU / VINTRP  -------------------------- */
+   else if (instr->isVALU() || instr->isVINTRP()) {
       if (instr->isDPP()) {
-         NOPs = MAX2(NOPs, ctx.valu_wr_exec_then_dpp);
+         NOPs = std::max(NOPs,
+                         static_cast<int>(ctx.valu_wr_exec_then_dpp));
          handle_valu_then_read_hazard(state, &NOPs, 2, instr->operands[0]);
       }
 
-      for (Definition def : instr->definitions) {
-         if (def.regClass().type() != RegType::sgpr) {
-            for (unsigned i = 0; i < def.size(); i++)
-               NOPs = MAX2(NOPs, ctx.vmem_store_then_wr_data[(def.physReg() & 0xff) + i]);
-         }
+      /* VMEM-store followed by WRDATA hazard. */
+      for (const Definition& def : instr->definitions) {
+            if (def.regClass().type() == RegType::sgpr)
+                  continue;
+
+            const unsigned base = def.physReg() & 0xff;
+            int max_wait = 0;
+            for (unsigned i = 0; i < def.size(); ++i) {
+                  max_wait = std::max(max_wait, static_cast<int>(ctx.vmem_store_then_wr_data[base + i]));
+            }
+            if (max_wait > 0) {
+                  // Use s_waitcnt for GFX9 if wait ≥3 (more efficient than NOPs)
+                  if (state.program->gfx_level == GFX9 && max_wait >= 3) {
+                        Builder bld(state.program, &new_instructions);
+                        wait_imm imm;
+                        imm.lgkm = 0; // Wait for LGKM (LDS/GFX/MEM) operations to complete
+                        bld.sopp(aco_opcode::s_waitcnt, imm.pack(state.program->gfx_level));
+                        ctx.vmem_store_then_wr_data.reset(); // Clear hazard after wait
+                  } else {
+                        NOPs = std::max(NOPs, max_wait);
+                  }
+            }
       }
 
-      if ((instr->opcode == aco_opcode::v_readlane_b32 ||
-           instr->opcode == aco_opcode::v_readlane_b32_e64 ||
-           instr->opcode == aco_opcode::v_writelane_b32 ||
+      /* readlane / writelane hazards (SGPR index is operand[1]). */
+      if ((instr->opcode == aco_opcode::v_readlane_b32      ||
+           instr->opcode == aco_opcode::v_readlane_b32_e64  ||
+           instr->opcode == aco_opcode::v_writelane_b32     ||
            instr->opcode == aco_opcode::v_writelane_b32_e64) &&
-          !instr->operands[1].isConstant()) {
+          !instr->operands[1].isConstant())
+      {
          handle_valu_then_read_hazard(state, &NOPs, 4, instr->operands[1]);
       }
 
-      /* It's required to insert 1 wait state if the dst VGPR of any v_interp_*
-       * is followed by a read with v_readfirstlane or v_readlane to fix GPU
-       * hangs on GFX6. Note that v_writelane_* is apparently not affected.
-       * This hazard isn't documented anywhere but AMD confirmed that hazard.
-       */
+      /* undocumented GFX6 VINTRP → readlane hazard. */
       if (state.program->gfx_level == GFX6 &&
-          (instr->opcode == aco_opcode::v_readlane_b32 || /* GFX6 doesn't have v_readlane_b32_e64 */
-           instr->opcode == aco_opcode::v_readfirstlane_b32)) {
+          (instr->opcode == aco_opcode::v_readlane_b32 ||
+           instr->opcode == aco_opcode::v_readfirstlane_b32))
+      {
          handle_vintrp_then_read_hazard(state, &NOPs, 1, instr->operands[0]);
       }
 
+      /* VALU writes VCC → v_div_fmas reads VCC later. */
       if (instr->opcode == aco_opcode::v_div_fmas_f32 ||
-          instr->opcode == aco_opcode::v_div_fmas_f64)
-         NOPs = MAX2(NOPs, ctx.valu_wr_vcc_then_div_fmas);
-   } else if (instr->isVMEM() || instr->isFlatLike()) {
-      /* If the VALU writes the SGPR that is used by a VMEM, the user must add five wait states. */
-      for (Operand op : instr->operands) {
-         if (!op.isConstant() && !op.isUndefined() && op.regClass().type() == RegType::sgpr)
+            instr->opcode == aco_opcode::v_div_fmas_f64)
+      {
+            ctx.valu_wr_vcc_then_div_fmas = (state.program->gfx_level == GFX9) ? 3 : 4;
+      }
+   }
+
+   /* -------------------------  VMEM / FLAT hazards  -------------------- */
+   else if (instr->isVMEM() || instr->isFlatLike()) {
+      for (const Operand& op : instr->operands) {
+         if (!op.isConstant() && !op.isUndefined() &&
+             op.regClass().type() == RegType::sgpr)
+         {
             handle_valu_then_read_hazard(state, &NOPs, 5, op);
+         }
       }
    }
 
+   /* v_skip wait-state hazard (non-SALU / non-SMEM). */
    if (!instr->isSALU() && instr->format != Format::SMEM)
-      NOPs = MAX2(NOPs, ctx.set_vskip_mode_then_vector);
+      NOPs = std::max(NOPs,
+                      static_cast<int>(ctx.set_vskip_mode_then_vector));
 
+   /* Extra GFX9 LDS hazards. */
    if (state.program->gfx_level == GFX9) {
-      bool lds_scratch_global = (instr->isScratch() || instr->isGlobal()) && instr->flatlike().lds;
+      const bool lds_scratch_global =
+         (instr->isScratch() || instr->isGlobal()) && instr->flatlike().lds;
+
       if (instr->isVINTRP() || lds_scratch_global ||
-          instr->opcode == aco_opcode::ds_read_addtid_b32 ||
+          instr->opcode == aco_opcode::ds_read_addtid_b32  ||
           instr->opcode == aco_opcode::ds_write_addtid_b32 ||
-          instr->opcode == aco_opcode::buffer_store_lds_dword) {
-         NOPs = MAX2(NOPs, ctx.salu_wr_m0_then_lds);
+          instr->opcode == aco_opcode::buffer_store_lds_dword)
+      {
+         NOPs = std::max(NOPs,
+                         static_cast<int>(ctx.salu_wr_m0_then_lds));
       }
    }
 
-   ctx.add_wait_states(NOPs + get_wait_states(instr));
+   /* --------------------------------------------------------------------
+    *  2.  Emit NOPs / waitcnt and age live counters
+    * ------------------------------------------------------------------ */
+   ctx.add_wait_states(static_cast<unsigned>(NOPs) + get_wait_states(instr));
 
-   // TODO: try to schedule the NOP-causing instruction up to reduce the number of stall cycles
    if (NOPs) {
-      /* create NOP */
-      aco_ptr<Instruction> nop{create_instruction(aco_opcode::s_nop, Format::SOPP, 0, 0)};
-      nop->salu().imm = NOPs - 1;
-      new_instructions.emplace_back(std::move(nop));
+         Builder bld(state.program, &new_instructions);
+         const bool long_wait  = NOPs >= 3;
+         const bool mem_hazard = ctx.vmem_store_then_wr_data.any() ||
+         ctx.smem_clause || ctx.smem_write;
+
+         if (long_wait && mem_hazard) {
+               wait_imm imm;
+               imm.vm   = 0;
+               imm.lgkm = 0;
+               bld.sopp(aco_opcode::s_waitcnt, imm.pack(state.program->gfx_level));
+         } else {
+               bld.sopp(aco_opcode::s_nop, static_cast<uint16_t>(NOPs - 1));
+         }
    }
 
-   /* update information to check for later hazards */
-   if ((ctx.smem_clause || ctx.smem_write) && (NOPs || instr->format != Format::SMEM)) {
-      ctx.smem_clause = false;
-      ctx.smem_write = false;
-
+   /* --------------------------------------------------------------------
+    *  3.  Update context (hazards *caused* by @instr)
+    * ------------------------------------------------------------------ */
+
+   /* ---------- SMEM clause tracking ----------------------------------- */
+   if ((ctx.smem_clause || ctx.smem_write) &&
+       (NOPs || instr->format != Format::SMEM))
+   {
+      ctx.smem_clause = ctx.smem_write = false;
       if (state.program->dev.xnack_enabled) {
          BITSET_ZERO(ctx.smem_clause_read_write);
          BITSET_ZERO(ctx.smem_clause_write);
@@ -629,242 +757,307 @@ handle_instruction_gfx6(State& state, NO
    }
 
    if (instr->isSMEM()) {
-      if (instr->definitions.empty() || instr_info.is_atomic[(unsigned)instr->opcode]) {
+      if (instr->definitions.empty() ||
+          instr_info.is_atomic[static_cast<unsigned>(instr->opcode)])
+      {
          ctx.smem_write = true;
       } else {
          ctx.smem_clause = true;
 
          if (state.program->dev.xnack_enabled) {
-            for (Operand op : instr->operands) {
-               if (!op.isConstant()) {
-                  set_bitset_range(ctx.smem_clause_read_write, op.physReg(), op.size());
-               }
-            }
-
-            Definition def = instr->definitions[0];
-            set_bitset_range(ctx.smem_clause_read_write, def.physReg(), def.size());
-            set_bitset_range(ctx.smem_clause_write, def.physReg(), def.size());
+            for (const Operand& op : instr->operands)
+               if (!op.isConstant())
+                  set_bitset_range(ctx.smem_clause_read_write,
+                                   op.physReg(), op.size());
+
+            const Definition& def = instr->definitions[0];
+            set_bitset_range(ctx.smem_clause_read_write,
+                             def.physReg(), def.size());
+            set_bitset_range(ctx.smem_clause_write,
+                             def.physReg(), def.size());
          }
       }
-   } else if (instr->isVALU()) {
-      for (Definition def : instr->definitions) {
-         if (def.regClass().type() == RegType::sgpr) {
-            if (def.physReg() == vcc || def.physReg() == vcc_hi) {
-               ctx.valu_wr_vcc_then_div_fmas = 4;
-            }
-            if (def.physReg() == exec || def.physReg() == exec_hi) {
-               ctx.valu_wr_exec_then_dpp = 5;
+   }
+
+   /* ---------- VALU post-processing ------------------------------------ */
+   else if (instr->isVALU()) {
+      for (const Definition& def : instr->definitions) {
+         if (def.regClass().type() != RegType::sgpr)
+            continue;
+
+         if (def.physReg() == vcc || def.physReg() == vcc_hi) {
+            ctx.valu_wr_vcc_then_div_fmas = (state.program->gfx_level == GFX9) ? 3 : 4;
             }
-         }
+         if (def.physReg() == exec || def.physReg() == exec_hi)
+            ctx.valu_wr_exec_then_dpp     = 5;
       }
-   } else if (instr->isSALU()) {
+   }
+
+   /* ---------- SALU post-processing ------------------------------------ */
+   else if (instr->isSALU()) {
       if (!instr->definitions.empty()) {
-         /* all other definitions should be SCC */
-         Definition def = instr->definitions[0];
+         const Definition& def = instr->definitions[0];
          if (def.physReg() == m0) {
             ctx.salu_wr_m0_then_gds_msg_ttrace = 1;
-            ctx.salu_wr_m0_then_lds = 1;
-            ctx.salu_wr_m0_then_moverel = 1;
+            ctx.salu_wr_m0_then_lds            = 1;
+            ctx.salu_wr_m0_then_moverel        = 1;
          }
-      } else if (instr->opcode == aco_opcode::s_setreg_b32 ||
-                 instr->opcode == aco_opcode::s_setreg_imm32_b32) {
+      }
+
+      if (instr->opcode == aco_opcode::s_setreg_b32 ||
+          instr->opcode == aco_opcode::s_setreg_imm32_b32)
+      {
          SALU_instruction& sopk = instr->salu();
-         unsigned offset = (sopk.imm >> 6) & 0x1f;
-         unsigned size = ((sopk.imm >> 11) & 0x1f) + 1;
-         unsigned reg = sopk.imm & 0x3f;
+         const unsigned offset = (sopk.imm >> 6) & 0x1f;
+         const unsigned size   = ((sopk.imm >> 11) & 0x1f) + 1;
+         const unsigned reg    =  sopk.imm & 0x3f;
+
          ctx.setreg_then_getsetreg = 2;
 
-         if (reg == 1 && offset >= 28 && size > (28 - offset))
-            ctx.set_vskip_mode_then_vector = 2;
+         /* MODE register (SGPR1), bit 28 is v_skip. */
+         if (reg == 1u && offset <= 28u && (28u - offset) < size) {
+            bool bit_known = false;
+            uint32_t src_val = 0u;
+
+            if (instr->opcode == aco_opcode::s_setreg_imm32_b32) {
+               src_val  = sopk.imm;
+               bit_known = true;
+            } else if (sopk.operands[0].isConstant()) {
+               src_val  = sopk.operands[0].constantValue();
+               bit_known = true;
+            }
+
+            if (bit_known) {
+               const uint8_t new_bit =
+                  static_cast<uint8_t>((src_val >> (28u - offset)) & 1u);
+               if (new_bit != ctx.current_vskip) {
+                  ctx.set_vskip_mode_then_vector = 2;
+                  ctx.current_vskip = new_bit;
+               }
+            } else {
+               /* Unknown value – conservatively assume it toggles. */
+               ctx.set_vskip_mode_then_vector = 2;
+               ctx.current_vskip ^= 1u;
+            }
+         }
       }
-   } else if (instr->isVMEM() || instr->isFlatLike()) {
-      /* >64-bit MUBUF/MTBUF store with a constant in SOFFSET */
-      bool consider_buf = (instr->isMUBUF() || instr->isMTBUF()) && instr->operands.size() == 4 &&
-                          instr->operands[3].size() > 2 && instr->operands[2].physReg() >= 128;
-      /* MIMG store with a 128-bit T# with more than two bits set in dmask (making it a >64-bit
-       * store) */
-      bool consider_mimg = instr->isMIMG() &&
-                           instr->operands[1].regClass().type() == RegType::vgpr &&
-                           instr->operands[1].size() > 2 && instr->operands[0].size() == 4;
-      /* FLAT/GLOBAL/SCRATCH store with >64-bit data */
-      bool consider_flat =
-         instr->isFlatLike() && instr->operands.size() == 3 && instr->operands[2].size() > 2;
+   }
+
+   /* ---------- VMEM store → WRDATA tracker ---------------------------- */
+   else if (instr->isVMEM() || instr->isFlatLike()) {
+      const bool consider_buf  = (instr->isMUBUF() || instr->isMTBUF()) &&
+                                 instr->operands.size() == 4 &&
+                                 instr->operands[3].size() > 2 &&
+                                 instr->operands[2].physReg() >= 128;
+      const bool consider_mimg = instr->isMIMG() &&
+                                 instr->operands[1].regClass().type() == RegType::vgpr &&
+                                 instr->operands[1].size() > 2 &&
+                                 instr->operands[0].size() == 4;
+      const bool consider_flat = instr->isFlatLike() &&
+                                 instr->operands.size() == 3 &&
+                                 instr->operands[2].size() > 2;
+
       if (consider_buf || consider_mimg || consider_flat) {
-         PhysReg wrdata = instr->operands[consider_flat ? 2 : 3].physReg();
-         unsigned size = instr->operands[consider_flat ? 2 : 3].size();
-         for (unsigned i = 0; i < size; i++)
-            ctx.vmem_store_then_wr_data[(wrdata & 0xff) + i] = 1;
+         const unsigned op_idx = consider_flat ? 2 : 3;
+         const PhysReg wrdata  = instr->operands[op_idx].physReg();
+         const unsigned size   = instr->operands[op_idx].size();
+
+         for (unsigned i = 0; i < size; ++i)
+            ctx.vmem_store_then_wr_data[(wrdata & 0xff) + i] = 1u;
+      }
+   }
+
+   /* ---------- Track SALU writes to VCC for next branch --------------- */
+   if (instr->isSALU()) {
+      for (const Definition& def : instr->definitions) {
+         if (def.physReg() == vcc || def.physReg() == vcc_hi) {
+            ctx.vcc_wr_then_branch = 1;  /* Vega: exactly 1 wait-state. */
+            break;
+         }
       }
    }
 }
 
 bool
-is_latest_instr_vintrp(bool& global_state, bool& block_state, aco_ptr<Instruction>& pred)
-{
-   if (pred->isVINTRP())
-      global_state = true;
-   return true;
+is_latest_instr_vintrp(bool& global_state, bool& block_state, aco_ptr<Instruction>& pred) {
+      if (pred->isVINTRP())
+            global_state = true;
+      return true;
 }
 
 template <bool Salu, bool Sgpr>
 bool
-handle_wr_hazard_instr(int& global_state, int& block_state, aco_ptr<Instruction>& pred)
-{
-   if (Salu ? pred->isSALU() : (pred->isVALU() || pred->isVINTRP())) {
-      for (Definition dst : pred->definitions) {
-         if ((dst.physReg().reg() < 256) == Sgpr) {
-            global_state = MAX2(global_state, block_state);
-            return true;
-         }
+handle_wr_hazard_instr(int& global_state, int& block_state, aco_ptr<Instruction>& pred) {
+      if (Salu ? pred->isSALU() : (pred->isVALU() || pred->isVINTRP())) {
+            for (Definition dst : pred->definitions) {
+                  if ((dst.physReg().reg() < 256) == Sgpr) {
+                        global_state = MAX2(global_state, block_state);
+                        return true;
+                  }
+            }
       }
-   }
 
-   block_state -= get_wait_states(pred);
-   return block_state <= 0;
+      block_state -= get_wait_states(pred);
+      return block_state <= 0;
 }
 
 template <bool Salu, bool Sgpr>
 void
-handle_wr_hazard(State& state, int* NOPs, int min_states)
-{
-   if (*NOPs >= min_states)
-      return;
+handle_wr_hazard(State& state, int* NOPs, int min_states) {
+      if (*NOPs >= min_states)
+            return;
 
-   int global = 0;
-   int block = min_states;
-   search_backwards<int, int, nullptr, handle_wr_hazard_instr<Salu, Sgpr>>(state, global, block);
-   *NOPs = MAX2(*NOPs, global);
+      int global = 0;
+      int block = min_states;
+      search_backwards<int, int, nullptr, handle_wr_hazard_instr<Salu, Sgpr>>(state, global, block);
+      *NOPs = MAX2(*NOPs, global);
 }
 
-void
+/* ---------------------------------------------------------------------------
+ *  Final “resolve all pending hazards” for the current basic block (GFX6-9)
+ * ------------------------------------------------------------------------- */
+static void
 resolve_all_gfx6(State& state, NOP_ctx_gfx6& ctx,
-                 std::vector<aco_ptr<Instruction>>& new_instructions)
-{
+                 std::vector<aco_ptr<Instruction>>& new_instructions) {
    int NOPs = 0;
 
-   /* SGPR->SMEM hazards */
+   /* SGPR→SMEM hazards (only on pre-GFX8) */
    if (state.program->gfx_level == GFX6) {
       handle_wr_hazard<true, true>(state, &NOPs, 4);
       handle_wr_hazard<false, true>(state, &NOPs, 4);
    }
 
-   /* Break up SMEM clauses */
+   /* Break SMEM clauses if one is still open. */
    if (ctx.smem_clause || ctx.smem_write)
-      NOPs = MAX2(NOPs, 1);
+      NOPs = std::max(NOPs, 1);
 
-   /* SALU/GDS hazards */
-   NOPs = MAX2(NOPs, ctx.setreg_then_getsetreg);
+   /* SALU / LDS hazards still active? */
+   NOPs = std::max(NOPs, static_cast<int>(ctx.setreg_then_getsetreg));
    if (state.program->gfx_level == GFX9)
-      NOPs = MAX2(NOPs, ctx.salu_wr_m0_then_moverel);
-   NOPs = MAX2(NOPs, ctx.salu_wr_m0_then_gds_msg_ttrace);
+      NOPs = std::max(NOPs, static_cast<int>(ctx.salu_wr_m0_then_moverel));
+   NOPs = std::max(NOPs, static_cast<int>(ctx.salu_wr_m0_then_gds_msg_ttrace));
 
    /* VALU hazards */
-   NOPs = MAX2(NOPs, ctx.valu_wr_exec_then_dpp);
+   NOPs = std::max(NOPs, static_cast<int>(ctx.valu_wr_exec_then_dpp));
    if (state.program->gfx_level >= GFX8)
-      handle_wr_hazard<false, false>(state, &NOPs, 2); /* VALU->DPP */
-   NOPs = MAX2(NOPs, ctx.vmem_store_then_wr_data.any() ? 1 : 0);
+      handle_wr_hazard<false, false>(state, &NOPs, 2); /* VALU→DPP */
+   if (ctx.vmem_store_then_wr_data.any())
+      NOPs = std::max(NOPs, 1);
    if (state.program->gfx_level == GFX6) {
-      /* VINTRP->v_readlane_b32/etc */
       bool vintrp = false;
-      search_backwards<bool, bool, nullptr, is_latest_instr_vintrp>(state, vintrp, vintrp);
+      search_backwards<bool, bool, nullptr, is_latest_instr_vintrp>(
+         state, vintrp, vintrp);
       if (vintrp)
-         NOPs = MAX2(NOPs, 1);
+         NOPs = std::max(NOPs, 1);
    }
-   NOPs = MAX2(NOPs, ctx.valu_wr_vcc_then_div_fmas);
+   NOPs = std::max(NOPs, static_cast<int>(ctx.valu_wr_vcc_then_div_fmas));
 
-   /* VALU(sgpr)->VMEM/v_readlane_b32/etc hazards. v_readlane_b32/etc require only 4 NOPs. */
+   /* VALU(sgpr)→VMEM / readlane hazards. */
    handle_wr_hazard<false, true>(state, &NOPs, 5);
 
-   NOPs = MAX2(NOPs, ctx.set_vskip_mode_then_vector);
+   /* MODE.vskip hazard still pending? */
+   NOPs = std::max(NOPs, static_cast<int>(ctx.set_vskip_mode_then_vector));
 
    if (state.program->gfx_level == GFX9)
-      NOPs = MAX2(NOPs, ctx.salu_wr_m0_then_lds);
+      NOPs = std::max(NOPs, static_cast<int>(ctx.salu_wr_m0_then_lds));
+
+   /* --------------------------------------------------------------------
+    *  Emit final waits and age counters
+    * ------------------------------------------------------------------ */
+   ctx.add_wait_states(static_cast<unsigned>(NOPs));
 
-   ctx.add_wait_states(NOPs);
    if (NOPs) {
       Builder bld(state.program, &new_instructions);
-      bld.sopp(aco_opcode::s_nop, NOPs - 1);
+
+      const bool long_wait  = NOPs >= 3;
+      const bool mem_hazard = ctx.vmem_store_then_wr_data.any() ||
+                              ctx.smem_clause || ctx.smem_write;
+
+      if (long_wait && mem_hazard) {
+         wait_imm imm;
+         imm.vm   = 0;
+         imm.lgkm = 0;
+         bld.sopp(aco_opcode::s_waitcnt,
+                  imm.pack(state.program->gfx_level)); /* <<< FIXED */
+      } else {
+         bld.sopp(aco_opcode::s_nop,
+                  static_cast<uint16_t>(NOPs - 1));
+      }
    }
 }
 
 template <std::size_t N>
 bool
-check_written_regs(const aco_ptr<Instruction>& instr, const std::bitset<N>& check_regs)
-{
-   return std::any_of(instr->definitions.begin(), instr->definitions.end(),
-                      [&check_regs](const Definition& def) -> bool
-                      {
-                         bool writes_any = false;
-                         for (unsigned i = 0; i < def.size(); i++) {
-                            unsigned def_reg = def.physReg() + i;
-                            writes_any |= def_reg < check_regs.size() && check_regs[def_reg];
-                         }
-                         return writes_any;
-                      });
+check_written_regs(const aco_ptr<Instruction>& instr, const std::bitset<N>& check_regs) {
+      return std::any_of(instr->definitions.begin(), instr->definitions.end(),
+                         [&check_regs](const Definition& def) -> bool {
+                               bool writes_any = false;
+                               for (unsigned i = 0; i < def.size(); i++) {
+                                     unsigned def_reg = def.physReg() + i;
+                                     writes_any |= def_reg < check_regs.size() && check_regs[def_reg];
+                               }
+                               return writes_any;
+                         });
 }
 
 template <std::size_t N>
 void
-mark_read_regs(const aco_ptr<Instruction>& instr, std::bitset<N>& reg_reads)
-{
-   for (const Operand& op : instr->operands) {
-      for (unsigned i = 0; i < op.size(); i++) {
-         unsigned reg = op.physReg() + i;
-         if (reg < reg_reads.size())
-            reg_reads.set(reg);
+mark_read_regs(const aco_ptr<Instruction>& instr, std::bitset<N>& reg_reads) {
+      for (const Operand& op : instr->operands) {
+            for (unsigned i = 0; i < op.size(); i++) {
+                  unsigned reg = op.physReg() + i;
+                  if (reg < reg_reads.size())
+                        reg_reads.set(reg);
+            }
       }
-   }
 }
 
 template <std::size_t N>
 void
-mark_read_regs_exec(State& state, const aco_ptr<Instruction>& instr, std::bitset<N>& reg_reads)
-{
-   mark_read_regs(instr, reg_reads);
-   reg_reads.set(exec);
-   if (state.program->wave_size == 64)
-      reg_reads.set(exec_hi);
+mark_read_regs_exec(State& state, const aco_ptr<Instruction>& instr, std::bitset<N>& reg_reads) {
+      mark_read_regs(instr, reg_reads);
+      reg_reads.set(exec);
+      if (state.program->wave_size == 64)
+            reg_reads.set(exec_hi);
 }
 
 bool
-VALU_writes_sgpr(aco_ptr<Instruction>& instr)
-{
-   if (instr->isVOPC())
-      return true;
-   if (instr->isVOP3() && instr->definitions.size() == 2)
-      return true;
-   if (instr->opcode == aco_opcode::v_readfirstlane_b32 ||
-       instr->opcode == aco_opcode::v_readlane_b32 ||
-       instr->opcode == aco_opcode::v_readlane_b32_e64)
-      return true;
-   return false;
+VALU_writes_sgpr(aco_ptr<Instruction>& instr) {
+      if (instr->isVOPC())
+            return true;
+      if (instr->isVOP3() && instr->definitions.size() == 2)
+            return true;
+      if (instr->opcode == aco_opcode::v_readfirstlane_b32 ||
+            instr->opcode == aco_opcode::v_readlane_b32 ||
+            instr->opcode == aco_opcode::v_readlane_b32_e64)
+            return true;
+      return false;
 }
 
 bool
-instr_writes_sgpr(const aco_ptr<Instruction>& instr)
-{
-   return std::any_of(instr->definitions.begin(), instr->definitions.end(),
-                      [](const Definition& def) -> bool
-                      { return def.getTemp().type() == RegType::sgpr; });
+instr_writes_sgpr(const aco_ptr<Instruction>& instr) {
+      return std::any_of(instr->definitions.begin(), instr->definitions.end(),
+                         [](const Definition& def) -> bool {
+                               return def.getTemp().type() == RegType::sgpr;
+                         });
 }
 
 inline bool
-instr_is_branch(const aco_ptr<Instruction>& instr)
-{
-   return instr->opcode == aco_opcode::s_branch || instr->opcode == aco_opcode::s_cbranch_scc0 ||
-          instr->opcode == aco_opcode::s_cbranch_scc1 ||
-          instr->opcode == aco_opcode::s_cbranch_vccz ||
-          instr->opcode == aco_opcode::s_cbranch_vccnz ||
-          instr->opcode == aco_opcode::s_cbranch_execz ||
-          instr->opcode == aco_opcode::s_cbranch_execnz ||
-          instr->opcode == aco_opcode::s_cbranch_cdbgsys ||
-          instr->opcode == aco_opcode::s_cbranch_cdbguser ||
-          instr->opcode == aco_opcode::s_cbranch_cdbgsys_or_user ||
-          instr->opcode == aco_opcode::s_cbranch_cdbgsys_and_user ||
-          instr->opcode == aco_opcode::s_subvector_loop_begin ||
-          instr->opcode == aco_opcode::s_subvector_loop_end ||
-          instr->opcode == aco_opcode::s_setpc_b64 || instr->opcode == aco_opcode::s_swappc_b64 ||
-          instr->opcode == aco_opcode::s_getpc_b64 || instr->opcode == aco_opcode::s_call_b64;
+instr_is_branch(const aco_ptr<Instruction>& instr) {
+      return instr->opcode == aco_opcode::s_branch || instr->opcode == aco_opcode::s_cbranch_scc0 ||
+      instr->opcode == aco_opcode::s_cbranch_scc1 ||
+      instr->opcode == aco_opcode::s_cbranch_vccz ||
+      instr->opcode == aco_opcode::s_cbranch_vccnz ||
+      instr->opcode == aco_opcode::s_cbranch_execz ||
+      instr->opcode == aco_opcode::s_cbranch_execnz ||
+      instr->opcode == aco_opcode::s_cbranch_cdbgsys ||
+      instr->opcode == aco_opcode::s_cbranch_cdbguser ||
+      instr->opcode == aco_opcode::s_cbranch_cdbgsys_or_user ||
+      instr->opcode == aco_opcode::s_cbranch_cdbgsys_and_user ||
+      instr->opcode == aco_opcode::s_subvector_loop_begin ||
+      instr->opcode == aco_opcode::s_subvector_loop_end ||
+      instr->opcode == aco_opcode::s_setpc_b64 || instr->opcode == aco_opcode::s_swappc_b64 ||
+      instr->opcode == aco_opcode::s_getpc_b64 || instr->opcode == aco_opcode::s_call_b64;
 }
 
 void
