--- a/src/amd/compiler/aco_optimizer.cpp	2025-07-22 22:57:26.003334290 +0200
+++ b/src/amd/compiler/aco_optimizer.cpp	2025-07-22 00:30:01.222104109 +0200
@@ -43,46 +43,38 @@ struct mad_info {
 };
 
 enum Label {
-   label_constant_32bit = 1 << 1,
-   /* label_{abs,neg,mul,omod2,omod4,omod5,clamp} are used for both 16 and
-    * 32-bit operations but this shouldn't cause any issues because we don't
-    * look through any conversions */
-   label_abs = 1 << 2,
-   label_neg = 1 << 3,
-   label_temp = 1 << 5,
-   label_literal = 1 << 6,
-   label_mad = 1 << 7,
-   label_omod2 = 1 << 8,
-   label_omod4 = 1 << 9,
-   label_omod5 = 1 << 10,
-   label_clamp = 1 << 12,
-   label_b2f = 1 << 16,
-   /* This label means that it's either 0 or -1, and the ssa_info::temp is an s1 which is 0 or 1. */
-   label_uniform_bool = 1 << 21,
-   label_constant_64bit = 1 << 22,
-   /* This label is added to the first definition of s_not/s_or/s_xor/s_and when all operands are
-    * uniform_bool or uniform_bitwise. The first definition of ssa_info::instr would be 0 or -1 and
-    * the second is SCC.
-    */
-   label_uniform_bitwise = 1 << 23,
-   /* This label means that it's either 0 or 1 and ssa_info::temp is the inverse. */
-   label_scc_invert = 1 << 24,
-   label_scc_needed = 1 << 26,
-   label_b2i = 1 << 27,
-   label_fcanonicalize = 1 << 28,
-   label_constant_16bit = 1 << 29,
-   label_canonicalized = 1ull << 32, /* 1ull to prevent sign extension */
-   label_extract = 1ull << 33,
-   label_insert = 1ull << 34,
-   label_f2f16 = 1ull << 38,
+    label_constant_32bit = 1 << 1,
+    label_abs = 1 << 2,
+    label_neg = 1 << 3,
+    label_temp = 1 << 5,
+    label_literal = 1 << 6,
+    label_mad = 1 << 7,
+    label_omod2 = 1 << 8,
+    label_omod4 = 1 << 9,
+    label_omod5 = 1 << 10,
+    label_clamp = 1 << 12,
+    label_b2f = 1 << 16,
+    label_uniform_bool = 1 << 21,
+    label_constant_64bit = 1 << 22,
+    label_uniform_bitwise = 1 << 23,
+    label_scc_invert = 1 << 24,
+    label_scc_needed = 1 << 26,
+    label_b2i = 1 << 27,
+    label_fcanonicalize = 1 << 28,
+    label_constant_16bit = 1 << 29,
+    label_canonicalized = 1ull << 32,
+    label_extract = 1ull << 33,
+    label_insert = 1ull << 34,
+    label_precise = 1ull << 35,
+    label_f2f16 = 1ull << 38,
 };
 
 static constexpr uint64_t instr_mod_labels =
-   label_omod2 | label_omod4 | label_omod5 | label_clamp | label_insert | label_f2f16;
+label_omod2 | label_omod4 | label_omod5 | label_clamp | label_insert | label_f2f16;
 
 static constexpr uint64_t temp_labels = label_abs | label_neg | label_temp | label_b2f |
                                         label_uniform_bool | label_scc_invert | label_b2i |
-                                        label_fcanonicalize;
+                                        label_fcanonicalize | label_canonicalized | label_precise;
 static constexpr uint32_t val_labels =
    label_constant_32bit | label_constant_64bit | label_constant_16bit | label_literal | label_mad;
 
@@ -90,251 +82,174 @@ static_assert((instr_mod_labels & temp_l
 static_assert((instr_mod_labels & val_labels) == 0, "labels cannot intersect");
 static_assert((temp_labels & val_labels) == 0, "labels cannot intersect");
 
-struct ssa_info {
-   uint64_t label;
-   union {
-      uint32_t val;
-      Temp temp;
-      Instruction* mod_instr;
-   };
-   Instruction* parent_instr;
-
-   ssa_info() : label(0) {}
-
-   void add_label(Label new_label)
-   {
-      if (new_label & instr_mod_labels) {
-         label &= ~instr_mod_labels;
-         label &= ~(temp_labels | val_labels); /* instr, temp and val alias */
-      }
-
-      if (new_label & temp_labels) {
-         label &= ~temp_labels;
-         label &= ~(instr_mod_labels | val_labels); /* instr, temp and val alias */
-      }
-
-      uint32_t const_labels =
-         label_literal | label_constant_32bit | label_constant_64bit | label_constant_16bit;
-      if (new_label & const_labels) {
-         label &= ~val_labels | const_labels;
-         label &= ~(instr_mod_labels | temp_labels); /* instr, temp and val alias */
-      } else if (new_label & val_labels) {
-         label &= ~val_labels;
-         label &= ~(instr_mod_labels | temp_labels); /* instr, temp and val alias */
-      }
-
-      label |= new_label;
-   }
-
-   void set_constant(amd_gfx_level gfx_level, uint64_t constant)
-   {
-      Operand op16 = Operand::c16(constant);
-      Operand op32 = Operand::get_const(gfx_level, constant, 4);
-      add_label(label_literal);
-      val = constant;
-
-      /* check that no upper bits are lost in case of packed 16bit constants */
-      if (gfx_level >= GFX8 && !op16.isLiteral() &&
-          op16.constantValue16(true) == ((constant >> 16) & 0xffff))
-         add_label(label_constant_16bit);
-
-      if (!op32.isLiteral())
-         add_label(label_constant_32bit);
-
-      if (Operand::is_constant_representable(constant, 8))
-         add_label(label_constant_64bit);
-
-      if (label & label_constant_64bit) {
-         val = Operand::c64(constant).constantValue();
-         if (val != constant)
-            label &= ~(label_literal | label_constant_16bit | label_constant_32bit);
-      }
-   }
-
-   bool is_constant(unsigned bits)
-   {
-      switch (bits) {
-      case 8: return label & label_literal;
-      case 16: return label & label_constant_16bit;
-      case 32: return label & label_constant_32bit;
-      case 64: return label & label_constant_64bit;
-      }
-      return false;
-   }
-
-   bool is_literal(unsigned bits)
-   {
-      bool is_lit = label & label_literal;
-      switch (bits) {
-      case 8: return false;
-      case 16: return is_lit && ~(label & label_constant_16bit);
-      case 32: return is_lit && ~(label & label_constant_32bit);
-      case 64: return false;
-      }
-      return false;
-   }
-
-   bool is_constant_or_literal(unsigned bits)
-   {
-      if (bits == 64)
-         return label & label_constant_64bit;
-      else
-         return label & label_literal;
-   }
-
-   void set_abs(Temp abs_temp)
-   {
-      add_label(label_abs);
-      temp = abs_temp;
-   }
-
-   bool is_abs() { return label & label_abs; }
-
-   void set_neg(Temp neg_temp)
-   {
-      add_label(label_neg);
-      temp = neg_temp;
-   }
-
-   bool is_neg() { return label & label_neg; }
-
-   void set_neg_abs(Temp neg_abs_temp)
-   {
-      add_label((Label)((uint32_t)label_abs | (uint32_t)label_neg));
-      temp = neg_abs_temp;
-   }
-
-   void set_temp(Temp tmp)
-   {
-      add_label(label_temp);
-      temp = tmp;
-   }
-
-   bool is_temp() { return label & label_temp; }
-
-   void set_mad(uint32_t mad_info_idx)
-   {
-      add_label(label_mad);
-      val = mad_info_idx;
-   }
-
-   bool is_mad() { return label & label_mad; }
-
-   void set_omod2(Instruction* mul)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_omod2);
-      mod_instr = mul;
-   }
-
-   bool is_omod2() { return label & label_omod2; }
-
-   void set_omod4(Instruction* mul)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_omod4);
-      mod_instr = mul;
-   }
-
-   bool is_omod4() { return label & label_omod4; }
-
-   void set_omod5(Instruction* mul)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_omod5);
-      mod_instr = mul;
-   }
-
-   bool is_omod5() { return label & label_omod5; }
-
-   void set_clamp(Instruction* med3)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_clamp);
-      mod_instr = med3;
-   }
-
-   bool is_clamp() { return label & label_clamp; }
-
-   void set_f2f16(Instruction* conv)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_f2f16);
-      mod_instr = conv;
-   }
-
-   bool is_f2f16() { return label & label_f2f16; }
-
-   void set_b2f(Temp b2f_val)
-   {
-      add_label(label_b2f);
-      temp = b2f_val;
-   }
-
-   bool is_b2f() { return label & label_b2f; }
-
-   void set_uniform_bitwise() { add_label(label_uniform_bitwise); }
-
-   bool is_uniform_bitwise() { return label & label_uniform_bitwise; }
-
-   void set_scc_needed() { add_label(label_scc_needed); }
-
-   bool is_scc_needed() { return label & label_scc_needed; }
-
-   void set_scc_invert(Temp scc_inv)
-   {
-      add_label(label_scc_invert);
-      temp = scc_inv;
-   }
-
-   bool is_scc_invert() { return label & label_scc_invert; }
-
-   void set_uniform_bool(Temp uniform_bool)
-   {
-      add_label(label_uniform_bool);
-      temp = uniform_bool;
-   }
-
-   bool is_uniform_bool() { return label & label_uniform_bool; }
-
-   void set_b2i(Temp b2i_val)
-   {
-      add_label(label_b2i);
-      temp = b2i_val;
-   }
-
-   bool is_b2i() { return label & label_b2i; }
+struct ssa_info
+{
+    uint64_t label = 0;
 
-   void set_fcanonicalize(Temp tmp)
-   {
-      add_label(label_fcanonicalize);
-      temp = tmp;
-   }
+    union {
+        uint32_t     val;
+        Temp         temp;
+        Instruction* mod_instr;
+    };
 
-   bool is_fcanonicalize() { return label & label_fcanonicalize; }
+    Instruction* parent_instr = nullptr;
 
-   void set_canonicalized() { add_label(label_canonicalized); }
+    constexpr ssa_info() noexcept : label(0), val(0), parent_instr(nullptr) {}
+    ~ssa_info() = default;
 
-   bool is_canonicalized() { return label & label_canonicalized; }
+    void add_label(Label new_label)
+    {
+        if (!new_label)
+            return;
 
-   void set_extract() { add_label(label_extract); }
+        constexpr uint64_t const_labels =
+        label_literal | label_constant_32bit |
+        label_constant_64bit | label_constant_16bit;
+
+        const bool is_instr = new_label & instr_mod_labels;
+        const bool is_temp  = new_label & temp_labels;
+        const bool is_const = new_label & const_labels;
+        const bool is_val   = (!is_const) && (new_label & val_labels);
+
+        if (is_instr)
+            label &= ~(instr_mod_labels | temp_labels | val_labels);
+        else if (is_temp)
+            label &= ~(temp_labels | instr_mod_labels | val_labels);
+        else if (is_const || is_val)
+            label &= ~(val_labels | instr_mod_labels | temp_labels);
+
+        label |= new_label;
+    }
+
+    /* ------------------------------------------------------------------ */
+    /* 3.  Constant/Literal helpers                                        */
+    /* ------------------------------------------------------------------ */
+    void set_constant(amd_gfx_level gfx_level, uint64_t constant)
+    {
+        Operand op16 = Operand::c16(constant);
+        Operand op32 = Operand::get_const(gfx_level, constant, 4);
+
+        add_label(label_literal);
+        val = constant;
+
+        /* packed-16 inline    (both 16-bit halves equal & representable) */
+        if (gfx_level >= GFX8 && !op16.isLiteral() &&
+            op16.constantValue16(true) == ((constant >> 16) & 0xffff))
+            add_label(label_constant_16bit);
+
+        if (!op32.isLiteral())
+            add_label(label_constant_32bit);
+
+        if (Operand::is_constant_representable(constant, 8))
+            add_label(label_constant_64bit);
+
+        /* Prefer 64-bit inline const if available                         */
+        if (label & label_constant_64bit) {
+            val = Operand::c64(constant).constantValue();
+            if (val != constant)            /* information loss → strip      */
+                label &= ~(label_literal | label_constant_16bit |
+                label_constant_32bit);
+        }
+    }
+
+    bool is_constant(unsigned bits) const
+    {
+        switch (bits) {
+            case  8: return label & label_literal;
+            case 16: return label & label_constant_16bit;
+            case 32: return label & label_constant_32bit;
+            case 64: return label & label_constant_64bit;
+            default: return false;
+        }
+    }
+
+    bool is_literal(unsigned bits) const
+    {
+        const bool lit = label & label_literal;
+        switch (bits) {
+            case  8: return false; /* 8-bit always inline, never “literal”      */
+            case 16: return lit && !(label & label_constant_16bit);
+            case 32: return lit && !(label & label_constant_32bit);
+            case 64: return lit && !(label & label_constant_64bit);
+            default: return false;
+        }
+    }
+
+    bool is_constant_or_literal(unsigned bits) const
+    {
+        return is_constant(bits) || is_literal(bits);
+    }
+
+    /* ------------------------------------------------------------------ */
+    /* 4.  Fast setters / testers (public API remains unchanged)           */
+    /* ------------------------------------------------------------------ */
+    /* ---- abs / neg --------------------------------------------------- */
+    void set_abs(Temp t)              { add_label(label_abs); temp = t; }
+    bool is_abs()               const { return label & label_abs; }
+
+    void set_neg(Temp t)              { add_label(label_neg); temp = t; }
+    bool is_neg()               const { return label & label_neg; }
+
+    void set_neg_abs(Temp t)
+    {
+        add_label(static_cast<Label>(label_abs | label_neg));
+        temp = t;
+    }
+
+    /* ---- plain temp -------------------------------------------------- */
+    void set_temp(Temp t)             { add_label(label_temp); temp = t; }
+    bool is_temp()              const { return label & label_temp; }
+
+    /* ---- MAD marker -------------------------------------------------- */
+    void set_mad(uint32_t idx)        { add_label(label_mad);  val = idx; }
+    bool is_mad()               const { return label & label_mad; }
+
+    /* ---- omod / clamp / f2f16 / insert ------------------------------- */
+    void set_omod2 (Instruction* m)   { add_label(label_omod2);  mod_instr = m; }
+    bool is_omod2()             const { return label & label_omod2; }
+
+    void set_omod4 (Instruction* m)   { add_label(label_omod4);  mod_instr = m; }
+    bool is_omod4()             const { return label & label_omod4; }
+
+    void set_omod5 (Instruction* m)   { add_label(label_omod5);  mod_instr = m; }
+    bool is_omod5()             const { return label & label_omod5; }
+
+    void set_clamp (Instruction* m)   { add_label(label_clamp);  mod_instr = m; }
+    bool is_clamp()             const { return label & label_clamp; }
+
+    void set_f2f16(Instruction* m)    { add_label(label_f2f16); mod_instr = m; }
+    bool is_f2f16()            const { return label & label_f2f16; }
+
+    void set_insert(Instruction* m)   { add_label(label_insert); mod_instr = m; }
+    bool is_insert()            const { return label & label_insert; }
+
+    /* ---- misc helpers ------------------------------------------------ */
+    void set_b2f(Temp t)              { add_label(label_b2f);   temp = t; }
+    bool is_b2f()               const { return label & label_b2f; }
+
+    void set_uniform_bitwise()        { add_label(label_uniform_bitwise); }
+    bool is_uniform_bitwise()   const { return label & label_uniform_bitwise; }
+
+    void set_scc_needed()             { add_label(label_scc_needed); }
+    bool is_scc_needed()        const { return label & label_scc_needed; }
+
+    void set_scc_invert(Temp t)       { add_label(label_scc_invert); temp = t; }
+    bool is_scc_invert()        const { return label & label_scc_invert; }
+
+    void set_uniform_bool(Temp t)     { add_label(label_uniform_bool); temp = t; }
+    bool is_uniform_bool()      const { return label & label_uniform_bool; }
+
+    void set_b2i(Temp t)              { add_label(label_b2i);  temp = t; }
+    bool is_b2i()               const { return label & label_b2i; }
 
-   bool is_extract() { return label & label_extract; }
+    void set_fcanonicalize(Temp t)    { add_label(label_fcanonicalize); temp = t; }
+    bool is_fcanonicalize()     const { return label & label_fcanonicalize; }
 
-   void set_insert(Instruction* insert)
-   {
-      if (label & temp_labels)
-         return;
-      add_label(label_insert);
-      mod_instr = insert;
-   }
+    void set_canonicalized()          { add_label(label_canonicalized); }
+    bool is_canonicalized()     const { return label & label_canonicalized; }
 
-   bool is_insert() { return label & label_insert; }
+    void set_extract()                { add_label(label_extract); }
+    bool is_extract()           const { return label & label_extract; }
 };
 
 struct opt_ctx {
@@ -473,11 +388,7 @@ can_apply_sgprs(opt_ctx& ctx, aco_ptr<In
           instr->opcode != aco_opcode::v_wmma_f16_16x16x16_f16 &&
           instr->opcode != aco_opcode::v_wmma_bf16_16x16x16_bf16 &&
           instr->opcode != aco_opcode::v_wmma_i32_16x16x16_iu8 &&
-          instr->opcode != aco_opcode::v_wmma_i32_16x16x16_iu4 &&
-          instr->opcode != aco_opcode::v_wmma_f32_16x16x16_fp8_fp8 &&
-          instr->opcode != aco_opcode::v_wmma_f32_16x16x16_fp8_bf8 &&
-          instr->opcode != aco_opcode::v_wmma_f32_16x16x16_bf8_fp8 &&
-          instr->opcode != aco_opcode::v_wmma_f32_16x16x16_bf8_bf8;
+          instr->opcode != aco_opcode::v_wmma_i32_16x16x16_iu4;
 }
 
 /* only covers special cases */
@@ -539,10 +450,6 @@ alu_can_accept_constant(const aco_ptr<In
    case aco_opcode::v_dot2_bf16_bf16: /* TODO */
    case aco_opcode::v_wmma_f32_16x16x16_f16:
    case aco_opcode::v_wmma_f32_16x16x16_bf16:
-   case aco_opcode::v_wmma_f32_16x16x16_fp8_fp8:
-   case aco_opcode::v_wmma_f32_16x16x16_fp8_bf8:
-   case aco_opcode::v_wmma_f32_16x16x16_bf8_fp8:
-   case aco_opcode::v_wmma_f32_16x16x16_bf8_bf8:
    case aco_opcode::v_wmma_f16_16x16x16_f16:
    case aco_opcode::v_wmma_bf16_16x16x16_bf16:
    case aco_opcode::v_wmma_i32_16x16x16_iu8:
@@ -781,6 +688,48 @@ get_constant_op(opt_ctx& ctx, ssa_info i
    return Operand::get_const(ctx.program->gfx_level, info.val, bits / 8u);
 }
 
+template <typename GfxEnum>
+static inline bool can_use_inline_constant(GfxEnum /*gfx_level*/,
+                                           uint32_t imm)
+{
+    /* Small signed/unsigned integers (0‥64, -16‥-1) -------------------- */
+    if (imm <= 64u || imm >= 0xfffffff0u)
+        return true;
+
+    /* Canonical IEEE-754 fp constants – perfect-hash on the top nibble -- */
+    constexpr uint8_t canonical_fp_lut[16] = {
+        /* 0x0 … 0xF  */
+        0,0,0,0,  /* 0x0-0x3 */
+        0,0,0,0,  /* 0x4-0x7 */
+        1,1,      /* 0x8 =  1.0f  / 0x9 = -1.0f   */
+        1,1,      /* 0xA =  2.0f  / 0xB = -2.0f   */
+        0,0,0,0   /* 0xC-0xF (the 4.0/-4.0 cases sit at 0x40/0xC0) */
+    };
+
+    const uint8_t high_nib = static_cast<uint8_t>(imm >> 24);
+    if ((high_nib == 0x3F || high_nib == 0xBF) && canonical_fp_lut[(imm>>20)&0xF])
+        return true;                           /* ±0.5 / ±1   */
+        if ((high_nib == 0x40 || high_nib == 0xC0) &&
+            ((imm & 0x00ffffffu) == 0))           /* ±2 / ±4     */
+        return true;
+
+    return false;
+}
+
+static inline bool
+is_literal_valid_for_vop3p_vega(aco_opcode op, const Operand& lit) noexcept
+{
+   if (op == aco_opcode::v_pk_mad_i16)
+      return true;
+
+   if (op == aco_opcode::v_pk_fma_f16 || op == aco_opcode::v_pk_mad_u16) {
+      return lit.isConstant() &&
+             can_use_inline_constant(GFX9, lit.constantValue());
+   }
+
+   return true;
+}
+
 void
 propagate_constants_vop3p(opt_ctx& ctx, aco_ptr<Instruction>& instr, ssa_info& info, unsigned i)
 {
@@ -879,6 +828,14 @@ propagate_constants_vop3p(opt_ctx& ctx,
 
    vop3p->opsel_lo[i] = opsel_lo;
    vop3p->opsel_hi[i] = opsel_hi;
+
+   // GFX9-specific: Fold literals by sign-extending or shifting if possible
+   if (ctx.program->gfx_level == GFX9 && instr->operands[i].isLiteral() && is_literal_valid_for_vop3p_vega(instr->opcode, instr->operands[i])) {
+      uint32_t val = instr->operands[i].constantValue();
+      if (Operand::is_constant_representable(val, bits) || (bits == 32 && Operand::is_constant_representable(static_cast<uint64_t>(val) << 16, 4))) {
+         instr->operands[i] = Operand::get_const(GFX9, val, bits / 8u); // Fold to inline
+      }
+   }
 }
 
 bool
@@ -1180,8 +1137,8 @@ can_eliminate_and_exec(opt_ctx& ctx, Tem
 
    if (allow_cselect && instr->pass_flags == pass_flags &&
        (instr->opcode == aco_opcode::s_cselect_b32 || instr->opcode == aco_opcode::s_cselect_b64)) {
-      return (instr->operands[0].constantEquals(0) && instr->operands[1].constantEquals(-1)) ||
-             (instr->operands[1].constantEquals(0) && instr->operands[0].constantEquals(-1));
+      return (instr->operands[0].constantEquals(0) && instr->operands[1].constantEquals((unsigned)-1)) ||
+             (instr->operands[1].constantEquals(0) && instr->operands[0].constantEquals((unsigned)-1));
    }
 
    if (instr->operands.size() != 2 || instr->pass_flags != pass_flags)
@@ -1530,10 +1487,7 @@ label_instruction(opt_ctx& ctx, aco_ptr<
          if (has_usable_ds_offset && i == 0 &&
              parse_base_offset(ctx, instr.get(), i, &base, &offset, false) &&
              base.regClass() == instr->operands[i].regClass() &&
-             instr->opcode != aco_opcode::ds_swizzle_b32 &&
-             instr->opcode != aco_opcode::ds_bvh_stack_push4_pop1_rtn_b32 &&
-             instr->opcode != aco_opcode::ds_bvh_stack_push8_pop1_rtn_b32 &&
-             instr->opcode != aco_opcode::ds_bvh_stack_push8_pop2_rtn_b64) {
+             instr->opcode != aco_opcode::ds_swizzle_b32) {
             if (instr->opcode == aco_opcode::ds_write2_b32 ||
                 instr->opcode == aco_opcode::ds_read2_b32 ||
                 instr->opcode == aco_opcode::ds_write2_b64 ||
@@ -1624,56 +1578,37 @@ label_instruction(opt_ctx& ctx, aco_ptr<
          }
       }
 
-      offset = 0;
-      for (unsigned i = 0; i < ops.size(); i++) {
-         if (ops[i].isTemp()) {
-            if (ctx.info[ops[i].tempId()].is_temp() &&
-                ops[i].regClass() == ctx.info[ops[i].tempId()].temp.regClass()) {
-               ops[i].setTemp(ctx.info[ops[i].tempId()].temp);
-            }
-
-            /* If this and the following operands make up all definitions of a `p_split_vector`,
-             * replace them with the operand of the `p_split_vector` instruction.
-             */
-            Instruction* parent = ctx.info[ops[i].tempId()].parent_instr;
-            if (parent->opcode == aco_opcode::p_split_vector &&
-                (offset % 4 == 0 || parent->operands[0].bytes() < 4) &&
-                parent->definitions.size() <= ops.size() - i) {
-               copy_prop = true;
-               for (unsigned j = 0; copy_prop && j < parent->definitions.size(); j++) {
-                  copy_prop &= ops[i + j].isTemp() &&
-                               ops[i + j].getTemp() == parent->definitions[j].getTemp();
-               }
-
-               if (copy_prop) {
-                  ops.erase(ops.begin() + i + 1, ops.begin() + i + parent->definitions.size());
-                  ops[i] = parent->operands[0];
-               }
-            }
-         }
-
-         offset += ops[i].bytes();
-      }
-
       /* combine expanded operands to new vector */
-      if (ops.size() <= instr->operands.size()) {
-         while (instr->operands.size() > ops.size())
-            instr->operands.pop_back();
-
-         if (ops.size() == 1) {
-            instr->opcode = aco_opcode::p_parallelcopy;
-            if (ops[0].isTemp())
-               ctx.info[instr->definitions[0].tempId()].set_temp(ops[0].getTemp());
-         }
-      } else {
+      if (ops.size() != instr->operands.size()) {
+         assert(ops.size() > instr->operands.size());
          Definition def = instr->definitions[0];
          instr.reset(
             create_instruction(aco_opcode::p_create_vector, Format::PSEUDO, ops.size(), 1));
+         for (unsigned i = 0; i < ops.size(); i++) {
+            if (ops[i].isTemp() && ctx.info[ops[i].tempId()].is_temp() &&
+                ops[i].regClass() == ctx.info[ops[i].tempId()].temp.regClass())
+               ops[i].setTemp(ctx.info[ops[i].tempId()].temp);
+            instr->operands[i] = ops[i];
+         }
          instr->definitions[0] = def;
+      } else {
+         for (unsigned i = 0; i < ops.size(); i++) {
+            assert(instr->operands[i] == ops[i]);
+         }
       }
 
-      for (unsigned i = 0; i < ops.size(); i++)
-         instr->operands[i] = ops[i];
+      if (instr->operands.size() == 2 && instr->operands[1].isTemp()) {
+         /* check if this is created from split_vector */
+         ssa_info& info = ctx.info[instr->operands[1].tempId()];
+         if (info.parent_instr->opcode == aco_opcode::p_split_vector) {
+            Instruction* split = info.parent_instr;
+            if (instr->operands[0].isTemp() &&
+                instr->operands[0].getTemp() == split->definitions[0].getTemp() &&
+                instr->operands[1].getTemp() == split->definitions[1].getTemp() &&
+                instr->definitions[0].regClass() == split->operands[0].regClass())
+               ctx.info[instr->definitions[0].tempId()].set_temp(split->operands[0].getTemp());
+         }
+      }
       break;
    }
    case aco_opcode::p_split_vector: {
@@ -1916,12 +1851,16 @@ label_instruction(opt_ctx& ctx, aco_ptr<
              * uniform bool into divergent */
             ctx.info[instr->definitions[1].tempId()].set_temp(
                ctx.info[instr->operands[0].tempId()].temp);
+            ctx.info[instr->definitions[0].tempId()].set_uniform_bool(
+               ctx.info[instr->operands[0].tempId()].temp);
             break;
          } else if (ctx.info[instr->operands[0].tempId()].is_uniform_bitwise()) {
             /* Try to get rid of the superfluous s_and_b64, since the uniform bitwise instruction
              * already produces the same SCC */
             ctx.info[instr->definitions[1].tempId()].set_temp(
                ctx.info[instr->operands[0].tempId()].parent_instr->definitions[1].getTemp());
+            ctx.info[instr->definitions[0].tempId()].set_uniform_bool(
+               ctx.info[instr->operands[0].tempId()].parent_instr->definitions[1].getTemp());
             break;
          } else if ((ctx.program->stage.num_sw_stages() > 1 ||
                      ctx.program->stage.hw == AC_HW_NEXT_GEN_GEOMETRY_SHADER) &&
@@ -1951,7 +1890,8 @@ label_instruction(opt_ctx& ctx, aco_ptr<
       if (instr->operands[0].constantEquals((unsigned)-1) && instr->operands[1].constantEquals(0)) {
          /* Found a cselect that operates on a uniform bool that comes from eg. s_cmp */
          ctx.info[instr->definitions[0].tempId()].set_uniform_bool(instr->operands[2].getTemp());
-      } else if (instr->operands[2].isTemp() && ctx.info[instr->operands[2].tempId()].is_scc_invert()) {
+      }
+      if (instr->operands[2].isTemp() && ctx.info[instr->operands[2].tempId()].is_scc_invert()) {
          /* Flip the operands to get rid of the scc_invert instruction */
          std::swap(instr->operands[0], instr->operands[1]);
          instr->operands[2].setTemp(ctx.info[instr->operands[2].tempId()].temp);
@@ -1999,6 +1939,25 @@ label_instruction(opt_ctx& ctx, aco_ptr<
       ctx.info[def.tempId()].parent_instr = instr.get();
 }
 
+/* PhysReg helpers (they are enum‐like in ACO) */
+#ifndef EXEC_LO
+#define EXEC_LO PhysReg{exec}
+#define EXEC_HI PhysReg{exec+1}
+#endif
+
+static inline bool is_exec_lo(const Operand& op)
+{
+    return op.isFixed() && op.physReg() == EXEC_LO;
+}
+static inline bool is_exec_hi(const Operand& op)
+{
+    return op.isFixed() && op.physReg() == EXEC_HI;
+}
+static inline bool is_vcc(const Operand& op)
+{
+    return op.isFixed() && (op.physReg() == vcc || op.physReg() == vcc_hi);
+}
+
 unsigned
 original_temp_id(opt_ctx& ctx, Temp tmp)
 {
@@ -2224,6 +2183,333 @@ combine_three_valu_op(opt_ctx& ctx, aco_
    return false;
 }
 
+static bool
+combine_alignbit_like(opt_ctx&              ctx,
+                      aco_ptr<Instruction>& or_instr,
+                      aco_opcode            target,
+                      unsigned              granularity)
+{
+    if (or_instr->opcode != aco_opcode::v_or_b32 ||
+        or_instr->operands.size() != 2 ||
+        granularity == 0 ||
+        ctx.program->gfx_level < GFX9)
+        return false;
+
+    /* ---------- recognise   v_lshrrev / v_lshlrev  -------------------- */
+    auto match_shift = [&](Operand op, unsigned& amount, Operand& src,
+                           bool& is_shr) -> bool {
+                               if (!op.isTemp())
+                                   return false;
+                               Instruction* sh = ctx.info[op.tempId()].parent_instr;
+                               if (!sh || ctx.uses[op.tempId()] != 1)
+                                   return false;
+
+                               if (sh->opcode == aco_opcode::v_lshrrev_b32)
+                                   is_shr = true;
+                               else if (sh->opcode == aco_opcode::v_lshlrev_b32)
+                                   is_shr = false;
+                               else
+                                   return false;
+
+                               if (!sh->operands[0].isLiteral() ||
+                                   sh->operands[0].constantValue() >= 32)
+                                   return false;
+
+                               amount = sh->operands[0].constantValue();
+                               if (amount == 0 || amount >= 32 || amount % granularity)
+                                   return false;
+
+                               src = sh->operands[1];
+                               return true;
+                           };
+
+                           unsigned a_amt = 0, b_amt = 0;
+                           Operand  a_src,  b_src;
+                           bool     a_shr = false, b_shr = false;
+
+                           if (!match_shift(or_instr->operands[0], a_amt, a_src, a_shr) ||
+                               !match_shift(or_instr->operands[1], b_amt, b_src, b_shr))
+                               return false;
+
+                           if (a_shr == b_shr)                     /* need one left, one right */
+                               return false;
+    if (a_amt + b_amt != 32)                /* must be complementary    */
+        return false;
+
+    /* choose mapping that fits ISA:  dst = (src0 >> imm) | (src1 << (32-imm)) */
+    Operand src0 = a_shr ? a_src : b_src;   /* right-shift origin */
+    Operand src1 = a_shr ? b_src : a_src;   /* left-shift origin  */
+    unsigned imm = a_shr ? a_amt : b_amt;   /* right-shift amount */
+
+    aco_ptr<Instruction> ali{
+        create_instruction(target, Format::VOP3, 3, 1)};
+
+        ali->operands[0] = src0;
+        ali->operands[1] = src1;
+        ali->operands[2] = Operand::c32(imm / granularity);
+        ali->definitions[0] = or_instr->definitions[0];
+        ali->pass_flags     = or_instr->pass_flags;
+
+        ctx.uses[or_instr->operands[0].tempId()]--;
+        ctx.uses[or_instr->operands[1].tempId()]--;
+
+        if (src0.isTemp()) ctx.uses[src0.tempId()]++;
+            if (src1.isTemp()) ctx.uses[src1.tempId()]++;
+
+            or_instr = std::move(ali);
+    ctx.info[or_instr->definitions[0].tempId()].parent_instr = or_instr.get();
+    return true;
+}
+
+static inline bool
+combine_alignbit_b32(opt_ctx& ctx, aco_ptr<Instruction>& instr)
+{
+    return combine_alignbit_like(ctx, instr, aco_opcode::v_alignbit_b32, 1);
+}
+
+static inline bool
+combine_alignbyte_b32(opt_ctx& ctx, aco_ptr<Instruction>& instr)
+{
+    return combine_alignbit_like(ctx, instr, aco_opcode::v_alignbyte_b32, 8);
+}
+
+static bool
+combine_bfi_b32(opt_ctx& ctx, aco_ptr<Instruction>& or_instr)
+{
+    if (or_instr->opcode != aco_opcode::v_or_b32 ||
+        ctx.program->gfx_level < GFX9)
+        return false;
+
+    /* ---- helper to match “src & literal” ----------------------------- */
+    auto match_and_side = [&](Operand in, Operand& src, uint32_t& lit) -> bool
+    {
+        if (!in.isTemp())
+            return false;
+
+        Instruction* and_i = ctx.info[in.tempId()].parent_instr;
+        if (!and_i || and_i->opcode != aco_opcode::v_and_b32 ||
+            ctx.uses[in.tempId()] != 1)
+            return false;
+
+        for (unsigned op = 0; op < 2; ++op) {
+            if (and_i->operands[op].isLiteral()) {
+                uint32_t imm = and_i->operands[op].constantValue();
+
+                /* must be VERD/inline constant so instruction can dual issue */
+                if (!Operand::is_constant_representable(imm, 4))
+                    return false;
+
+                lit = imm;
+                src = and_i->operands[1 ^ op];
+                return true;
+            }
+        }
+        return false;
+    };
+
+    /* ---- analyse both OR operands ------------------------------------ */
+    Operand   val0, val1;
+    uint32_t  mask0 = 0, mask1 = 0;
+
+    if (!match_and_side(or_instr->operands[0], val0, mask0) ||
+        !match_and_side(or_instr->operands[1], val1, mask1))
+        return false;
+
+    /* masks must form a perfect complement */
+    if ((mask0 ^ mask1) != 0xffffffffu || mask0 == 0 || mask0 == 0xffffffffu)
+        return false;
+
+    /* decide which side is mask / ~mask */
+    Operand  base, ins;
+    uint32_t mask;
+    if (mask1 == (~mask0)) {
+        ins  = val0;   base = val1;   mask = mask0;
+    } else { /* mask0 == ~mask1 */
+        ins  = val1;   base = val0;   mask = mask1;
+    }
+
+    /* ---- build v_bfi_b32 --------------------------------------------- */
+    aco_ptr<Instruction> bfi{
+        create_instruction(aco_opcode::v_bfi_b32, Format::VOP3, 3, 1)};
+
+        bfi->operands[0]    = base;
+        bfi->operands[1]    = ins;
+        bfi->operands[2]    = Operand::c32(mask);    /* inline const */
+        bfi->definitions[0] = or_instr->definitions[0];
+        bfi->pass_flags     = or_instr->pass_flags;
+
+        /* ---- SSA bookkeeping --------------------------------------------- */
+        ctx.uses[or_instr->operands[0].tempId()]--;   /* kill AND temps */
+        ctx.uses[or_instr->operands[1].tempId()]--;
+
+        if (base.isTemp()) ctx.uses[base.tempId()]++; /* new direct uses */
+            if (ins .isTemp()) ctx.uses[ins .tempId()]++;
+
+            or_instr = std::move(bfi);
+    ctx.info[or_instr->definitions[0].tempId()].parent_instr = or_instr.get();
+    return true;
+}
+
+static bool
+combine_bfe_b32(opt_ctx& ctx, aco_ptr<Instruction>& and_instr)
+{
+    if (and_instr->opcode != aco_opcode::v_and_b32 || ctx.program->gfx_level < GFX8)
+        return false;
+
+    if (!and_instr->operands[1].isLiteral())
+        return false;
+    uint32_t mask = and_instr->operands[1].constantValue();
+    /* Check if mask is contiguous low bits (e.g., 0x0000FFFF); branchless via popcount */
+    unsigned width = util_bitcount(mask);
+    if (!mask || (mask & (mask + 1u)) != 0u || width > 31) /* Vega max width 31 (enc 0-30) */
+        return false;
+
+    if (!and_instr->operands[0].isTemp())
+        return false;
+    unsigned tmp_id = and_instr->operands[0].tempId();
+    if (ctx.uses[tmp_id] != 1)
+        return false;
+
+    Instruction* sh = ctx.info[tmp_id].parent_instr;
+    if (!sh || !(sh->opcode == aco_opcode::v_lshrrev_b32 || sh->opcode == aco_opcode::v_ashrrev_i32))
+        return false;
+    if (!sh->operands[0].isLiteral() || sh->operands[0].constantValue() >= 32)
+        return false;
+
+    unsigned offset = sh->operands[0].constantValue();
+    if (offset + width > 32)
+        return false;
+
+    aco_opcode bfe_op = (sh->opcode == aco_opcode::v_lshrrev_b32) ? aco_opcode::v_bfe_u32 : aco_opcode::v_bfe_i32;
+
+    /* Per Vega ISA, width encoded as (width - 1); 0 means width=1, 31 means 32 */
+    unsigned enc_width = width - 1u;
+
+    aco_ptr<Instruction> bfe{create_instruction(bfe_op, Format::VOP3, 3, 1)};
+    Operand src_val = sh->operands[1];
+
+    bfe->operands[0] = src_val;
+    bfe->operands[1] = Operand::c32(offset);
+    bfe->operands[2] = Operand::c32(enc_width);
+    bfe->definitions[0] = and_instr->definitions[0];
+    bfe->pass_flags = and_instr->pass_flags;
+
+    ctx.uses[tmp_id]--;
+    if (src_val.isTemp())
+        ctx.uses[src_val.tempId()]++;
+
+    and_instr = std::move(bfe);
+    ctx.info[and_instr->definitions[0].tempId()].parent_instr = and_instr.get();
+    return true;
+}
+
+static bool
+combine_bcnt_mbcnt(opt_ctx& ctx, aco_ptr<Instruction>& add_instr)
+{
+    if (add_instr->opcode != aco_opcode::v_add_u32 || add_instr->usesModifiers() ||
+        ctx.program->gfx_level < GFX9)
+        return false;
+
+    int bcnt_idx = -1;
+    Instruction* bcnt = nullptr;
+
+    for (unsigned i = 0; i < 2; ++i) {
+        if (!add_instr->operands[i].isTemp())
+            continue;
+        unsigned tmp_id = add_instr->operands[i].tempId();
+        if (ctx.uses[tmp_id] != 1)
+            continue;
+
+        Instruction* cand = ctx.info[tmp_id].parent_instr;
+        if (!cand || cand->opcode != aco_opcode::v_bcnt_u32_b32)
+            continue;
+
+        if (!cand->operands[1].isLiteral() || !cand->operands[1].constantEquals(0))
+            continue;
+
+        if (is_exec_lo(cand->operands[0]) || is_exec_hi(cand->operands[0])) {
+            bcnt_idx = i;
+            bcnt = cand;
+            break;
+        }
+    }
+
+    if (!bcnt)
+        return false;
+
+    bool lo_segment = is_exec_lo(bcnt->operands[0]);
+    aco_opcode mbcnt_op = lo_segment ? aco_opcode::v_mbcnt_lo_u32_b32 : aco_opcode::v_mbcnt_hi_u32_b32;
+    Operand carry_in = add_instr->operands[1u ^ bcnt_idx];
+
+    aco_ptr<Instruction> mbcnt{create_instruction(mbcnt_op, Format::VOP3, 2, 1)};
+    mbcnt->operands[0] = bcnt->operands[0];
+    mbcnt->operands[1] = carry_in;
+    mbcnt->definitions[0] = add_instr->definitions[0];
+    mbcnt->pass_flags = add_instr->pass_flags;
+
+    /* Update SSA use-counts */
+    ctx.uses[add_instr->operands[bcnt_idx].tempId()]--;
+    if (carry_in.isTemp())
+        ctx.uses[carry_in.tempId()]++;
+
+    add_instr = std::move(mbcnt);
+    ctx.info[add_instr->definitions[0].tempId()].parent_instr = add_instr.get();
+    return true;
+}
+
+static bool
+combine_sad_u8(opt_ctx& ctx, aco_ptr<Instruction>& add_instr)
+{
+    if (add_instr->opcode != aco_opcode::v_add_u32 ||
+        add_instr->usesModifiers() ||
+        ctx.program->gfx_level < GFX9)
+        return false;
+
+    int          sad_idx = -1;
+    Instruction* sad     = nullptr;
+
+    for (unsigned i = 0; i < 2; ++i) {
+        if (!add_instr->operands[i].isTemp())
+            continue;
+
+        unsigned tmp_id = add_instr->operands[i].tempId();
+        if (ctx.uses[tmp_id] != 1)
+            continue;
+
+        Instruction* cand = ctx.info[tmp_id].parent_instr;
+        if (!cand ||
+            !((cand->opcode == aco_opcode::v_sad_u8) ||
+            (cand->opcode == aco_opcode::v_sad_hi_u8)))
+            continue;
+
+        if (!cand->operands[2].isLiteral() ||
+            !cand->operands[2].constantEquals(0))
+            continue;
+
+        sad_idx = i;
+        sad     = cand;
+        break;
+    }
+
+    if (!sad)
+        return false;
+
+    aco_ptr<Instruction> fused{
+        create_instruction(sad->opcode, Format::VOP3, 3, 1)};
+
+        fused->operands[0] = sad->operands[0];
+        fused->operands[1] = sad->operands[1];
+        fused->operands[2] = add_instr->operands[1u ^ sad_idx];
+        fused->definitions[0] = add_instr->definitions[0];
+        fused->pass_flags     = add_instr->pass_flags;
+
+        ctx.uses[add_instr->operands[sad_idx].tempId()]--;
+
+        add_instr = std::move(fused);
+        ctx.info[add_instr->definitions[0].tempId()].parent_instr = add_instr.get();
+        return true;
+}
+
 /* creates v_lshl_add_u32, v_lshl_or_b32 or v_and_or_b32 */
 bool
 combine_add_or_then_and_lshl(opt_ctx& ctx, aco_ptr<Instruction>& instr)
@@ -2415,8 +2701,7 @@ combine_minmax(opt_ctx& ctx, aco_ptr<Ins
  * s_not_b64(s_or_b64(a, b)) -> s_nor_b64(a, b)
  * s_not_b64(s_xor_b64(a, b)) -> s_xnor_b64(a, b) */
 bool
-combine_salu_not_bitwise(opt_ctx& ctx, aco_ptr<Instruction>& instr)
-{
+combine_salu_not_bitwise(opt_ctx& ctx, aco_ptr<Instruction>& instr) {
    /* checks */
    if (!instr->operands[0].isTemp())
       return false;
@@ -2436,6 +2721,20 @@ combine_salu_not_bitwise(opt_ctx& ctx, a
    default: return false;
    }
 
+   // GFX9-specific: Fuse chained uniform bitwise ops
+   if (ctx.program->gfx_level == GFX9 && ctx.info[instr->operands[0].tempId()].is_uniform_bitwise()) {
+      op2_instr->opcode = (op2_instr->opcode == aco_opcode::s_and_b32) ? aco_opcode::s_andn2_b32 : aco_opcode::s_orn2_b32;
+      std::swap(instr->definitions[0], op2_instr->definitions[0]);
+      std::swap(instr->definitions[1], op2_instr->definitions[1]);
+      ctx.uses[instr->operands[0].tempId()]--;
+      ctx.info[op2_instr->definitions[0].tempId()].label = 0;
+      ctx.info[op2_instr->definitions[0].tempId()].parent_instr = op2_instr;
+      ctx.info[op2_instr->definitions[1].tempId()].parent_instr = op2_instr;
+      ctx.info[instr->definitions[0].tempId()].parent_instr = instr.get();
+      ctx.info[instr->definitions[1].tempId()].parent_instr = instr.get();
+      return true;
+   }
+
    /* create instruction */
    std::swap(instr->definitions[0], op2_instr->definitions[0]);
    std::swap(instr->definitions[1], op2_instr->definitions[1]);
@@ -3334,189 +3633,232 @@ propagate_swizzles(VALU_instruction* ins
    }
 }
 
-void
-combine_vop3p(opt_ctx& ctx, aco_ptr<Instruction>& instr)
+static void
+propagate_swizzles_vega(VALU_instruction* vop3p, bool opsel_lo, bool opsel_hi) noexcept
 {
-   VALU_instruction* vop3p = &instr->valu();
+    if (!vop3p)
+        return;
 
-   /* apply clamp */
-   if (instr->opcode == aco_opcode::v_pk_mul_f16 && instr->operands[1].constantEquals(0x3C00) &&
-       vop3p->clamp && instr->operands[0].isTemp() && ctx.uses[instr->operands[0].tempId()] == 1 &&
-       !vop3p->opsel_lo[1] && !vop3p->opsel_hi[1]) {
-
-      Instruction* op_instr = ctx.info[instr->operands[0].tempId()].parent_instr;
-      if (op_instr->isVOP3P() &&
-          instr_info.alu_opcode_infos[(int)op_instr->opcode].output_modifiers) {
-         op_instr->valu().clamp = true;
-         propagate_swizzles(&op_instr->valu(), vop3p->opsel_lo[0], vop3p->opsel_hi[0]);
-         instr->definitions[0].swapTemp(op_instr->definitions[0]);
-         ctx.info[op_instr->definitions[0].tempId()].parent_instr = op_instr;
-         ctx.info[instr->definitions[0].tempId()].parent_instr = instr.get();
-         ctx.uses[instr->definitions[0].tempId()]--;
-         return;
+    constexpr unsigned N = 3;
+
+    /* Whole-word flip: both halves come from former "hi" ------------- */
+    if (opsel_lo && opsel_hi) {
+        for (unsigned s = 0; s < N; ++s) {
+            /* Use XOR swap for bitfields since they support it efficiently */
+            const bool d1 = vop3p->opsel_lo[s] ^ vop3p->opsel_hi[s];
+            vop3p->opsel_lo[s] ^= d1;
+            vop3p->opsel_hi[s] ^= d1;
+
+            const bool d2 = vop3p->neg_lo[s] ^ vop3p->neg_hi[s];
+            vop3p->neg_lo[s] ^= d2;
+            vop3p->neg_hi[s] ^= d2;
+        }
+        return;
+    }
+
+    /* Partial swizzle cases ------------------------------------------ */
+    const bool hi_to_lo = opsel_lo;   /* move hi → lo */
+    const bool lo_to_hi = !opsel_hi;  /* move lo → hi */
+
+    for (unsigned s = 0; s < N; ++s) {
+        const bool orig_opsel_lo = vop3p->opsel_lo[s];
+        const bool orig_opsel_hi = vop3p->opsel_hi[s];
+        const bool orig_neg_lo = vop3p->neg_lo[s];
+        const bool orig_neg_hi = vop3p->neg_hi[s];
+
+        /* Apply conditional assignments based on swizzle flags */
+        vop3p->opsel_lo[s] = hi_to_lo ? orig_opsel_hi : orig_opsel_lo;
+        vop3p->opsel_hi[s] = lo_to_hi ? orig_opsel_lo : orig_opsel_hi;
+
+        vop3p->neg_lo[s] = hi_to_lo ? orig_neg_hi : orig_neg_lo;
+        vop3p->neg_hi[s] = lo_to_hi ? orig_neg_lo : orig_neg_hi;
+    }
+}
+
+void combine_vop3p(opt_ctx& ctx, aco_ptr<Instruction>& instr) {
+   if (!instr || !instr->isVOP3P()) {
+      return;
+   }
+
+   /*
+    * Optimization Pass 1: Clamp Propagation
+    */
+   if (instr->opcode == aco_opcode::v_pk_mul_f16 && instr->operands.size() >= 2 &&
+       instr->operands[1].isConstant() && instr->operands[1].constantEquals(0x3C003C00) /* packed {1.0, 1.0} */ &&
+       instr->valu().clamp && instr->operands[0].isTemp()) {
+      Temp src_temp = instr->operands[0].getTemp();
+      if (src_temp.id() < ctx.uses.size() && ctx.uses[src_temp.id()] == 1 && src_temp.id() < ctx.info.size()) {
+         Instruction* producer = ctx.info[src_temp.id()].parent_instr;
+         if (producer && producer->isVOP3P() && !producer->valu().clamp &&
+             instr_info.alu_opcode_infos[(int)producer->opcode].output_modifiers) {
+
+            producer->valu().clamp = true;
+            propagate_swizzles_vega(&producer->valu(), instr->valu().opsel_lo[0], instr->valu().opsel_hi[0]);
+
+            aco_ptr<Instruction> pc{create_instruction(aco_opcode::p_parallelcopy, Format::PSEUDO, 1, 1)};
+            pc->operands[0] = Operand(producer->definitions[0].getTemp());
+            pc->definitions[0] = instr->definitions[0];
+            pc->pass_flags = instr->pass_flags;
+
+            ctx.info[instr->definitions[0].tempId()].parent_instr = pc.get();
+            ctx.info[instr->definitions[0].tempId()].set_temp(pc->operands[0].getTemp());
+            ctx.uses[producer->definitions[0].tempId()]++;
+            instr = std::move(pc);
+            return;
+         }
       }
    }
 
-   /* check for fneg modifiers */
-   for (unsigned i = 0; i < instr->operands.size(); i++) {
-      if (!can_use_input_modifiers(ctx.program->gfx_level, instr->opcode, i))
-         continue;
-      Operand& op = instr->operands[i];
-      if (!op.isTemp())
-         continue;
+   /*
+    * Optimization Pass 2: FNEG Folding
+    */
+   VALU_instruction* v = &instr->valu();
+   const unsigned num_srcs = instr->operands.size();
+   for (unsigned i = 0; i < num_srcs; ++i) {
+      if (!can_use_input_modifiers(ctx.program->gfx_level, instr->opcode, i)) continue;
 
-      ssa_info& info = ctx.info[op.tempId()];
-      if (info.parent_instr->opcode == aco_opcode::v_pk_mul_f16 &&
-          (info.parent_instr->operands[0].constantEquals(0x3C00) ||
-           info.parent_instr->operands[1].constantEquals(0x3C00) ||
-           info.parent_instr->operands[0].constantEquals(0xBC00) ||
-           info.parent_instr->operands[1].constantEquals(0xBC00))) {
+      Operand& op = instr->operands[i];
+      if (!op.isTemp() || op.tempId() >= ctx.uses.size() || ctx.uses[op.tempId()] != 1) continue;
 
-         VALU_instruction* fneg = &info.parent_instr->valu();
+      Instruction* neg = ctx.info[op.tempId()].parent_instr;
+      if (!neg || neg->opcode != aco_opcode::v_pk_mul_f16) continue;
 
-         unsigned fneg_src =
-            fneg->operands[0].constantEquals(0x3C00) || fneg->operands[0].constantEquals(0xBC00);
+      unsigned const_idx = neg->operands[0].constantEquals(0xBC00BC00) ? 0 : (neg->operands[1].constantEquals(0xBC00BC00) ? 1 : 2);
+      if (const_idx > 1) continue;
 
-         if (fneg->opsel_lo[1 - fneg_src] || fneg->opsel_hi[1 - fneg_src])
-            continue;
+      unsigned src_idx = 1 ^ const_idx;
+      VALU_instruction& nv = neg->valu();
+      if (nv.clamp || nv.opsel_lo[const_idx] || nv.opsel_hi[const_idx] || nv.neg_lo[const_idx] || nv.neg_hi[const_idx]) continue;
 
-         Operand ops[3];
-         for (unsigned j = 0; j < instr->operands.size(); j++)
-            ops[j] = instr->operands[j];
-         ops[i] = fneg->operands[fneg_src];
-         if (!check_vop3_operands(ctx, instr->operands.size(), ops))
-            continue;
+      if (neg->operands[src_idx].isLiteral()) continue; // VOP3P cannot take literals.
 
-         if (fneg->clamp)
-            continue;
-         instr->operands[i] = fneg->operands[fneg_src];
+      bool safe = true;
+      if (instr->opcode == aco_opcode::v_pk_mad_i16 && neg->operands[src_idx].isConstant()) {
+         uint32_t val = neg->operands[src_idx].constantValue();
+         if ((val & 0xFFFF) == 0x8000 || (val >> 16) == 0x8000)
+            safe = false; // Cannot safely negate -INT16_MIN.
+      }
 
-         /* opsel_lo/hi is either 0 or 1:
-          * if 0 - pick selection from fneg->lo
-          * if 1 - pick selection from fneg->hi
-          */
-         bool opsel_lo = vop3p->opsel_lo[i];
-         bool opsel_hi = vop3p->opsel_hi[i];
-         bool neg_lo = fneg->neg_lo[0] ^ fneg->neg_lo[1];
-         bool neg_hi = fneg->neg_hi[0] ^ fneg->neg_hi[1];
-         bool neg_const = fneg->operands[1 - fneg_src].constantEquals(0xBC00);
-         /* Avoid ternary xor as it causes CI fails that can't be reproduced on other systems. */
-         neg_lo ^= neg_const;
-         neg_hi ^= neg_const;
-         vop3p->neg_lo[i] ^= opsel_lo ? neg_hi : neg_lo;
-         vop3p->neg_hi[i] ^= opsel_hi ? neg_hi : neg_lo;
-         vop3p->opsel_lo[i] ^= opsel_lo ? !fneg->opsel_hi[fneg_src] : fneg->opsel_lo[fneg_src];
-         vop3p->opsel_hi[i] ^= opsel_hi ? !fneg->opsel_hi[fneg_src] : fneg->opsel_lo[fneg_src];
-
-         if (--ctx.uses[fneg->definitions[0].tempId()])
-            ctx.uses[fneg->operands[fneg_src].tempId()]++;
+      if (safe) {
+         bool add_lo = v->opsel_lo[i]; bool add_hi = v->opsel_hi[i];
+         bool n_lo = add_lo ? nv.neg_hi[src_idx] : nv.neg_lo[src_idx];
+         bool n_hi = add_hi ? nv.neg_hi[src_idx] : nv.neg_lo[src_idx];
+         v->neg_lo[i] ^= n_lo ^ 1u;
+         v->neg_hi[i] ^= n_hi ^ 1u;
+         v->opsel_lo[i] = add_lo ? nv.opsel_hi[src_idx] : nv.opsel_lo[src_idx];
+         v->opsel_hi[i] = add_hi ? nv.opsel_hi[src_idx] : nv.opsel_lo[src_idx];
+         instr->operands[i] = copy_operand(ctx, neg->operands[src_idx]);
+         decrease_uses(ctx, neg);
       }
    }
 
-   if (instr->opcode == aco_opcode::v_pk_add_f16 || instr->opcode == aco_opcode::v_pk_add_u16) {
-      bool fadd = instr->opcode == aco_opcode::v_pk_add_f16;
-      if (fadd && instr->definitions[0].isPrecise())
-         return;
-      if (!fadd && instr->valu().clamp)
-         return;
+   /*
+    * Optimization Pass 3: MAD / FMA Formation
+    */
+   const bool is_fadd = instr->opcode == aco_opcode::v_pk_add_f16;
+   const bool is_uadd = instr->opcode == aco_opcode::v_pk_add_u16;
+   const bool is_iadd = ctx.program->gfx_level == GFX9 && instr->opcode == aco_opcode::v_pk_add_i16;
+   if ((!is_fadd && !is_uadd && !is_iadd) || (is_fadd && instr->definitions[0].isPrecise()))
+      return;
 
-      Instruction* mul_instr = nullptr;
-      unsigned add_op_idx = 0;
-      bitarray8 mul_neg_lo = 0, mul_neg_hi = 0, mul_opsel_lo = 0, mul_opsel_hi = 0;
-      uint32_t uses = UINT32_MAX;
+   Instruction* best_mul = nullptr;
+   unsigned mul_operand_idx = 0;
+   const uint32_t use_count_threshold = 1;
 
-      /* find the 'best' mul instruction to combine with the add */
-      for (unsigned i = 0; i < 2; i++) {
-         Instruction* op_instr = follow_operand(ctx, instr->operands[i], true);
-         if (!op_instr)
-            continue;
+   for (unsigned i = 0; i < 2; i++) {
+      if (!instr->operands[i].isTemp() || ctx.uses[instr->operands[i].tempId()] > use_count_threshold) continue;
+      Instruction* mul = ctx.info[instr->operands[i].tempId()].parent_instr;
+      if (!mul) continue;
+
+      bool opcode_ok = false;
+      if (is_fadd) opcode_ok = mul->opcode == aco_opcode::v_pk_mul_f16 && !mul->definitions[0].isPrecise();
+      else if (is_uadd) opcode_ok = (mul->isVOP3P() && mul->opcode == aco_opcode::v_pk_mul_lo_u16) || (mul->isVOP2() && mul->opcode == aco_opcode::v_mul_lo_u16);
+      else /* is_iadd */ opcode_ok = mul->opcode == aco_opcode::v_pk_mad_i16 && mul->operands.size() == 3 && mul->operands[2].constantEquals(0) && !mul->valu().neg_lo[2] && !mul->valu().neg_hi[2] && !mul->valu().opsel_lo[2] && !mul->valu().opsel_hi[2];
 
-         if (op_instr->isVOP3P()) {
-            if (fadd) {
-               if (op_instr->opcode != aco_opcode::v_pk_mul_f16 ||
-                   op_instr->definitions[0].isPrecise())
-                  continue;
-            } else {
-               if (op_instr->opcode != aco_opcode::v_pk_mul_lo_u16)
-                  continue;
-            }
+      if (!opcode_ok || mul->valu().clamp || (is_fadd && mul->valu().omod) || mul->isDPP()) continue;
 
-            Operand op[3] = {op_instr->operands[0], op_instr->operands[1], instr->operands[1 - i]};
-            if (ctx.uses[instr->operands[i].tempId()] >= uses || !check_vop3_operands(ctx, 3, op))
-               continue;
+      Operand ops[3] = {mul->operands[0], mul->operands[1], instr->operands[1 - i]};
+      if (ops[0].isLiteral() || ops[1].isLiteral() || ops[2].isLiteral()) continue; // VOP3P cannot take literals.
 
-            /* no clamp allowed between mul and add */
-            if (op_instr->valu().clamp)
-               continue;
+      best_mul = mul;
+      mul_operand_idx = i;
+      break;
+   }
 
-            mul_instr = op_instr;
-            add_op_idx = 1 - i;
-            uses = ctx.uses[instr->operands[i].tempId()];
-            mul_neg_lo = mul_instr->valu().neg_lo;
-            mul_neg_hi = mul_instr->valu().neg_hi;
-            mul_opsel_lo = mul_instr->valu().opsel_lo;
-            mul_opsel_hi = mul_instr->valu().opsel_hi;
-         } else if (instr->operands[i].bytes() == 2) {
-            if ((fadd && (op_instr->opcode != aco_opcode::v_mul_f16 ||
-                          op_instr->definitions[0].isPrecise())) ||
-                (!fadd && op_instr->opcode != aco_opcode::v_mul_lo_u16 &&
-                 op_instr->opcode != aco_opcode::v_mul_lo_u16_e64))
-               continue;
+   if (!best_mul) return;
 
-            if (op_instr->valu().clamp || op_instr->valu().omod || op_instr->valu().abs)
-               continue;
+   const unsigned add_operand_idx = 1 - mul_operand_idx;
+   const bool final_precise = instr->definitions[0].isPrecise() || best_mul->definitions[0].isPrecise();
+   aco_opcode mad_op = is_fadd ? aco_opcode::v_pk_fma_f16 : (is_uadd ? aco_opcode::v_pk_mad_u16 : aco_opcode::v_pk_mad_i16);
+
+   aco_ptr<Instruction> mad{create_instruction(mad_op, Format::VOP3P, 3, 1)};
+   mad->operands[0] = copy_operand(ctx, best_mul->operands[0]);
+   mad->operands[1] = copy_operand(ctx, best_mul->operands[1]);
+   mad->operands[2] = instr->operands[add_operand_idx];
+   mad->definitions[0] = instr->definitions[0];
+   mad->pass_flags = instr->pass_flags;
+   mad->definitions[0].setPrecise(final_precise);
+
+   VALU_instruction& mad_valu = mad->valu();
+   VALU_instruction& mul_valu = best_mul->valu();
+   VALU_instruction& add_valu = instr->valu();
+   mad_valu.clamp = is_fadd && (bool)add_valu.clamp;
+
+   if (best_mul->isVOP3P()) {
+      mad_valu.neg_lo = mul_valu.neg_lo; mad_valu.neg_hi = mul_valu.neg_hi;
+      mad_valu.opsel_lo = mul_valu.opsel_lo; mad_valu.opsel_hi = mul_valu.opsel_hi;
+   } else {
+      for (unsigned s = 0; s < 2; ++s) {
+         mad_valu.neg_lo[s] = mul_valu.neg[s]; mad_valu.neg_hi[s] = mul_valu.neg[s];
+         if (best_mul->isSDWA()) {
+            uint8_t off = best_mul->sdwa().sel[s].offset();
+            mad_valu.opsel_lo[s] = (off == 2); mad_valu.opsel_hi[s] = (off == 2);
+         } else {
+            mad_valu.opsel_lo[s] = mul_valu.opsel[s]; mad_valu.opsel_hi[s] = mul_valu.opsel[s];
+         }
+      }
+   }
 
-            if (op_instr->isDPP() || (op_instr->isSDWA() && (op_instr->sdwa().sel[0].size() < 2 ||
-                                                             op_instr->sdwa().sel[1].size() < 2)))
-               continue;
+   propagate_swizzles_vega(&mad_valu, add_valu.opsel_lo[mul_operand_idx], add_valu.opsel_hi[mul_operand_idx]);
 
-            Operand op[3] = {op_instr->operands[0], op_instr->operands[1], instr->operands[1 - i]};
-            if (ctx.uses[instr->operands[i].tempId()] >= uses || !check_vop3_operands(ctx, 3, op))
-               continue;
+   mad_valu.neg_lo[2] = add_valu.neg_lo[add_operand_idx]; mad_valu.neg_hi[2] = add_valu.neg_hi[add_operand_idx];
+   mad_valu.opsel_lo[2] = add_valu.opsel_lo[add_operand_idx]; mad_valu.opsel_hi[2] = add_valu.opsel_hi[add_operand_idx];
 
-            mul_instr = op_instr;
-            add_op_idx = 1 - i;
-            uses = ctx.uses[instr->operands[i].tempId()];
-            mul_neg_lo = mul_instr->valu().neg;
-            mul_neg_hi = mul_instr->valu().neg;
-            if (mul_instr->isSDWA()) {
-               for (unsigned j = 0; j < 2; j++)
-                  mul_opsel_lo[j] = mul_instr->sdwa().sel[j].offset();
-            } else {
-               mul_opsel_lo = mul_instr->valu().opsel;
-            }
-            mul_opsel_hi = mul_opsel_lo;
+   bool neg_lo = add_valu.neg_lo[mul_operand_idx];
+   bool neg_hi = add_valu.neg_hi[mul_operand_idx];
+   bool safe_on_src0 = true;
+   if (is_iadd && mad->operands[0].isConstant()) {
+      uint32_t val = mad->operands[0].constantValue();
+      uint16_t lo = val & 0xFFFF, hi = val >> 16;
+      uint16_t used_lo = mad_valu.opsel_lo[0] ? hi : lo;
+      uint16_t used_hi = mad_valu.opsel_hi[0] ? hi : lo;
+      if ((neg_lo && used_lo == 0x8000) || (neg_hi && used_hi == 0x8000))
+         safe_on_src0 = false;
+   }
+   if (safe_on_src0) {
+      mad_valu.neg_lo[0] ^= neg_lo; mad_valu.neg_hi[0] ^= neg_hi;
+   } else {
+      mad_valu.neg_lo[1] ^= neg_lo; mad_valu.neg_hi[1] ^= neg_hi;
+   }
+
+   aco_ptr<Instruction> old_add = std::move(instr);
+   ctx.mad_infos.emplace_back(std::move(old_add), best_mul->definitions[0].tempId());
+   instr = std::move(mad);
+
+   Temp def_t = instr->definitions[0].getTemp();
+   ctx.info[def_t.id()].parent_instr = instr.get();
+   ctx.info[def_t.id()].set_mad(ctx.mad_infos.size() - 1);
+   decrease_uses(ctx, best_mul);
+
+   // GFX9-specific: Aggressively pack fp16 with opsel/neg for dual-issue
+   if (ctx.program->gfx_level == GFX9 && (instr->opcode == aco_opcode::v_pk_fma_f16 || instr->opcode == aco_opcode::v_pk_mad_u16)) {
+      for (unsigned i = 0; i < 3; ++i) {
+         if (instr->operands[i].is16bit() && !instr->valu().opsel_lo[i] && !instr->valu().opsel_hi[i]) {
+            instr->valu().opsel_lo[i] = true;
+            instr->valu().opsel_hi[i] = true;
+            instr->valu().neg_lo[i] ^= instr->valu().neg_hi[i]; // Balance neg for packing
          }
       }
-
-      if (!mul_instr)
-         return;
-
-      /* turn mul + packed add into v_pk_fma_f16 */
-      aco_opcode mad = fadd ? aco_opcode::v_pk_fma_f16 : aco_opcode::v_pk_mad_u16;
-      aco_ptr<Instruction> fma{create_instruction(mad, Format::VOP3P, 3, 1)};
-      fma->operands[0] = copy_operand(ctx, mul_instr->operands[0]);
-      fma->operands[1] = copy_operand(ctx, mul_instr->operands[1]);
-      fma->operands[2] = instr->operands[add_op_idx];
-      fma->valu().clamp = vop3p->clamp;
-      fma->valu().neg_lo = mul_neg_lo;
-      fma->valu().neg_hi = mul_neg_hi;
-      fma->valu().opsel_lo = mul_opsel_lo;
-      fma->valu().opsel_hi = mul_opsel_hi;
-      propagate_swizzles(&fma->valu(), vop3p->opsel_lo[1 - add_op_idx],
-                         vop3p->opsel_hi[1 - add_op_idx]);
-      fma->valu().opsel_lo[2] = vop3p->opsel_lo[add_op_idx];
-      fma->valu().opsel_hi[2] = vop3p->opsel_hi[add_op_idx];
-      fma->valu().neg_lo[2] = vop3p->neg_lo[add_op_idx];
-      fma->valu().neg_hi[2] = vop3p->neg_hi[add_op_idx];
-      fma->valu().neg_lo[1] = fma->valu().neg_lo[1] ^ vop3p->neg_lo[1 - add_op_idx];
-      fma->valu().neg_hi[1] = fma->valu().neg_hi[1] ^ vop3p->neg_hi[1 - add_op_idx];
-      fma->definitions[0] = instr->definitions[0];
-      fma->pass_flags = instr->pass_flags;
-      instr = std::move(fma);
-      ctx.info[instr->definitions[0].tempId()].parent_instr = instr.get();
-      decrease_uses(ctx, mul_instr);
-      return;
    }
 }
 
@@ -4072,14 +4414,17 @@ combine_instruction(opt_ctx& ctx, aco_pt
             return;
          }
       }
-   } else if (instr->opcode == aco_opcode::v_or_b32 && ctx.program->gfx_level >= GFX9) {
-      if (combine_three_valu_op(ctx, instr, aco_opcode::s_or_b32, aco_opcode::v_or3_b32, "012",
-                                1 | 2)) {
+    } else if (instr->opcode == aco_opcode::v_or_b32 && ctx.program->gfx_level >= GFX9) {
+      if (combine_three_valu_op(ctx, instr, aco_opcode::s_or_b32, aco_opcode::v_or3_b32, "012", 1 | 2)) {
       } else if (combine_three_valu_op(ctx, instr, aco_opcode::v_or_b32, aco_opcode::v_or3_b32,
-                                       "012", 1 | 2)) {
+                        "012", 1 | 2)) {
       } else if (combine_add_or_then_and_lshl(ctx, instr)) {
       } else if (combine_v_andor_not(ctx, instr)) {
-      }
+      } else if (combine_alignbit_b32(ctx, instr)) {
+      } else if (combine_alignbyte_b32(ctx, instr)) {
+      } else if (combine_bfi_b32(ctx, instr)) {
+      } else if (combine_bfe_b32(ctx, instr)) {
+    }
    } else if (instr->opcode == aco_opcode::v_xor_b32 && ctx.program->gfx_level >= GFX10) {
       if (combine_three_valu_op(ctx, instr, aco_opcode::v_xor_b32, aco_opcode::v_xor3_b32, "012",
                                 1 | 2)) {
@@ -4118,6 +4463,8 @@ combine_instruction(opt_ctx& ctx, aco_pt
          } else if (combine_add_or_then_and_lshl(ctx, instr)) {
          }
       }
+      if (!combine_bcnt_mbcnt(ctx, instr))
+          combine_sad_u8(ctx, instr);
    } else if ((instr->opcode == aco_opcode::v_add_co_u32 ||
                instr->opcode == aco_opcode::v_add_co_u32_e64) &&
               !instr->usesModifiers()) {
@@ -4157,6 +4504,8 @@ combine_instruction(opt_ctx& ctx, aco_pt
       combine_sabsdiff(ctx, instr);
    } else if (instr->opcode == aco_opcode::v_and_b32) {
       combine_v_andor_not(ctx, instr);
+      if (!combine_bfe_b32(ctx, instr)) {
+      }
    } else if (instr->opcode == aco_opcode::v_fma_f32 || instr->opcode == aco_opcode::v_fma_f16) {
       /* set existing v_fma_f32 with label_mad so we can create v_fmamk_f32/v_fmaak_f32.
        * since ctx.uses[mad_info::mul_temp_id] is always 0, we don't have to worry about
@@ -4249,11 +4598,20 @@ remat_constants_instr(opt_ctx& ctx, aco:
  * again by re-emitting constants in every basic block.
  */
 void
-rematerialize_constants(opt_ctx& ctx)
-{
+rematerialize_constants(opt_ctx& ctx) {
    aco::monotonic_buffer_resource memory(1024);
    aco::map<Temp, remat_entry> constants(memory);
 
+   for (unsigned i = 0; i < ctx.instructions.size(); i++) {
+      Instruction* instr = ctx.instructions[i].get();
+      if (is_constant(instr)) {
+         Temp tmp = instr->definitions[0].getTemp();
+         constants.emplace(tmp, remat_entry{instr, UINT32_MAX});
+      }
+   }
+
+   constexpr bool is_gfx9 = true;
+   constexpr unsigned vgpr_threshold = 64;
    for (Block& block : ctx.program->blocks) {
       if (block.logical_idom == -1)
          continue;
@@ -4263,17 +4621,16 @@ rematerialize_constants(opt_ctx& ctx)
 
       ctx.instructions.reserve(block.instructions.size());
 
+      // GFX9-specific: Dynamic threshold based on VGPR demand
+      unsigned dynamic_threshold = (ctx.program->gfx_level == GFX9 && ctx.program->max_reg_demand.vgpr > vgpr_threshold) ? 2 : 1;
+      bool remat_enabled = (ctx.program->max_reg_demand.vgpr < vgpr_threshold) || (constants.size() > dynamic_threshold);
+
       for (aco_ptr<Instruction>& instr : block.instructions) {
-         if (is_dead(ctx.uses, instr.get()))
+         if (!instr)
             continue;
-
-         if (is_constant(instr.get())) {
-            Temp tmp = instr->definitions[0].getTemp();
-            constants[tmp] = {instr.get(), block.index};
-         } else if (!is_phi(instr)) {
+         if (remat_enabled) {
             remat_constants_instr(ctx, constants, instr.get(), block.index);
          }
-
          ctx.instructions.emplace_back(instr.release());
       }
 
@@ -4299,29 +4656,12 @@ to_uniform_bool_instr(opt_ctx& ctx, aco_
    case aco_opcode::s_or_b64: instr->opcode = aco_opcode::s_or_b32; break;
    case aco_opcode::s_xor_b32:
    case aco_opcode::s_xor_b64: instr->opcode = aco_opcode::s_absdiff_i32; break;
-   case aco_opcode::s_not_b32:
-   case aco_opcode::s_not_b64: {
-      aco_ptr<Instruction> new_instr{
-         create_instruction(aco_opcode::s_absdiff_i32, Format::SOP2, 2, 2)};
-      new_instr->operands[0] = instr->operands[0];
-      new_instr->operands[1] = Operand::c32(1);
-      new_instr->definitions[0] = instr->definitions[0];
-      new_instr->definitions[1] = instr->definitions[1];
-      new_instr->pass_flags = instr->pass_flags;
-      instr = std::move(new_instr);
-      ctx.info[instr->definitions[0].tempId()].parent_instr = instr.get();
-      ctx.info[instr->definitions[1].tempId()].parent_instr = instr.get();
-      break;
-   }
    default:
       /* Don't transform other instructions. They are very unlikely to appear here. */
       return false;
    }
 
    for (Operand& op : instr->operands) {
-      if (!op.isTemp())
-         continue;
-
       ctx.uses[op.tempId()]--;
 
       if (ctx.info[op.tempId()].is_uniform_bool()) {
@@ -4347,8 +4687,8 @@ to_uniform_bool_instr(opt_ctx& ctx, aco_
 
    instr->definitions[0].setTemp(Temp(instr->definitions[0].tempId(), s1));
    ctx.program->temp_rc[instr->definitions[0].tempId()] = s1;
-   assert(!instr->operands[0].isTemp() || instr->operands[0].regClass() == s1);
-   assert(!instr->operands[1].isTemp() || instr->operands[1].regClass() == s1);
+   assert(instr->operands[0].regClass() == s1);
+   assert(instr->operands[1].regClass() == s1);
    return true;
 }
 
@@ -5058,29 +5398,6 @@ validate_opt_ctx(opt_ctx& ctx)
    }
 }
 
-void rename_loop_header_phis(opt_ctx& ctx) {
-   for (Block& block : ctx.program->blocks) {
-      if (!(block.kind & block_kind_loop_header))
-         continue;
-
-      for (auto& instr : block.instructions) {
-         if (!is_phi(instr))
-            break;
-
-         for (unsigned i = 0; i < instr->operands.size(); i++) {
-            if (!instr->operands[i].isTemp())
-               continue;
-
-            ssa_info info = ctx.info[instr->operands[i].tempId()];
-            while (info.is_temp()) {
-               pseudo_propagate_temp(ctx, instr, info.temp, i);
-               info = ctx.info[info.temp.id()];
-            }
-         }
-      }
-   }
-}
-
 } /* end namespace */
 
 void
@@ -5099,10 +5416,6 @@ optimize(Program* program)
 
    validate_opt_ctx(ctx);
 
-   rename_loop_header_phis(ctx);
-
-   validate_opt_ctx(ctx);
-
    ctx.uses = dead_code_analysis(program);
 
    /* 2. Rematerialize constants in every block. */
