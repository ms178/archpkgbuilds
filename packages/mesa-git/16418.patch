From 85f67aa4a7151005db01d366a1a34eacf9b8bf4d Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Wed, 11 May 2022 15:11:27 +0800
Subject: [PATCH 1/8] ac/llvm: get back
 nir_intrinsic_load_tess_rel_patch_id_amd
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

radeonsi will use it. This can be removed again after radeonsi support
radv_nir_lower_abi like lower pass.

Reviewed-by: Timur Kristóf <timur.kristof@gmail.com>
Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/llvm/ac_nir_to_llvm.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 875708ca9eff..e45feceb018c 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -4034,6 +4034,10 @@ static void visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
       result = ac_build_gather_values(&ctx->ac, coord, 3);
       break;
    }
+   case nir_intrinsic_load_tess_rel_patch_id_amd:
+      assert(ctx->stage == MESA_SHADER_TESS_CTRL);
+      result = ac_unpack_param(&ctx->ac, ac_get_arg(&ctx->ac, ctx->args->tcs_rel_ids), 0, 8);
+      break;
    case nir_intrinsic_vote_all: {
       result = ac_build_vote_all(&ctx->ac, get_src(ctx, instr->src[0]));
       break;
-- 
GitLab


From 3e3aa2fce4617132420f0799fd584c832142d3e5 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Sat, 7 May 2022 17:34:54 +0800
Subject: [PATCH 2/8] nir: add nir_intrinsic_load_lshs_vertex_stride_amd
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

For loading LS-HS vertex stride by shader argument in radeonsi.

Reviewed-by: Timur Kristóf <timur.kristof@gmail.com>
Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/compiler/nir/nir_divergence_analysis.c | 1 +
 src/compiler/nir/nir_intrinsics.py         | 3 +++
 2 files changed, 4 insertions(+)

diff --git a/src/compiler/nir/nir_divergence_analysis.c b/src/compiler/nir/nir_divergence_analysis.c
index 7efbca39f465..96261b982418 100644
--- a/src/compiler/nir/nir_divergence_analysis.c
+++ b/src/compiler/nir/nir_divergence_analysis.c
@@ -172,6 +172,7 @@ visit_intrinsic(nir_shader *shader, nir_intrinsic_instr *instr)
    case nir_intrinsic_load_global_block_intel:
    case nir_intrinsic_load_btd_global_arg_addr_intel:
    case nir_intrinsic_load_btd_local_arg_addr_intel:
+   case nir_intrinsic_load_lshs_vertex_stride_amd:
       is_divergent = false;
       break;
 
diff --git a/src/compiler/nir/nir_intrinsics.py b/src/compiler/nir/nir_intrinsics.py
index 2b8a6c6ab6e3..83f0f00ea7e0 100644
--- a/src/compiler/nir/nir_intrinsics.py
+++ b/src/compiler/nir/nir_intrinsics.py
@@ -1375,6 +1375,9 @@ intrinsic("load_shared2_amd", [1], dest_comp=2, indices=[OFFSET0, OFFSET1, ST64]
 # src[] = { value, offset }.
 intrinsic("store_shared2_amd", [2, 1], indices=[OFFSET0, OFFSET1, ST64])
 
+# Vertex stride in LS-HS buffer
+system_value("lshs_vertex_stride_amd", 1)
+
 # V3D-specific instrinc for tile buffer color reads.
 #
 # The hardware requires that we read the samples and components of a pixel
-- 
GitLab


From cdf61fc4d5b76796fbe2da44727abe7462535555 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Sat, 7 May 2022 17:38:04 +0800
Subject: [PATCH 3/8] ac/nir: use nir_intrinsic_load_lshs_vertex_stride_amd
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

For radeonsi which pass this value by argument.

Reviewed-by: Timur Kristóf <timur.kristof@gmail.com>
Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir.h                      |  7 ++---
 src/amd/common/ac_nir_lower_tess_io_to_mem.c | 28 +++++++-------------
 src/amd/vulkan/radv_nir_lower_abi.c          | 10 ++++++-
 src/amd/vulkan/radv_shader.c                 |  7 +++--
 4 files changed, 23 insertions(+), 29 deletions(-)

diff --git a/src/amd/common/ac_nir.h b/src/amd/common/ac_nir.h
index 3ef13c796874..966f982f38b5 100644
--- a/src/amd/common/ac_nir.h
+++ b/src/amd/common/ac_nir.h
@@ -62,13 +62,11 @@ bool ac_nir_optimize_outputs(nir_shader *nir, bool sprite_tex_disallowed,
 void
 ac_nir_lower_ls_outputs_to_mem(nir_shader *ls,
                                bool tcs_in_out_eq,
-                               uint64_t tcs_temp_only_inputs,
-                               unsigned num_reserved_ls_outputs);
+                               uint64_t tcs_temp_only_inputs);
 
 void
 ac_nir_lower_hs_inputs_to_mem(nir_shader *shader,
-                              bool tcs_in_out_eq,
-                              unsigned num_reserved_tcs_inputs);
+                              bool tcs_in_out_eq);
 
 void
 ac_nir_lower_hs_outputs_to_mem(nir_shader *shader,
@@ -76,7 +74,6 @@ ac_nir_lower_hs_outputs_to_mem(nir_shader *shader,
                                bool tes_reads_tessfactors,
                                uint64_t tes_inputs_read,
                                uint64_t tes_patch_inputs_read,
-                               unsigned num_reserved_tcs_inputs,
                                unsigned num_reserved_tcs_outputs,
                                unsigned num_reserved_tcs_patch_outputs,
                                bool emit_tess_factor_write);
diff --git a/src/amd/common/ac_nir_lower_tess_io_to_mem.c b/src/amd/common/ac_nir_lower_tess_io_to_mem.c
index 2fe6b2cd957b..0fe115f0493e 100644
--- a/src/amd/common/ac_nir_lower_tess_io_to_mem.c
+++ b/src/amd/common/ac_nir_lower_tess_io_to_mem.c
@@ -140,10 +140,6 @@ typedef struct {
    /* Whether TES reads the tess factors. */
    bool tes_reads_tessfactors;
 
-   /* Number of inputs for which memory should be reserved.
-    * When compacted, this should be the number of linked inputs.
-    */
-   unsigned tcs_num_reserved_inputs;
    unsigned tcs_num_reserved_outputs;
    unsigned tcs_num_reserved_patch_outputs;
 
@@ -220,7 +216,7 @@ lower_ls_output_store(nir_builder *b,
    b->cursor = nir_before_instr(instr);
 
    nir_ssa_def *vertex_idx = nir_load_local_invocation_index(b);
-   nir_ssa_def *base_off_var = nir_imul_imm(b, vertex_idx, st->tcs_num_reserved_inputs * 16u);
+   nir_ssa_def *base_off_var = nir_imul(b, vertex_idx, nir_load_lshs_vertex_stride_amd(b));
 
    nir_ssa_def *io_off = nir_build_calc_io_offset(b, intrin, nir_imm_int(b, 16u), 4u);
    unsigned write_mask = nir_intrinsic_write_mask(intrin);
@@ -272,15 +268,15 @@ hs_per_vertex_input_lds_offset(nir_builder *b,
                                lower_tess_io_state *st,
                                nir_intrinsic_instr *instr)
 {
-   unsigned tcs_in_vertex_stride = st->tcs_num_reserved_inputs * 16u;
    nir_ssa_def *tcs_in_vtxcnt = nir_load_patch_vertices_in(b);
    nir_ssa_def *rel_patch_id = nir_load_tess_rel_patch_id_amd(b);
+   nir_ssa_def *vertex_index = nir_get_io_arrayed_index_src(instr)->ssa;
 
-   nir_ssa_def *tcs_in_patch_stride = nir_imul_imm(b, tcs_in_vtxcnt, tcs_in_vertex_stride);
-   nir_ssa_def *tcs_in_current_patch_offset = nir_imul(b, rel_patch_id, tcs_in_patch_stride);
+   nir_ssa_def *stride = nir_load_lshs_vertex_stride_amd(b);
+   nir_ssa_def *tcs_in_patch_stride = nir_imul(b, tcs_in_vtxcnt, stride);
+   nir_ssa_def *vertex_index_off = nir_imul(b, vertex_index, stride);
 
-   nir_ssa_def *vertex_index = nir_get_io_arrayed_index_src(instr)->ssa;
-   nir_ssa_def *vertex_index_off = nir_imul_imm(b, vertex_index, tcs_in_vertex_stride);
+   nir_ssa_def *tcs_in_current_patch_offset = nir_imul(b, rel_patch_id, tcs_in_patch_stride);
 
    nir_ssa_def *io_offset = nir_build_calc_io_offset(b, instr, nir_imm_int(b, 16u), 4u);
 
@@ -302,7 +298,7 @@ hs_output_lds_offset(nir_builder *b,
 
    nir_ssa_def *tcs_in_vtxcnt = nir_load_patch_vertices_in(b);
    nir_ssa_def *tcs_num_patches = nir_load_tcs_num_patches_amd(b);
-   nir_ssa_def *input_patch_size = nir_imul_imm(b, tcs_in_vtxcnt, st->tcs_num_reserved_inputs * 16u);
+   nir_ssa_def *input_patch_size = nir_imul(b, tcs_in_vtxcnt, nir_load_lshs_vertex_stride_amd(b));
    nir_ssa_def *output_patch0_offset = nir_imul(b, input_patch_size, tcs_num_patches);
 
    nir_ssa_def *off = intrin
@@ -634,13 +630,11 @@ filter_any_input_access(const nir_instr *instr,
 void
 ac_nir_lower_ls_outputs_to_mem(nir_shader *shader,
                                bool tcs_in_out_eq,
-                               uint64_t tcs_temp_only_inputs,
-                               unsigned num_reserved_ls_outputs)
+                               uint64_t tcs_temp_only_inputs)
 {
    assert(shader->info.stage == MESA_SHADER_VERTEX);
 
    lower_tess_io_state state = {
-      .tcs_num_reserved_inputs = num_reserved_ls_outputs,
       .tcs_in_out_eq = tcs_in_out_eq,
       .tcs_temp_only_inputs = tcs_in_out_eq ? tcs_temp_only_inputs : 0,
    };
@@ -653,14 +647,12 @@ ac_nir_lower_ls_outputs_to_mem(nir_shader *shader,
 
 void
 ac_nir_lower_hs_inputs_to_mem(nir_shader *shader,
-                              bool tcs_in_out_eq,
-                              unsigned num_reserved_tcs_inputs)
+                              bool tcs_in_out_eq)
 {
    assert(shader->info.stage == MESA_SHADER_TESS_CTRL);
 
    lower_tess_io_state state = {
       .tcs_in_out_eq = tcs_in_out_eq,
-      .tcs_num_reserved_inputs = num_reserved_tcs_inputs,
    };
 
    nir_shader_lower_instructions(shader,
@@ -675,7 +667,6 @@ ac_nir_lower_hs_outputs_to_mem(nir_shader *shader,
                                bool tes_reads_tessfactors,
                                uint64_t tes_inputs_read,
                                uint64_t tes_patch_inputs_read,
-                               unsigned num_reserved_tcs_inputs,
                                unsigned num_reserved_tcs_outputs,
                                unsigned num_reserved_tcs_patch_outputs,
                                bool emit_tess_factor_write)
@@ -687,7 +678,6 @@ ac_nir_lower_hs_outputs_to_mem(nir_shader *shader,
       .tes_reads_tessfactors = tes_reads_tessfactors,
       .tes_inputs_read = tes_inputs_read,
       .tes_patch_inputs_read = tes_patch_inputs_read,
-      .tcs_num_reserved_inputs = num_reserved_tcs_inputs,
       .tcs_num_reserved_outputs = num_reserved_tcs_outputs,
       .tcs_num_reserved_patch_outputs = num_reserved_tcs_patch_outputs,
       .tcs_out_patch_fits_subgroup = 32 % shader->info.tess.tcs_vertices_out == 0,
diff --git a/src/amd/vulkan/radv_nir_lower_abi.c b/src/amd/vulkan/radv_nir_lower_abi.c
index f89f4f6065ca..0570a0f1d889 100644
--- a/src/amd/vulkan/radv_nir_lower_abi.c
+++ b/src/amd/vulkan/radv_nir_lower_abi.c
@@ -182,6 +182,13 @@ lower_abi_instr(nir_builder *b, nir_instr *instr, void *state)
    case nir_intrinsic_load_task_ib_stride:
       return ac_nir_load_arg(b, &s->args->ac, s->args->task_ib_stride);
 
+   case nir_intrinsic_load_lshs_vertex_stride_amd: {
+      unsigned io_num = stage == MESA_SHADER_VERTEX ?
+         s->info->vs.num_linked_outputs :
+         s->info->tcs.num_linked_inputs;
+      return nir_imm_int(b, io_num * 16);
+   }
+
    default:
       unreachable("invalid NIR RADV ABI intrinsic.");
    }
@@ -225,7 +232,8 @@ filter_abi_instr(const nir_instr *instr,
           intrin->intrinsic == nir_intrinsic_load_ring_task_payload_amd ||
           intrin->intrinsic == nir_intrinsic_load_task_ring_entry_amd ||
           intrin->intrinsic == nir_intrinsic_load_task_ib_addr ||
-          intrin->intrinsic == nir_intrinsic_load_task_ib_stride;
+          intrin->intrinsic == nir_intrinsic_load_task_ib_stride ||
+          intrin->intrinsic == nir_intrinsic_load_lshs_vertex_stride_amd;
 }
 
 void
diff --git a/src/amd/vulkan/radv_shader.c b/src/amd/vulkan/radv_shader.c
index b69c504e8459..c75e97f612c4 100644
--- a/src/amd/vulkan/radv_shader.c
+++ b/src/amd/vulkan/radv_shader.c
@@ -1019,8 +1019,7 @@ radv_lower_io_to_mem(struct radv_device *device, struct radv_pipeline_stage *sta
    if (nir->info.stage == MESA_SHADER_VERTEX) {
       if (info->vs.as_ls) {
          ac_nir_lower_ls_outputs_to_mem(nir, info->vs.tcs_in_out_eq,
-                                        info->vs.tcs_temp_only_input_mask,
-                                        info->vs.num_linked_outputs);
+                                        info->vs.tcs_temp_only_input_mask);
          return true;
       } else if (info->vs.as_es) {
          ac_nir_lower_es_outputs_to_mem(nir, device->physical_device->rad_info.gfx_level,
@@ -1028,10 +1027,10 @@ radv_lower_io_to_mem(struct radv_device *device, struct radv_pipeline_stage *sta
          return true;
       }
    } else if (nir->info.stage == MESA_SHADER_TESS_CTRL) {
-      ac_nir_lower_hs_inputs_to_mem(nir, info->vs.tcs_in_out_eq, info->tcs.num_linked_inputs);
+      ac_nir_lower_hs_inputs_to_mem(nir, info->vs.tcs_in_out_eq);
       ac_nir_lower_hs_outputs_to_mem(
          nir, device->physical_device->rad_info.gfx_level, info->tcs.tes_reads_tess_factors,
-         info->tcs.tes_inputs_read, info->tcs.tes_patch_inputs_read, info->tcs.num_linked_inputs,
+         info->tcs.tes_inputs_read, info->tcs.tes_patch_inputs_read,
          info->tcs.num_linked_outputs, info->tcs.num_linked_patch_outputs, true);
 
       return true;
-- 
GitLab


From b771a532a546adc7d2ffe66e73d4f2131cc2d25c Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Sat, 7 May 2022 17:54:02 +0800
Subject: [PATCH 4/8] radeonsi: implement load_lshs_vertex_stride abi
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Reviewed-by: Timur Kristóf <timur.kristof@gmail.com>
Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/llvm/ac_nir_to_llvm.c                      | 1 +
 src/gallium/drivers/radeonsi/si_shader_internal.h  | 1 +
 src/gallium/drivers/radeonsi/si_shader_llvm.c      | 4 ++++
 src/gallium/drivers/radeonsi/si_shader_llvm_tess.c | 8 ++++----
 4 files changed, 10 insertions(+), 4 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index e45feceb018c..31d326f46d68 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -3626,6 +3626,7 @@ static void visit_intrinsic(struct ac_nir_context *ctx, nir_intrinsic_instr *ins
    case nir_intrinsic_load_ring_tess_factors_amd:
    case nir_intrinsic_load_ring_tess_offchip_amd:
    case nir_intrinsic_load_ring_esgs_amd:
+   case nir_intrinsic_load_lshs_vertex_stride_amd:
       result = ctx->abi->intrinsic_load(ctx->abi, instr->intrinsic);
       break;
    case nir_intrinsic_load_vertex_id:
diff --git a/src/gallium/drivers/radeonsi/si_shader_internal.h b/src/gallium/drivers/radeonsi/si_shader_internal.h
index 12ba6c332858..d34025c529fc 100644
--- a/src/gallium/drivers/radeonsi/si_shader_internal.h
+++ b/src/gallium/drivers/radeonsi/si_shader_internal.h
@@ -244,6 +244,7 @@ void si_llvm_gs_build_end(struct si_shader_context *ctx);
 void si_llvm_init_gs_callbacks(struct si_shader_context *ctx);
 
 /* si_shader_llvm_tess.c */
+LLVMValueRef si_get_tcs_in_vertex_dw_stride(struct si_shader_context *ctx);
 LLVMValueRef si_get_num_tcs_out_vertices(struct si_shader_context *ctx);
 void si_llvm_preload_tes_rings(struct si_shader_context *ctx);
 void si_llvm_ls_build_end(struct si_shader_context *ctx);
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm.c b/src/gallium/drivers/radeonsi/si_shader_llvm.c
index fed85ad7b5aa..9e4686aafa06 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm.c
@@ -772,6 +772,10 @@ static LLVMValueRef si_llvm_load_intrinsic(struct ac_shader_abi *abi, nir_intrin
    case nir_intrinsic_load_sample_mask_in:
       return ac_to_integer(&ctx->ac, ac_get_arg(&ctx->ac, ctx->args.sample_coverage));
 
+   case nir_intrinsic_load_lshs_vertex_stride_amd:
+      return LLVMBuildShl(ctx->ac.builder, si_get_tcs_in_vertex_dw_stride(ctx),
+                          LLVMConstInt(ctx->ac.i32, 2, 0), "");
+
    default:
       return NULL;
    }
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c b/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c
index df228eed990e..72c355378bb9 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c
@@ -149,7 +149,7 @@ LLVMValueRef si_get_num_tcs_out_vertices(struct si_shader_context *ctx)
                        si_unpack_param(ctx, ctx->tcs_offchip_layout, 6, 5), ctx->ac.i32_1, "");
 }
 
-static LLVMValueRef get_tcs_in_vertex_dw_stride(struct si_shader_context *ctx)
+LLVMValueRef si_get_tcs_in_vertex_dw_stride(struct si_shader_context *ctx)
 {
    unsigned stride;
 
@@ -419,7 +419,7 @@ static LLVMValueRef si_nir_load_tcs_varyings(struct ac_shader_abi *abi, LLVMType
            semantic == VARYING_SLOT_TESS_LEVEL_OUTER) == is_patch);
 
    if (load_input) {
-      stride = get_tcs_in_vertex_dw_stride(ctx);
+      stride = si_get_tcs_in_vertex_dw_stride(ctx);
       dw_addr = get_tcs_in_current_patch_offset(ctx);
    } else {
       if (is_patch) {
@@ -577,7 +577,7 @@ static void si_copy_tcs_inputs(struct si_shader_context *ctx)
    buffer = get_tess_ring_descriptor(ctx, TESS_OFFCHIP_RING_TCS);
    buffer_offset = ac_get_arg(&ctx->ac, ctx->args.tess_offchip_offset);
 
-   lds_vertex_stride = get_tcs_in_vertex_dw_stride(ctx);
+   lds_vertex_stride = si_get_tcs_in_vertex_dw_stride(ctx);
    lds_base = get_tcs_in_current_patch_offset(ctx);
    lds_base = ac_build_imad(&ctx->ac, invocation_id, lds_vertex_stride, lds_base);
 
@@ -886,7 +886,7 @@ void si_llvm_ls_build_end(struct si_shader_context *ctx)
    } else {
       vertex_id = ac_get_arg(&ctx->ac, ctx->args.vs_rel_patch_id);
    }
-   LLVMValueRef vertex_dw_stride = get_tcs_in_vertex_dw_stride(ctx);
+   LLVMValueRef vertex_dw_stride = si_get_tcs_in_vertex_dw_stride(ctx);
    LLVMValueRef base_dw_addr = LLVMBuildMul(ctx->ac.builder, vertex_id, vertex_dw_stride, "");
    LLVMValueRef *addrs = ctx->abi.outputs;
    unsigned ret_offset = 8 + GFX9_TCS_NUM_USER_SGPR + 2;
-- 
GitLab


From 987601e33b436987892eb8fbe66b82864f60dca4 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Sun, 8 May 2022 22:10:58 +0800
Subject: [PATCH 5/8] radeonsi: add tcs_vgpr_only_inputs parameter to
 si_get_nir_shader

Will be used latter.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/gallium/drivers/radeonsi/si_shader.c          | 5 +++--
 src/gallium/drivers/radeonsi/si_shader_internal.h | 3 ++-
 src/gallium/drivers/radeonsi/si_shader_llvm.c     | 5 +++--
 src/gallium/drivers/radeonsi/si_state.c           | 3 ++-
 4 files changed, 10 insertions(+), 6 deletions(-)

diff --git a/src/gallium/drivers/radeonsi/si_shader.c b/src/gallium/drivers/radeonsi/si_shader.c
index 4b1c3f7f7cea..b9ce10945b8d 100644
--- a/src/gallium/drivers/radeonsi/si_shader.c
+++ b/src/gallium/drivers/radeonsi/si_shader.c
@@ -1492,7 +1492,8 @@ static bool si_nir_kill_outputs(nir_shader *nir, const union si_shader_key *key)
 
 struct nir_shader *si_get_nir_shader(struct si_shader_selector *sel,
                                      const union si_shader_key *key,
-                                     bool *free_nir)
+                                     bool *free_nir,
+                                     uint64_t tcs_vgpr_only_inputs)
 {
    nir_shader *nir;
    *free_nir = false;
@@ -1681,7 +1682,7 @@ bool si_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *compi
 {
    struct si_shader_selector *sel = shader->selector;
    bool free_nir;
-   struct nir_shader *nir = si_get_nir_shader(sel, &shader->key, &free_nir);
+   struct nir_shader *nir = si_get_nir_shader(sel, &shader->key, &free_nir, 0);
 
    /* Assign param export indices. */
    if ((sel->stage == MESA_SHADER_VERTEX ||
diff --git a/src/gallium/drivers/radeonsi/si_shader_internal.h b/src/gallium/drivers/radeonsi/si_shader_internal.h
index d34025c529fc..907dc04b796a 100644
--- a/src/gallium/drivers/radeonsi/si_shader_internal.h
+++ b/src/gallium/drivers/radeonsi/si_shader_internal.h
@@ -176,7 +176,8 @@ void si_get_vs_prolog_key(const struct si_shader_info *info, unsigned num_input_
                           struct si_shader *shader_out, union si_shader_part_key *key);
 struct nir_shader *si_get_nir_shader(struct si_shader_selector *sel,
                                      const union si_shader_key *key,
-                                     bool *free_nir);
+                                     bool *free_nir,
+                                     uint64_t tcs_vgpr_only_inputs);
 void si_get_tcs_epilog_key(struct si_shader *shader, union si_shader_part_key *key);
 bool si_need_ps_prolog(const union si_shader_part_key *key);
 void si_get_ps_prolog_key(struct si_shader *shader, union si_shader_part_key *key,
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm.c b/src/gallium/drivers/radeonsi/si_shader_llvm.c
index 9e4686aafa06..ec6acdb67b60 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm.c
@@ -1252,7 +1252,8 @@ bool si_llvm_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *
          shader_ls.key.ge.opt.inline_uniforms = false; /* only TCS can inline uniforms */
          shader_ls.is_monolithic = true;
 
-         nir = si_get_nir_shader(ls, &shader_ls.key, &free_nir);
+         nir = si_get_nir_shader(ls, &shader_ls.key, &free_nir,
+                                 sel->info.tcs_vgpr_only_inputs);
          si_update_shader_binary_info(shader, nir);
 
          if (!si_llvm_translate_nir(&ctx, &shader_ls, nir, free_nir, false)) {
@@ -1312,7 +1313,7 @@ bool si_llvm_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *
          shader_es.key.ge.opt.kill_outputs = 0;
          shader_es.is_monolithic = true;
 
-         nir = si_get_nir_shader(es, &shader_es.key, &free_nir);
+         nir = si_get_nir_shader(es, &shader_es.key, &free_nir, 0);
          si_update_shader_binary_info(shader, nir);
 
          if (!si_llvm_translate_nir(&ctx, &shader_es, nir, free_nir, false)) {
diff --git a/src/gallium/drivers/radeonsi/si_state.c b/src/gallium/drivers/radeonsi/si_state.c
index ee19553f370f..6e5a7b2ff2d4 100644
--- a/src/gallium/drivers/radeonsi/si_state.c
+++ b/src/gallium/drivers/radeonsi/si_state.c
@@ -657,7 +657,8 @@ static bool si_check_blend_dst_sampler_noop(struct si_context *sctx)
       struct si_shader_selector *sel = sctx->shader.ps.cso;
       bool free_nir;
       if (unlikely(sel->info.writes_1_if_tex_is_1 == 0xff)) {
-         struct nir_shader *nir = si_get_nir_shader(sel, &sctx->shader.ps.key, &free_nir);
+         struct nir_shader *nir =
+            si_get_nir_shader(sel, &sctx->shader.ps.key, &free_nir, 0);
 
          /* Determine if this fragment shader always writes vec4(1) if a specific texture
           * is all 1s.
-- 
GitLab


From 63077488451d4e6f3176198c908a2360c6d8801e Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Mon, 9 May 2022 21:42:47 +0800
Subject: [PATCH 6/8] ac/nir: skip gl_Layer/gl_ViewportIndex write for LS
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

This is from radeonsi.

Reviewed-by: Timur Kristóf <timur.kristof@gmail.com>
Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/common/ac_nir_lower_tess_io_to_mem.c | 19 +++++++++++++++++++
 1 file changed, 19 insertions(+)

diff --git a/src/amd/common/ac_nir_lower_tess_io_to_mem.c b/src/amd/common/ac_nir_lower_tess_io_to_mem.c
index 0fe115f0493e..7aec472b490c 100644
--- a/src/amd/common/ac_nir_lower_tess_io_to_mem.c
+++ b/src/amd/common/ac_nir_lower_tess_io_to_mem.c
@@ -207,6 +207,25 @@ lower_ls_output_store(nir_builder *b,
    if (intrin->intrinsic != nir_intrinsic_store_output)
       return false;
 
+   /* The ARB_shader_viewport_layer_array spec contains the
+    * following issue:
+    *
+    *    2) What happens if gl_ViewportIndex or gl_Layer is
+    *    written in the vertex shader and a geometry shader is
+    *    present?
+    *
+    *    RESOLVED: The value written by the last vertex processing
+    *    stage is used. If the last vertex processing stage
+    *    (vertex, tessellation evaluation or geometry) does not
+    *    statically assign to gl_ViewportIndex or gl_Layer, index
+    *    or layer zero is assumed.
+    *
+    * So writes to those outputs in VS-as-LS are simply ignored.
+    */
+   unsigned semantic = nir_intrinsic_io_semantics(intrin).location;
+   if (semantic == VARYING_SLOT_LAYER || semantic == VARYING_SLOT_VIEWPORT)
+      return false;
+
    lower_tess_io_state *st = (lower_tess_io_state *) state;
 
    /* If this is a temp-only TCS input, we don't need to use shared memory at all. */
-- 
GitLab


From fe0d72c25b8736368264b6b1604601ea5fd0105c Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timur=20Krist=C3=B3f?= <timur.kristof@gmail.com>
Date: Thu, 12 May 2022 15:48:24 +0200
Subject: [PATCH 7/8] ac/nir: Add remappability to tess and ESGS I/O lowering
 passes.
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Timur Kristóf <timur.kristof@gmail.com>
---
 src/amd/common/ac_nir.c                      | 31 ++++++++++++++++++++
 src/amd/common/ac_nir.h                      | 16 ++++++++++
 src/amd/common/ac_nir_lower_esgs_io_to_mem.c | 11 +++++--
 src/amd/common/ac_nir_lower_tess_io_to_mem.c | 21 +++++++++----
 src/amd/vulkan/radv_shader.c                 | 14 ++++-----
 src/compiler/nir/nir_builder.h               | 26 ----------------
 6 files changed, 79 insertions(+), 40 deletions(-)

diff --git a/src/amd/common/ac_nir.c b/src/amd/common/ac_nir.c
index c2f2d66ba54b..0a25cee6aa56 100644
--- a/src/amd/common/ac_nir.c
+++ b/src/amd/common/ac_nir.c
@@ -35,6 +35,37 @@ ac_nir_load_arg(nir_builder *b, const struct ac_shader_args *ac_args, struct ac_
       return nir_load_vector_arg_amd(b, num_components, .base = arg.arg_index);
 }
 
+/**
+ * This function takes an I/O intrinsic like load/store_input,
+ * and emits a sequence that calculates the full offset of that instruction,
+ * including a stride to the base and component offsets.
+ */
+nir_ssa_def *
+ac_nir_calc_io_offset(nir_builder *b,
+                      nir_intrinsic_instr *intrin,
+                      nir_ssa_def *base_stride,
+                      unsigned component_stride,
+                      ac_nir_map_io_driver_location map_io)
+{
+   unsigned base = nir_intrinsic_base(intrin);
+   unsigned semantic = nir_intrinsic_io_semantics(intrin).location;
+   unsigned mapped_driver_location = map_io ? map_io(semantic) : base;
+
+   /* base is the driver_location, which is in slots (1 slot = 4x4 bytes) */
+   nir_ssa_def *base_op = nir_imul_imm(b, base_stride, mapped_driver_location);
+
+   /* offset should be interpreted in relation to the base,
+    * so the instruction effectively reads/writes another input/output
+    * when it has an offset
+    */
+   nir_ssa_def *offset_op = nir_imul(b, base_stride, nir_ssa_for_src(b, *nir_get_io_offset_src(intrin), 1));
+
+   /* component is in bytes */
+   unsigned const_op = nir_intrinsic_component(intrin) * component_stride;
+
+   return nir_iadd_imm_nuw(b, nir_iadd_nuw(b, base_op, offset_op), const_op);
+}
+
 bool
 ac_nir_lower_indirect_derefs(nir_shader *shader,
                              enum amd_gfx_level gfx_level)
diff --git a/src/amd/common/ac_nir.h b/src/amd/common/ac_nir.h
index 966f982f38b5..aaa9fe883091 100644
--- a/src/amd/common/ac_nir.h
+++ b/src/amd/common/ac_nir.h
@@ -48,6 +48,9 @@ enum
    AC_EXP_PARAM_UNDEFINED = 255, /* deprecated, use AC_EXP_PARAM_DEFAULT_VAL_0000 instead */
 };
 
+/* Maps I/O semantics to the actual location used by the lowering pass. */
+typedef unsigned (*ac_nir_map_io_driver_location)(unsigned semantic);
+
 /* Forward declaration of nir_builder so we don't have to include nir_builder.h here */
 struct nir_builder;
 typedef struct nir_builder nir_builder;
@@ -55,21 +58,31 @@ typedef struct nir_builder nir_builder;
 nir_ssa_def *
 ac_nir_load_arg(nir_builder *b, const struct ac_shader_args *ac_args, struct ac_arg arg);
 
+nir_ssa_def *
+ac_nir_calc_io_offset(nir_builder *b,
+                      nir_intrinsic_instr *intrin,
+                      nir_ssa_def *base_stride,
+                      unsigned component_stride,
+                      ac_nir_map_io_driver_location map_io);
+
 bool ac_nir_optimize_outputs(nir_shader *nir, bool sprite_tex_disallowed,
                              int8_t slot_remap[NUM_TOTAL_VARYING_SLOTS],
                              uint8_t param_export_index[NUM_TOTAL_VARYING_SLOTS]);
 
 void
 ac_nir_lower_ls_outputs_to_mem(nir_shader *ls,
+                               ac_nir_map_io_driver_location map,
                                bool tcs_in_out_eq,
                                uint64_t tcs_temp_only_inputs);
 
 void
 ac_nir_lower_hs_inputs_to_mem(nir_shader *shader,
+                              ac_nir_map_io_driver_location map,
                               bool tcs_in_out_eq);
 
 void
 ac_nir_lower_hs_outputs_to_mem(nir_shader *shader,
+                               ac_nir_map_io_driver_location map,
                                enum amd_gfx_level gfx_level,
                                bool tes_reads_tessfactors,
                                uint64_t tes_inputs_read,
@@ -80,16 +93,19 @@ ac_nir_lower_hs_outputs_to_mem(nir_shader *shader,
 
 void
 ac_nir_lower_tes_inputs_to_mem(nir_shader *shader,
+                               ac_nir_map_io_driver_location map,
                                unsigned num_reserved_tcs_outputs,
                                unsigned num_reserved_tcs_patch_outputs);
 
 void
 ac_nir_lower_es_outputs_to_mem(nir_shader *shader,
+                               ac_nir_map_io_driver_location map,
                                enum amd_gfx_level gfx_level,
                                unsigned num_reserved_es_outputs);
 
 void
 ac_nir_lower_gs_inputs_to_mem(nir_shader *shader,
+                              ac_nir_map_io_driver_location map,
                               enum amd_gfx_level gfx_level,
                               unsigned num_reserved_es_outputs);
 
diff --git a/src/amd/common/ac_nir_lower_esgs_io_to_mem.c b/src/amd/common/ac_nir_lower_esgs_io_to_mem.c
index 1d5f9e9032b8..9cd7f4d6f9b0 100644
--- a/src/amd/common/ac_nir_lower_esgs_io_to_mem.c
+++ b/src/amd/common/ac_nir_lower_esgs_io_to_mem.c
@@ -44,6 +44,9 @@ typedef struct {
    /* Which hardware generation we're dealing with */
    enum amd_gfx_level gfx_level;
 
+   /* I/O semantic -> real location used by lowering. */
+   ac_nir_map_io_driver_location map_io;
+
    /* Number of ES outputs for which memory should be reserved.
     * When compacted, this should be the number of linked ES outputs.
     */
@@ -125,7 +128,7 @@ lower_es_output_store(nir_builder *b,
    unsigned write_mask = nir_intrinsic_write_mask(intrin);
 
    b->cursor = nir_before_instr(instr);
-   nir_ssa_def *io_off = nir_build_calc_io_offset(b, intrin, nir_imm_int(b, 16u), 4u);
+   nir_ssa_def *io_off = ac_nir_calc_io_offset(b, intrin, nir_imm_int(b, 16u), 4u, st->map_io);
 
    if (st->gfx_level <= GFX8) {
       /* GFX6-8: ES is a separate HW stage, data is passed from ES to GS in VRAM. */
@@ -198,7 +201,7 @@ gs_per_vertex_input_offset(nir_builder *b,
                                 : gs_per_vertex_input_vertex_offset_gfx6(b, vertex_src);
 
    unsigned base_stride = st->gfx_level >= GFX9 ? 1 : 64 /* Wave size on GFX6-8 */;
-   nir_ssa_def *io_off = nir_build_calc_io_offset(b, instr, nir_imm_int(b, base_stride * 4u), base_stride);
+   nir_ssa_def *io_off = ac_nir_calc_io_offset(b, instr, nir_imm_int(b, base_stride * 4u), base_stride, st->map_io);
    nir_ssa_def *off = nir_iadd(b, io_off, vertex_offset);
    return nir_imul_imm(b, off, 4u);
 }
@@ -230,12 +233,14 @@ filter_load_per_vertex_input(const nir_instr *instr, UNUSED const void *state)
 
 void
 ac_nir_lower_es_outputs_to_mem(nir_shader *shader,
+                               ac_nir_map_io_driver_location map,
                                enum amd_gfx_level gfx_level,
                                unsigned num_reserved_es_outputs)
 {
    lower_esgs_io_state state = {
       .gfx_level = gfx_level,
       .num_reserved_es_outputs = num_reserved_es_outputs,
+      .map_io = map,
    };
 
    nir_shader_instructions_pass(shader,
@@ -246,12 +251,14 @@ ac_nir_lower_es_outputs_to_mem(nir_shader *shader,
 
 void
 ac_nir_lower_gs_inputs_to_mem(nir_shader *shader,
+                              ac_nir_map_io_driver_location map,
                               enum amd_gfx_level gfx_level,
                               unsigned num_reserved_es_outputs)
 {
    lower_esgs_io_state state = {
       .gfx_level = gfx_level,
       .num_reserved_es_outputs = num_reserved_es_outputs,
+      .map_io = map,
    };
 
    nir_shader_lower_instructions(shader,
diff --git a/src/amd/common/ac_nir_lower_tess_io_to_mem.c b/src/amd/common/ac_nir_lower_tess_io_to_mem.c
index 7aec472b490c..9bd7cce163d9 100644
--- a/src/amd/common/ac_nir_lower_tess_io_to_mem.c
+++ b/src/amd/common/ac_nir_lower_tess_io_to_mem.c
@@ -123,6 +123,9 @@ typedef struct {
    /* Which hardware generation we're dealing with */
    enum amd_gfx_level gfx_level;
 
+   /* I/O semantic -> real location used by lowering. */
+   ac_nir_map_io_driver_location map_io;
+
    /* True if merged VS+TCS (on GFX9+) has the same number
     * of input and output patch size.
     */
@@ -237,7 +240,7 @@ lower_ls_output_store(nir_builder *b,
    nir_ssa_def *vertex_idx = nir_load_local_invocation_index(b);
    nir_ssa_def *base_off_var = nir_imul(b, vertex_idx, nir_load_lshs_vertex_stride_amd(b));
 
-   nir_ssa_def *io_off = nir_build_calc_io_offset(b, intrin, nir_imm_int(b, 16u), 4u);
+   nir_ssa_def *io_off = ac_nir_calc_io_offset(b, intrin, nir_imm_int(b, 16u), 4u, st->map_io);
    unsigned write_mask = nir_intrinsic_write_mask(intrin);
 
    nir_ssa_def *off = nir_iadd_nuw(b, base_off_var, io_off);
@@ -297,7 +300,7 @@ hs_per_vertex_input_lds_offset(nir_builder *b,
 
    nir_ssa_def *tcs_in_current_patch_offset = nir_imul(b, rel_patch_id, tcs_in_patch_stride);
 
-   nir_ssa_def *io_offset = nir_build_calc_io_offset(b, instr, nir_imm_int(b, 16u), 4u);
+   nir_ssa_def *io_offset = ac_nir_calc_io_offset(b, instr, nir_imm_int(b, 16u), 4u, st->map_io);
 
    return nir_iadd_nuw(b, nir_iadd_nuw(b, tcs_in_current_patch_offset, vertex_index_off), io_offset);
 }
@@ -321,7 +324,7 @@ hs_output_lds_offset(nir_builder *b,
    nir_ssa_def *output_patch0_offset = nir_imul(b, input_patch_size, tcs_num_patches);
 
    nir_ssa_def *off = intrin
-                    ? nir_build_calc_io_offset(b, intrin, nir_imm_int(b, 16u), 4u)
+                    ? ac_nir_calc_io_offset(b, intrin, nir_imm_int(b, 16u), 4u, st->map_io)
                     : nir_imm_int(b, 0);
 
    nir_ssa_def *rel_patch_id = nir_load_tess_rel_patch_id_amd(b);
@@ -351,7 +354,7 @@ hs_per_vertex_output_vmem_offset(nir_builder *b,
 
    nir_ssa_def *tcs_num_patches = nir_load_tcs_num_patches_amd(b);
    nir_ssa_def *attr_stride = nir_imul(b, tcs_num_patches, nir_imul_imm(b, out_vertices_per_patch, 16u));
-   nir_ssa_def *io_offset = nir_build_calc_io_offset(b, intrin, attr_stride, 4u);
+   nir_ssa_def *io_offset = ac_nir_calc_io_offset(b, intrin, attr_stride, 4u, st->map_io);
 
    nir_ssa_def *rel_patch_id = nir_load_tess_rel_patch_id_amd(b);
    nir_ssa_def *patch_offset = nir_imul(b, rel_patch_id, nir_imul_imm(b, out_vertices_per_patch, 16u));
@@ -377,7 +380,7 @@ hs_per_patch_output_vmem_offset(nir_builder *b,
    nir_ssa_def *per_patch_data_offset = nir_imul(b, tcs_num_patches, per_vertex_output_patch_size);
 
    nir_ssa_def * off = intrin
-                    ? nir_build_calc_io_offset(b, intrin, nir_imul_imm(b, tcs_num_patches, 16u), 4u)
+                    ? ac_nir_calc_io_offset(b, intrin, nir_imul_imm(b, tcs_num_patches, 16u), 4u, st->map_io)
                     : nir_imm_int(b, 0);
 
    if (const_base_offset)
@@ -648,6 +651,7 @@ filter_any_input_access(const nir_instr *instr,
 
 void
 ac_nir_lower_ls_outputs_to_mem(nir_shader *shader,
+                               ac_nir_map_io_driver_location map,
                                bool tcs_in_out_eq,
                                uint64_t tcs_temp_only_inputs)
 {
@@ -656,6 +660,7 @@ ac_nir_lower_ls_outputs_to_mem(nir_shader *shader,
    lower_tess_io_state state = {
       .tcs_in_out_eq = tcs_in_out_eq,
       .tcs_temp_only_inputs = tcs_in_out_eq ? tcs_temp_only_inputs : 0,
+      .map_io = map,
    };
 
    nir_shader_instructions_pass(shader,
@@ -666,12 +671,14 @@ ac_nir_lower_ls_outputs_to_mem(nir_shader *shader,
 
 void
 ac_nir_lower_hs_inputs_to_mem(nir_shader *shader,
+                              ac_nir_map_io_driver_location map,
                               bool tcs_in_out_eq)
 {
    assert(shader->info.stage == MESA_SHADER_TESS_CTRL);
 
    lower_tess_io_state state = {
       .tcs_in_out_eq = tcs_in_out_eq,
+      .map_io = map,
    };
 
    nir_shader_lower_instructions(shader,
@@ -682,6 +689,7 @@ ac_nir_lower_hs_inputs_to_mem(nir_shader *shader,
 
 void
 ac_nir_lower_hs_outputs_to_mem(nir_shader *shader,
+                               ac_nir_map_io_driver_location map,
                                enum amd_gfx_level gfx_level,
                                bool tes_reads_tessfactors,
                                uint64_t tes_inputs_read,
@@ -700,6 +708,7 @@ ac_nir_lower_hs_outputs_to_mem(nir_shader *shader,
       .tcs_num_reserved_outputs = num_reserved_tcs_outputs,
       .tcs_num_reserved_patch_outputs = num_reserved_tcs_patch_outputs,
       .tcs_out_patch_fits_subgroup = 32 % shader->info.tess.tcs_vertices_out == 0,
+      .map_io = map,
    };
 
    nir_shader_lower_instructions(shader,
@@ -713,6 +722,7 @@ ac_nir_lower_hs_outputs_to_mem(nir_shader *shader,
 
 void
 ac_nir_lower_tes_inputs_to_mem(nir_shader *shader,
+                               ac_nir_map_io_driver_location map,
                                unsigned num_reserved_tcs_outputs,
                                unsigned num_reserved_tcs_patch_outputs)
 {
@@ -721,6 +731,7 @@ ac_nir_lower_tes_inputs_to_mem(nir_shader *shader,
    lower_tess_io_state state = {
       .tcs_num_reserved_outputs = num_reserved_tcs_outputs,
       .tcs_num_reserved_patch_outputs = num_reserved_tcs_patch_outputs,
+      .map_io = map,
    };
 
    nir_shader_lower_instructions(shader,
diff --git a/src/amd/vulkan/radv_shader.c b/src/amd/vulkan/radv_shader.c
index c75e97f612c4..14dc7bc54671 100644
--- a/src/amd/vulkan/radv_shader.c
+++ b/src/amd/vulkan/radv_shader.c
@@ -1018,34 +1018,34 @@ radv_lower_io_to_mem(struct radv_device *device, struct radv_pipeline_stage *sta
 
    if (nir->info.stage == MESA_SHADER_VERTEX) {
       if (info->vs.as_ls) {
-         ac_nir_lower_ls_outputs_to_mem(nir, info->vs.tcs_in_out_eq,
+         ac_nir_lower_ls_outputs_to_mem(nir, NULL, info->vs.tcs_in_out_eq,
                                         info->vs.tcs_temp_only_input_mask);
          return true;
       } else if (info->vs.as_es) {
-         ac_nir_lower_es_outputs_to_mem(nir, device->physical_device->rad_info.gfx_level,
+         ac_nir_lower_es_outputs_to_mem(nir, NULL, device->physical_device->rad_info.gfx_level,
                                         info->vs.num_linked_outputs);
          return true;
       }
    } else if (nir->info.stage == MESA_SHADER_TESS_CTRL) {
-      ac_nir_lower_hs_inputs_to_mem(nir, info->vs.tcs_in_out_eq);
+      ac_nir_lower_hs_inputs_to_mem(nir, NULL, info->vs.tcs_in_out_eq);
       ac_nir_lower_hs_outputs_to_mem(
-         nir, device->physical_device->rad_info.gfx_level, info->tcs.tes_reads_tess_factors,
+         nir, NULL, device->physical_device->rad_info.gfx_level, info->tcs.tes_reads_tess_factors,
          info->tcs.tes_inputs_read, info->tcs.tes_patch_inputs_read,
          info->tcs.num_linked_outputs, info->tcs.num_linked_patch_outputs, true);
 
       return true;
    } else if (nir->info.stage == MESA_SHADER_TESS_EVAL) {
-      ac_nir_lower_tes_inputs_to_mem(nir, info->tes.num_linked_inputs,
+      ac_nir_lower_tes_inputs_to_mem(nir, NULL, info->tes.num_linked_inputs,
                                      info->tes.num_linked_patch_inputs);
 
       if (info->tes.as_es) {
-         ac_nir_lower_es_outputs_to_mem(nir, device->physical_device->rad_info.gfx_level,
+         ac_nir_lower_es_outputs_to_mem(nir, NULL, device->physical_device->rad_info.gfx_level,
                                         info->tes.num_linked_outputs);
       }
 
       return true;
    } else if (nir->info.stage == MESA_SHADER_GEOMETRY) {
-      ac_nir_lower_gs_inputs_to_mem(nir, device->physical_device->rad_info.gfx_level,
+      ac_nir_lower_gs_inputs_to_mem(nir, NULL, device->physical_device->rad_info.gfx_level,
                                     info->gs.num_linked_inputs);
       return true;
    } else if (nir->info.stage == MESA_SHADER_TASK) {
diff --git a/src/compiler/nir/nir_builder.h b/src/compiler/nir/nir_builder.h
index 928d7797f3f0..0f73655a8bca 100644
--- a/src/compiler/nir/nir_builder.h
+++ b/src/compiler/nir/nir_builder.h
@@ -1509,32 +1509,6 @@ nir_load_param(nir_builder *build, uint32_t param_idx)
    return nir_build_load_param(build, param->num_components, param->bit_size, param_idx);
 }
 
-/**
- * This function takes an I/O intrinsic like load/store_input,
- * and emits a sequence that calculates the full offset of that instruction,
- * including a stride to the base and component offsets.
- */
-static inline nir_ssa_def *
-nir_build_calc_io_offset(nir_builder *b,
-                         nir_intrinsic_instr *intrin,
-                         nir_ssa_def *base_stride,
-                         unsigned component_stride)
-{
-   /* base is the driver_location, which is in slots (1 slot = 4x4 bytes) */
-   nir_ssa_def *base_op = nir_imul_imm(b, base_stride, nir_intrinsic_base(intrin));
-
-   /* offset should be interpreted in relation to the base,
-    * so the instruction effectively reads/writes another input/output
-    * when it has an offset
-    */
-   nir_ssa_def *offset_op = nir_imul(b, base_stride, nir_ssa_for_src(b, *nir_get_io_offset_src(intrin), 1));
-
-   /* component is in bytes */
-   unsigned const_op = nir_intrinsic_component(intrin) * component_stride;
-
-   return nir_iadd_imm_nuw(b, nir_iadd_nuw(b, base_op, offset_op), const_op);
-}
-
 /* calculate a `(1 << value) - 1` in ssa without overflows */
 static inline nir_ssa_def *
 nir_mask(nir_builder *b, nir_ssa_def *bits, unsigned dst_bit_size)
-- 
GitLab


From 4e7a3bdf8e18051366f31da40de78f039587715a Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Mon, 9 May 2022 21:28:26 +0800
Subject: [PATCH 8/8] radeonsi: replace llvm ls/hs interface lds ops with nir
 lowered ones

Use ac nir lower pass to generate these lds load/store ops explicitly.

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 src/amd/llvm/ac_nir_to_llvm.c                 |   9 +-
 src/amd/llvm/ac_shader_abi.h                  |   3 +-
 src/gallium/drivers/radeonsi/si_shader.c      |  42 ++++++-
 .../drivers/radeonsi/si_shader_internal.h     |   1 -
 src/gallium/drivers/radeonsi/si_shader_llvm.c |   7 +-
 .../drivers/radeonsi/si_shader_llvm_tess.c    | 105 +++++-------------
 6 files changed, 70 insertions(+), 97 deletions(-)

diff --git a/src/amd/llvm/ac_nir_to_llvm.c b/src/amd/llvm/ac_nir_to_llvm.c
index 31d326f46d68..7464a139b8c2 100644
--- a/src/amd/llvm/ac_nir_to_llvm.c
+++ b/src/amd/llvm/ac_nir_to_llvm.c
@@ -3459,17 +3459,10 @@ static LLVMValueRef visit_load(struct ac_nir_context *ctx, nir_intrinsic_instr *
 
    if (ctx->stage == MESA_SHADER_TESS_CTRL ||
        (ctx->stage == MESA_SHADER_TESS_EVAL && !is_output)) {
-      bool vertex_index_is_invoc_id =
-         vertex_index_src &&
-         vertex_index_src->ssa->parent_instr->type == nir_instr_type_intrinsic &&
-         nir_instr_as_intrinsic(vertex_index_src->ssa->parent_instr)->intrinsic ==
-         nir_intrinsic_load_invocation_id;
-
       LLVMValueRef result = ctx->abi->load_tess_varyings(ctx->abi, component_type,
                                                          vertex_index, indir_index,
                                                          base, component,
-                                                         count, !is_output,
-                                                         vertex_index_is_invoc_id);
+                                                         count, !is_output);
       if (instr->dest.ssa.bit_size == 16) {
          result = ac_to_integer(&ctx->ac, result);
          result = LLVMBuildTrunc(ctx->ac.builder, result, dest_type, "");
diff --git a/src/amd/llvm/ac_shader_abi.h b/src/amd/llvm/ac_shader_abi.h
index 0c370ffbc9ba..4cf7bbfd7fea 100644
--- a/src/amd/llvm/ac_shader_abi.h
+++ b/src/amd/llvm/ac_shader_abi.h
@@ -67,8 +67,7 @@ struct ac_shader_abi {
    LLVMValueRef (*load_tess_varyings)(struct ac_shader_abi *abi, LLVMTypeRef type,
                                       LLVMValueRef vertex_index, LLVMValueRef param_index,
                                       unsigned driver_location, unsigned component,
-                                      unsigned num_components,
-                                      bool load_inputs, bool vertex_index_is_invoc_id);
+                                      unsigned num_components, bool load_inputs);
 
    void (*store_tcs_outputs)(struct ac_shader_abi *abi,
                              LLVMValueRef vertex_index, LLVMValueRef param_index,
diff --git a/src/gallium/drivers/radeonsi/si_shader.c b/src/gallium/drivers/radeonsi/si_shader.c
index b9ce10945b8d..aaa4531136d7 100644
--- a/src/gallium/drivers/radeonsi/si_shader.c
+++ b/src/gallium/drivers/radeonsi/si_shader.c
@@ -1490,6 +1490,31 @@ static bool si_nir_kill_outputs(nir_shader *nir, const union si_shader_key *key)
    return progress;
 }
 
+static unsigned si_map_io_driver_location(unsigned semantic)
+{
+   return si_shader_io_get_unique_index(semantic, false);
+}
+
+static bool si_lower_io_mem(const union si_shader_key *key,
+                            nir_shader *nir,
+                            uint64_t tcs_vgpr_only_inputs)
+{
+   if (nir->info.stage == MESA_SHADER_VERTEX) {
+      if (key->ge.as_ls) {
+         ac_nir_lower_ls_outputs_to_mem(nir, si_map_io_driver_location,
+                                        key->ge.opt.same_patch_vertices,
+                                        tcs_vgpr_only_inputs);
+         return true;
+      }
+   } else if (nir->info.stage == MESA_SHADER_TESS_CTRL) {
+      ac_nir_lower_hs_inputs_to_mem(nir, si_map_io_driver_location,
+                                    key->ge.opt.same_patch_vertices);
+      return true;
+   }
+
+   return false;
+}
+
 struct nir_shader *si_get_nir_shader(struct si_shader_selector *sel,
                                      const union si_shader_key *key,
                                      bool *free_nir,
@@ -1603,10 +1628,23 @@ struct nir_shader *si_get_nir_shader(struct si_shader_selector *sel,
     * this should be done after that.
     */
    progress2 |= ac_nir_lower_indirect_derefs(nir, sel->screen->info.gfx_level);
-   if (progress2)
+
+   bool opt_offsets = false;
+   opt_offsets |= si_lower_io_mem(key, nir, tcs_vgpr_only_inputs);
+
+   if (progress2 || opt_offsets)
       si_nir_opts(sel->screen, nir, false);
 
-   if (progress || progress2)
+   if (opt_offsets) {
+      static const nir_opt_offsets_options offset_options = {
+         .uniform_max = 0,
+         .buffer_max = ~0,
+         .shared_max = ~0,
+      };
+      NIR_PASS_V(nir, nir_opt_offsets, &offset_options);
+   }
+
+   if (progress || progress2 || opt_offsets)
       si_nir_late_opts(nir);
 
    /* This helps LLVM form VMEM clauses and thus get more GPU cache hits.
diff --git a/src/gallium/drivers/radeonsi/si_shader_internal.h b/src/gallium/drivers/radeonsi/si_shader_internal.h
index 907dc04b796a..ee04b3708d7f 100644
--- a/src/gallium/drivers/radeonsi/si_shader_internal.h
+++ b/src/gallium/drivers/radeonsi/si_shader_internal.h
@@ -39,7 +39,6 @@ struct si_shader_output_values {
 struct si_shader_context {
    struct ac_llvm_context ac;
    struct si_shader *shader;
-   struct si_shader_selector *next_shader_sel;
    struct si_screen *screen;
    struct pipe_stream_output_info so;
 
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm.c b/src/gallium/drivers/radeonsi/si_shader_llvm.c
index ec6acdb67b60..bb24d1378e1f 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm.c
@@ -743,10 +743,10 @@ static LLVMValueRef si_llvm_load_intrinsic(struct ac_shader_abi *abi, nir_intrin
    }
 
    case nir_intrinsic_load_tess_level_outer:
-      return abi->load_tess_varyings(abi, ctx->ac.f32, NULL, NULL, info->num_inputs, 0, 4, true, false);
+      return abi->load_tess_varyings(abi, ctx->ac.f32, NULL, NULL, info->num_inputs, 0, 4, true);
 
    case nir_intrinsic_load_tess_level_inner:
-      return abi->load_tess_varyings(abi, ctx->ac.f32, NULL, NULL, info->num_inputs + 1, 0, 4, true, false);
+      return abi->load_tess_varyings(abi, ctx->ac.f32, NULL, NULL, info->num_inputs + 1, 0, 4, true);
 
    case nir_intrinsic_load_tess_level_outer_default:
    case nir_intrinsic_load_tess_level_inner_default: {
@@ -1240,9 +1240,6 @@ bool si_llvm_compile_shader(struct si_screen *sscreen, struct ac_llvm_compiler *
          si_llvm_build_tcs_epilog(&ctx, &tcs_epilog_key);
          parts[3] = ctx.main_fn;
 
-         /* VS as LS main part */
-         ctx.next_shader_sel = ctx.shader->selector;
-
          struct si_shader shader_ls = {};
          shader_ls.selector = ls;
          shader_ls.key.ge.part.vs.prolog = shader->key.ge.part.tcs.ls_prolog;
diff --git a/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c b/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c
index 72c355378bb9..146a05fce273 100644
--- a/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c
+++ b/src/gallium/drivers/radeonsi/si_shader_llvm_tess.c
@@ -384,44 +384,31 @@ void si_llvm_preload_tes_rings(struct si_shader_context *ctx)
 static LLVMValueRef si_nir_load_tcs_varyings(struct ac_shader_abi *abi, LLVMTypeRef type,
                                              LLVMValueRef vertex_index, LLVMValueRef param_index,
                                              unsigned driver_location, unsigned component,
-                                             unsigned num_components, bool load_input,
-                                             bool vertex_index_is_invoc_id)
+                                             unsigned num_components, bool load_input)
 {
    struct si_shader_context *ctx = si_shader_context_from_abi(abi);
    struct si_shader_info *info = &ctx->shader->selector->info;
-   LLVMValueRef dw_addr, stride;
-   ubyte semantic;
+   LLVMValueRef value[4];
 
    if (load_input) {
-      semantic = info->input[driver_location].semantic;
-   } else {
-      semantic = info->output_semantic[driver_location];
-   }
+      assert(ctx->shader->key.ge.opt.same_patch_vertices && !param_index);
 
-   /* Load the TCS input from a VGPR if possible. */
-   if (ctx->shader->key.ge.opt.same_patch_vertices &&
-       load_input && vertex_index_is_invoc_id && !param_index) {
-      unsigned func_param = ctx->args.tcs_rel_ids.arg_index + 1 +
-                            si_shader_io_get_unique_index(semantic, false) * 4;
-      LLVMValueRef value[4];
+      /* Load the TCS input from a VGPR. */
+      unsigned func_param = ctx->args.tcs_rel_ids.arg_index + 1 + driver_location * 4;
 
       for (unsigned i = component; i < component + num_components; i++) {
          value[i] = LLVMGetParam(ctx->main_fn, func_param + i);
          value[i] = LLVMBuildBitCast(ctx->ac.builder, value[i], type, "");
       }
+   } else {
+      ubyte semantic = info->output_semantic[driver_location];
 
-      return ac_build_varying_gather_values(&ctx->ac, value, num_components, component);
-   }
-
-   bool is_patch = vertex_index == NULL;
-   assert((semantic >= VARYING_SLOT_PATCH0 ||
-           semantic == VARYING_SLOT_TESS_LEVEL_INNER ||
-           semantic == VARYING_SLOT_TESS_LEVEL_OUTER) == is_patch);
+      bool is_patch = vertex_index == NULL;
+      assert((semantic >= VARYING_SLOT_PATCH0 ||
+              semantic == VARYING_SLOT_TESS_LEVEL_INNER ||
+              semantic == VARYING_SLOT_TESS_LEVEL_OUTER) == is_patch);
 
-   if (load_input) {
-      stride = si_get_tcs_in_vertex_dw_stride(ctx);
-      dw_addr = get_tcs_in_current_patch_offset(ctx);
-   } else {
+      LLVMValueRef dw_addr, stride;
       if (is_patch) {
          stride = NULL;
          dw_addr = get_tcs_out_current_patch_data_offset(ctx);
@@ -429,14 +416,13 @@ static LLVMValueRef si_nir_load_tcs_varyings(struct ac_shader_abi *abi, LLVMType
          stride = get_tcs_out_vertex_dw_stride(ctx);
          dw_addr = get_tcs_out_current_patch_offset(ctx);
       }
-   }
 
-   dw_addr = get_dw_address_from_generic_indices(ctx, stride, dw_addr, vertex_index, param_index,
-                                                 semantic);
+      dw_addr = get_dw_address_from_generic_indices(ctx, stride, dw_addr, vertex_index,
+                                                    param_index, semantic);
 
-   LLVMValueRef value[4];
-   for (unsigned i = component; i < component + num_components; i++)
-      value[i] = lshs_lds_load(ctx, type, i, dw_addr);
+      for (unsigned i = component; i < component + num_components; i++)
+         value[i] = lshs_lds_load(ctx, type, i, dw_addr);
+   }
 
    return ac_build_varying_gather_values(&ctx->ac, value, num_components, component);
 }
@@ -444,8 +430,7 @@ static LLVMValueRef si_nir_load_tcs_varyings(struct ac_shader_abi *abi, LLVMType
 static LLVMValueRef si_nir_load_input_tes(struct ac_shader_abi *abi, LLVMTypeRef type,
                                           LLVMValueRef vertex_index, LLVMValueRef param_index,
                                           unsigned driver_location, unsigned component,
-                                          unsigned num_components,
-                                          bool load_input, bool vertex_index_is_invoc_id)
+                                          unsigned num_components, bool load_input)
 {
    struct si_shader_context *ctx = si_shader_context_from_abi(abi);
    struct si_shader_info *info = &ctx->shader->selector->info;
@@ -877,58 +862,20 @@ void si_llvm_ls_build_end(struct si_shader_context *ctx)
 {
    struct si_shader *shader = ctx->shader;
    struct si_shader_info *info = &shader->selector->info;
-   unsigned i, chan;
-   LLVMValueRef vertex_id;
-   if (ctx->screen->info.gfx_level >= GFX11) {
-      vertex_id = ac_build_imad(&ctx->ac, si_unpack_param(ctx, ctx->args.tcs_wave_id, 0, 5),
-                                LLVMConstInt(ctx->ac.i32, ctx->ac.wave_size, 0),
-                                ac_get_thread_id(&ctx->ac));
-   } else {
-      vertex_id = ac_get_arg(&ctx->ac, ctx->args.vs_rel_patch_id);
-   }
-   LLVMValueRef vertex_dw_stride = si_get_tcs_in_vertex_dw_stride(ctx);
-   LLVMValueRef base_dw_addr = LLVMBuildMul(ctx->ac.builder, vertex_id, vertex_dw_stride, "");
    LLVMValueRef *addrs = ctx->abi.outputs;
    unsigned ret_offset = 8 + GFX9_TCS_NUM_USER_SGPR + 2;
 
-   /* Write outputs to LDS. The next shader (TCS aka HS) will read
-    * its inputs from it. */
-   for (i = 0; i < info->num_outputs; i++) {
-      unsigned semantic = info->output_semantic[i];
-
-      /* The ARB_shader_viewport_layer_array spec contains the
-       * following issue:
-       *
-       *    2) What happens if gl_ViewportIndex or gl_Layer is
-       *    written in the vertex shader and a geometry shader is
-       *    present?
-       *
-       *    RESOLVED: The value written by the last vertex processing
-       *    stage is used. If the last vertex processing stage
-       *    (vertex, tessellation evaluation or geometry) does not
-       *    statically assign to gl_ViewportIndex or gl_Layer, index
-       *    or layer zero is assumed.
-       *
-       * So writes to those outputs in VS-as-LS are simply ignored.
-       */
-      if (semantic == VARYING_SLOT_LAYER || semantic == VARYING_SLOT_VIEWPORT)
-         continue;
-
-      int param = si_shader_io_get_unique_index(semantic, false);
-      LLVMValueRef dw_addr =
-         LLVMBuildAdd(ctx->ac.builder, base_dw_addr, LLVMConstInt(ctx->ac.i32, param * 4, 0), "");
-
-      for (chan = 0; chan < 4; chan++) {
-         if (!(info->output_usagemask[i] & (1 << chan)))
-            continue;
+   if (shader->key.ge.opt.same_patch_vertices) {
+      for (unsigned i = 0; i < info->num_outputs; i++) {
+         unsigned semantic = info->output_semantic[i];
+         int param = si_shader_io_get_unique_index(semantic, false);
 
-         LLVMValueRef value = LLVMBuildLoad(ctx->ac.builder, addrs[4 * i + chan], "");
+         for (unsigned chan = 0; chan < 4; chan++) {
+            if (!(info->output_usagemask[i] & (1 << chan)))
+               continue;
 
-         if (!shader->key.ge.opt.same_patch_vertices ||
-             !(ctx->next_shader_sel->info.tcs_vgpr_only_inputs & (1ull << semantic)))
-            lshs_lds_store(ctx, chan, dw_addr, value);
+            LLVMValueRef value = LLVMBuildLoad(ctx->ac.builder, addrs[4 * i + chan], "");
 
-         if (shader->key.ge.opt.same_patch_vertices) {
             ctx->return_value = LLVMBuildInsertValue(ctx->ac.builder, ctx->return_value,
                                                      value, ret_offset + param * 4 + chan, "");
          }
-- 
GitLab

