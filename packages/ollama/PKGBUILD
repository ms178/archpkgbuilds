pkgbase=ollama
pkgname=(ollama ollama-rocm)
pkgver=0.5.13
pkgrel=2.1
pkgdesc='Create, run and share large language models (LLMs)'
arch=(x86_64)
url='https://github.com/ollama/ollama'
license=(MIT)
options=('!lto') # Disable LTO to avoid conflicts with PGO
makedepends=(cmake ninja git go hipblas clblast)
source=(git+https://github.com/ollama/ollama#tag=v$pkgver
        ollama-ld.conf
        ollama.service
        sysusers.conf
        tmpfiles.d
        workload.txt)
b2sums=('SKIP')

prepare() {
  cd ollama

  # Remove runtime dependencies from CMake installation to avoid unnecessary system dependencies
  sed -i 's/PRE_INCLUDE_REGEXES.*/PRE_INCLUDE_REGEXES = ""/' CMakeLists.txt
}

build() {
  export CGO_CPPFLAGS="${CPPFLAGS}"
  export CGO_CFLAGS="${CFLAGS} -march=native -mtune=native -fprofile-generate"
  export CGO_CXXFLAGS="${CXXFLAGS} -march=native -mtune=native -fprofile-generate"
  export CGO_LDFLAGS="${LDFLAGS} -march=native -mtune=native -fprofile-generate"
  export GOPATH="${srcdir}"
  export GOFLAGS="-buildmode=pie -mod=readonly -modcacherw '-ldflags=-linkmode=external -compressdwarf=false -X=github.com/ollama/ollama/version.Version=$pkgver -X=github.com/ollama/ollama/server.mode=release' -gcflags=all=-B -trimpath -buildvcs=false"

  cd ollama

  # Configure CMake with ROCm support for Vega 64 (gfx900) and explicitly disable CUDA
  cmake -B build -G Ninja \
    -DAMDGPU_TARGETS="gfx900" \
    -DGGML_CUDA=OFF \
    -DCMAKE_INSTALL_PREFIX=/usr
  cmake --build build

  # Stage 1: Build with instrumentation for PGO
  go build -gcflags="-N -l" -o ollama-instrumented .

  # Debugging: Print current directory and verify files
  echo "Debug: Current directory: $(pwd)"
  echo "Debug: Listing files in parent directory:"
  ls -l ../
  echo "Debug: Checking for workload.txt:"
  if [[ ! -f ../workload.txt ]]; then
    echo "Error: workload.txt not found in ${srcdir}"
    exit 1
  fi
  echo "Debug: workload.txt exists and is readable"
  echo "Debug: Checking for ollama-instrumented binary:"
  if [[ ! -x ollama-instrumented ]]; then
    echo "Error: ollama-instrumented binary not found or not executable"
    exit 1
  fi
  echo "Debug: ollama-instrumented binary exists and is executable"

  # Start the Ollama server in the background
  echo "Starting Ollama server for PGO workload..."
  ./ollama-instrumented serve &
  ollama_pid=$!
  sleep 5  # Wait for the server to start

  # Run the representative workload to generate profiling data
  echo "Running PGO workload with deepseek-r1:8b..."
  if ! (while IFS= read -r line; do
    if [[ -n "$line" && ! "$line" =~ ^# ]]; then
      echo "Processing prompt: $line"
      if ! ./ollama-instrumented run deepseek-r1:8b "$line"; then
        echo "Error: Failed to process prompt: $line"
        kill $ollama_pid
        exit 1
      fi
    fi
  done < ../workload.txt); then
    echo "Error: PGO workload execution failed"
    kill $ollama_pid
    exit 1
  fi

  # Stop the Ollama server
  echo "Stopping Ollama server..."
  kill $ollama_pid

  # Stage 2: Rebuild with PGO data, disabling warnings-as-errors and ensuring profile data is used
  echo "Rebuilding with PGO optimizations..."
  export CGO_CFLAGS="${CFLAGS} -march=native -mtune=native -fprofile-use -fprofile-correction -Wno-error -Wno-missing-profile"
  export CGO_CXXFLAGS="${CXXFLAGS} -march=native -mtune=native -fprofile-use -fprofile-correction -Wno-error -Wno-missing-profile"
  export CGO_LDFLAGS="${LDFLAGS} -march=native -mtune=native -fprofile-use -fprofile-correction -Wno-error -Wno-missing-profile"
  cmake --build build --clean-first
  go build -o ollama .
}

check() {
  cd ollama
  ./ollama --version > /dev/null
  go test .
}

package_ollama() {
  DESTDIR="$pkgdir" cmake --install ollama/build --component CPU

  install -Dm755 ollama/ollama "$pkgdir/usr/bin/ollama"
  install -dm755 "$pkgdir/var/lib/ollama"
  install -Dm644 ollama.service "$pkgdir/usr/lib/systemd/system/ollama.service"
  install -Dm644 sysusers.conf "$pkgdir/usr/lib/sysusers.d/ollama.conf"
  install -Dm644 tmpfiles.d "$pkgdir/usr/lib/tmpfiles.d/ollama.conf"
  install -Dm644 ollama/LICENSE "$pkgdir/usr/share/licenses/$pkgname/LICENSE"

  ln -s /var/lib/ollama "$pkgdir/usr/share/ollama"
}

package_ollama-rocm() {
  pkgdesc='Create, run and share large language models (LLMs) with ROCm'
  depends+=(ollama hipblas)

  DESTDIR="$pkgdir" cmake --install ollama/build --component HIP
  rm -rf "$pkgdir"/usr/lib/ollama/rocm/rocblas/library
}
