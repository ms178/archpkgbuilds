pkgbase=harfbuzz-git
pkgname=(harfbuzz-git harfbuzz-icu-git)
pkgver=12.3.0
pkgrel=2.1
pkgdesc="OpenType text shaping engine"
url="https://www.freedesktop.org/wiki/Software/HarfBuzz"
arch=(x86_64)
license=(MIT)
depends=(
  freetype2
  glib2
  graphite
)
makedepends=(
  cairo
  clang
  git
  gobject-introspection
  icu
  lld
  llvm
  meson
  python
  python-fonttools
  python-setuptools
  ragel
  # Fonts for comprehensive PGO training workload
  noto-fonts
  noto-fonts-cjk
  ttf-dejavu
)
source=("git+https://github.com/harfbuzz/harfbuzz")
sha256sums=('SKIP')

pkgver() {
  cd harfbuzz
  git describe --tags | sed 's/-/+/g'
}

# Comprehensive PGO training workload
_run_training_workload() {
  local build_dir="$1"
  local run_num="$2"

  echo "==> PGO Training Run $run_num: Executing comprehensive workload..."

  local hb_shape="$srcdir/$build_dir/util/hb-shape"
  local hb_subset="$srcdir/$build_dir/util/hb-subset"
  local hb_view="$srcdir/$build_dir/util/hb-view"
  local hb_ot_shape_closure="$srcdir/$build_dir/util/hb-ot-shape-closure"

  # --- Phase 1: Run meson test suite ---
  echo "  -> Running test suite..."
  meson test -C "$build_dir" --print-errorlogs -j"$(nproc)" || true

  # --- Phase 2: Collect system fonts ---
  local -a fonts=()
  local -a font_paths=(
    /usr/share/fonts/noto
    /usr/share/fonts/noto-cjk
    /usr/share/fonts/TTF
    /usr/share/fonts/OTF
    /usr/share/fonts/truetype/dejavu
    /usr/share/fonts/truetype/noto
  )

  for fp in "${font_paths[@]}"; do
    [[ -d "$fp" ]] || continue
    while IFS= read -r -d '' f; do
      fonts+=("$f")
      ((${#fonts[@]} >= 35)) && break 2
    done < <(find "$fp" -maxdepth 2 -type f \( -name '*.ttf' -o -name '*.otf' \) -print0 2>/dev/null | head -z -n 50)
  done

  if ((${#fonts[@]} == 0)); then
    echo "  -> Warning: No fonts found for extended training"
    return 0
  fi

  echo "  -> Training with ${#fonts[@]} fonts..."

  # --- Phase 3: Representative text samples ---
  # Covers Latin, Cyrillic, Greek, Arabic, Hebrew, Devanagari, Thai, CJK, emoji
  local -a texts=(
    # Latin with ligatures, kerning, diacritics
    "The quick brown fox jumps over the lazy dog. WAVE Typography fi fl ffi ffl"
    "Ã€ÃÃ‚ÃƒÃ„Ã…Ã†Ã‡ÃˆÃ‰ÃŠÃ‹ Ã Ã¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ« Ã±Ã‘Ã¸Ã˜Å“Å’ÃŸÃ¿ PÅ™Ã­liÅ¡ Å¾luÅ¥ouÄkÃ½ kÅ¯Åˆ"
    # Cyrillic
    "Ð¡ÑŠÐµÑˆÑŒ ÐµÑ‰Ñ‘ ÑÑ‚Ð¸Ñ… Ð¼ÑÐ³ÐºÐ¸Ñ… Ñ„Ñ€Ð°Ð½Ñ†ÑƒÐ·ÑÐºÐ¸Ñ… Ð±ÑƒÐ»Ð¾Ðº, Ð´Ð° Ð²Ñ‹Ð¿ÐµÐ¹ Ñ‡Ð°ÑŽ. ÐÐ‘Ð’Ð“Ð”Ð•ÐÐ–Ð—Ð˜Ð™"
    # Greek
    "ÎžÎµÏƒÎºÎµÏ€Î¬Î¶Ï‰ Ï„á½´Î½ ÏˆÏ…Ï‡Î¿Ï†Î¸ÏŒÏÎ± Î²Î´ÎµÎ»Ï…Î³Î¼Î¯Î±. Î‘Î’Î“Î”Î•Î–Î—Î˜Î™ÎšÎ›ÎœÎ Î±Î²Î³Î´ÎµÎ¶Î·Î¸"
    # Arabic (RTL, cursive joining)
    "ØµÙÙ Ø®ÙŽÙ„Ù‚ÙŽ Ø®ÙŽÙˆØ¯Ù ÙƒÙŽÙ…ÙØ«Ù„Ù Ø§Ù„Ø´ÙŽÙ‘Ù…Ø³Ù Ø¥ÙØ° Ø¨ÙŽØ²ÙŽØºÙŽØª ÙŠÙŽØ­Ø¸Ù‰ Ø§Ù„Ø¶ÙŽÙ‘Ø¬ÙŠØ¹Ù Ø¨ÙÙ‡Ø§ Ù†ÙŽØ¬Ù„Ø§Ø¡ÙŽ Ù…ÙØ¹Ø·Ø§Ø±Ù"
    # Hebrew (RTL)
    "×“×’ ×¡×§×¨×Ÿ ×©×˜ ×‘×™× ×ž××•×›×–×‘ ×•×œ×¤×ª×¢ ×ž×¦× ×—×‘×¨×”. ××‘×’×“×”×•×–×—×˜×™×›×œ×ž× ×¡×¢×¤×¦×§×¨×©×ª"
    # Devanagari (complex clusters)
    "à¤‹à¤·à¤¿à¤¯à¥‹à¤‚ à¤•à¥‹ à¤¸à¤¤à¤¾à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ à¤¦à¥à¤·à¥à¤Ÿ à¤°à¤¾à¤•à¥à¤·à¤¸à¥‹à¤‚ à¤•à¥‡ à¤°à¤¾à¤œà¤¾ à¤°à¤¾à¤µà¤£ à¤•à¥à¤· à¤¤à¥à¤° à¤œà¥à¤ž à¤¶à¥à¤°"
    # Thai (no word breaks)
    "à¹€à¸›à¹‡à¸™à¸¡à¸™à¸¸à¸©à¸¢à¹Œà¸ªà¸¸à¸”à¸›à¸£à¸°à¹€à¸ªà¸£à¸´à¸à¹€à¸¥à¸´à¸¨à¸„à¸¸à¸“à¸„à¹ˆà¸² à¸à¸§à¹ˆà¸²à¸šà¸£à¸£à¸”à¸²à¸à¸¹à¸‡à¸ªà¸±à¸•à¸§à¹Œà¹€à¸”à¸£à¸±à¸ˆà¸‰à¸²à¸™"
    # CJK ideographs
    "å¤©åœ°çŽ„é»„å®‡å®™æ´ªè’æ—¥æœˆç›ˆæ˜ƒè¾°å®¿åˆ—å¼ å¯’æ¥æš‘å¾€ç§‹æ”¶å†¬è—"
    # Japanese (mixed scripts)
    "æ—¥æœ¬èªžãƒ†ã‚­ã‚¹ãƒˆã€‚ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠABCæ¼¢å­—123ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"
    # Korean (Hangul jamo)
    "í•œêµ­ì–´ í…ìŠ¤íŠ¸ ìƒ˜í”Œìž…ë‹ˆë‹¤. ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìžì°¨ì¹´íƒ€íŒŒí•˜"
    # Emoji and symbols
    "ðŸ˜€ðŸŽ‰ðŸš€ðŸ’»ðŸ”¥âœ¨ðŸŒðŸŽ¨ðŸ“šðŸ”§ Â©Â®â„¢ â†’â†â†‘â†“ â˜…â˜†â™ â™£â™¥â™¦ 0123456789"
  )

  # OpenType features to exercise
  local -a features=(
    ""
    "+kern,+liga"
    "+calt,+clig,+liga"
    "-liga,-kern"
    "+smcp"
    "+onum,+pnum"
    "+tnum,+lnum"
    "+dlig,+hlig"
  )

  local -a directions=("ltr" "rtl" "ttb")

  # --- Phase 4: Exercise hb-shape ---
  if [[ -x "$hb_shape" ]]; then
    echo "  -> Exercising hb-shape..."
    local count=0
    for font in "${fonts[@]}"; do
      for text in "${texts[@]}"; do
        "$hb_shape" "$font" "$text" &>/dev/null || true
        ((++count))

        for feat in "${features[@]}"; do
          [[ -n "$feat" ]] && "$hb_shape" --features="$feat" "$font" "$text" &>/dev/null || true
        done

        for dir in "${directions[@]}"; do
          "$hb_shape" --direction="$dir" "$font" "$text" &>/dev/null || true
        done
      done

      # Cluster level variations
      for cl in 0 1 2; do
        "$hb_shape" --cluster-level="$cl" "$font" "${texts[0]}" &>/dev/null || true
      done
    done
    echo "    Completed $count base shaping operations"
  fi

  # --- Phase 5: Exercise hb-subset ---
  if [[ -x "$hb_subset" ]]; then
    echo "  -> Exercising hb-subset..."
    local tmpout
    tmpout=$(mktemp)

    local -a ranges=(
      "U+0020-007F"   # Basic Latin
      "U+0080-00FF"   # Latin-1 Supplement
      "U+0100-017F"   # Latin Extended-A
      "U+0400-04FF"   # Cyrillic
      "U+0600-06FF"   # Arabic
      "U+0900-097F"   # Devanagari
      "U+3040-30FF"   # Hiragana + Katakana
      "U+4E00-4FFF"   # CJK subset
      "U+AC00-ACFF"   # Hangul subset
    )

    for font in "${fonts[@]:0:15}"; do
      for range in "${ranges[@]}"; do
        "$hb_subset" --output-file="$tmpout" --unicodes="$range" "$font" &>/dev/null || true
        "$hb_subset" --output-file="$tmpout" --unicodes="$range" --retain-gids "$font" &>/dev/null || true
        "$hb_subset" --output-file="$tmpout" --unicodes="$range" --desubroutinize "$font" &>/dev/null || true
        "$hb_subset" --output-file="$tmpout" --unicodes="$range" --no-hinting "$font" &>/dev/null || true
      done

      for text in "${texts[@]:0:6}"; do
        "$hb_subset" --output-file="$tmpout" --text="$text" "$font" &>/dev/null || true
      done

      # Layout feature tests
      "$hb_subset" --output-file="$tmpout" --layout-features+=kern,liga,calt --unicodes="U+0020-007F" "$font" &>/dev/null || true
    done

    rm -f "$tmpout"
  fi

  # --- Phase 6: Exercise hb-ot-shape-closure ---
  if [[ -x "$hb_ot_shape_closure" ]]; then
    echo "  -> Exercising hb-ot-shape-closure..."
    for font in "${fonts[@]:0:12}"; do
      for text in "${texts[@]:0:6}"; do
        "$hb_ot_shape_closure" "$font" "$text" &>/dev/null || true
      done
    done
  fi

  # --- Phase 7: Exercise hb-view ---
  if [[ -x "$hb_view" ]]; then
    echo "  -> Exercising hb-view..."
    local tmpimg
    tmpimg=$(mktemp --suffix=.png)

    for font in "${fonts[@]:0:8}"; do
      for text in "${texts[@]:0:6}"; do
        "$hb_view" --output-file="$tmpimg" --font-size=24 "$font" "$text" &>/dev/null || true
        "$hb_view" --output-file="$tmpimg" --font-size=48 --margin=10 "$font" "$text" &>/dev/null || true
      done
    done

    rm -f "$tmpimg"
  fi

  echo "==> Training workload complete"
}

build() {
  cd "$srcdir"

  # Use Clang/LLVM toolchain for PGO
  export CC=clang
  export CXX=clang++
  export LD=lld
  export AR=llvm-ar
  export NM=llvm-nm
  export STRIP=llvm-strip
  export OBJCOPY=llvm-objcopy
  export OBJDUMP=llvm-objdump
  export READELF=llvm-readelf
  export RANLIB=llvm-ranlib
  export HOSTCC=clang
  export HOSTCXX=clang++

  # Meson configuration shared across all stages
  local -a meson_args=(
    -D graphite2=enabled
    -D cairo=enabled
    -D freetype=enabled
    -D glib=enabled
    -D gobject=enabled
    -D icu=enabled
    -D docs=disabled
    --buildtype=plain
  )

  # PGO profile directories (absolute paths for reliability)
  local pgo_dir="$srcdir/pgo"
  local pgo_standard_dir="$pgo_dir/standard"
  local pgo_cs_dir="$pgo_dir/cs"

  # Clean previous builds but preserve any existing profdata for reference
  rm -rf build build-pgo1 build-pgo2
  rm -rf "$pgo_standard_dir" "$pgo_cs_dir"
  mkdir -p "$pgo_standard_dir" "$pgo_cs_dir"

  # PGO instrumentation enhancement flags (improves profile quality)
  local pgo_instr_cflags="-Xclang -mllvm -Xclang -vp-counters-per-site=50"
  pgo_instr_cflags+=" -Xclang -mllvm -Xclang -runtime-counter-relocation"
  pgo_instr_cflags+=" -Xclang -mllvm -Xclang -enable-value-profiling"

  # ===========================================================================
  # Stage 1: Build with standard PGO instrumentation
  # ===========================================================================
  echo ""
  echo "=========================================================================="
  echo " Stage 1/3: Building with standard PGO instrumentation"
  echo "=========================================================================="

  local stage1_cflags="$CFLAGS $pgo_instr_cflags -fprofile-generate=$pgo_standard_dir"
  local stage1_cxxflags="$CXXFLAGS $pgo_instr_cflags -fprofile-generate=$pgo_standard_dir"
  local stage1_ldflags="$LDFLAGS -fprofile-generate=$pgo_standard_dir"

  arch-meson harfbuzz build-pgo1 \
    "${meson_args[@]}" \
    -D tests=enabled \
    -D b_ndebug=false \
    -D c_args="$stage1_cflags" \
    -D cpp_args="$stage1_cxxflags" \
    -D c_link_args="$stage1_ldflags" \
    -D cpp_link_args="$stage1_ldflags"

  meson compile -C build-pgo1

  # Run training workload to generate profiles
  _run_training_workload build-pgo1 1

  # Verify profile data was generated
  local profraw_count
  profraw_count=$(find "$pgo_standard_dir" -maxdepth 1 -name '*.profraw' -type f 2>/dev/null | wc -l)
  if ((profraw_count == 0)); then
    echo "ERROR: No standard PGO profile data generated!"
    exit 1
  fi
  echo "==> Merging $profraw_count standard profile files..."

  llvm-profdata merge \
    --output="$pgo_dir/standard.profdata" \
    "$pgo_standard_dir"/*.profraw

  if [[ ! -s "$pgo_dir/standard.profdata" ]]; then
    echo "ERROR: Failed to create standard.profdata"
    exit 1
  fi

  # ===========================================================================
  # Stage 2: Build with context-sensitive PGO instrumentation
  # ===========================================================================
  echo ""
  echo "=========================================================================="
  echo " Stage 2/3: Building with context-sensitive PGO instrumentation"
  echo "=========================================================================="

  local stage2_cflags="$CFLAGS $pgo_instr_cflags"
  stage2_cflags+=" -fprofile-use=$pgo_dir/standard.profdata"
  stage2_cflags+=" -fcs-profile-generate=$pgo_cs_dir"
  local stage2_cxxflags="$CXXFLAGS $pgo_instr_cflags"
  stage2_cxxflags+=" -fprofile-use=$pgo_dir/standard.profdata"
  stage2_cxxflags+=" -fcs-profile-generate=$pgo_cs_dir"
  local stage2_ldflags="$LDFLAGS"
  stage2_ldflags+=" -fprofile-use=$pgo_dir/standard.profdata"
  stage2_ldflags+=" -fcs-profile-generate=$pgo_cs_dir"

  arch-meson harfbuzz build-pgo2 \
    "${meson_args[@]}" \
    -D tests=enabled \
    -D b_ndebug=false \
    -D c_args="$stage2_cflags" \
    -D cpp_args="$stage2_cxxflags" \
    -D c_link_args="$stage2_ldflags" \
    -D cpp_link_args="$stage2_ldflags"

  meson compile -C build-pgo2

  # Run training workload again for CS profiles
  _run_training_workload build-pgo2 2

  # Verify CS profile data was generated
  profraw_count=$(find "$pgo_cs_dir" -maxdepth 1 -name '*.profraw' -type f 2>/dev/null | wc -l)
  if ((profraw_count == 0)); then
    echo "ERROR: No context-sensitive PGO profile data generated!"
    exit 1
  fi
  echo "==> Merging $profraw_count CS profile files with standard profile..."

  # Merge CS profiles with standard profile (base profile first)
  llvm-profdata merge \
    --output="$pgo_dir/merged.profdata" \
    "$pgo_dir/standard.profdata" \
    "$pgo_cs_dir"/*.profraw

  if [[ ! -s "$pgo_dir/merged.profdata" ]]; then
    echo "ERROR: Failed to create merged.profdata"
    exit 1
  fi

  # ===========================================================================
  # Stage 3: Final optimized build with merged PGO data
  # ===========================================================================
  echo ""
  echo "=========================================================================="
  echo " Stage 3/3: Building final PGO-optimized version"
  echo "=========================================================================="

  local final_cflags="$CFLAGS -fprofile-use=$pgo_dir/merged.profdata -fprofile-correction"
  local final_cxxflags="$CXXFLAGS -fprofile-use=$pgo_dir/merged.profdata -fprofile-correction"
  local final_ldflags="$LDFLAGS -fprofile-use=$pgo_dir/merged.profdata"

  arch-meson harfbuzz build \
    "${meson_args[@]}" \
    -D tests=disabled \
    -D b_ndebug=true \
    -D c_args="$final_cflags" \
    -D cpp_args="$final_cxxflags" \
    -D c_link_args="$final_ldflags" \
    -D cpp_link_args="$final_ldflags"

  meson compile -C build

  echo ""
  echo "=========================================================================="
  echo " Build complete!"
  echo " Profile data preserved in: $pgo_dir"
  echo "   - standard.profdata: $(du -h "$pgo_dir/standard.profdata" | cut -f1)"
  echo "   - merged.profdata:   $(du -h "$pgo_dir/merged.profdata" | cut -f1)"
  echo "=========================================================================="
}

package_harfbuzz-git() {
  depends=(
    cairo
    freetype2
    glib2
    graphite
  )
  provides=(
    harfbuzz
    libharfbuzz.so
    libharfbuzz-cairo.so
    libharfbuzz-gobject.so
    libharfbuzz-subset.so
  )
  conflicts=(harfbuzz)
  optdepends=(
    'chafa: hb-view terminal output'
  )

  DESTDIR="$pkgdir" meson install -C build

  # Split harfbuzz-icu into separate package
  mkdir -p hb-icu/usr/{include/harfbuzz,lib/pkgconfig}
  mv -t hb-icu/usr/lib "$pkgdir"/usr/lib/libharfbuzz-icu*
  mv -t hb-icu/usr/lib/pkgconfig "$pkgdir"/usr/lib/pkgconfig/harfbuzz-icu.pc
  mv -t hb-icu/usr/include/harfbuzz "$pkgdir"/usr/include/harfbuzz/hb-icu.h

  install -Dm644 harfbuzz/COPYING "$pkgdir/usr/share/licenses/$pkgname/LICENSE"
}

package_harfbuzz-icu-git() {
  pkgdesc="$pkgdesc (ICU integration)"
  depends=(
    harfbuzz-git
    icu
  )
  provides=(
    harfbuzz-icu
    libharfbuzz-icu.so
  )
  conflicts=(harfbuzz-icu)

  mv hb-icu/* "$pkgdir"

  install -Dm644 harfbuzz/COPYING "$pkgdir/usr/share/licenses/$pkgname/LICENSE"
}
