pkgname=zstd
pkgver=1.5.6
pkgrel=14.3
pkgdesc='Zstandard - Fast real-time compression algorithm'
url='https://facebook.github.io/zstd/'
arch=(x86_64)
license=(BSD GPL2)
depends=(glibc gcc-libs zlib xz lz4)
makedepends=(gtest clang llvm lld cmake ninja perl python)
provides=("libzstd.so" "zstd=${pkgver}" "libzstd.so=1-64")
options=(!debug lto !strip)
source=(https://github.com/facebook/zstd/releases/download/v${pkgver}/zstd-${pkgver}.tar.zst{,.sig}
        fopen-use-m.patch
        multi-thread-default.patch
        notrace.patch)
sha256sums=('SKIP'
            'SKIP'
            'SKIP'
            'SKIP'
            'SKIP')

prepare() {
  cd "${pkgname}-${pkgver}"

  # Apply patches
  for src in "${source[@]}"; do
    src="${src%%::*}"
    src="${src##*/}"
    [[ $src = *.patch ]] || continue
    patch -Np1 -i "../${src}"
  done

  # Fix test builds
  sed -i '/build static library to build tests/d' build/cmake/CMakeLists.txt
  sed -i 's/libzstd_static/libzstd_shared/g' build/cmake/tests/CMakeLists.txt
}

# Define the function OUTSIDE of the build() function
generate_training_data() {
  local pgo_dir="$1"

  # ======================
  # Phase 1: Training Data
  # ======================
  echo "Generating comprehensive training data..."
  mkdir -p "${pgo_dir}/training"

  # Enhanced pattern-based training files (Increase iterations)
  echo "Creating pattern files..."
  for i in {1..100}; do
    {
      seq 1 4000
      yes "pattern${i}" | head -n 4000
      dd if=/dev/urandom bs=1K count=200 2>/dev/null | base64
      printf "%0.sA" $(seq 1 40000)
      printf "%0.sB" $(seq 1 40000)
      echo "Common header ${i}"
      echo "Common footer ${i}"
    } > "${pgo_dir}/training/training_${i}.txt"
  done

  # Specialized test files (Increase sizes)
  echo "Generating test files..."
  dd if=/dev/urandom bs=1M count=100 2>/dev/null | base64 > "${pgo_dir}/training/text1.txt"
  seq 1 1000000 > "${pgo_dir}/training/numbers.txt"
  yes "repeated data" | head -n 1000000 > "${pgo_dir}/training/repeated.txt"
  dd if=/dev/urandom of="${pgo_dir}/training/random.bin" bs=1M count=100 status=none

  # Compression ratio test files (Increase sizes)
  for i in {1..5}; do
    dd if=/dev/urandom bs=1K count=$((i * 2000)) 2>/dev/null > "${pgo_dir}/training/binary_${i}.bin"
  done

  # Highly compressible files (Increase sizes)
  for i in {1..3}; do
    printf "%0.sA" $(seq 1 $((i * 1000000))) > "${pgo_dir}/training/compressible_${i}.txt"
  done

  # Mixed-content files (Add more sources if available)
  if [ -d "/usr/share/doc" ]; then
    find /usr/share/doc /usr/share/man -type f -name "*.txt" -o -name "*.gz" 2>/dev/null | head -n 100 | while read -r file; do
      if [[ $file == *.gz ]]; then
        zcat "${file}" 2>/dev/null
      else
        cat "${file}" 2>/dev/null
      fi
    done > "${pgo_dir}/training/docs.txt"
  else
    for i in {1..5000}; do # Increased from 1000 to 5000
      echo "Sample documentation line $i with some common technical terms: buffer, memory, cache, process, thread, socket"
    done > "${pgo_dir}/training/docs.txt"
  fi

  # Source code test file
  {
    echo "#include <stdio.h>"
    echo "int main() {"
    echo "  printf(\"Hello, world!\\n\");"
    echo "  return 0;"
    echo "}"
  } > "${pgo_dir}/training/source_code.txt"
}

run_training_workload() {
  local zstd_binary="$1"
  local PROFILE_DIR="$2"
  local TMPDIR="$3"

  # Initial parallel compression/decompression training
  find "${PROFILE_DIR}" -type f -print0 | xargs -0 -P$(nproc) -I{} \
    sh -c '
      set -e
      input_file="$1"
      zstd="$2"
      tmpdir="$3"

      tmpfile=$(mktemp -p "${tmpdir}" "zstd.tmp.XXXXXX")

      # Multi-threaded compression
      "${zstd}" -T0 -3 -f "${input_file}" -o "${tmpfile}"

      # Multi-threaded decompression
      "${zstd}" -T0 -d -f "${tmpfile}" -o /dev/null

      rm -f "${tmpfile}"
    ' _ "{}" "${zstd_binary}" "${TMPDIR}"

  # Dictionary training and testing
  echo 'Training dictionary...'

  # Create a samples directory for dictionary training
  mkdir -p "${PROFILE_DIR}/samples"

  # Split training files into smaller samples (16KB each)
  for file in "${PROFILE_DIR}"/training_*.txt; do
    split -b 16384 "${file}" "${PROFILE_DIR}/samples/sample_" --additional-suffix=".txt"
  done

  # Additional samples from docs and source
  split -b 16384 "${PROFILE_DIR}/docs.txt" "${PROFILE_DIR}/samples/docs_" --additional-suffix=".txt"
  split -b 16384 "${PROFILE_DIR}/source_code.txt" "${PROFILE_DIR}/samples/source_" --additional-suffix=".txt"

  # Train dictionary with the samples
  "${zstd_binary}" --train "${PROFILE_DIR}/samples/"*.txt \
    -o "${PROFILE_DIR}/dictionary" \
    --maxdict=16384 \
    --dictID=1

  # Create enhanced dictionary with more sample types
  "${zstd_binary}" --train "${PROFILE_DIR}/samples/"*.txt \
    -o "${PROFILE_DIR}/dictionary_enhanced" \
    --maxdict=32768 \
    --dictID=2

  # Test dictionary compression
  for dict in "${PROFILE_DIR}/dictionary" "${PROFILE_DIR}/dictionary_enhanced"; do
    for file in "${PROFILE_DIR}"/training_*.txt "${PROFILE_DIR}/docs.txt" "${PROFILE_DIR}/source_code.txt"; do
      "${zstd_binary}" -f -D "${dict}" "${file}" -o /dev/null
    done
  done

  # Cleanup samples
  rm -rf "${PROFILE_DIR}/samples"

  # Single-threaded compression at different levels
  for level in 1 3 5 9 15 19; do
    find "${PROFILE_DIR}" -type f -not -name 'training_*' -not -name '*.zst' -print0 | \
      xargs -0 -P1 -n1 "${zstd_binary}" -f "-${level}" -o /dev/null
  done

  # Multi-threaded compression
  for thread in 2 4 8; do
    find "${PROFILE_DIR}" -type f -not -name 'training_*' -not -name '*.zst' -print0 | \
      xargs -0 -P1 -n1 "${zstd_binary}" -f "-T${thread}" -3 -o /dev/null
  done

  # Long range mode for larger files
  find "${PROFILE_DIR}" \( -name '*.bin' -o -name 'text1.txt' \) -print0 | \
    xargs -0 -n1 "${zstd_binary}" -f --long -o /dev/null

  # Streaming compression
  find "${PROFILE_DIR}" -type f -not -name 'training_*' -not -name '*.zst' -print0 | \
    while IFS= read -r -d '' file; do
      cat "${file}" | "${zstd_binary}" -f > /dev/null
    done

  # Decompression workload
  find "${PROFILE_DIR}" -type f -not -name 'training_*' -not -name '*.zst' -print0 | \
    while IFS= read -r -d '' file; do
      "${zstd_binary}" -f -3 "${file}" -o "${file}.zst"
      "${zstd_binary}" -f -d "${file}.zst" -o /dev/null 2>/dev/null
      rm -f "${file}.zst"
    done
}
export -f run_training_workload

build() {
  cd "${pkgname}-${pkgver}"

  # Set Clang toolchain with proper PGO flags
  export CC=clang
  export CXX=clang++
  export AR=llvm-ar
  export NM=llvm-nm
  export RANLIB=llvm-ranlib
  export CFLAGS+=" -pthread"
  export CXXFLAGS+=" -pthread"
  export LDFLAGS+=" -lpthread"
  export LLVM_PROFILE_FILE="${srcdir}/zstd-pgo/zstd-%p-%m.profraw"

  local pgo_dir="${srcdir}/zstd-pgo"
  mkdir -p "${pgo_dir}"

  # Generate the training data
  generate_training_data "${pgo_dir}"

  # ===========================
  # Phase 2: PGO Instrumentation
  # ===========================
  cmake -S build/cmake -B build-pgo -G Ninja \
    -DCMAKE_BUILD_TYPE=RelWithDebInfo \
    -DCMAKE_C_FLAGS="${CFLAGS} -fprofile-generate -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -pthread" \
    -DCMAKE_CXX_FLAGS="${CXXFLAGS} -fprofile-generate -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -pthread" \
    -DCMAKE_EXE_LINKER_FLAGS="${LDFLAGS} -fprofile-generate -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -lpthread" \
    -DCMAKE_SHARED_LINKER_FLAGS="${LDFLAGS} -fprofile-generate -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -lpthread" \
    -DCMAKE_THREAD_LIBS_INIT="-lpthread" \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DCMAKE_INSTALL_LIBDIR=lib \
    -DZSTD_ZLIB_SUPPORT=ON \
    -DZSTD_LZMA_SUPPORT=ON \
    -DZSTD_LZ4_SUPPORT=ON \
    -DZSTD_BUILD_CONTRIB=ON \
    -DZSTD_BUILD_STATIC=OFF \
    -DZSTD_BUILD_TESTS=ON \
    -DZSTD_PROGRAMS_LINK_SHARED=ON \
    -DZSTD_MULTITHREAD_SUPPORT=ON

  cmake --build build-pgo

  # ====================
  # Phase 3: PGO Training
  # ===========================
  echo "Executing PGO training workload..."
  local zstd_pgo="${PWD}/build-pgo/programs/zstd"
  local PROFILE_DIR="${pgo_dir}/training"

  # Preload pthread library if needed
  export LD_LIBRARY_PATH="${PWD}/build-pgo/lib:${LD_LIBRARY_PATH}"

  # Create secure temp directory with proper permissions
  export TMPDIR="${pgo_dir}/tmp"
  mkdir -p "${TMPDIR}" || { echo "Failed to create temp directory"; exit 1; }
  chmod 700 "${TMPDIR}"

  run_training_workload "${zstd_pgo}" "${PROFILE_DIR}" "${TMPDIR}"

  # Merge profiles
  echo "Merging profiles..."
  llvm-profdata merge \
    --output "${pgo_dir}/zstd.profdata" \
    "${pgo_dir}"/zstd-*.profraw

  # =========================
  # Phase 4: PGO Optimized Build
  # =========================
  cmake -S build/cmake -B build-bolt -G Ninja \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_C_FLAGS="${CFLAGS} -fprofile-use=${pgo_dir}/zstd.profdata" \
    -DCMAKE_CXX_FLAGS="${CXXFLAGS} -fprofile-use=${pgo_dir}/zstd.profdata" \
    -DCMAKE_EXE_LINKER_FLAGS="${LDFLAGS} -fuse-ld=lld -Wl,--emit-relocs" \
    -DCMAKE_SHARED_LINKER_FLAGS="${LDFLAGS} -fuse-ld=lld -Wl,--emit-relocs" \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DCMAKE_INSTALL_LIBDIR=lib

  cmake --build build-bolt

  # =====================
  # Phase 5: BOLT Optimization
  # =====================
  echo "Performing BOLT optimization..."
  local zstd_bolt="${PWD}/build-bolt/programs/zstd"
  local libzstd_bolt="${PWD}/build-bolt/lib/libzstd.so"

  # Profile collection
  perf record -o "${pgo_dir}/perf.data" -b --max-size=6G -F 5000 -e branch-instructions:u,cycles:u,cache-misses:u,branch-misses:u,branches:u,branch-loads:u,branch-load-misses:u,iTLB-load-misses:u,dTLB-store-misses:u,dTLB-load-misses:u,L1-icache-load-misses:u,LLC-load-misses:u -- \
    sh -c 'run_training_workload "$1" "$2" "$3"' _ "${zstd_bolt}" "${PROFILE_DIR}" "${TMPDIR}"

  # Convert profile
  perf2bolt "${zstd_bolt}" \
    -p "${pgo_dir}/perf.data" \
    -o "${pgo_dir}/zstd.fdata" \
    -w "${pgo_dir}/zstd.bolt"

  # Apply BOLT
  llvm-bolt "${zstd_bolt}" -o "${zstd_bolt}.optimized" \
    --data "${pgo_dir}/zstd.fdata" \
    --dyno-stats \
    --frame-opt=hot \
    --lite=false \
    --infer-stale-profile=1 \
    --icf=safe \
    --plt=all \
    --hugify \
    --peepholes=all \
    --x86-strip-redundant-address-size \
    --indirect-call-promotion=all \
    --reorder-blocks=ext-tsp \
    --reorder-functions=cdsort \
    --split-all-cold \
    --split-eh \
    --split-functions \
    --split-strategy=cdsplit \
    --redirect-never-taken-jumps

  # Apply BOLT to libzstd library
  llvm-bolt "${libzstd_bolt}" -o "${libzstd_bolt}.optimized" \
    --data "${pgo_dir}/zstd.fdata" \
    --dyno-stats \
    --frame-opt=hot \
    --lite=false \
    --infer-stale-profile=1 \
    --icf=safe \
    --plt=all \
    --hugify \
    --peepholes=all \
    --x86-strip-redundant-address-size \
    --indirect-call-promotion=all \
    --reorder-blocks=ext-tsp \
    --reorder-functions=cdsort \
    --split-all-cold \
    --split-eh \
    --split-functions \
    --split-strategy=cdsplit \
    --redirect-never-taken-jumps

  # Replace binary
  mv -f "${zstd_bolt}.optimized" "${zstd_bolt}"

  # Replace libzstd library
  mv -f "${libzstd_bolt}.optimized" "${libzstd_bolt}"
}

#check() {
#  cd "${pkgname}-${pkgver}"
#  LD_LIBRARY_PATH="${PWD}/build-bolt/lib" ctest -VV --test-dir build-bolt
#}

package() {
  cd "${pkgname}-${pkgver}"
  DESTDIR="${pkgdir}" cmake --install build-bolt

  # Use llvm-strip only on recognized file formats
  find "$pkgdir" -type f \( -name '*.so*' -o -name '*.a' -o -executable \) -print0 | while IFS= read -r -d '' file; do
    if llvm-strip --strip-unneeded "$file" 2>/dev/null || llvm-strip --strip-all "$file" 2>/dev/null; then
      echo "Stripped: $file"
    else
      echo "Skipping: $file (not a valid object file)" >&2
    fi
  done

  # Create symlink
  ln -sf /usr/bin/zstd "${pkgdir}/usr/bin/zstdmt"

  # Install license
  install -Dm644 LICENSE -t "${pkgdir}/usr/share/licenses/${pkgname}/"

  # Cleanup after everything is done
  rm -rf "${pgo_dir}" /tmp/zstd.tmp

}
