pkgname=zstd
pkgver=1.5.7
pkgrel=12.5
pkgdesc='Zstandard - Fast real-time compression algorithm'
url='https://facebook.github.io/zstd/'
arch=(x86_64)
license=(BSD GPL2)
depends=(glibc gcc-libs zlib xz lz4)
makedepends=(gtest clang llvm lld cmake ninja perl python)
provides=("libzstd.so" "zstd=${pkgver}" "libzstd.so=1-64")
options=(!debug lto !strip)
source=(https://github.com/facebook/zstd/releases/download/v${pkgver}/zstd-${pkgver}.tar.zst{,.sig}
        fopen-use-m.patch
        notrace.patch)
sha256sums=('SKIP'
            'SKIP'
            'SKIP'
            'SKIP'
            'SKIP')

prepare() {
  cd "${pkgname}-${pkgver}"

  # Apply patches
  for src in "${source[@]}"; do
    src="${src%%::*}"
    src="${src##*/}"
    [[ $src = *.patch ]] || continue
    patch -Np1 -i "../${src}"
  done

  # Fix test builds
  sed -i '/build static library to build tests/d' build/cmake/CMakeLists.txt
  sed -i 's/libzstd_static/libzstd_shared/g' build/cmake/tests/CMakeLists.txt
}

generate_training_data() {
  local pgo_dir="$1"

  # ======================
  # Phase 1: Training Data
  # ======================
  echo "Generating comprehensive training data..."
  mkdir -p "${pgo_dir}/training"

  # Enhanced pattern-based training files (Increase iterations)
  echo "Creating pattern files..."
  for i in {1..100}; do
    {
      seq 1 4000
      yes "pattern${i}" | head -n 4000
      dd if=/dev/urandom bs=1K count=200 2>/dev/null | base64
      printf "%0.sA" $(seq 1 40000)
      printf "%0.sB" $(seq 1 40000)
      echo "Common header ${i}"
      echo "Common footer ${i}"
    } > "${pgo_dir}/training/training_${i}.txt"
  done

  # Specialized test files (Increase sizes)
  echo "Generating test files..."
  dd if=/dev/urandom bs=1M count=100 2>/dev/null | base64 > "${pgo_dir}/training/text1.txt"
  seq 1 1000000 > "${pgo_dir}/training/numbers.txt"
  yes "repeated data" | head -n 1000000 > "${pgo_dir}/training/repeated.txt"
  dd if=/dev/urandom of="${pgo_dir}/training/random.bin" bs=1M count=100 status=none

  # Compression ratio test files (Increase sizes)
  for i in {1..5}; do
    dd if=/dev/urandom bs=1K count=$((i * 2000)) 2>/dev/null > "${pgo_dir}/training/binary_${i}.bin"
  done

  # Highly compressible files (Increase sizes)
  for i in {1..3}; do
    printf "%0.sA" $(seq 1 $((i * 1000000))) > "${pgo_dir}/training/compressible_${i}.txt"
  done

  # Mixed-content files (Add more sources if available)
  if [ -d "/usr/share/doc" ]; then
    find /usr/share/doc /usr/share/man -type f -name "*.txt" -o -name "*.gz" 2>/dev/null | head -n 100 | while read -r file; do
      if [[ $file == *.gz ]]; then
        zcat "${file}" 2>/dev/null
      else
        cat "${file}" 2>/dev/null
      fi
    done > "${pgo_dir}/training/docs.txt"
  else
    for i in {1..5000}; do # Increased from 1000 to 5000
      echo "Sample documentation line $i with some common technical terms: buffer, memory, cache, process, thread, socket"
    done > "${pgo_dir}/training/docs.txt"
  fi

  # Source code test file
  {
    echo "#include <stdio.h>"
    echo "int main() {"
    echo "  printf(\"Hello, world!\\n\");"
    echo "  return 0;"
    echo "}"
  } > "${pgo_dir}/training/source_code.txt"
}

run_training_workload() {
  local zstd_binary="$1"
  local PROFILE_DIR="$2"
  local TMPDIR="$3"

  # Initial parallel compression/decompression training
  find "${PROFILE_DIR}" -type f -print0 | xargs -0 -P$(nproc) -I{} \
    sh -c '
      set -e
      input_file="$1"
      zstd="$2"
      tmpdir="$3"

      tmpfile=$(mktemp -p "${tmpdir}" "zstd.tmp.XXXXXX")

      # Multi-threaded compression
      "${zstd}" -T0 -3 -f "${input_file}" -o "${tmpfile}"

      # Multi-threaded decompression
      "${zstd}" -T0 -d -f "${tmpfile}" -o /dev/null

      rm -f "${tmpfile}"
    ' _ "{}" "${zstd_binary}" "${TMPDIR}"

  # Dictionary training and testing
  echo 'Training dictionary...'

  # Create a samples directory for dictionary training
  mkdir -p "${PROFILE_DIR}/samples"

  # Split training files into smaller samples (16KB each)
  for file in "${PROFILE_DIR}/training/training_"*.txt; do
    split -b 16384 "${file}" "${PROFILE_DIR}/samples/sample_" --additional-suffix=".txt"
  done

  # Additional samples from docs and source
  split -b 16384 "${PROFILE_DIR}/training/docs.txt" "${PROFILE_DIR}/samples/docs_" --additional-suffix=".txt"
  split -b 16384 "${PROFILE_DIR}/training/source_code.txt" "${PROFILE_DIR}/samples/source_" --additional-suffix=".txt"

  # Train dictionary with the samples
  "${zstd_binary}" --train "${PROFILE_DIR}/samples/"*.txt \
    -o "${PROFILE_DIR}/dictionary" \
    --maxdict=16384 \
    --dictID=1

  # Create enhanced dictionary with more sample types
  "${zstd_binary}" --train "${PROFILE_DIR}/samples/"*.txt \
    -o "${PROFILE_DIR}/dictionary_enhanced" \
    --maxdict=32768 \
    --dictID=2

  # Test dictionary compression
  for dict in "${PROFILE_DIR}/dictionary" "${PROFILE_DIR}/dictionary_enhanced"; do
    for file in "${PROFILE_DIR}/training/training_"*.txt "${PROFILE_DIR}/training/docs.txt" "${PROFILE_DIR}/training/source_code.txt"; do
      "${zstd_binary}" -f -D "${dict}" "${file}" -o /dev/null
    done
  done

  # Cleanup samples
  rm -rf "${PROFILE_DIR}/samples"

  # Single-threaded compression at different levels
  for level in 1 3 5 9 15 19; do
    find "${PROFILE_DIR}/training" -type f -not -name 'training_*' -not -name '*.zst' -print0 | \
      xargs -0 -P1 -n1 "${zstd_binary}" -f "-${level}" -o /dev/null
  done

  # Multi-threaded compression
  for thread in 2 4 8; do
    find "${PROFILE_DIR}/training" -type f -not -name 'training_*' -not -name '*.zst' -print0 | \
      xargs -0 -P1 -n1 "${zstd_binary}" -f "-T${thread}" -3 -o /dev/null
  done

  # Long range mode for larger files
  find "${PROFILE_DIR}/training" \( -name '*.bin' -o -name 'text1.txt' \) -print0 | \
    xargs -0 -n1 "${zstd_binary}" -f --long -o /dev/null

  # Streaming compression
  find "${PROFILE_DIR}/training" -type f -not -name 'training_*' -not -name '*.zst' -print0 | \
    while IFS= read -r -d '' file; do
      cat "${file}" | "${zstd_binary}" -f > /dev/null
    done

  # Decompression workload
  find "${PROFILE_DIR}/training" -type f -not -name 'training_*' -not -name '*.zst' -print0 | \
    while IFS= read -r -d '' file; do
      "${zstd_binary}" -f -3 "${file}" -o "${file}.zst"
      "${zstd_binary}" -f -d "${file}.zst" -o /dev/null 2>/dev/null
      rm -f "${file}.zst"
    done
}
export -f run_training_workload

run_library_tests() {
  local zstd_binary="$1"
  local PROFILE_DIR="$2"
  local TMPDIR="$3"

  echo "Running direct library function tests..."

  # Get the directory containing the zstd binary
  local BIN_DIR=$(dirname "${zstd_binary}")
  echo "Using library directory: ${BIN_DIR}"

  # Create the test program with better error handling
  mkdir -p "${TMPDIR}/lib_test"
  cat > "${TMPDIR}/lib_test/test_lib.c" << EOF
#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <zstd.h>
#include <zdict.h>

// Debug function to print errors
void check_error(size_t code, const char* location) {
    if (ZSTD_isError(code)) {
        fprintf(stderr, "Error in %s: %s\n", location, ZSTD_getErrorName(code));
        exit(1);
    }
}

int main() {
    printf("Starting zstd library test program\n");

    // Basic compression test
    const char* text = "This is a test string for ZSTD library function testing.";
    size_t text_size = strlen(text);
    printf("Input text size: %zu bytes\n", text_size);

    // Get compression bound
    size_t comp_bound = ZSTD_compressBound(text_size);
    printf("Compression bound: %zu bytes\n", comp_bound);

    // Allocate buffer
    void* comp_buffer = malloc(comp_bound);
    if (!comp_buffer) {
        fprintf(stderr, "Failed to allocate compression buffer\n");
        return 1;
    }

    // Basic direct compression test
    printf("Testing basic compression...\n");
    size_t comp_size = ZSTD_compress(comp_buffer, comp_bound, text, text_size, 1);
    if (ZSTD_isError(comp_size)) {
        fprintf(stderr, "Compression error: %s\n", ZSTD_getErrorName(comp_size));
        free(comp_buffer);
        return 1;
    }
    printf("Compressed size: %zu bytes\n", comp_size);

    // Decompress test
    printf("Testing basic decompression...\n");
    char* decomp_buffer = malloc(text_size + 100);
    if (!decomp_buffer) {
        fprintf(stderr, "Failed to allocate decompression buffer\n");
        free(comp_buffer);
        return 1;
    }

    size_t decomp_size = ZSTD_decompress(decomp_buffer, text_size + 100, comp_buffer, comp_size);
    if (ZSTD_isError(decomp_size)) {
        fprintf(stderr, "Decompression error: %s\n", ZSTD_getErrorName(decomp_size));
        free(comp_buffer);
        free(decomp_buffer);
        return 1;
    }
    printf("Decompressed size: %zu bytes\n", decomp_size);

    // Test streaming API with simplified approach and error checking
    printf("Testing streaming API...\n");

    // Create context
    ZSTD_CCtx* cctx = ZSTD_createCCtx();
    if (cctx == NULL) {
        fprintf(stderr, "Failed to create compression context\n");
        free(comp_buffer);
        free(decomp_buffer);
        return 1;
    }
    printf("Compression context created successfully\n");

    // Set a simple parameter
    size_t ret = ZSTD_CCtx_setParameter(cctx, ZSTD_c_compressionLevel, 3);
    if (ZSTD_isError(ret)) {
        fprintf(stderr, "Parameter setting error: %s\n", ZSTD_getErrorName(ret));
        ZSTD_freeCCtx(cctx);
        free(comp_buffer);
        free(decomp_buffer);
        return 1;
    }

    // Simple one-shot compression with the context
    printf("Compressing with context...\n");
    ret = ZSTD_compress2(cctx, comp_buffer, comp_bound, text, text_size);
    if (ZSTD_isError(ret)) {
        fprintf(stderr, "Context compression error: %s\n", ZSTD_getErrorName(ret));
        ZSTD_freeCCtx(cctx);
        free(comp_buffer);
        free(decomp_buffer);
        return 1;
    }
    printf("Context compression successful, size: %zu bytes\n", ret);

    // Clean up
    ZSTD_freeCCtx(cctx);
    free(comp_buffer);
    free(decomp_buffer);

    printf("Library test completed successfully\n");
    return 0;
}
EOF

  # Compile with more careful flags and link options
  echo "Compiling test program..."
  clang -Wall -o "${TMPDIR}/lib_test/test_lib" "${TMPDIR}/lib_test/test_lib.c" \
    -I/usr/include \
    -L"${BIN_DIR}" \
    -Wl,-rpath,"${BIN_DIR}" \
    -lzstd \
    -v

  # Check if the compilation was successful
  if [ ! -x "${TMPDIR}/lib_test/test_lib" ]; then
    echo "Compilation failed!"
    return 1
  fi

  # Set up the environment with explicit LD_LIBRARY_PATH
  local OLD_LD_LIBRARY_PATH="${LD_LIBRARY_PATH}"
  export LD_LIBRARY_PATH="${BIN_DIR}:${LD_LIBRARY_PATH}"
  echo "LD_LIBRARY_PATH set to: ${LD_LIBRARY_PATH}"

  # Run a ldd check to verify library loading
  echo "Checking library dependencies:"
  ldd "${TMPDIR}/lib_test/test_lib"

  # Run the test program with careful error checking
  echo "Running library test program..."
  if ! "${TMPDIR}/lib_test/test_lib"; then
    echo "Library test program failed with exit code $?"
    # Try running with direct library preloading if the normal run fails
    echo "Attempting to run with explicit LD_PRELOAD..."
    LD_PRELOAD="${BIN_DIR}/libzstd.so" "${TMPDIR}/lib_test/test_lib"
  else
    echo "Library test completed successfully"
  fi

  # Restore original LD_LIBRARY_PATH
  export LD_LIBRARY_PATH="${OLD_LD_LIBRARY_PATH}"
}

export -f run_library_tests

build() {
  cd "${pkgname}-${pkgver}"

  # Store original flags
  CFLAGS_ORIG="$CFLAGS"
  CXXFLAGS_ORIG="$CXXFLAGS"
  LDFLAGS_ORIG="$LDFLAGS"

  # Set Clang toolchain
  export CC=clang
  export CXX=clang++
  export AR=llvm-ar
  export NM=llvm-nm
  export RANLIB=llvm-ranlib

  # Ensure pthread is properly linked
  export CFLAGS+=" -pthread"
  export CXXFLAGS+=" -pthread"
  export LDFLAGS+=" -lpthread"

  local pgo_dir="${srcdir}/zstd-pgo"
  mkdir -p "${pgo_dir}"
  local tmpdir="${srcdir}/tmp"
  mkdir -p "${tmpdir}"

  # Generate the training data
  generate_training_data "${pgo_dir}"

  # --- Stage 1: Standard PGO - First round with standard instrumentation ---
  echo "Stage 1: Building with standard PGO instrumentation..."

  # Create pgo_standard directory
  mkdir -p "${srcdir}/pgo_standard"

  # Add standard PGO instrumentation flags
  CFLAGS+=" -fprofile-generate=${srcdir}/pgo_standard -g3 -fno-omit-frame-pointer -Xclang -mllvm -Xclang -vp-counters-per-site=50 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"
  CXXFLAGS+=" -fprofile-generate=${srcdir}/pgo_standard -g3 -fno-omit-frame-pointer -Xclang -mllvm -Xclang -vp-counters-per-site=50 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"
  LDFLAGS+=" -fprofile-generate=${srcdir}/pgo_standard -g3 -fno-omit-frame-pointer -Xclang -mllvm -Xclang -vp-counters-per-site=50 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"

  # Configure and build with standard instrumentation - including proper threading options
  cmake -S build/cmake -B build-pgo1 -G Ninja \
    -DCMAKE_BUILD_TYPE=Debug \
    -DCMAKE_C_FLAGS="${CFLAGS}" \
    -DCMAKE_CXX_FLAGS="${CXXFLAGS}" \
    -DCMAKE_EXE_LINKER_FLAGS="${LDFLAGS}" \
    -DCMAKE_SHARED_LINKER_FLAGS="${LDFLAGS}" \
    -DZSTD_MULTITHREAD_SUPPORT=ON \
    -DZSTD_BUILD_TESTS=ON \
    -DZSTD_BUILD_STATIC=OFF \
    -DZSTD_PROGRAMS_LINK_SHARED=ON \
    -DCMAKE_POSITION_INDEPENDENT_CODE=ON \
    -DZSTD_ZLIB_SUPPORT=ON \
    -DZSTD_LZMA_SUPPORT=ON \
    -DZSTD_LZ4_SUPPORT=ON

  # Build with instrumentation
  cmake --build build-pgo1 -j$(nproc)

  # Make sure the library dir is in LD_LIBRARY_PATH
  export LD_LIBRARY_PATH="${PWD}/build-pgo1/lib:${LD_LIBRARY_PATH}"

  # Get path to the zstd binary
  ZSTD_BINARY="${PWD}/build-pgo1/programs/zstd"

  # Simple sanity check
  if [ ! -x "${ZSTD_BINARY}" ]; then
    echo "ERROR: zstd binary not found or not executable"
    return 1
  fi

  # Run the training workload
  run_training_workload "${ZSTD_BINARY}" "${pgo_dir}" "${tmpdir}"

  # Run library tests for standard PGO
  echo "Running library tests for standard PGO profiling..."
  run_library_tests "${ZSTD_BINARY}" "${pgo_dir}" "${tmpdir}"

  # Merge standard profile data
  echo "Merging standard PGO profile data..."
  llvm-profdata merge -output="${srcdir}/standard.profdata" "${srcdir}/pgo_standard"

  # --- Stage 2: Context-Sensitive PGO - Second round using first profile ---
  echo "Stage 2: Building with context-sensitive PGO instrumentation..."

  # Create pgo_cs directory
  mkdir -p "${srcdir}/pgo_cs"

  # Update flags for CS-PGO instrumentation, using standard profile data
  CFLAGS="${CFLAGS_ORIG} -fprofile-use=${srcdir}/standard.profdata -fcs-profile-generate=${srcdir}/pgo_cs -g3 -fno-omit-frame-pointer -Xclang -mllvm -Xclang -vp-counters-per-site=50 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling -pthread"
  CXXFLAGS="${CXXFLAGS_ORIG} -fprofile-use=${srcdir}/standard.profdata -fcs-profile-generate=${srcdir}/pgo_cs -g3 -fno-omit-frame-pointer -Xclang -mllvm -Xclang -vp-counters-per-site=50 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling -pthread"
  LDFLAGS="${LDFLAGS_ORIG} -fprofile-use=${srcdir}/standard.profdata -fcs-profile-generate=${srcdir}/pgo_cs -g3 -fno-omit-frame-pointer -Xclang -mllvm -Xclang -vp-counters-per-site=50 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling -lpthread"

  # Configure and build with CS-PGO instrumentation
  cmake -S build/cmake -B build-pgo2 -G Ninja \
    -DCMAKE_BUILD_TYPE=Debug \
    -DCMAKE_C_FLAGS="${CFLAGS}" \
    -DCMAKE_CXX_FLAGS="${CXXFLAGS}" \
    -DCMAKE_EXE_LINKER_FLAGS="${LDFLAGS}" \
    -DCMAKE_SHARED_LINKER_FLAGS="${LDFLAGS}" \
    -DZSTD_MULTITHREAD_SUPPORT=ON \
    -DZSTD_BUILD_TESTS=ON \
    -DZSTD_BUILD_STATIC=OFF \
    -DZSTD_PROGRAMS_LINK_SHARED=ON \
    -DCMAKE_POSITION_INDEPENDENT_CODE=ON \
    -DZSTD_ZLIB_SUPPORT=ON \
    -DZSTD_LZMA_SUPPORT=ON \
    -DZSTD_LZ4_SUPPORT=ON

  # Build with CS-PGO instrumentation
  cmake --build build-pgo2 -j$(nproc)

  # Update LD_LIBRARY_PATH for the new build
  export LD_LIBRARY_PATH="${PWD}/build-pgo2/lib:${LD_LIBRARY_PATH}"

  # Run the same training workload to generate context-sensitive profile data
  echo "Running workload to generate context-sensitive PGO profile data..."
  ZSTD_BINARY="${PWD}/build-pgo2/programs/zstd"
  run_training_workload "${ZSTD_BINARY}" "${pgo_dir}" "${tmpdir}"

  # Run library tests for context-sensitive PGO
  echo "Running library tests for context-sensitive PGO profiling..."
  run_library_tests "${ZSTD_BINARY}" "${pgo_dir}" "${tmpdir}"

  # Merge context-sensitive profile with standard profile
  echo "Merging context-sensitive profile with standard profile..."
  llvm-profdata merge -output="${srcdir}/merged.profdata" "${srcdir}/pgo_cs" "${srcdir}/standard.profdata"

  # --- Stage 3: Final build with merged profile data ---
  echo "Stage 3: Building final version with merged profile data..."

  # Update flags for the final optimized build
  CFLAGS="${CFLAGS_ORIG} -fprofile-use=${srcdir}/merged.profdata -pthread"
  CXXFLAGS="${CXXFLAGS_ORIG} -fprofile-use=${srcdir}/merged.profdata -pthread"
  LDFLAGS="${LDFLAGS_ORIG} -fprofile-use=${srcdir}/merged.profdata -Wl,--emit-relocs -lpthread"

  # Configure and build with final optimizations
  cmake -S build/cmake -B build-opt -G Ninja \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_C_FLAGS="${CFLAGS}" \
    -DCMAKE_CXX_FLAGS="${CXXFLAGS}" \
    -DCMAKE_EXE_LINKER_FLAGS="${LDFLAGS}" \
    -DCMAKE_SHARED_LINKER_FLAGS="${LDFLAGS}" \
    -DZSTD_MULTITHREAD_SUPPORT=ON \
    -DZSTD_BUILD_TESTS=OFF \
    -DZSTD_BUILD_STATIC=OFF \
    -DZSTD_PROGRAMS_LINK_SHARED=ON \
    -DCMAKE_POSITION_INDEPENDENT_CODE=ON \
    -DZSTD_ZLIB_SUPPORT=ON \
    -DZSTD_LZMA_SUPPORT=ON \
    -DZSTD_LZ4_SUPPORT=ON \
    -DCMAKE_INSTALL_PREFIX=/usr

  # Build final optimized version
  cmake --build build-opt -j$(nproc)

  # =====================
  # Phase 5: BOLT Optimization - Only for the executable
  # =====================
  echo "Performing BOLT optimization for zstd executable only..."

  # Set up directories
  mkdir -p "${pgo_dir}/bolt_inst"
  mkdir -p "${pgo_dir}/bolt_bin"

  # Get path to original executable
  local zstd_orig="${PWD}/build-opt/programs/zstd"

  # Create instrumented version of the executable
  echo "Creating BOLT instrumented executable..."
  llvm-bolt "${zstd_orig}" \
    -o "${pgo_dir}/bolt_bin/zstd" \
    --instrument \
    --instrumentation-file="${pgo_dir}/bolt_inst/zstd.fdata"

  # Make sure the binary is executable
  chmod +x "${pgo_dir}/bolt_bin/zstd"

  # Set up environment for instrumented binary
  export LD_LIBRARY_PATH="${PWD}/build-opt/lib:${LD_LIBRARY_PATH}"

  # Run workloads with instrumented binary
  echo "Running workload with BOLT-instrumented executable..."
  run_training_workload "${pgo_dir}/bolt_bin/zstd" "${pgo_dir}" "${tmpdir}"

  # Run library tests with instrumented binary
  echo "Running library tests with BOLT-instrumented executable..."
  run_library_tests "${pgo_dir}/bolt_bin/zstd" "${pgo_dir}" "${tmpdir}"

  # Optimize executable if valid profile data exists
  if [ -s "${pgo_dir}/bolt_inst/zstd.fdata" ]; then
    echo "Optimizing zstd executable with BOLT..."

    llvm-bolt "${zstd_orig}" -o "${zstd_orig}.bolt" \
      --data="${pgo_dir}/bolt_inst/zstd.fdata" \
      --dyno-stats \
      --lite=false \
      --icf=all \
      --plt=all \
      --hugify \
      --peepholes=all \
      --indirect-call-promotion=all \
      --reorder-blocks=ext-tsp \
      --reorder-functions=cdsort \
      --split-all-cold \
      --split-eh \
      --split-functions \
      --split-strategy=cdsplit \
      --align-functions=32 --align-blocks --block-alignment=16 \
      --x86-strip-redundant-address-size \
      --frame-opt-rm-stores --frame-opt=all --hot-data \
      --jump-tables=aggressive \
      --stoke

    # Replace the original with the optimized version
    if [ -f "${zstd_orig}.bolt" ]; then
      mv -f "${zstd_orig}.bolt" "${zstd_orig}"
      echo "Successfully applied BOLT optimizations to zstd executable"
    else
      echo "Warning: BOLT optimization for zstd executable failed"
    fi
  else
    echo "Warning: No valid BOLT profile data found for zstd executable"
  fi

  # Create the final build directory that will be used for installation
  mkdir -p build-bolt
  cp -a build-opt/* build-bolt/

  # Clean up temporary directories
  rm -rf "${srcdir}/pgo_standard" "${srcdir}/pgo_cs" "${tmpdir}" "${pgo_dir}/bolt_inst" "${pgo_dir}/bolt_bin"
}

package() {
  cd "${pkgname}-${pkgver}"
  DESTDIR="${pkgdir}" cmake --install build-bolt

  # Use llvm-strip only on recognized file formats
  find "$pkgdir" -type f \( -name '*.so*' -o -name '*.a' -o -executable \) -print0 | while IFS= read -r -d '' file; do
    if llvm-strip --strip-unneeded "$file" 2>/dev/null || llvm-strip --strip-all "$file" 2>/dev/null; then
      echo "Stripped: $file"
    else
      echo "Skipping: $file (not a valid object file)" >&2
    fi
  done

  # Create symlink
  ln -sf /usr/bin/zstd "${pkgdir}/usr/bin/zstdmt"

  # Install license
  install -Dm644 LICENSE -t "${pkgdir}/usr/share/licenses/${pkgname}/"
}
