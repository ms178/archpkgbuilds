pkgname=glslang
pkgver=15.2.0
pkgrel=9.2
pkgdesc="OpenGL and OpenGL ES shader front end and validator"
arch=('x86_64')
url='https://github.com/KhronosGroup/glslang'
license=('BSD')
depends=('gcc-libs' 'spirv-tools')
makedepends=('cmake' 'ninja' 'spirv-headers' 'python' 'llvm')
options=('staticlibs' '!strip')
source=(${pkgname}-${pkgver}.tar.gz::https://github.com/KhronosGroup/glslang/archive/${pkgver}.tar.gz)
sha256sums=('1c4d0a5a38c8aaf89a2d7e6093be734320599f5a6775b2726beeb05b0c054e66')

# Function to generate synthetic test shaders for more comprehensive coverage
generate_training_shaders() {
  local output_dir="$1"

  echo "Generating synthetic GLSL shaders for training in $output_dir..."

  # Create output directory if it doesn't exist
  mkdir -p "$output_dir"

  # 1. Create a simple vertex shader
  cat > "$output_dir/simple.vert" << 'EOF'
#version 450
layout(location = 0) in vec3 inPosition;
layout(location = 1) in vec3 inColor;
layout(location = 0) out vec3 fragColor;
void main() {
    gl_Position = vec4(inPosition, 1.0);
    fragColor = inColor;
}
EOF

  # 2. Create a complex vertex shader with many features
  cat > "$output_dir/complex.vert" << 'EOF'
#version 450
#extension GL_ARB_separate_shader_objects : enable

layout(binding = 0) uniform UniformBufferObject {
    mat4 model;
    mat4 view;
    mat4 proj;
    float time;
} ubo;

layout(location = 0) in vec3 inPosition;
layout(location = 1) in vec3 inNormal;
layout(location = 2) in vec2 inTexCoord;

layout(location = 0) out vec3 fragPosition;
layout(location = 1) out vec3 fragNormal;
layout(location = 2) out vec2 fragTexCoord;
layout(location = 3) out vec3 fragColor;

const vec3 COLORS[6] = vec3[](
    vec3(1.0, 0.0, 0.0),
    vec3(0.0, 1.0, 0.0),
    vec3(0.0, 0.0, 1.0),
    vec3(1.0, 1.0, 0.0),
    vec3(0.0, 1.0, 1.0),
    vec3(1.0, 0.0, 1.0)
);

vec3 computeColor(vec3 position, float time) {
    int index = int(mod(position.x * position.y * position.z * 10.0 + time, 6.0));
    return COLORS[index];
}

void main() {
    vec3 animatedPosition = inPosition;
    animatedPosition.y += sin(ubo.time * 2.0 + inPosition.x * 4.0) * 0.2;

    gl_Position = ubo.proj * ubo.view * ubo.model * vec4(animatedPosition, 1.0);

    fragPosition = vec3(ubo.model * vec4(animatedPosition, 1.0));
    fragNormal = mat3(transpose(inverse(ubo.model))) * inNormal;
    fragTexCoord = inTexCoord;
    fragColor = computeColor(inPosition, ubo.time);
}
EOF

  # 3. Create a fragment shader
  cat > "$output_dir/lighting.frag" << 'EOF'
#version 450
#extension GL_ARB_separate_shader_objects : enable

layout(binding = 1) uniform sampler2D texSampler;
layout(binding = 2) uniform LightingData {
    vec3 lightPos;
    vec3 viewPos;
    vec3 lightColor;
    float ambientStrength;
    float specularStrength;
    float shininess;
} lighting;

layout(location = 0) in vec3 fragPosition;
layout(location = 1) in vec3 fragNormal;
layout(location = 2) in vec2 fragTexCoord;
layout(location = 3) in vec3 fragColor;

layout(location = 0) out vec4 outColor;

void main() {
    // Ambient
    vec3 ambient = lighting.ambientStrength * lighting.lightColor;

    // Diffuse
    vec3 norm = normalize(fragNormal);
    vec3 lightDir = normalize(lighting.lightPos - fragPosition);
    float diff = max(dot(norm, lightDir), 0.0);
    vec3 diffuse = diff * lighting.lightColor;

    // Specular
    vec3 viewDir = normalize(lighting.viewPos - fragPosition);
    vec3 reflectDir = reflect(-lightDir, norm);
    float spec = pow(max(dot(viewDir, reflectDir), 0.0), lighting.shininess);
    vec3 specular = lighting.specularStrength * spec * lighting.lightColor;

    // Combine with texture and vertex color
    vec3 result = (ambient + diffuse + specular) * fragColor * texture(texSampler, fragTexCoord).rgb;
    outColor = vec4(result, 1.0);
}
EOF

  # 4. Create a compute shader
  cat > "$output_dir/compute.comp" << 'EOF'
#version 450
#extension GL_ARB_separate_shader_objects : enable

layout(local_size_x = 16, local_size_y = 16) in;

layout(binding = 0, rgba8) uniform image2D inputImage;
layout(binding = 1, rgba8) uniform image2D outputImage;

layout(binding = 2) uniform FilterParams {
    float kernel[9];
    int width;
    int height;
    float intensity;
} params;

void main() {
    ivec2 pixel_coord = ivec2(gl_GlobalInvocationID.xy);

    if (pixel_coord.x >= params.width || pixel_coord.y >= params.height) {
        return;
    }

    vec4 sum = vec4(0.0);
    int kernelIndex = 0;

    for (int i = -1; i <= 1; i++) {
        for (int j = -1; j <= 1; j++) {
            ivec2 sample_coord = pixel_coord + ivec2(i, j);

            // Clamp to edge
            sample_coord = clamp(sample_coord, ivec2(0), ivec2(params.width-1, params.height-1));

            vec4 sample = imageLoad(inputImage, sample_coord);
            sum += sample * params.kernel[kernelIndex++];
        }
    }

    // Blend with original based on intensity
    vec4 original = imageLoad(inputImage, pixel_coord);
    vec4 filtered = mix(original, sum, params.intensity);

    imageStore(outputImage, pixel_coord, filtered);
}
EOF

  # 5. Create a tessellation control shader
  cat > "$output_dir/tessellation.tesc" << 'EOF'
#version 450
#extension GL_ARB_separate_shader_objects : enable

layout(vertices = 3) out;

layout(binding = 0) uniform TessParams {
    float innerLevel;
    float outerLevel;
    float time;
} tessParams;

layout(location = 0) in vec3 inPosition[];
layout(location = 1) in vec3 inNormal[];
layout(location = 2) in vec2 inTexCoord[];

layout(location = 0) out vec3 outPosition[];
layout(location = 1) out vec3 outNormal[];
layout(location = 2) out vec2 outTexCoord[];

float calculateTessLevel(vec3 pos0, vec3 pos1) {
    // Calculate distance-based tessellation
    float midX = (pos0.x + pos1.x) / 2.0;
    float variation = sin(tessParams.time + midX * 3.0) * 0.5 + 0.5;
    return mix(1.0, tessParams.outerLevel, variation);
}

void main() {
    // Pass attributes through
    outPosition[gl_InvocationID] = inPosition[gl_InvocationID];
    outNormal[gl_InvocationID] = inNormal[gl_InvocationID];
    outTexCoord[gl_InvocationID] = inTexCoord[gl_InvocationID];

    // Calculate tessellation levels
    if (gl_InvocationID == 0) {
        gl_TessLevelInner[0] = tessParams.innerLevel;

        gl_TessLevelOuter[0] = calculateTessLevel(inPosition[1], inPosition[2]);
        gl_TessLevelOuter[1] = calculateTessLevel(inPosition[2], inPosition[0]);
        gl_TessLevelOuter[2] = calculateTessLevel(inPosition[0], inPosition[1]);
    }
}
EOF

  # 6. Create a tessellation evaluation shader
  cat > "$output_dir/tessellation.tese" << 'EOF'
#version 450
#extension GL_ARB_separate_shader_objects : enable

layout(triangles, equal_spacing, ccw) in;

layout(binding = 1) uniform UniformBufferObject {
    mat4 model;
    mat4 view;
    mat4 proj;
    float time;
    float displacement;
} ubo;

layout(location = 0) in vec3 inPosition[];
layout(location = 1) in vec3 inNormal[];
layout(location = 2) in vec2 inTexCoord[];

layout(location = 0) out vec3 fragPosition;
layout(location = 1) out vec3 fragNormal;
layout(location = 2) out vec2 fragTexCoord;

// Barycentric interpolation function
vec3 interpolate3D(vec3 v0, vec3 v1, vec3 v2) {
    return gl_TessCoord.x * v0 + gl_TessCoord.y * v1 + gl_TessCoord.z * v2;
}

// Texture coordinate interpolation
vec2 interpolate2D(vec2 v0, vec2 v1, vec2 v2) {
    return gl_TessCoord.x * v0 + gl_TessCoord.y * v1 + gl_TessCoord.z * v2;
}

void main() {
    // Interpolate position, normal and texture coordinates
    vec3 position = interpolate3D(inPosition[0], inPosition[1], inPosition[2]);
    vec3 normal = normalize(interpolate3D(inNormal[0], inNormal[1], inNormal[2]));
    vec2 texCoord = interpolate2D(inTexCoord[0], inTexCoord[1], inTexCoord[2]);

    // Apply displacement along normal
    float disp = sin(position.x * 10.0 + ubo.time) * sin(position.z * 10.0 + ubo.time) * ubo.displacement;
    position += normal * disp;

    // Transform to clip space
    gl_Position = ubo.proj * ubo.view * ubo.model * vec4(position, 1.0);

    // Pass interpolated attributes to fragment shader
    fragPosition = vec3(ubo.model * vec4(position, 1.0));
    fragNormal = mat3(transpose(inverse(ubo.model))) * normal;
    fragTexCoord = texCoord;
}
EOF

  # 7. Create a geometry shader
  cat > "$output_dir/explode.geom" << 'EOF'
#version 450
#extension GL_ARB_separate_shader_objects : enable

layout(triangles) in;
layout(triangle_strip, max_vertices = 3) out;

layout(binding = 3) uniform GeometryParams {
    float magnitude;
    float time;
} geoParams;

layout(location = 0) in vec3 inPosition[];
layout(location = 1) in vec3 inNormal[];
layout(location = 2) in vec2 inTexCoord[];

layout(location = 0) out vec3 fragPosition;
layout(location = 1) out vec3 fragNormal;
layout(location = 2) out vec2 fragTexCoord;
layout(location = 3) out vec3 fragBaryCoords;

void main() {
    // Calculate triangle normal
    vec3 a = inPosition[1] - inPosition[0];
    vec3 b = inPosition[2] - inPosition[0];
    vec3 triangleNormal = normalize(cross(a, b));

    // Calculate explode direction with time-based variation
    float explodeFactor = geoParams.magnitude * (0.5 * sin(geoParams.time) + 0.5);
    vec3 explodeDirection = triangleNormal * explodeFactor;

    // Emit each vertex with displacement
    for (int i = 0; i < 3; i++) {
        gl_Position = gl_in[i].gl_Position + vec4(explodeDirection, 0.0);
        fragPosition = inPosition[i] + explodeDirection;
        fragNormal = inNormal[i];
        fragTexCoord = inTexCoord[i];

        // Pass barycentric coordinates
        fragBaryCoords = vec3(0.0);
        fragBaryCoords[i] = 1.0;

        EmitVertex();
    }

    EndPrimitive();
}
EOF

  # 8. Create invalid shaders for error path testing
  cat > "$output_dir/invalid_syntax.vert" << 'EOF'
#version 450
layout(location = 0) in vec3 inPosition
layout(location = 1) in vec3 inColor; // Missing semicolon above
layout(location = 0) out vec3 fragColor;
void main() {
    gl_Position = vec4(inPosition, 1.0);
    fragColor = inColor
} // Missing semicolon above
EOF

  cat > "$output_dir/invalid_type.frag" << 'EOF'
#version 450
layout(location = 0) in vec3 fragColor;
layout(location = 0) out vec4 outColor;
void main() {
    outColor = fragColor; // Type mismatch: vec3 assigned to vec4
}
EOF

  cat > "$output_dir/invalid_undeclared.comp" << 'EOF'
#version 450
layout(local_size_x = 16, local_size_y = 16) in;
void main() {
    undeclaredVariable = 5.0; // Using undeclared variable
}
EOF

  echo "Successfully generated $(ls "$output_dir" | wc -l) training shaders"
  return 0
}

# Function to run comprehensive training workload
run_training_workload() {
  local build_dir="$1"
  local workload_name="$2"
  local shaders_dir="$3"
  local temp_dir="$4"

  echo "Running comprehensive training workload ($workload_name) with build directory: $build_dir"

  # Find binaries in the build directory
  local glslang_binary="$build_dir/StandAlone/glslang"
  local spirv_remap_binary="$build_dir/StandAlone/spirv-remap"

  # Setup library paths for the specific build directory
  local lib_path="$build_dir/glslang:$build_dir/SPIRV:${LD_LIBRARY_PATH:-}"
  export LD_LIBRARY_PATH="$lib_path"

  echo "Using LD_LIBRARY_PATH: $LD_LIBRARY_PATH"

  # 1. Run standard test suite first
  echo "Running standard test suite..."
  (
    cd "$build_dir"
    ctest -C Release -VV -R ".*" -j$(nproc) --output-on-failure || echo "Warning: Some tests may have failed, continuing..."
  )

  # Exit if no binaries exist
  if [ ! -x "$glslang_binary" ] && [ ! -x "$spirv_remap_binary" ]; then
    echo "Warning: No binaries found in $build_dir, skipping extended workload"
    return 1
  fi

  # Create temporary directory for SPIR-V output
  mkdir -p "$temp_dir/spirv_temp"
  mkdir -p "$temp_dir/spirv_temp/out1" "$temp_dir/spirv_temp/out2" "$temp_dir/spirv_temp/out3" "$temp_dir/spirv_temp/out4"

  # 2. Process different shader types with different options
  if [ -x "$glslang_binary" ]; then
    echo "Processing shader files with $glslang_binary..."

    # Define shader types and options
    local shader_types=("vert" "frag" "comp" "tesc" "tese" "geom")
    local opt_levels=("" "-Os" "-Od")
    local resource_modes=("" "--resource-set-binding" "--auto-map-locations")
    local target_envs=("" "--target-env vulkan1.2" "--target-env opengl")

    # Process real shader samples from the test directory
    echo "Processing real shader samples from Test directory..."
    for shader_type in "${shader_types[@]}"; do
      # Find shader files of this type, limit to reasonable number
      find Test -name "*.$shader_type" | head -n 10 | while read -r shader; do
        echo "Processing $shader"

        for opt in "${opt_levels[@]}"; do
          for res in "${resource_modes[@]}"; do
            for target in "${target_envs[@]}"; do
              # Run with various combinations of options
              "$glslang_binary" $opt $res $target -S $shader_type "$shader" > /dev/null 2>&1 || true

              # Generate SPIR-V for some combinations (for spirv-remap testing)
              if [ -n "$target" ] && [ -n "$opt" ]; then
                "$glslang_binary" $opt -G $target -o "$temp_dir/spirv_temp/$(basename "$shader").spv" "$shader" > /dev/null 2>&1 || true
              fi
            done
          done
        done
      done
    done

    # Process synthetic shaders from our generated set
    echo "Processing synthetic shaders from $shaders_dir..."
    for shader in "$shaders_dir"/*; do
      # Skip invalid shaders for now
      if [[ "$(basename "$shader")" == invalid_* ]]; then
        continue
      fi

      # Extract shader type from filename
      local shader_ext="${shader##*.}"

      echo "Processing synthetic shader: $(basename "$shader") (type: $shader_ext)"

      for opt in "${opt_levels[@]}"; do
        for target in "${target_envs[@]}"; do
          "$glslang_binary" $opt $target -S "$shader_ext" "$shader" > /dev/null 2>&1 || true

          # Generate SPIR-V for some combinations
          if [ -n "$target" ] && [ -z "$opt" ]; then
            "$glslang_binary" -G $target -o "$temp_dir/spirv_temp/$(basename "$shader").spv" "$shader" > /dev/null 2>&1 || true
          fi
        done
      done
    done

    # Exercise error paths with invalid shaders
    echo "Exercising error paths with invalid shaders..."
    for invalid_shader in "$shaders_dir/invalid_"*; do
      if [ -f "$invalid_shader" ]; then
        echo "Testing invalid shader: $(basename "$invalid_shader")"
        "$glslang_binary" "$invalid_shader" > /dev/null 2>&1 || true
      fi
    done
  fi

  # 3. Exercise spirv-remap if available
  if [ -x "$spirv_remap_binary" ] && [ -d "$temp_dir/spirv_temp" ]; then
    echo "Exercising spirv-remap..."

    # Check if we generated any SPIR-V files
    if [ "$(find "$temp_dir/spirv_temp" -name "*.spv" | wc -l)" -eq 0 ]; then
      echo "No SPIR-V files found, generating some for spirv-remap testing..."

      # Generate some SPIR-V binaries to remap if we don't have any
      if [ -x "$glslang_binary" ]; then
        find Test -name "*.vert" -o -name "*.frag" | head -n 5 | while read -r shader; do
          "$glslang_binary" -G --target-env vulkan1.2 -o "$temp_dir/spirv_temp/$(basename "$shader").spv" "$shader" > /dev/null 2>&1 || true
        done
      fi
    fi

    # If we have SPIR-V files, process them with spirv-remap
    if [ "$(find "$temp_dir/spirv_temp" -name "*.spv" | wc -l)" -gt 0 ]; then
      # Exercise different spirv-remap options
      "$spirv_remap_binary" --map all --input "$temp_dir/spirv_temp/" --output "$temp_dir/spirv_temp/out1/" > /dev/null 2>&1 || true
      "$spirv_remap_binary" --dce all --input "$temp_dir/spirv_temp/" --output "$temp_dir/spirv_temp/out2/" > /dev/null 2>&1 || true
      "$spirv_remap_binary" --opt all --input "$temp_dir/spirv_temp/" --output "$temp_dir/spirv_temp/out3/" > /dev/null 2>&1 || true
      "$spirv_remap_binary" --strip all --input "$temp_dir/spirv_temp/" --output "$temp_dir/spirv_temp/out4/" > /dev/null 2>&1 || true
    else
      echo "No SPIR-V files available for spirv-remap testing"
    fi
  fi

  echo "Completed comprehensive training workload ($workload_name)"
  return 0
}

build() {
  cd ${pkgname}-${pkgver}

  # Store original flags
  CFLAGS_ORIG="$CFLAGS"
  CXXFLAGS_ORIG="$CXXFLAGS"
  LDFLAGS_ORIG="$LDFLAGS"

  # Create directories for profiles and instrumentation
  mkdir -p "$srcdir/pgo_standard"
  mkdir -p "$srcdir/pgo_cs"
  mkdir -p "$srcdir/bolt_profile"
  mkdir -p "$srcdir/bolt_instrumented"
  mkdir -p "$srcdir/bolt_optimized"
  mkdir -p "$srcdir/workload_shaders"
  mkdir -p "$srcdir/workload_temp"

  # Setup cleanup trap
  cleanup() {
    echo "Cleaning up temporary files..."
    rm -rf "$srcdir/clang-wrapper.sh" "$srcdir/clang++-wrapper.sh"
    rm -rf "$srcdir/clang-cs-wrapper.sh" "$srcdir/clang++-cs-wrapper.sh"
    rm -rf "$srcdir/run-instrumented-tests.sh"
    rm -rf "$srcdir/workload_temp"
    # Keep profile data and generated shaders for debugging
  }
  trap cleanup EXIT

  # Generate synthetic test shaders
  generate_training_shaders "$srcdir/workload_shaders"

  # Create run-instrumented-tests.sh script with correct paths
  cat > "$srcdir/run-instrumented-tests.sh" << EOF
#!/bin/bash
# Set LD_LIBRARY_PATH (include both glslang and SPIRV)
export LD_LIBRARY_PATH="$srcdir/${pkgname}-${pkgver}/build-pgo/glslang:$srcdir/${pkgname}-${pkgver}/build-pgo/SPIRV:\${LD_LIBRARY_PATH:-}"

# Execute the glslang test script with the correct path and any arguments passed by ctest
"$srcdir/${pkgname}-${pkgver}/Test/glslang-test.sh" "\$@"
EOF
  chmod +x "$srcdir/run-instrumented-tests.sh"

  # Create compiler wrapper scripts to guarantee LLVM flags are used
  cat > "$srcdir/clang-wrapper.sh" << 'EOF'
#!/bin/bash
exec clang "$@" -mllvm -vp-counters-per-site=200 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling
EOF

  cat > "$srcdir/clang++-wrapper.sh" << 'EOF'
#!/bin/bash
exec clang++ "$@" -mllvm -vp-counters-per-site=200 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling
EOF

  chmod +x "$srcdir/clang-wrapper.sh" "$srcdir/clang++-wrapper.sh"

  local _common_cmake_options=(
    -DCMAKE_INSTALL_PREFIX=/usr
    -DCMAKE_C_STANDARD=23
    -DCMAKE_CXX_STANDARD=23
    -DALLOW_EXTERNAL_SPIRV_TOOLS=ON
    -DGLSLANG_TESTS=ON
  )

  # --- Stage 1: Standard PGO - First round with standard instrumentation ---
  echo "Stage 1: Building with standard PGO instrumentation..."

  # Set environment variables for compiler flags
  export LLVM_VP_COUNTERS_PER_SITE=200
  export LLVM_PROFILE_FILE="$srcdir/pgo_standard/%m-%p.profraw"

  # Add standard PGO instrumentation flags with increased counters
  CFLAGS+=" -fprofile-generate=$srcdir/pgo_standard -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=200 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"
  CXXFLAGS+=" -fprofile-generate=$srcdir/pgo_standard -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=200 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"
  LDFLAGS+=" -fprofile-generate=$srcdir/pgo_standard -g3 -fno-omit-frame-pointer"

  cmake \
    -Bbuild-pgo1 \
    -GNinja \
    -DCMAKE_BUILD_TYPE=Debug \
    "${_common_cmake_options[@]}" \
    -DBUILD_SHARED_LIBS=ON \
    -DCMAKE_C_COMPILER="$srcdir/clang-wrapper.sh" \
    -DCMAKE_CXX_COMPILER="$srcdir/clang++-wrapper.sh" \
    -DCMAKE_C_FLAGS="$CFLAGS" \
    -DCMAKE_CXX_FLAGS="$CXXFLAGS" \
    -DCMAKE_EXE_LINKER_FLAGS="$LDFLAGS" \
    -DCMAKE_SHARED_LINKER_FLAGS="$LDFLAGS"

  ninja -Cbuild-pgo1 || { echo "Error: Failed to build with standard PGO instrumentation"; return 1; }

  # Run comprehensive workload for standard PGO
  run_training_workload "$srcdir/${pkgname}-${pkgver}/build-pgo1" "standard-pgo" "$srcdir/workload_shaders" "$srcdir/workload_temp"

  # Merge standard profile data
  echo "Merging standard PGO profile data..."
  if ! llvm-profdata merge -output="$srcdir/standard.profdata" "$srcdir/pgo_standard"/*.profraw; then
    echo "Error: Failed to merge standard profile data!"
    return 1
  fi

  # Verify merged .profdata file
  if [ ! -s "$srcdir/standard.profdata" ] || [ "$(stat -c%s "$srcdir/standard.profdata")" -lt 1000 ]; then
    echo "Error: Standard .profdata file is invalid or too small!"
    return 1
  fi

  # --- Stage 2: Context-Sensitive PGO - Second round using first profile ---
  echo "Stage 2: Building with context-sensitive PGO instrumentation..."

  # Update environment variables for CS profile - don't specify a custom pattern
  # Let LLVM use its default naming scheme since that's working
  export LLVM_PROFILE_FILE="$srcdir/pgo_cs/%m-%p.profraw"

  # Create new wrapper scripts for CS-PGO
  cat > "$srcdir/clang-cs-wrapper.sh" << 'EOF'
#!/bin/bash
exec clang "$@" -mllvm -vp-counters-per-site=200 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling
EOF

  cat > "$srcdir/clang++-cs-wrapper.sh" << 'EOF'
#!/bin/bash
exec clang++ "$@" -mllvm -vp-counters-per-site=200 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling
EOF

  chmod +x "$srcdir/clang-cs-wrapper.sh" "$srcdir/clang++-cs-wrapper.sh"

  # Update flags for CS-PGO instrumentation, using standard profile data
  CFLAGS="${CFLAGS_ORIG} -fprofile-use=$srcdir/standard.profdata -fcs-profile-generate=$srcdir/pgo_cs -g3 -fno-omit-frame-pointer"
  CXXFLAGS="${CXXFLAGS_ORIG} -fprofile-use=$srcdir/standard.profdata -fcs-profile-generate=$srcdir/pgo_cs -g3 -fno-omit-frame-pointer"
  LDFLAGS="${LDFLAGS_ORIG} -fprofile-use=$srcdir/standard.profdata -fcs-profile-generate=$srcdir/pgo_cs -g3 -fno-omit-frame-pointer"

  cmake \
    -Bbuild-pgo2 \
    -GNinja \
    -DCMAKE_BUILD_TYPE=Debug \
    "${_common_cmake_options[@]}" \
    -DBUILD_SHARED_LIBS=ON \
    -DCMAKE_C_COMPILER="$srcdir/clang-cs-wrapper.sh" \
    -DCMAKE_CXX_COMPILER="$srcdir/clang++-cs-wrapper.sh" \
    -DCMAKE_C_FLAGS="$CFLAGS" \
    -DCMAKE_CXX_FLAGS="$CXXFLAGS" \
    -DCMAKE_EXE_LINKER_FLAGS="$LDFLAGS" \
    -DCMAKE_SHARED_LINKER_FLAGS="$LDFLAGS"

  ninja -Cbuild-pgo2 || { echo "Error: Failed to build with CS-PGO instrumentation"; return 1; }

  # Run comprehensive workload for CS-PGO
  run_training_workload "$srcdir/${pkgname}-${pkgver}/build-pgo2" "cs-pgo" "$srcdir/workload_shaders" "$srcdir/workload_temp"

  # Verify that CS profile data files exist before attempting to merge
  echo "Verifying context-sensitive profile data files..."
  CS_PROFILE_COUNT=$(find "$srcdir/pgo_cs" -name "*.profraw" | wc -l)
  if [ "$CS_PROFILE_COUNT" -eq 0 ]; then
    echo "Error: No context-sensitive profile data files found in $srcdir/pgo_cs!"
    echo "Directory contents:"
    ls -la "$srcdir/pgo_cs"
    return 1
  else
    echo "Found $CS_PROFILE_COUNT context-sensitive profile data files"
  fi

  # Merge CS profiles first, then merge with standard profile
  echo "Merging context-sensitive profiles to a single file..."
  if ! llvm-profdata merge -output="$srcdir/cs.profdata" $(find "$srcdir/pgo_cs" -name "*.profraw"); then
    echo "Error: Failed to merge CS profiles!"
    # Show diagnostic info about the profiles
    echo "Profile filenames:"
    find "$srcdir/pgo_cs" -name "*.profraw" | head -n 10
    echo "Profile file sizes:"
    find "$srcdir/pgo_cs" -name "*.profraw" -exec ls -lh {} \; | head -n 10
    return 1
  fi

  # Then merge the CS profile with the standard profile
  echo "Merging CS profiles with standard profile..."
  if ! llvm-profdata merge -weighted-input=1,"$srcdir/standard.profdata" \
                           -weighted-input=3,"$srcdir/cs.profdata" \
                           -output="$srcdir/merged.profdata"; then
    echo "Error: Failed to merge CS profiles with standard profile!"
    return 1
  fi

  # --- Stage 3: Final build with merged profile data ---
  echo "Stage 3: Building final version with merged profile data..."

  # Clear any profile environment variables
  unset LLVM_PROFILE_FILE
  unset LLVM_VP_COUNTERS_PER_SITE

  # Update flags for the final optimized build
  CFLAGS="${CFLAGS_ORIG} -fprofile-use=$srcdir/merged.profdata -fno-common -ffunction-sections -fdata-sections"
  CXXFLAGS="${CXXFLAGS_ORIG} -fprofile-use=$srcdir/merged.profdata -fno-common -ffunction-sections -fdata-sections"
  LDFLAGS="${LDFLAGS_ORIG} -fprofile-use=$srcdir/merged.profdata -Wl,--gc-sections -Wl,--emit-relocs"

  cmake \
    -Bbuild-pgo \
    -GNinja \
    -DCMAKE_BUILD_TYPE=Release \
    "${_common_cmake_options[@]}" \
    -DBUILD_SHARED_LIBS=ON \
    -DCMAKE_C_FLAGS="$CFLAGS" \
    -DCMAKE_CXX_FLAGS="$CXXFLAGS" \
    -DCMAKE_EXE_LINKER_FLAGS="$LDFLAGS" \
    -DCMAKE_SHARED_LINKER_FLAGS="$LDFLAGS"

  ninja -Cbuild-pgo || { echo "Error: Failed to build final optimized version"; return 1; }

  # --- Stage 4: Instrument for BOLT ---
  echo "Stage 4: Creating instrumented binaries for BOLT..."

  # Detect binaries automatically
  local binaries=()
  while IFS= read -r -d '' binary; do
    if [[ -x "$binary" && ! -L "$binary" && "$(file -b "$binary")" == *"ELF"* ]]; then
      binaries+=("$binary")
    fi
  done < <(find "$srcdir/${pkgname}-${pkgver}/build-pgo/StandAlone" -type f -print0)

  echo "Found ${#binaries[@]} binaries to instrument for BOLT"

  # Create a proper directory structure for instrumented binaries
  # that matches what our training workload function expects
  rm -rf "$srcdir/bolt_instrumented"
  mkdir -p "$srcdir/bolt_instrumented/StandAlone"
  mkdir -p "$srcdir/bolt_instrumented/glslang"
  mkdir -p "$srcdir/bolt_instrumented/SPIRV"

  # Instrument binaries and place them in the right location
  for binary in "${binaries[@]}"; do
    local binary_name=$(basename "$binary")
    echo "Instrumenting binary for BOLT: $binary_name"

    # Instrument binary
    if ! llvm-bolt "$binary" \
         --instrument \
         --lite=false \
         --instrumentation-file-append-pid \
         --instrumentation-file="$srcdir/bolt_profile/prof.fdata" \
         -o "$srcdir/bolt_instrumented/StandAlone/$binary_name"; then
      echo "Warning: BOLT instrumentation failed for $binary_name, skipping..."
      # Copy the original binary as fallback
      cp "$binary" "$srcdir/bolt_instrumented/StandAlone/$binary_name"
    else
      echo "Successfully instrumented $binary_name"
    fi
  done

  # Copy required libraries to match the build directory structure
  echo "Copying libraries to match build directory structure..."
  cp -a "$srcdir/${pkgname}-${pkgver}/build-pgo/glslang"/*.so* "$srcdir/bolt_instrumented/glslang/" 2>/dev/null || true
  cp -a "$srcdir/${pkgname}-${pkgver}/build-pgo/SPIRV"/*.so* "$srcdir/bolt_instrumented/SPIRV/" 2>/dev/null || true

  # Copy required test scripts and data
  echo "Copying test scripts and data..."
  mkdir -p "$srcdir/bolt_instrumented/Test"
  cp -a "$srcdir/${pkgname}-${pkgver}/Test"/* "$srcdir/bolt_instrumented/Test/" 2>/dev/null || true

  # Run the same training workload as used for PGO
  echo "Running training workload for BOLT instrumentation..."
  export LD_LIBRARY_PATH="$srcdir/bolt_instrumented/glslang:$srcdir/bolt_instrumented/SPIRV:${LD_LIBRARY_PATH:-}"
  export PATH="$srcdir/bolt_instrumented/StandAlone:$PATH"

  run_training_workload "$srcdir/bolt_instrumented" "bolt" "$srcdir/workload_shaders" "$srcdir/workload_temp"

  # Verify BOLT profile data files
  echo "Looking for BOLT profile data files..."
  BOLT_PROFILE_COUNT=$(find "$srcdir/bolt_profile" -name "prof.fdata*" | wc -l)

  if [ "$BOLT_PROFILE_COUNT" -eq 0 ]; then
    echo "Warning: No BOLT profile data files found. Skipping BOLT optimization."
    return 0
  else
    echo "Found $BOLT_PROFILE_COUNT BOLT profile data files"
  fi

  # Merge BOLT profile data files
  echo "Merging BOLT profile data files..."
  BOLT_PROFILES=$(find "$srcdir/bolt_profile" -name "prof.fdata*" | tr '\n' ' ')

  if ! merge-fdata $BOLT_PROFILES > "$srcdir/bolt_profile/merged.fdata" 2>/dev/null; then
    echo "Error: Failed to merge BOLT profile data! Trying alternative approach..."
    # Try merging files one by one
    > "$srcdir/bolt_profile/merged.fdata"
    for profile in $(find "$srcdir/bolt_profile" -name "prof.fdata*"); do
      cat "$profile" >> "$srcdir/bolt_profile/merged.fdata" 2>/dev/null || true
    done
  fi

  # Verify merged BOLT profile data file
  if [ ! -s "$srcdir/bolt_profile/merged.fdata" ]; then
    echo "Warning: Merged BOLT profile data file is empty! Skipping BOLT optimization."
    return 0
  fi

  # --- Stage 5: Optimize with BOLT ---
  echo "Stage 5: Optimizing with BOLT..."

  # Clear the output directory
  rm -rf "$srcdir/bolt_optimized"
  mkdir -p "$srcdir/bolt_optimized"

  # Define tiered BOLT optimization options
  local bolt_basic_options=(
    --data "$srcdir/bolt_profile/merged.fdata"
    --dyno-stats
    --use-gnu-stack
  )

  local bolt_aggressive_options=(
    "${bolt_basic_options[@]}"
    --lite=false
    --icf=all
    --plt=all
    --hugify
    --peepholes=all
    --x86-strip-redundant-address-size
    --indirect-call-promotion=all
    --reorder-blocks=ext-tsp
    --reorder-functions=cdsort
    --split-all-cold
    --split-eh
    --split-functions
    --split-strategy=cdsplit
  )

  # Optimize binaries
  for binary in "${binaries[@]}"; do
    local binary_name=$(basename "$binary")
    echo "Optimizing binary with BOLT: $binary_name"

    # First check if the profile has data for this binary
    if ! grep -q "$binary_name" "$srcdir/bolt_profile/merged.fdata"; then
      echo "Warning: No profile data for $binary_name in merged.fdata, attempting optimization anyway..."
    fi

    # Try aggressive optimization first, fall back to basic if it fails
    if ! llvm-bolt "$binary" \
         "${bolt_aggressive_options[@]}" \
         -o "$srcdir/bolt_optimized/$binary_name" 2> "$srcdir/bolt_optimized/${binary_name}.log"; then
      echo "Warning: Aggressive BOLT optimization failed, trying basic optimization..."

      if ! llvm-bolt "$binary" \
           "${bolt_basic_options[@]}" \
           -o "$srcdir/bolt_optimized/$binary_name" 2>> "$srcdir/bolt_optimized/${binary_name}.log"; then
        echo "Warning: BOLT optimization failed completely for $binary_name, skipping..."
        # Check if we still have a binary in the output directory
        if [ ! -f "$srcdir/bolt_optimized/$binary_name" ]; then
          # Copy the original as a fallback
          cp "$binary" "$srcdir/bolt_optimized/$binary_name"
          echo "Copied original binary as fallback"
        fi
        continue
      fi
    fi

    # Verify the optimized binary exists and is executable
    if [ -f "$srcdir/bolt_optimized/$binary_name" ] && [ -x "$srcdir/bolt_optimized/$binary_name" ]; then
      echo "Successfully optimized $binary_name with BOLT"
      # Check the file size difference
      local orig_size=$(stat -c %s "$binary")
      local bolt_size=$(stat -c %s "$srcdir/bolt_optimized/$binary_name")
      echo "Size: Original = $orig_size bytes, Optimized = $bolt_size bytes ($(( (bolt_size - orig_size) * 100 / orig_size ))% change)"
    else
      echo "Error: BOLT optimization produced invalid binary for $binary_name"
      # Copy the original as a fallback
      cp "$binary" "$srcdir/bolt_optimized/$binary_name"
      echo "Copied original binary as fallback"
    fi
  done

  # Print BOLT optimization summary
  echo "BOLT optimization summary:"
  for bolt_log in "$srcdir/bolt_optimized"/*.log; do
    if [ -f "$bolt_log" ]; then
      binary_name=$(basename "$bolt_log" .log)
      echo "--------------------------------------------------------"
      echo "Summary for $binary_name:"
      grep "BOLT-INFO:" "$bolt_log" | grep -E "runtime|improvement|optimized" || echo "No optimization info found"
      echo "--------------------------------------------------------"
    fi
  done
}
package() {
  cd ${pkgname}-${pkgver}

  # Install PGO-optimized files first
  DESTDIR="${pkgdir}" cmake --install build-pgo

  # Install BOLT-optimized binaries if they exist
  echo "Installing BOLT-optimized binaries if available..."
  if [ -d "$srcdir/bolt_optimized" ] && [ "$(ls -A "$srcdir/bolt_optimized")" ]; then
    # Find all binaries in bolt_optimized directory
    find "$srcdir/bolt_optimized" -type f -executable -print0 | while IFS= read -r -d '' bolt_binary; do
      if [ -f "$bolt_binary" ] && [ -x "$bolt_binary" ]; then
        binary_name=$(basename "$bolt_binary")
        echo "Installing BOLT-optimized binary: $binary_name"
        install -Dm755 "$bolt_binary" "${pkgdir}/usr/bin/$binary_name"
      fi
    done
  fi

  # Install license
  install -Dm644 LICENSE.txt "${pkgdir}"/usr/share/licenses/${pkgname}/LICENSE

  # Create symlinks for shared libraries
  cd "${pkgdir}"/usr/lib
  for lib in *.so.*; do
    if [ -f "$lib" ]; then
      ln -sf "${lib}" "${lib%.*}"
      ln -sf "${lib}" "${lib%.*.*}"
    fi
  done

  # Create symlink for glslangValidator
  cd "${pkgdir}"/usr/bin
  if [ -f "glslang" ]; then
    ln -sf glslang glslangValidator
  fi

  # Use llvm-strip only on recognized file formats
  echo "Stripping binaries and libraries..."
  find "$pkgdir" -type f \( -name '*.so*' -o -name '*.a' -o -executable \) -print0 | while IFS= read -r -d '' file; do
    if [ -L "$file" ]; then
      continue  # Skip symlinks
    fi

    # Check file type before attempting to strip
    if file "$file" | grep -q "ELF"; then
      if llvm-strip --strip-unneeded "$file" 2>/dev/null || llvm-strip --strip-all "$file" 2>/dev/null; then
        echo "Stripped: $file"
      else
        echo "Failed to strip: $file"
      fi
    else
      echo "Skipping: $file (not an ELF file)"
    fi
  done
}
