pkgname=(
  zlib-ng
  zlib-ng-compat
)
pkgver=2.2.4
pkgrel=15.1
_zlibver=1.3.1
pkgdesc='zlib-Ersatz mit Optimierungen für Systeme der nächsten Generation'
url='https://github.com/zlib-ng/zlib-ng'
arch=('x86_64')
license=('custom:zlib')
depends=('glibc')
makedepends=(
  cmake
  ninja
  git
  llvm
)
source=(git+https://github.com/zlib-ng/zlib-ng#tag=${pkgver})
sha256sums=('SKIP')

generate_training_data() {
    local pgo_dir="$1"

    echo "Generating comprehensive training data..."
    mkdir -p "${pgo_dir}/training"

    # Pattern-based training files
    echo "Creating pattern files..."
    for i in {1..100}; do
        {
            seq 1 4000
            yes "pattern${i}" | head -n 4000
            dd if=/dev/urandom bs=1K count=200 2>/dev/null | base64
            printf "%0.sA" $(seq 1 40000)
            printf "%0.sB" $(seq 1 40000)
            echo "Common header ${i}"
            echo "Common footer ${i}"
        } > "${pgo_dir}/training/training_${i}.txt"
    done

    # Large text files
    dd if=/dev/urandom bs=1M count=100 2>/dev/null | base64 > "${pgo_dir}/training/text1.txt"
    seq 1 1000000 > "${pgo_dir}/training/numbers.txt"
    yes "repeated data" | head -n 1000000 > "${pgo_dir}/training/repeated.txt"

    # Binary files
    dd if=/dev/urandom of="${pgo_dir}/training/random.bin" bs=1M count=100 status=none

    # Compression ratio test files
    for i in {1..5}; do
        dd if=/dev/urandom bs=1K count=$((i * 2000)) 2>/dev/null > "${pgo_dir}/training/binary_${i}.bin"
    done

    # Highly compressible files
    for i in {1..3}; do
        printf "%0.sA" $(seq 1 $((i * 1000000))) > "${pgo_dir}/training/compressible_${i}.txt"
    done

    # Mixed content files
    if [ -d "/usr/share/doc" ]; then
        find /usr/share/doc /usr/share/man -type f -name "*.txt" -o -name "*.gz" 2>/dev/null | \
        head -n 100 | while read -r file; do
            if [[ $file == *.gz ]]; then
                zcat "${file}" 2>/dev/null
            else
                cat "${file}" 2>/dev/null
            fi
        done > "${pgo_dir}/training/docs.txt"
    fi

    # HTML-like content
    for i in {1..1000}; do
        echo "<html><body><h1>Header $i</h1><p>$(dd if=/dev/urandom bs=100 count=1 2>/dev/null | base64)</p></body></html>" \
        >> "${pgo_dir}/training/web_content.txt"
    done

    # JSON-like content
    for i in {1..1000}; do
        echo "{\"id\": $i, \"data\": \"$(dd if=/dev/urandom bs=50 count=1 2>/dev/null | base64)\", \"array\": [1,2,3,4,5]}" \
        >> "${pgo_dir}/training/json_content.txt"
    done
}

run_training_workload() {
    local build_dir="$1"
    local PROFILE_DIR="$2"
    local TMPDIR="$3"

    # Function to run compression tests with different strategies and levels
    run_compression_tests() {
        local input_file="$1"
        local lib_path="$2"
        local temp_gz="${TMPDIR}/temp.gz"

        # Test different compression levels
        for level in {1..9}; do
            LD_LIBRARY_PATH="${lib_path}" "${build_dir}/minigzip" -${level} < "${input_file}" > "${temp_gz}"
            LD_LIBRARY_PATH="${lib_path}" "${build_dir}/minigzip" -d < "${temp_gz}" > /dev/null
            rm -f "${temp_gz}"
        done

        # Test with different window bits
        for bits in {9..15}; do
            local temp_deflate="${TMPDIR}/temp.deflate"
            local temp_inflated="${TMPDIR}/temp.inflated"
            LD_LIBRARY_PATH="${lib_path}" "${build_dir}/example" "${input_file}" "${temp_deflate}" $bits
            LD_LIBRARY_PATH="${lib_path}" "${build_dir}/example" -d "${temp_deflate}" "${temp_inflated}" $bits
            rm -f "${temp_deflate}" "${temp_inflated}"
        done

        # Test different strategies
        for strategy in {0..4}; do
            LD_LIBRARY_PATH="${lib_path}" "${build_dir}/example" -s$strategy "${input_file}" /dev/null
        done
    }

    # Create temporary directory for compressed files
    local COMP_DIR="${TMPDIR}/compressed"
    mkdir -p "${COMP_DIR}"

    # Process each training file
    find "${PROFILE_DIR}" -type f -print0 | while IFS= read -r -d '' file; do
        # Regular compression/decompression
        run_compression_tests "${file}" "${build_dir}"

        # Parallel processing simulation
        for i in $(seq 1 $(nproc)); do
            {
                local temp_gz="${COMP_DIR}/compressed_${i}.gz"
                LD_LIBRARY_PATH="${build_dir}" "${build_dir}/minigzip" -6 < "${file}" > "${temp_gz}"
                LD_LIBRARY_PATH="${build_dir}" "${build_dir}/minigzip" -d < "${temp_gz}" > /dev/null
                rm -f "${temp_gz}"
            } &
        done
        wait

        # Stream processing simulation
        dd if="${file}" bs=4K 2>/dev/null | while read -r -n 4096 chunk; do
            echo "${chunk}" | LD_LIBRARY_PATH="${build_dir}" "${build_dir}/minigzip" > "${COMP_DIR}/temp_stream.gz"
            rm -f "${COMP_DIR}/temp_stream.gz"
        done

        # Memory-mapped compression (if supported)
        if [ -x "${build_dir}/example" ]; then
            local temp_mmap="${COMP_DIR}/mmap_compressed"
            LD_LIBRARY_PATH="${build_dir}" "${build_dir}/example" "${file}" "${temp_mmap}"
            LD_LIBRARY_PATH="${build_dir}" "${build_dir}/example" -d "${temp_mmap}" /dev/null
            rm -f "${temp_mmap}"
        fi
    done

    # Dictionary-based compression simulation
    echo "Performing dictionary-based compression tests..."
    local dict_file="${COMP_DIR}/dictionary"
    cat "${PROFILE_DIR}"/training_*.txt > "${COMP_DIR}/combined_dict.txt"
    dd if="${COMP_DIR}/combined_dict.txt" bs=32K count=1 2>/dev/null > "${dict_file}"

    find "${PROFILE_DIR}" -type f -size -1M -print0 | while IFS= read -r -d '' file; do
        LD_LIBRARY_PATH="${build_dir}" "${build_dir}/example" -d "${dict_file}" "${file}" /dev/null
    done

    # Cleanup
    rm -rf "${COMP_DIR}"
}
export -f run_training_workload

build() {
  cd "zlib-ng"

  # Store original flags
  orig_cflags="${CFLAGS}"
  orig_cxxflags="${CXXFLAGS}"
  orig_ldflags="${LDFLAGS}"

  # Create profile directories
  local pgo_dir="${srcdir}/zlib-ng-pgo"
  mkdir -p "${pgo_dir}/standard" "${pgo_dir}/cs" "${pgo_dir}/tmp"
  chmod -R u+rw "${pgo_dir}"

  # Generate training data
  generate_training_data "${pgo_dir}"

  ###########################################################################
  # Phase 1: Standard PGO Instrumentation
  ###########################################################################
  msg2 "== Building with standard PGO instrumentation"

  # Standard PGO instrumentation flags
  export CFLAGS="${orig_cflags} -fprofile-generate=${pgo_dir}/standard -flto -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"
  export CXXFLAGS="${orig_cxxflags} -fprofile-generate=${pgo_dir}/standard -flto -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"
  export LDFLAGS="${orig_ldflags} -fprofile-generate=${pgo_dir}/standard -flto -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"

  local _options=(
    -G Ninja
    -DCMAKE_BUILD_TYPE=Debug
    -DCMAKE_C_STANDARD=11
    -DCMAKE_CXX_STANDARD=23
    -DCMAKE_INSTALL_PREFIX=/usr
    -DCMAKE_INSTALL_LIBDIR=lib
    -DWITH_GTEST=ON
    -Wno-dev
  )

  # Build for zlib-ng
  cmake -B build_std_pgo "${_options[@]}"
  cmake --build build_std_pgo

  # Build for zlib-ng-compat
  cmake -B build_std_pgo_compat "${_options[@]}" -DZLIB_COMPAT=ON
  cmake --build build_std_pgo_compat

  # Run training workload for standard PGO
  msg2 "== Running standard PGO training workload"
  export TMPDIR="${pgo_dir}/tmp"
  run_training_workload "${PWD}/build_std_pgo" "${pgo_dir}/training" "${TMPDIR}"
  run_training_workload "${PWD}/build_std_pgo_compat" "${pgo_dir}/training" "${TMPDIR}"

  # Run tests for additional coverage
  ctest --test-dir build_std_pgo --output-on-failure || true
  ctest --test-dir build_std_pgo_compat --output-on-failure || true

  # Merge standard profile data
  msg2 "== Merging standard PGO profiles"
  cd "${pgo_dir}"
  llvm-profdata merge -output=standard.profdata standard/
  cd "${srcdir}/zlib-ng"

  ###########################################################################
  # Phase 2: Context-Sensitive PGO Instrumentation
  ###########################################################################
  msg2 "== Building with context-sensitive PGO instrumentation"

  # CS-PGO instrumentation flags (using standard profile data)
  export CFLAGS="${orig_cflags} -fprofile-use=${pgo_dir}/standard.profdata -fcs-profile-generate=${pgo_dir}/cs -flto -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"
  export CXXFLAGS="${orig_cxxflags} -fprofile-use=${pgo_dir}/standard.profdata -fcs-profile-generate=${pgo_dir}/cs -flto -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"
  export LDFLAGS="${orig_ldflags} -fprofile-use=${pgo_dir}/standard.profdata -fcs-profile-generate=${pgo_dir}/cs -flto -g3 -fno-omit-frame-pointer -mllvm -vp-counters-per-site=10 -mllvm -runtime-counter-relocation -mllvm -enable-value-profiling"

  # Build for zlib-ng with CS-PGO
  cmake -B build_cs_pgo "${_options[@]}"
  cmake --build build_cs_pgo

  # Build for zlib-ng-compat with CS-PGO
  cmake -B build_cs_pgo_compat "${_options[@]}" -DZLIB_COMPAT=ON
  cmake --build build_cs_pgo_compat

  # Run training workload for CS-PGO
  msg2 "== Running context-sensitive PGO training workload"
  run_training_workload "${PWD}/build_cs_pgo" "${pgo_dir}/training" "${TMPDIR}"
  run_training_workload "${PWD}/build_cs_pgo_compat" "${pgo_dir}/training" "${TMPDIR}"

  # Run tests for additional coverage
  ctest --test-dir build_cs_pgo --output-on-failure || true
  ctest --test-dir build_cs_pgo_compat --output-on-failure || true

  # Merge CS-PGO profile data with standard profile
  msg2 "== Merging context-sensitive and standard profiles"
  cd "${pgo_dir}"
  llvm-profdata merge -output=merged.profdata cs/ standard.profdata
  cd "${srcdir}/zlib-ng"

  ###########################################################################
  # Phase 3: Final Optimized Build with Merged Profiles
  ###########################################################################
  msg2 "== Building optimized version with merged profile data"

  # Optimized build flags with merged profiles
  export CFLAGS="${orig_cflags} -fprofile-use=${pgo_dir}/merged.profdata -flto -fno-common -ffunction-sections -fdata-sections"
  export CXXFLAGS="${orig_cxxflags} -fprofile-use=${pgo_dir}/merged.profdata -flto -fno-common -ffunction-sections -fdata-sections"
  export LDFLAGS="${orig_ldflags} -fprofile-use=${pgo_dir}/merged.profdata -flto -Wl,--gc-sections -Wl,--emit-relocs"

  # Update options for release build
  _options=(
    -G Ninja
    -DCMAKE_BUILD_TYPE=Release
    -DCMAKE_C_STANDARD=11
    -DCMAKE_CXX_STANDARD=23
    -DCMAKE_INSTALL_PREFIX=/usr
    -DCMAKE_INSTALL_LIBDIR=lib
    -DWITH_GTEST=OFF
    -Wno-dev
  )

  cmake -B build_opt "${_options[@]}"
  cmake --build build_opt
  cmake -B build_opt_compat "${_options[@]}" -DZLIB_COMPAT=ON
  cmake --build build_opt_compat

  ###########################################################################
  # Phase 4: BOLT Instrumentation
  ###########################################################################
  msg2 "== BOLT instrumentation phase"

  # Instrument both libraries
  llvm-bolt "${PWD}/build_opt/libz-ng.so.${pkgver}" \
    --instrument \
    --lite=false \
    --instrumentation-file-append-pid \
    --instrumentation-file="${pgo_dir}/bolt.fdata" \
    -o "${PWD}/build_opt/libz-ng.so.${pkgver}.inst"

  llvm-bolt "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng" \
    --instrument \
    --lite=false \
    --instrumentation-file-append-pid \
    --instrumentation-file="${pgo_dir}/bolt_compat.fdata" \
    -o "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng.inst"

  # Backup originals and replace with instrumented versions
  mv "${PWD}/build_opt/libz-ng.so.${pkgver}" "${PWD}/build_opt/libz-ng.so.${pkgver}.org"
  mv "${PWD}/build_opt/libz-ng.so.${pkgver}.inst" "${PWD}/build_opt/libz-ng.so.${pkgver}"

  mv "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng" "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng.org"
  mv "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng.inst" "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng"

  ###########################################################################
  # Phase 5: BOLT Training
  ###########################################################################
  msg2 "== Running BOLT training workload"
  export BOLT_PROFILE_FILE="${pgo_dir}/bolt.fdata"
  run_training_workload "${PWD}/build_opt" "${pgo_dir}/training" "${TMPDIR}"

  export BOLT_PROFILE_FILE="${pgo_dir}/bolt_compat.fdata"
  run_training_workload "${PWD}/build_opt_compat" "${pgo_dir}/training" "${TMPDIR}"

  ###########################################################################
  # Phase 6: Merge BOLT Profiles
  ###########################################################################
  msg2 "== Merging BOLT profiles"
  LD_PRELOAD=/usr/lib/libmimalloc.so merge-fdata "${pgo_dir}"/*.fdata > "${pgo_dir}/combined.fdata"

  ###########################################################################
  # Phase 7: Final BOLT Optimization
  ###########################################################################
  msg2 "== Applying final BOLT optimizations"

  # Optimize zlib-ng
  LD_PRELOAD=/usr/lib/libmimalloc.so llvm-bolt "${PWD}/build_opt/libz-ng.so.${pkgver}.org" \
    --data "${pgo_dir}/combined.fdata" \
    -o "${PWD}/build_opt/libz-ng.so.${pkgver}.bolt" \
    --dyno-stats \
    --frame-opt=all \
    --lite=false \
    --infer-stale-profile=1 \
    --icf=all \
    --plt=all \
    --hugify \
    --peepholes=all \
    --x86-strip-redundant-address-size \
    --indirect-call-promotion=all \
    --reorder-blocks=ext-tsp \
    --reorder-functions=cdsort \
    --split-all-cold \
    --split-eh \
    --split-functions \
    --split-strategy=cdsplit \
    --align-functions=32 \
    --frame-opt-rm-stores \
    --jump-tables=aggressive \
    --stoke || exit 1

  # Optimize zlib-ng-compat
  LD_PRELOAD=/usr/lib/libmimalloc.so llvm-bolt "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng.org" \
    --data "${pgo_dir}/combined.fdata" \
    -o "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng.bolt" \
    --dyno-stats \
    --frame-opt=all \
    --lite=false \
    --infer-stale-profile=1 \
    --icf=all \
    --plt=all \
    --hugify \
    --peepholes=all \
    --x86-strip-redundant-address-size \
    --indirect-call-promotion=all \
    --reorder-blocks=ext-tsp \
    --reorder-functions=cdsort \
    --split-all-cold \
    --split-eh \
    --split-functions \
    --split-strategy=cdsplit \
    --align-functions=32 \
    --frame-opt-rm-stores \
    --jump-tables=aggressive \
    --stoke || exit 1

  ###########################################################################
  # Phase 8: Finalize Build
  ###########################################################################
  msg2 "== Finalizing build with optimized libraries"

  # Replace original libraries with BOLT-optimized versions
  mv "${PWD}/build_opt/libz-ng.so.${pkgver}.bolt" "${PWD}/build_opt/libz-ng.so.${pkgver}"
  mv "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng.bolt" "${PWD}/build_opt_compat/libz.so.${_zlibver}.zlib-ng"

  # Update symlinks for zlib-ng
  cd "${PWD}/build_opt"
  ln -sf "libz-ng.so.${pkgver}" "libz-ng.so.2"
  ln -sf "libz-ng.so.2" "libz-ng.so"

  # Go back to the source directory before changing to the next directory
  cd "${srcdir}/zlib-ng"

  # Update symlinks for zlib-ng-compat
  cd "${PWD}/build_opt_compat"
  ln -sf "libz.so.${_zlibver}.zlib-ng" "libz.so.1"
  ln -sf "libz.so.1" "libz.so"

  # Restore environment
  cd "${srcdir}/zlib-ng"
  export CFLAGS="${orig_cflags}"
  export CXXFLAGS="${orig_cxxflags}"
  export LDFLAGS="${orig_ldflags}"
}

check() {
  cd "zlib-ng"
  msg "Testing zlib-ng (PGO-optimized build)"
  ctest --test-dir build_opt --output-on-failure
  msg "Testing zlib-ng-compat (PGO-optimized build)"
  ctest --test-dir build_opt_compat --output-on-failure
}

package_zlib-ng() {
  pkgdesc='zlib-Ersatz mit Optimierungen für Systeme der nächsten Generation'
  provides=("libz-ng.so")
  options=(!strip)
  cd "zlib-ng"
  DESTDIR="${pkgdir}" cmake --install build_opt

  # Use LLVM strip
  find "$pkgdir" -type f \( -name '*.so*' -o -name '*.a' -o -executable \) -print0 | while IFS= read -r -d '' file; do
    if llvm-strip --strip-unneeded "$file" 2>/dev/null || llvm-strip --strip-all "$file" 2>/dev/null; then
      echo "Stripped: $file"
    else
      echo "Skipping: $file (not a valid object file)" >&2
    fi
  done

  if [ -f "$srcdir/zlib-ng/build_opt/libz-ng.so.${pkgver}.bolt" ]; then
    install -Dm755 "$srcdir/zlib-ng/build_opt/libz-ng.so.${pkgver}.bolt" "$pkgdir/usr/lib/libz-ng.so.${pkgver}"
  fi

  install -Dm644 LICENSE.md -t "${pkgdir}/usr/share/licenses/${pkgname[0]}"
  install -Dm644 README.md -t "${pkgdir}/usr/share/doc/${pkgname[0]}"
}

package_zlib-ng-compat() {
  pkgdesc='zlib-Ersatz mit Optimierungen für Systeme der nächsten Generation (zlib compat)'
  provides=("zlib=1:${_zlibver}" "libz.so")
  depends=('zlib-ng')
  conflicts=('zlib')
  replaces=('zlib')
  options=('staticlibs' !strip)
  cd "zlib-ng"
  DESTDIR="${pkgdir}" cmake --install build_opt_compat

  # Use LLVM strip
  find "$pkgdir" -type f \( -name '*.so*' -o -name '*.a' -o -executable \) -print0 | while IFS= read -r -d '' file; do
    if llvm-strip --strip-unneeded "$file" 2>/dev/null || llvm-strip --strip-all "$file" 2>/dev/null; then
      echo "Stripped: $file"
    else
      echo "Skipping: $file (not a valid object file)" >&2
    fi
  done

  if [ -f "$srcdir/zlib-ng/build_opt_compat/libz.so.${_zlibver}.zlib-ng.bolt" ]; then
    install -Dm755 "$srcdir/zlib-ng/build_opt_compat/libz.so.${_zlibver}.zlib-ng.bolt" "$pkgdir/usr/lib/libz.so.${_zlibver}.zlib-ng"
  fi

  install -Dm644 LICENSE.md -t "${pkgdir}/usr/share/licenses/${pkgname[0]}"
  install -Dm644 README.md -t "${pkgdir}/usr/share/doc/${pkgname[0]}"
}
