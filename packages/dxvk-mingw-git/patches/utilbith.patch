--- util_bit.h.orig	2025-07-05 23:05:07.187210703 +0200
+++ util_bit.h	2025-07-06 17:57:35.950399815 +0200
@@ -1,31 +1,31 @@
 #pragma once
 
 #if (defined(__x86_64__) && !defined(__arm64ec__)) || (defined(_M_X64) && !defined(_M_ARM64EC)) \
-    || defined(__i386__) || defined(_M_IX86) || defined(__e2k__)
-  #define DXVK_ARCH_X86
-  #if defined(__x86_64__) || defined(_M_X64) || defined(__e2k__)
-    #define DXVK_ARCH_X86_64
-  #endif
+|| defined(__i386__) || defined(_M_IX86)
+#define DXVK_ARCH_X86
+#if defined(__x86_64__) || defined(_M_X64)
+#define DXVK_ARCH_X86_64
+#endif
 #elif defined(__aarch64__) || defined(_M_ARM64) || defined(_M_ARM64EC)
-  #define DXVK_ARCH_ARM64
+#define DXVK_ARCH_ARM64
+#elif defined(__e2k__)
+// E2K is a distinct architecture, not x86
+#define DXVK_ARCH_E2K
 #endif
 
 #ifdef DXVK_ARCH_X86
-  #ifndef _MSC_VER
-    #if defined(_WIN32) && (defined(__AVX__) || defined(__AVX2__))
-      #error "AVX-enabled builds not supported due to stack alignment issues."
-    #endif
-    #if defined(__WINE__) && defined(__clang__)
-      #pragma push_macro("_WIN32")
-      #undef _WIN32
-    #endif
-    #include <x86intrin.h>
-    #if defined(__WINE__) && defined(__clang__)
-      #pragma pop_macro("_WIN32")
-    #endif
-  #else
-    #include <intrin.h>
-  #endif
+#ifndef _MSC_VER
+#if defined(__WINE__) && defined(__clang__)
+#pragma push_macro("_WIN32")
+#undef _WIN32
+#endif
+#include <x86intrin.h>
+#if defined(__WINE__) && defined(__clang__)
+#pragma pop_macro("_WIN32")
+#endif
+#else
+#include <intrin.h>
+#endif
 #endif
 
 #include "util_likely.h"
@@ -38,25 +38,54 @@
 #include <type_traits>
 #include <vector>
 
+// Force inline macro
+#if defined(_MSC_VER)
+#define DXVK_FORCE_INLINE __forceinline
+#elif defined(__GNUC__) || defined(__clang__)
+#define DXVK_FORCE_INLINE inline __attribute__((always_inline))
+#else
+#define DXVK_FORCE_INLINE inline
+#endif
+
 namespace dxvk::bit {
 
   template<typename T, typename J>
-  T cast(const J& src) {
+  DXVK_FORCE_INLINE T cast(const J& src) {
     static_assert(sizeof(T) == sizeof(J));
-    static_assert(std::is_trivially_copyable<J>::value && std::is_trivial<T>::value);
+    static_assert(std::is_trivially_copyable_v<J> && std::is_trivial_v<T>);
 
     T dst;
     std::memcpy(&dst, &src, sizeof(T));
     return dst;
   }
-  
+
   template<typename T>
-  T extract(T value, uint32_t fst, uint32_t lst) {
+  DXVK_FORCE_INLINE T extract(T value, uint32_t fst, uint32_t lst) {
+    if (unlikely(lst < fst)) {
+      return 0;
+    }
     return (value >> fst) & ~(~T(0) << (lst - fst + 1));
   }
 
   template<typename T>
-  T popcnt(T n) {
+  DXVK_FORCE_INLINE T popcnt(T n) {
+    static_assert(std::is_unsigned<T>::value, "popcnt requires unsigned type");
+
+    #if defined(__POPCNT__) && (defined(__GNUC__) || defined(__clang__))
+    if constexpr (sizeof(T) <= 4) {
+      return static_cast<T>(__builtin_popcount(static_cast<uint32_t>(n)));
+    } else if constexpr (sizeof(T) == 8) {
+      return static_cast<T>(__builtin_popcountll(static_cast<uint64_t>(n)));
+    }
+    #elif defined(_MSC_VER) && defined(DXVK_ARCH_X86) && defined(__POPCNT__)
+    if constexpr (sizeof(T) <= 4) {
+      return static_cast<T>(__popcnt(static_cast<uint32_t>(n)));
+    } else if constexpr (sizeof(T) == 8 && defined(DXVK_ARCH_X86_64)) {
+      return static_cast<T>(__popcnt64(static_cast<uint64_t>(n)));
+    }
+    #endif
+
+    // Fallback implementation
     n -= ((n >> 1u) & T(0x5555555555555555ull));
     n = (n & T(0x3333333333333333ull)) + ((n >> 2u) & T(0x3333333333333333ull));
     n = (n + (n >> 4u)) & T(0x0f0f0f0f0f0f0f0full);
@@ -64,239 +93,169 @@ namespace dxvk::bit {
     return n >> (8u * (sizeof(T) - 1u));
   }
 
-  inline uint32_t tzcnt(uint32_t n) {
+  DXVK_FORCE_INLINE uint32_t tzcnt(uint32_t n) {
     #if defined(_MSC_VER) && !defined(__clang__)
-    if(n == 0)
-      return 32;
-    return _tzcnt_u32(n);
-    #elif defined(__BMI__)
-    return __tzcnt_u32(n);
-    #elif defined(DXVK_ARCH_X86) && (defined(__GNUC__) || defined(__clang__))
-    // tzcnt is encoded as rep bsf, so we can use it on all
-    // processors, but the behaviour of zero inputs differs:
-    // - bsf:   zf = 1, cf = ?, result = ?
-    // - tzcnt: zf = 0, cf = 1, result = 32
-    // We'll have to handle this case manually.
-    uint32_t res;
-    uint32_t tmp;
-    asm (
-      "tzcnt %2, %0;"
-      "mov  $32, %1;"
-      "test  %2, %2;"
-      "cmovz %1, %0;"
-      : "=&r" (res), "=&r" (tmp)
-      : "r" (n)
-      : "cc");
-    return res;
+    unsigned long idx;
+    return _BitScanForward(&idx, n) ? idx : 32;
     #elif defined(__GNUC__) || defined(__clang__)
     return n != 0 ? __builtin_ctz(n) : 32;
     #else
+    if (unlikely(n == 0)) {
+      return 32;
+    }
     uint32_t r = 31;
-    n &= -n;
-    r -= (n & 0x0000FFFF) ? 16 : 0;
-    r -= (n & 0x00FF00FF) ?  8 : 0;
-    r -= (n & 0x0F0F0F0F) ?  4 : 0;
-    r -= (n & 0x33333333) ?  2 : 0;
-    r -= (n & 0x55555555) ?  1 : 0;
-    return n != 0 ? r : 32;
+    n &= -int32_t(n);
+    if (n & 0x0000FFFF) r -= 16;
+    if (n & 0x00FF00FF) r -=  8;
+    if (n & 0x0F0F0F0F) r -=  4;
+    if (n & 0x33333333) r -=  2;
+    if (n & 0x55555555) r -=  1;
+    return r;
     #endif
   }
 
-  inline uint32_t tzcnt(uint64_t n) {
+  DXVK_FORCE_INLINE uint32_t tzcnt(uint64_t n) {
     #if defined(DXVK_ARCH_X86_64) && defined(_MSC_VER) && !defined(__clang__)
-    if(n == 0)
-      return 64;
-    return (uint32_t)_tzcnt_u64(n);
-    #elif defined(DXVK_ARCH_X86_64) && defined(__BMI__)
-    return __tzcnt_u64(n);
-    #elif defined(DXVK_ARCH_X86_64) && (defined(__GNUC__) || defined(__clang__))
-    uint64_t res;
-    uint64_t tmp;
-    asm (
-      "tzcnt %2, %0;"
-      "mov  $64, %1;"
-      "test  %2, %2;"
-      "cmovz %1, %0;"
-      : "=&r" (res), "=&r" (tmp)
-      : "r" (n)
-      : "cc");
-    return res;
+    unsigned long idx;
+    return _BitScanForward64(&idx, n) ? static_cast<uint32_t>(idx) : 64;
     #elif defined(__GNUC__) || defined(__clang__)
     return n != 0 ? __builtin_ctzll(n) : 64;
     #else
     uint32_t lo = uint32_t(n);
     if (lo) {
       return tzcnt(lo);
-    } else {
-      uint32_t hi = uint32_t(n >> 32);
-      return tzcnt(hi) + 32;
     }
+    uint32_t hi = uint32_t(n >> 32);
+    return hi ? tzcnt(hi) + 32 : 64;
     #endif
   }
 
-  inline uint32_t bsf(uint32_t n) {
-    #if (defined(__GNUC__) || defined(__clang__)) && !defined(__BMI__) && defined(DXVK_ARCH_X86)
-    uint32_t res;
-    asm ("tzcnt %1,%0"
-    : "=r" (res)
-    : "r" (n)
-    : "cc");
-    return res;
-    #else
+  DXVK_FORCE_INLINE uint32_t bsf(uint32_t n) {
     return tzcnt(n);
-    #endif
   }
 
-  inline uint32_t bsf(uint64_t n) {
-    #if (defined(__GNUC__) || defined(__clang__)) && !defined(__BMI__) && defined(DXVK_ARCH_X86_64)
-    uint64_t res;
-    asm ("tzcnt %1,%0"
-    : "=r" (res)
-    : "r" (n)
-    : "cc");
-    return res;
-    #else
+  DXVK_FORCE_INLINE uint32_t bsf(uint64_t n) {
     return tzcnt(n);
-    #endif
   }
 
-  inline uint32_t lzcnt(uint32_t n) {
-    #if defined(_MSC_VER) && !defined(__clang__) && !defined(__LZCNT__)
+  DXVK_FORCE_INLINE uint32_t lzcnt(uint32_t n) {
+    #if defined(_MSC_VER) && !defined(__clang__)
     unsigned long bsr;
-    if(n == 0)
-      return 32;
-    _BitScanReverse(&bsr, n);
-    return 31-bsr;
-    #elif (defined(_MSC_VER) && !defined(__clang__)) || defined(__LZCNT__)
-    return _lzcnt_u32(n);
+    return _BitScanReverse(&bsr, n) ? 31 - bsr : 32;
     #elif defined(__GNUC__) || defined(__clang__)
     return n != 0 ? __builtin_clz(n) : 32;
     #else
+    if (unlikely(n == 0)) {
+      return 32;
+    }
     uint32_t r = 0;
-
-    if (n == 0)	return 32;
-
     if (n <= 0x0000FFFF) { r += 16; n <<= 16; }
-    if (n <= 0x00FFFFFF) { r += 8;  n <<= 8; }
-    if (n <= 0x0FFFFFFF) { r += 4;  n <<= 4; }
-    if (n <= 0x3FFFFFFF) { r += 2;  n <<= 2; }
-    if (n <= 0x7FFFFFFF) { r += 1;  n <<= 1; }
-
+    if (n <= 0x00FFFFFF) { r +=  8; n <<=  8; }
+    if (n <= 0x0FFFFFFF) { r +=  4; n <<=  4; }
+    if (n <= 0x3FFFFFFF) { r +=  2; n <<=  2; }
+    if (n <= 0x7FFFFFFF) { r +=  1; }
     return r;
     #endif
   }
 
-  inline uint32_t lzcnt(uint64_t n) {
-    #if defined(_MSC_VER) && !defined(__clang__) && !defined(__LZCNT__) && defined(DXVK_ARCH_X86_64)
+  DXVK_FORCE_INLINE uint32_t lzcnt(uint64_t n) {
+    #if defined(DXVK_ARCH_X86_64) && defined(_MSC_VER) && !defined(__clang__)
     unsigned long bsr;
-    if(n == 0)
-      return 64;
-    _BitScanReverse64(&bsr, n);
-    return 63-bsr;
-    #elif defined(DXVK_ARCH_X86_64) && ((defined(_MSC_VER) && !defined(__clang__)) && defined(__LZCNT__))
-    return _lzcnt_u64(n);
-    #elif defined(DXVK_ARCH_X86_64) && (defined(__GNUC__) || defined(__clang__))
+    return _BitScanReverse64(&bsr, n) ? 63 - bsr : 64;
+    #elif defined(__GNUC__) || defined(__clang__)
     return n != 0 ? __builtin_clzll(n) : 64;
     #else
-    uint32_t lo = uint32_t(n);
     uint32_t hi = uint32_t(n >> 32u);
-    return hi ? lzcnt(hi) : lzcnt(lo) + 32u;
+    return hi ? lzcnt(hi) : lzcnt(uint32_t(n)) + 32u;
     #endif
   }
 
   template<typename T>
-  uint32_t pack(T& dst, uint32_t& shift, T src, uint32_t count) {
+  DXVK_FORCE_INLINE uint32_t pack(T& dst, uint32_t& shift, T src, uint32_t count) {
     constexpr uint32_t Bits = 8 * sizeof(T);
-    if (likely(shift < Bits))
+    if (likely(shift < Bits)) {
       dst |= src << shift;
+    }
     shift += count;
     return shift > Bits ? shift - Bits : 0;
   }
 
   template<typename T>
-  uint32_t unpack(T& dst, T src, uint32_t& shift, uint32_t count) {
+  DXVK_FORCE_INLINE uint32_t unpack(T& dst, T src, uint32_t& shift, uint32_t count) {
     constexpr uint32_t Bits = 8 * sizeof(T);
-    if (likely(shift < Bits))
+    if (likely(shift < Bits)) {
       dst = (src >> shift) & ((T(1) << count) - 1);
+    }
     shift += count;
     return shift > Bits ? shift - Bits : 0;
   }
 
-
-  /**
-   * \brief Clears cache lines of memory
-   *
-   * Uses non-temporal stores. The memory region offset
-   * and size are assumed to be aligned to 64 bytes.
-   * \param [in] mem Memory region to clear
-   * \param [in] size Number of bytes to clear
-   */
   inline void bclear(void* mem, size_t size) {
-    #if defined(DXVK_ARCH_X86) && (defined(__GNUC__) || defined(__clang__) || defined(_MSC_VER))
+    #if defined(DXVK_ARCH_X86) && defined(__AVX2__)
+    auto zero = _mm256_setzero_si256();
+    #pragma nounroll
+    for (size_t i = 0; i < size; i += 64u) {
+      auto* ptr = reinterpret_cast<__m256i*>(reinterpret_cast<char*>(mem) + i);
+      _mm256_stream_si256(ptr + 0u, zero);
+      _mm256_stream_si256(ptr + 1u, zero);
+    }
+    _mm_sfence();
+    #elif defined(DXVK_ARCH_X86) && (defined(__GNUC__) || defined(__clang__) || defined(_MSC_VER))
     auto zero = _mm_setzero_si128();
-
-    #if defined(__clang__)
     #pragma nounroll
-    #elif defined(__GNUC__)
-    #pragma GCC unroll 0
-    #endif
     for (size_t i = 0; i < size; i += 64u) {
-      auto* ptr = reinterpret_cast<__m128i*>(mem) + i / sizeof(zero);
+      auto* ptr = reinterpret_cast<__m128i*>(reinterpret_cast<char*>(mem) + i);
       _mm_stream_si128(ptr + 0u, zero);
       _mm_stream_si128(ptr + 1u, zero);
       _mm_stream_si128(ptr + 2u, zero);
       _mm_stream_si128(ptr + 3u, zero);
     }
+    _mm_sfence();
     #else
     std::memset(mem, 0, size);
     #endif
   }
 
-
-  /**
-   * \brief Compares two aligned structs bit by bit
-   *
-   * \param [in] a First struct
-   * \param [in] b Second struct
-   * \returns \c true if the structs are equal
-   */
   template<typename T>
   bool bcmpeq(const T* a, const T* b) {
     static_assert(alignof(T) >= 16);
     #if defined(DXVK_ARCH_X86) && (defined(__GNUC__) || defined(__clang__) || defined(_MSC_VER))
-    auto ai = reinterpret_cast<const __m128i*>(a);
-    auto bi = reinterpret_cast<const __m128i*>(b);
-
-    size_t i = 0;
-
-    #if defined(__clang__)
-    #pragma nounroll
-    #elif defined(__GNUC__)
-    #pragma GCC unroll 0
+    const char* ap = reinterpret_cast<const char*>(a);
+    const char* bp = reinterpret_cast<const char*>(b);
+    size_t offset = 0;
+
+    #if defined(__AVX2__)
+    if constexpr (alignof(T) >= 32) {
+      #pragma nounroll
+      for ( ; offset + 64 <= sizeof(T); offset += 64) {
+        _mm_prefetch(ap + offset + 256, _MM_HINT_T0);
+        __m256i eq0 = _mm256_cmpeq_epi8(_mm256_load_si256(reinterpret_cast<const __m256i*>(ap + offset)),
+                                        _mm256_load_si256(reinterpret_cast<const __m256i*>(bp + offset)));
+        __m256i eq1 = _mm256_cmpeq_epi8(_mm256_load_si256(reinterpret_cast<const __m256i*>(ap + offset + 32)),
+                                        _mm256_load_si256(reinterpret_cast<const __m256i*>(bp + offset + 32)));
+        __m256i eq = _mm256_and_si256(eq0, eq1);
+        if (_mm256_movemask_epi8(eq) != 0xFFFFFFFF) {
+          return false;
+        }
+      }
+    }
     #endif
 
-    for ( ; i < 2 * (sizeof(T) / 32); i += 2) {
-      __m128i eq0 = _mm_cmpeq_epi8(
-        _mm_load_si128(ai + i),
-        _mm_load_si128(bi + i));
-      __m128i eq1 = _mm_cmpeq_epi8(
-        _mm_load_si128(ai + i + 1),
-        _mm_load_si128(bi + i + 1));
+    #pragma nounroll
+    for ( ; offset + 32 <= sizeof(T); offset += 32) {
+      _mm_prefetch(ap + offset + 128, _MM_HINT_T0);
+      __m128i eq0 = _mm_cmpeq_epi8(_mm_load_si128(reinterpret_cast<const __m128i*>(ap + offset)),
+                                   _mm_load_si128(reinterpret_cast<const __m128i*>(bp + offset)));
+      __m128i eq1 = _mm_cmpeq_epi8(_mm_load_si128(reinterpret_cast<const __m128i*>(ap + offset + 16)),
+                                   _mm_load_si128(reinterpret_cast<const __m128i*>(bp + offset + 16)));
       __m128i eq = _mm_and_si128(eq0, eq1);
-
-      int mask = _mm_movemask_epi8(eq);
-      if (mask != 0xFFFF)
+      if (_mm_movemask_epi8(eq) != 0xFFFF) {
         return false;
+      }
     }
 
-    for ( ; i < sizeof(T) / 16; i++) {
-      __m128i eq = _mm_cmpeq_epi8(
-        _mm_load_si128(ai + i),
-        _mm_load_si128(bi + i));
-
-      int mask = _mm_movemask_epi8(eq);
-      if (mask != 0xFFFF)
-        return false;
+    if (offset < sizeof(T)) {
+      return !std::memcmp(ap + offset, bp + offset, sizeof(T) - offset);
     }
 
     return true;
@@ -311,82 +270,90 @@ namespace dxvk::bit {
   public:
 
     constexpr bitset()
-      : m_dwords() {
+    : m_dwords() {
 
     }
 
     constexpr bool get(uint32_t idx) const {
+      if (unlikely(idx >= Bits)) {
+        return false;
+      }
       uint32_t dword = 0;
       uint32_t bit   = idx;
-
-      // Compiler doesn't remove this otherwise.
       if constexpr (Dwords > 1) {
         dword = idx / 32;
         bit   = idx % 32;
       }
-
       return m_dwords[dword] & (1u << bit);
     }
 
     constexpr void set(uint32_t idx, bool value) {
+      if (unlikely(idx >= Bits)) {
+        return;
+      }
       uint32_t dword = 0;
       uint32_t bit   = idx;
-
-      // Compiler doesn't remove this otherwise.
       if constexpr (Dwords > 1) {
         dword = idx / 32;
         bit   = idx % 32;
       }
-
-      if (value)
+      if (value) {
         m_dwords[dword] |= 1u << bit;
-      else
+      } else {
         m_dwords[dword] &= ~(1u << bit);
+      }
     }
 
     constexpr bool exchange(uint32_t idx, bool value) {
+      if (unlikely(idx >= Bits)) {
+        return value;
+      }
       bool oldValue = get(idx);
       set(idx, value);
       return oldValue;
     }
 
     constexpr void flip(uint32_t idx) {
+      if (unlikely(idx >= Bits)) {
+        return;
+      }
       uint32_t dword = 0;
       uint32_t bit   = idx;
-
-      // Compiler doesn't remove this otherwise.
       if constexpr (Dwords > 1) {
         dword = idx / 32;
         bit   = idx % 32;
       }
-
       m_dwords[dword] ^= 1u << bit;
     }
 
     constexpr void setAll() {
       if constexpr (Bits % 32 == 0) {
-        for (size_t i = 0; i < Dwords; i++)
-          m_dwords[i] = std::numeric_limits<uint32_t>::max();
-      }
-      else {
-        for (size_t i = 0; i < Dwords - 1; i++)
-          m_dwords[i] = std::numeric_limits<uint32_t>::max();
-
-        m_dwords[Dwords - 1] = (1u << (Bits % 32)) - 1;
+        for (size_t i = 0; i < Dwords; i++) {
+          m_dwords[i] = 0xFFFFFFFFu;
+        }
+      } else {
+        size_t i = 0;
+        for ( ; i < Dwords - 1; i++) {
+          m_dwords[i] = 0xFFFFFFFFu;
+        }
+        if constexpr (Dwords > 0) {
+          m_dwords[Dwords - 1] = (1ull << (Bits % 32)) - 1;
+        }
       }
     }
 
     constexpr void clearAll() {
-      for (size_t i = 0; i < Dwords; i++)
+      for (size_t i = 0; i < Dwords; i++) {
         m_dwords[i] = 0;
+      }
     }
 
     constexpr bool any() const {
       for (size_t i = 0; i < Dwords; i++) {
-        if (m_dwords[i] != 0)
+        if (m_dwords[i] != 0) {
           return true;
+        }
       }
-
       return false;
     }
 
@@ -394,11 +361,11 @@ namespace dxvk::bit {
       return m_dwords[idx];
     }
 
-    constexpr size_t bitCount() {
+    constexpr size_t bitCount() const {
       return Bits;
     }
 
-    constexpr size_t dwordCount() {
+    constexpr size_t dwordCount() const {
       return Dwords;
     }
 
@@ -407,14 +374,21 @@ namespace dxvk::bit {
     }
 
     constexpr void setN(uint32_t bits) {
+      if (unlikely(bits > Bits)) {
+        bits = Bits;
+      }
       uint32_t fullDwords = bits / 32;
       uint32_t offset = bits % 32;
 
-      for (size_t i = 0; i < fullDwords; i++)
-        m_dwords[i] = std::numeric_limits<uint32_t>::max();
-     
-      if (offset > 0)
+      for (size_t i = 0; i < Dwords; i++) {
+        m_dwords[i] = 0;
+      }
+      for (size_t i = 0; i < fullDwords; i++) {
+        m_dwords[i] = 0xFFFFFFFFu;
+      }
+      if (offset > 0 && fullDwords < Dwords) {
         m_dwords[fullDwords] = (1u << offset) - 1;
+      }
     }
 
   private:
@@ -427,35 +401,38 @@ namespace dxvk::bit {
   public:
 
     bool get(uint32_t idx) const {
+      if (unlikely(idx >= m_bitCount)) {
+        return false;
+      }
       uint32_t dword = idx / 32;
       uint32_t bit   = idx % 32;
-
       return m_dwords[dword] & (1u << bit);
     }
 
     void ensureSize(uint32_t bitCount) {
-      uint32_t dword = bitCount / 32;
-      if (unlikely(dword >= m_dwords.size())) {
-        m_dwords.resize(dword + 1);
+      if (bitCount <= m_bitCount) {
+        return;
       }
-      m_bitCount = std::max(m_bitCount, bitCount);
+      uint32_t dwordCount = (bitCount - 1) / 32 + 1;
+      if (dwordCount > m_dwords.size()) {
+        m_dwords.resize(dwordCount, 0);
+      }
+      m_bitCount = bitCount;
     }
 
     void set(uint32_t idx, bool value) {
       ensureSize(idx + 1);
-
-      uint32_t dword = 0;
-      uint32_t bit   = idx;
-
-      if (value)
+      uint32_t dword = idx / 32;
+      uint32_t bit   = idx % 32;
+      if (value) {
         m_dwords[dword] |= 1u << bit;
-      else
+      } else {
         m_dwords[dword] &= ~(1u << bit);
+      }
     }
 
     bool exchange(uint32_t idx, bool value) {
       ensureSize(idx + 1);
-
       bool oldValue = get(idx);
       set(idx, value);
       return oldValue;
@@ -463,37 +440,37 @@ namespace dxvk::bit {
 
     void flip(uint32_t idx) {
       ensureSize(idx + 1);
-
       uint32_t dword = idx / 32;
       uint32_t bit   = idx % 32;
-
       m_dwords[dword] ^= 1u << bit;
     }
 
     void setAll() {
-      if (m_bitCount % 32 == 0) {
-        for (size_t i = 0; i < m_dwords.size(); i++)
-          m_dwords[i] = std::numeric_limits<uint32_t>::max();
-      }
-      else {
-        for (size_t i = 0; i < m_dwords.size() - 1; i++)
-          m_dwords[i] = std::numeric_limits<uint32_t>::max();
-
-        m_dwords[m_dwords.size() - 1] = (1u << (m_bitCount % 32)) - 1;
+      if (m_dwords.empty()) {
+        return;
+      }
+      size_t lastDwordIdx = m_dwords.size() - 1;
+      std::memset(m_dwords.data(), 0xFF, lastDwordIdx * sizeof(uint32_t));
+      uint32_t remainderBits = m_bitCount % 32;
+      if (remainderBits == 0) {
+        m_dwords[lastDwordIdx] = 0xFFFFFFFFu;
+      } else {
+        m_dwords[lastDwordIdx] = (1ull << remainderBits) - 1;
       }
     }
 
     void clearAll() {
-      for (size_t i = 0; i < m_dwords.size(); i++)
-        m_dwords[i] = 0;
+      if (!m_dwords.empty()) {
+        std::memset(m_dwords.data(), 0, m_dwords.size() * sizeof(uint32_t));
+      }
     }
 
     bool any() const {
-      for (size_t i = 0; i < m_dwords.size(); i++) {
-        if (m_dwords[i] != 0)
+      for (uint32_t dword : m_dwords) {
+        if (dword != 0) {
           return true;
+        }
       }
-
       return false;
     }
 
@@ -515,15 +492,22 @@ namespace dxvk::bit {
 
     void setN(uint32_t bits) {
       ensureSize(bits);
-
+      if (bits == 0) {
+        clearAll();
+        return;
+      }
       uint32_t fullDwords = bits / 32;
       uint32_t offset = bits % 32;
-
-      for (size_t i = 0; i < fullDwords; i++)
-        m_dwords[i] = std::numeric_limits<uint32_t>::max();
-
-      if (offset > 0)
+      if (fullDwords > 0) {
+        std::memset(m_dwords.data(), 0xFF, fullDwords * sizeof(uint32_t));
+      }
+      if (offset > 0 && fullDwords < m_dwords.size()) {
         m_dwords[fullDwords] = (1u << offset) - 1;
+      }
+      size_t clearStart = fullDwords + (offset > 0 ? 1 : 0);
+      if (clearStart < m_dwords.size()) {
+        std::memset(&m_dwords[clearStart], 0, (m_dwords.size() - clearStart) * sizeof(uint32_t));
+      }
     }
 
   private:
@@ -547,7 +531,7 @@ namespace dxvk::bit {
       using reference = T;
 
       explicit iterator(T flags)
-        : m_mask(flags) { }
+      : m_mask(flags) { }
 
       iterator& operator ++ () {
         m_mask &= m_mask - 1;
@@ -574,10 +558,10 @@ namespace dxvk::bit {
     };
 
     BitMask()
-      : m_mask(0) { }
+    : m_mask(0) { }
 
     explicit BitMask(T n)
-      : m_mask(n) { }
+    : m_mask(n) { }
 
     iterator begin() {
       return iterator(m_mask);
@@ -607,25 +591,30 @@ namespace dxvk::bit {
    */
   template<typename T, int32_t I, int32_t F>
   T encodeFixed(float n) {
-    if (n != n)
+    static_assert(I + F <= int32_t(sizeof(T) * 8), "Fixed point format exceeds type size");
+    static_assert(I >= 0 && F >= 0, "Fixed point format requires non-negative bit counts");
+
+    if (unlikely(n != n)) {
       return 0u;
+    }
 
     n *= float(1u << F);
 
     if constexpr (std::is_signed_v<T>) {
-      n = std::max(n, -float(1u << (I + F - 1u)));
-      n = std::min(n,  float(1u << (I + F - 1u)) - 1.0f);
+      n = std::max(n, -float(1ull << (I + F - 1u)));
+      n = std::min(n,  float((1ull << (I + F - 1u)) - 1u));
       n += n < 0.0f ? -0.5f : 0.5f;
     } else {
       n = std::max(n, 0.0f);
-      n = std::min(n, float(1u << (I + F)) - 1.0f);
+      n = std::min(n, float((1ull << (I + F)) - 1u));
       n += 0.5f;
     }
 
     T result = T(n);
 
-    if constexpr (std::is_signed_v<T>)
-      result &= ((T(1u) << (I + F)) - 1u);
+    if constexpr (std::is_signed_v<T> && I + F < int32_t(sizeof(T) * 8)) {
+      result &= ((T(1) << (I + F)) - 1u);
+    }
 
     return result;
   }
@@ -642,9 +631,14 @@ namespace dxvk::bit {
    */
   template<typename T, int32_t I, int32_t F>
   float decodeFixed(T n) {
-    // Sign-extend as necessary
-    if constexpr (std::is_signed_v<T>)
-      n -= (n & (T(1u) << (I + F - 1u))) << 1u;
+    static_assert(I + F <= int32_t(sizeof(T) * 8), "Fixed point format exceeds type size");
+    static_assert(I >= 0 && F >= 0, "Fixed point format requires non-negative bit counts");
+
+    if constexpr (std::is_signed_v<T> && I + F < int32_t(sizeof(T) * 8)) {
+      if (n & (T(1) << (I + F - 1))) {
+        n |= ~((T(1) << (I + F)) - 1u);
+      }
+    }
 
     return float(n) / float(1u << F);
   }
@@ -653,7 +647,7 @@ namespace dxvk::bit {
   /**
    * \brief Inserts one null bit after each bit
    */
-  inline uint32_t split2(uint32_t c) {
+  DXVK_FORCE_INLINE uint32_t split2(uint32_t c) {
     c = (c ^ (c << 8u)) & 0x00ff00ffu;
     c = (c ^ (c << 4u)) & 0x0f0f0f0fu;
     c = (c ^ (c << 2u)) & 0x33333333u;
@@ -665,7 +659,7 @@ namespace dxvk::bit {
   /**
    * \brief Inserts two null bits after each bit
    */
-  inline uint64_t split3(uint64_t c) {
+  DXVK_FORCE_INLINE uint64_t split3(uint64_t c) {
     c = (c | c << 32u) & 0x001f00000000ffffull;
     c = (c | c << 16u) & 0x001f0000ff0000ffull;
     c = (c | c <<  8u) & 0x100f00f00f00f00full;
@@ -683,8 +677,14 @@ namespace dxvk::bit {
    * \param [in] y Y coordinate
    * \returns Morton code of x and y
    */
-  inline uint32_t interleave(uint16_t x, uint16_t y) {
+  DXVK_FORCE_INLINE uint32_t interleave(uint16_t x, uint16_t y) {
+    #if defined(__BMI2__) && (defined(__GNUC__) || defined(__clang__))
+    uint32_t x_spread = _pdep_u32(x, 0x55555555u);
+    uint32_t y_spread = _pdep_u32(y, 0xAAAAAAAAu);
+    return x_spread | y_spread;
+    #else
     return split2(x) | (split2(y) << 1u);
+    #endif
   }
 
 
@@ -693,8 +693,15 @@ namespace dxvk::bit {
    *
    * All three numbers must fit into 16 bits.
    */
-  inline uint64_t interleave(uint16_t x, uint16_t y, uint16_t z) {
+  DXVK_FORCE_INLINE uint64_t interleave(uint16_t x, uint16_t y, uint16_t z) {
+    #if defined(__BMI2__) && defined(DXVK_ARCH_X86_64) && (defined(__GNUC__) || defined(__clang__))
+    uint64_t x_spread = _pdep_u64(x, 0x1249249249249249ull);
+    uint64_t y_spread = _pdep_u64(y, 0x2492492492492492ull);
+    uint64_t z_spread = _pdep_u64(z, 0x4924924924924924ull);
+    return x_spread | y_spread | z_spread;
+    #else
     return split3(x) | (split3(y) << 1u) | (split3(z) << 2u);
+    #endif
   }
 
 
@@ -710,7 +717,6 @@ namespace dxvk::bit {
     uint16_t c;
 
     explicit operator uint64_t () const {
-      // GCC generates worse code if we promote to uint64 directly
       uint32_t lo = uint32_t(a) | (uint32_t(b) << 16);
       return uint64_t(lo) | (uint64_t(c) << 32);
     }
