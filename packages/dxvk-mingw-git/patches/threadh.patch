--- thread.h.orig	2025-07-05 23:59:58.545397731 +0200
+++ thread.h	2025-07-06 17:56:21.883519702 +0200
@@ -14,6 +14,15 @@
 #include "./rc/util_rc.h"
 #include "./rc/util_rc_ptr.h"
 
+// Force inline macro for hot paths
+#if defined(_MSC_VER)
+#define DXVK_FORCE_INLINE __forceinline
+#elif defined(__GNUC__) || defined(__clang__)
+#define DXVK_FORCE_INLINE inline __attribute__((always_inline))
+#else
+#define DXVK_FORCE_INLINE inline
+#endif
+
 namespace dxvk {
 
   /**
@@ -24,7 +33,7 @@ namespace dxvk {
     Lowest,
   };
 
-#ifdef _WIN32
+  #ifdef _WIN32
 
   using ThreadProc = std::function<void()>;
 
@@ -37,8 +46,9 @@ namespace dxvk {
     : proc(std::move(proc_)) { }
 
     ~ThreadData() {
-      if (handle)
+      if (handle) {
         CloseHandle(handle);
+      }
     }
 
     HANDLE                handle = nullptr;
@@ -47,8 +57,10 @@ namespace dxvk {
     ThreadProc            proc;
 
     void decRef() {
-      if (refs.fetch_sub(1, std::memory_order_release) == 1)
+      if (refs.fetch_sub(1, std::memory_order_release) == 1) {
+        std::atomic_thread_fence(std::memory_order_acquire);
         delete this;
+      }
     }
   };
 
@@ -72,35 +84,44 @@ namespace dxvk {
 
     ~thread();
 
-    thread(thread&& other)
+    thread(thread&& other) noexcept
     : m_data(std::exchange(other.m_data, nullptr)) { }
 
-    thread& operator = (thread&& other) {
-      if (m_data)
+    thread& operator = (thread&& other) noexcept {
+      if (joinable()) {
+        std::terminate();
+      }
+
+      if (m_data) {
         m_data->decRef();
+      }
 
       m_data = std::exchange(other.m_data, nullptr);
       return *this;
     }
 
     void detach() {
+      if (!joinable()) {
+        throw std::system_error(std::make_error_code(std::errc::invalid_argument), "Thread not detachable");
+      }
+
       m_data->decRef();
       m_data = nullptr;
     }
 
-    bool joinable() const {
+    DXVK_FORCE_INLINE bool joinable() const {
       return m_data != nullptr;
     }
 
-    id get_id() const {
+    DXVK_FORCE_INLINE id get_id() const {
       return joinable() ? m_data->id : id();
     }
 
-    native_handle_type native_handle() const {
+    DXVK_FORCE_INLINE native_handle_type native_handle() const {
       return joinable() ? m_data->handle : native_handle_type();
     }
 
-    void swap(thread& other) {
+    void swap(thread& other) noexcept {
       std::swap(m_data, other.m_data);
     }
 
@@ -120,11 +141,11 @@ namespace dxvk {
 
 
   namespace this_thread {
-    inline void yield() {
+    DXVK_FORCE_INLINE void yield() {
       SwitchToThread();
     }
 
-    inline thread::id get_id() {
+    DXVK_FORCE_INLINE thread::id get_id() {
       return thread::id(GetCurrentThreadId());
     }
 
@@ -149,19 +170,19 @@ namespace dxvk {
     mutex(const mutex&) = delete;
     mutex& operator = (const mutex&) = delete;
 
-    void lock() {
+    DXVK_FORCE_INLINE void lock() noexcept {
       AcquireSRWLockExclusive(&m_lock);
     }
 
-    void unlock() {
+    DXVK_FORCE_INLINE void unlock() noexcept {
       ReleaseSRWLockExclusive(&m_lock);
     }
 
-    bool try_lock() {
+    DXVK_FORCE_INLINE bool try_lock() noexcept {
       return TryAcquireSRWLockExclusive(&m_lock);
     }
 
-    native_handle_type native_handle() {
+    DXVK_FORCE_INLINE native_handle_type native_handle() noexcept {
       return &m_lock;
     }
 
@@ -173,6 +194,72 @@ namespace dxvk {
 
 
   /**
+   * \brief Fast mutex with adaptive spinning
+   *
+   * Spins briefly before falling back to SRW lock to reduce
+   * context switch overhead for short critical sections.
+   */
+  class fast_mutex {
+  public:
+    using native_handle_type = PSRWLOCK;
+
+    fast_mutex() { }
+
+    fast_mutex(const fast_mutex&) = delete;
+    fast_mutex& operator = (const fast_mutex&) = delete;
+
+    DXVK_FORCE_INLINE void lock() noexcept {
+      if (likely(try_lock())) {
+        return;
+      }
+
+      // Phase 1: Aggressive spin for ultra-short contention.
+      for (uint32_t i = 0; i < 64; i++) {
+        #if defined(DXVK_ARCH_X86)
+        #if defined(_MSC_VER)
+        _mm_pause();
+        #elif defined(__GNUC__) || defined(__clang__)
+        __builtin_ia32_pause();
+        #endif
+        #endif
+        if (try_lock()) {
+          return;
+        }
+      }
+
+      // Phase 2: Yielding spin for short-term contention.
+      for (uint32_t i = 0; i < 16; i++) {
+        dxvk::this_thread::yield();
+        if (try_lock()) {
+          return;
+        }
+      }
+
+      // Phase 3: Fall back to a blocking OS call.
+      AcquireSRWLockExclusive(&m_lock);
+    }
+
+    DXVK_FORCE_INLINE void unlock() noexcept {
+      ReleaseSRWLockExclusive(&m_lock);
+    }
+
+    DXVK_FORCE_INLINE bool try_lock() noexcept {
+      return TryAcquireSRWLockExclusive(&m_lock);
+    }
+
+    DXVK_FORCE_INLINE native_handle_type native_handle() noexcept {
+      return &m_lock;
+    }
+
+  private:
+    SRWLOCK m_lock = SRWLOCK_INIT;
+  };
+
+  // Alias for compatibility
+  using spin_mutex = fast_mutex;
+
+
+  /**
    * \brief Recursive mutex implementation
    *
    * Drop-in replacement for \c std::recursive_mutex that
@@ -195,19 +282,19 @@ namespace dxvk {
     recursive_mutex(const recursive_mutex&) = delete;
     recursive_mutex& operator = (const recursive_mutex&) = delete;
 
-    void lock() {
+    DXVK_FORCE_INLINE void lock() noexcept {
       EnterCriticalSection(&m_lock);
     }
 
-    void unlock() {
+    DXVK_FORCE_INLINE void unlock() noexcept {
       LeaveCriticalSection(&m_lock);
     }
 
-    bool try_lock() {
+    DXVK_FORCE_INLINE bool try_lock() noexcept {
       return TryEnterCriticalSection(&m_lock);
     }
 
-    native_handle_type native_handle() {
+    DXVK_FORCE_INLINE native_handle_type native_handle() noexcept {
       return &m_lock;
     }
 
@@ -238,11 +325,11 @@ namespace dxvk {
 
     condition_variable& operator = (condition_variable&) = delete;
 
-    void notify_one() {
+    DXVK_FORCE_INLINE void notify_one() noexcept {
       WakeConditionVariable(&m_cond);
     }
 
-    void notify_all() {
+    DXVK_FORCE_INLINE void notify_all() noexcept {
       WakeAllConditionVariable(&m_cond);
     }
 
@@ -253,26 +340,27 @@ namespace dxvk {
 
     template<typename Predicate>
     void wait(std::unique_lock<dxvk::mutex>& lock, Predicate pred) {
-      while (!pred())
+      while (!pred()) {
         wait(lock);
+      }
     }
 
     template<typename Clock, typename Duration>
     std::cv_status wait_until(std::unique_lock<dxvk::mutex>& lock, const std::chrono::time_point<Clock, Duration>& time) {
       auto now = Clock::now();
-
       return (now < time)
-        ? wait_for(lock, now - time)
-        : std::cv_status::timeout;
+      ? wait_for(lock, time - now)
+      : std::cv_status::timeout;
     }
 
     template<typename Clock, typename Duration, typename Predicate>
     bool wait_until(std::unique_lock<dxvk::mutex>& lock, const std::chrono::time_point<Clock, Duration>& time, Predicate pred) {
-      if (pred())
-        return true;
-
-      auto now = Clock::now();
-      return now < time && wait_for(lock, now - time, pred);
+      while (!pred()) {
+        if (wait_until(lock, time) == std::cv_status::timeout) {
+          return pred();
+        }
+      }
+      return true;
     }
 
     template<typename Rep, typename Period>
@@ -280,22 +368,27 @@ namespace dxvk {
       auto ms = std::chrono::duration_cast<std::chrono::milliseconds>(timeout);
       auto srw = lock.mutex()->native_handle();
 
-      return SleepConditionVariableSRW(&m_cond, srw, ms.count(), 0)
-        ? std::cv_status::no_timeout
-        : std::cv_status::timeout;
+      if (ms.count() < 0) {
+        ms = std::chrono::milliseconds(0);
+      }
+
+      return SleepConditionVariableSRW(&m_cond, srw, DWORD(ms.count()), 0)
+      ? std::cv_status::no_timeout
+      : std::cv_status::timeout;
     }
 
     template<typename Rep, typename Period, typename Predicate>
     bool wait_for(std::unique_lock<dxvk::mutex>& lock, const std::chrono::duration<Rep, Period>& timeout, Predicate pred) {
-      bool result = pred();
-
-      if (!result && wait_for(lock, timeout) == std::cv_status::no_timeout)
-        result = pred();
-
-      return result;
+      auto end_time = std::chrono::steady_clock::now() + timeout;
+      while (!pred()) {
+        if (wait_for(lock, end_time - std::chrono::steady_clock::now()) == std::cv_status::timeout) {
+          return pred();
+        }
+      }
+      return true;
     }
 
-    native_handle_type native_handle() {
+    DXVK_FORCE_INLINE native_handle_type native_handle() noexcept {
       return &m_cond;
     }
 
@@ -305,33 +398,36 @@ namespace dxvk {
 
   };
 
-#else
+  #else
+  #include <sched.h>
   class thread : public std::thread {
   public:
     using std::thread::thread;
 
     void set_priority(ThreadPriority priority) {
-      ::sched_param param = {};
-      int32_t policy;
+      sched_param param = {};
+      int policy;
       switch (priority) {
         default:
         case ThreadPriority::Normal: policy = SCHED_OTHER; break;
-#ifndef __linux__
+        #ifndef __linux__
         case ThreadPriority::Lowest: policy = SCHED_OTHER; break;
-#else
+        #else
         case ThreadPriority::Lowest: policy = SCHED_IDLE;  break;
-#endif
+        #endif
       }
-      ::pthread_setschedparam(this->native_handle(), policy, &param);
+      pthread_setschedparam(this->native_handle(), policy, Â¶m);
     }
   };
 
   using mutex              = std::mutex;
   using recursive_mutex    = std::recursive_mutex;
   using condition_variable = std::condition_variable;
+  using fast_mutex         = std::mutex;
+  using spin_mutex         = std::mutex;
 
   namespace this_thread {
-    inline void yield() {
+    DXVK_FORCE_INLINE void yield() {
       std::this_thread::yield();
     }
 
@@ -341,6 +437,6 @@ namespace dxvk {
       return false;
     }
   }
-#endif
+  #endif
 
 }
