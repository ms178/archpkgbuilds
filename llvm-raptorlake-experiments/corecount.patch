--- a/llvm/lib/Support/Unix/Threading.inc
+++ b/llvm/lib/Support/Unix/Threading.inc
@@ -5,12 +5,9 @@
 // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 //
 //===----------------------------------------------------------------------===//
-//
-// This file provides the Unix specific implementation of Threading functions.
-//
-//===----------------------------------------------------------------------===//
 
 #include "Unix.h"
+#include "llvm/ADT/BitVector.h"
 #include "llvm/ADT/ScopeExit.h"
 #include "llvm/ADT/SmallString.h"
 #include "llvm/ADT/SmallVector.h"
@@ -28,14 +25,12 @@
 #endif
 
 #include <pthread.h>
+#include <cstring>
 
 #if defined(__FreeBSD__) || defined(__OpenBSD__) || defined(__DragonFly__)
-#include <pthread_np.h> // For pthread_getthreadid_np() / pthread_set_name_np()
+#include <pthread_np.h>
 #endif
 
-// Must be included after Threading.inc to provide definition for llvm::thread
-// because FreeBSD's condvar.h (included by user.h) misuses the "thread"
-// keyword.
 #ifndef __FreeBSD__
 #include "llvm/Support/thread.h"
 #endif
@@ -49,17 +44,17 @@
 #endif
 
 #if defined(__NetBSD__)
-#include <lwp.h> // For _lwp_self()
+#include <lwp.h>
 #endif
 
 #if defined(__OpenBSD__)
-#include <unistd.h> // For getthrid()
+#include <unistd.h>
 #endif
 
 #if defined(__linux__)
-#include <sched.h>       // For sched_getaffinity
-#include <sys/syscall.h> // For syscall codes
-#include <unistd.h>      // For syscall()
+#include <sched.h>
+#include <sys/syscall.h>
+#include <unistd.h>
 #endif
 
 #if defined(__CYGWIN__)
@@ -67,35 +62,32 @@
 #endif
 
 #if defined(__HAIKU__)
-#include <OS.h> // For B_OS_NAME_LENGTH
+#include <OS.h>
 #endif
 
+#include <thread>
+
 namespace llvm {
+
 pthread_t
 llvm_execute_on_thread_impl(void *(*ThreadFunc)(void *), void *Arg,
                             std::optional<unsigned> StackSizeInBytes) {
-  int errnum;
+  int errnum = 0;
 
-  // Construct the attributes object.
   pthread_attr_t Attr;
-  if ((errnum = ::pthread_attr_init(&Attr)) != 0) {
+  if ((errnum = ::pthread_attr_init(&Attr)) != 0)
     ReportErrnumFatal("pthread_attr_init failed", errnum);
-  }
 
-  llvm::scope_exit AttrGuard([&] {
-    if ((errnum = ::pthread_attr_destroy(&Attr)) != 0) {
+  llvm::scope_exit AttrGuard([&Attr, &errnum]() noexcept {
+    if ((errnum = ::pthread_attr_destroy(&Attr)) != 0)
       ReportErrnumFatal("pthread_attr_destroy failed", errnum);
-    }
   });
 
-  // Set the requested stack size, if given.
   if (StackSizeInBytes) {
-    if ((errnum = ::pthread_attr_setstacksize(&Attr, *StackSizeInBytes)) != 0) {
+    if ((errnum = ::pthread_attr_setstacksize(&Attr, *StackSizeInBytes)) != 0)
       ReportErrnumFatal("pthread_attr_setstacksize failed", errnum);
-    }
   }
 
-  // Construct and execute the thread.
   pthread_t Thread;
   if ((errnum = ::pthread_create(&Thread, &Attr, ThreadFunc, Arg)) != 0)
     ReportErrnumFatal("pthread_create failed", errnum);
@@ -104,23 +96,19 @@ llvm_execute_on_thread_impl(void *(*Thre
 }
 
 void llvm_thread_detach_impl(pthread_t Thread) {
-  int errnum;
-
-  if ((errnum = ::pthread_detach(Thread)) != 0) {
+  int errnum = ::pthread_detach(Thread);
+  if (errnum != 0)
     ReportErrnumFatal("pthread_detach failed", errnum);
-  }
 }
 
 void llvm_thread_join_impl(pthread_t Thread) {
-  int errnum;
-
-  if ((errnum = ::pthread_join(Thread, nullptr)) != 0) {
+  int errnum = ::pthread_join(Thread, nullptr);
+  if (errnum != 0)
     ReportErrnumFatal("pthread_join failed", errnum);
-  }
 }
 
 llvm::thread::id llvm_thread_get_id_impl(pthread_t Thread) {
-#ifdef __MVS__
+#if defined(__MVS__)
   return Thread.__;
 #else
   return Thread;
@@ -135,31 +123,24 @@ llvm::thread::id llvm_thread_get_current
 
 uint64_t llvm::get_threadid() {
 #if defined(__APPLE__)
-  // Calling "mach_thread_self()" bumps the reference count on the thread
-  // port, so we need to deallocate it. mach_task_self() doesn't bump the ref
-  // count.
-  static thread_local thread_port_t Self = [] {
-    thread_port_t InitSelf = mach_thread_self();
-    mach_port_deallocate(mach_task_self(), Self);
-    return InitSelf;
-  }();
-  return Self;
+  static thread_local const thread_port_t Self = mach_thread_self();
+  return static_cast<uint64_t>(Self);
 #elif defined(__FreeBSD__) || defined(__DragonFly__)
-  return uint64_t(pthread_getthreadid_np());
+  return static_cast<uint64_t>(pthread_getthreadid_np());
 #elif defined(__NetBSD__)
-  return uint64_t(_lwp_self());
+  return static_cast<uint64_t>(_lwp_self());
 #elif defined(__OpenBSD__)
-  return uint64_t(getthrid());
+  return static_cast<uint64_t>(getthrid());
 #elif defined(__ANDROID__)
-  return uint64_t(gettid());
+  return static_cast<uint64_t>(gettid());
 #elif defined(__linux__)
-  return uint64_t(syscall(__NR_gettid));
+  return static_cast<uint64_t>(syscall(__NR_gettid));
 #elif defined(_AIX)
-  return uint64_t(thread_self());
+  return static_cast<uint64_t>(thread_self());
 #elif defined(__MVS__)
-  return llvm_thread_get_id_impl(pthread_self());
+  return static_cast<uint64_t>(llvm_thread_get_id_impl(pthread_self()));
 #else
-  return uint64_t(pthread_self());
+  return static_cast<uint64_t>(pthread_self());
 #endif
 }
 
@@ -174,7 +155,7 @@ static constexpr uint32_t get_max_thread
   return 31;
 #elif defined(__linux__) && HAVE_PTHREAD_SETNAME_NP
   return 16;
-#elif defined(__FreeBSD__) || defined(__FreeBSD_kernel__) ||                   \
+#elif defined(__FreeBSD__) || defined(__FreeBSD_kernel__) || \
     defined(__DragonFly__)
   return 16;
 #elif defined(__OpenBSD__)
@@ -191,18 +172,13 @@ uint32_t llvm::get_max_thread_name_lengt
 }
 
 void llvm::set_thread_name(const Twine &Name) {
-  // Make sure the input is null terminated.
   SmallString<64> Storage;
   StringRef NameStr = Name.toNullTerminatedStringRef(Storage);
 
-  // Truncate from the beginning, not the end, if the specified name is too
-  // long.  For one, this ensures that the resulting string is still null
-  // terminated, but additionally the end of a long thread name will usually
-  // be more unique than the beginning, since a common pattern is for similar
-  // threads to share a common prefix.
-  // Note that the name length includes the null terminator.
-  if (get_max_thread_name_length() > 0)
-    NameStr = NameStr.take_back(get_max_thread_name_length() - 1);
+  constexpr uint32_t MaxLen = get_max_thread_name_length_impl();
+  if (MaxLen > 0)
+    NameStr = NameStr.take_back(MaxLen - 1);
+
   (void)NameStr;
 #if defined(HAVE_PTHREAD_SET_NAME_NP) && HAVE_PTHREAD_SET_NAME_NP
   ::pthread_set_name_np(::pthread_self(), NameStr.data());
@@ -222,23 +198,22 @@ void llvm::get_thread_name(SmallVectorIm
   Name.clear();
 
 #if defined(__FreeBSD__) || defined(__FreeBSD_kernel__)
-  int pid = ::getpid();
-  uint64_t tid = get_threadid();
+  const int pid = ::getpid();
+  const uint64_t tid = get_threadid();
 
-  struct kinfo_proc *kp = nullptr, *nkp;
+  struct kinfo_proc *kp = nullptr;
   size_t len = 0;
-  int error;
   int ctl[4] = {CTL_KERN, KERN_PROC, KERN_PROC_PID | KERN_PROC_INC_THREAD,
-                (int)pid};
+                pid};
 
-  while (1) {
-    error = sysctl(ctl, 4, kp, &len, nullptr, 0);
+  for (;;) {
+    int error = sysctl(ctl, 4, kp, &len, nullptr, 0);
     if (kp == nullptr || (error != 0 && errno == ENOMEM)) {
-      // Add extra space in case threads are added before next call.
       len += sizeof(*kp) + len / 10;
-      nkp = (struct kinfo_proc *)::realloc(kp, len);
+      struct kinfo_proc *nkp =
+          static_cast<struct kinfo_proc *>(::realloc(kp, len));
       if (nkp == nullptr) {
-        free(kp);
+        ::free(kp);
         return;
       }
       kp = nkp;
@@ -249,227 +224,328 @@ void llvm::get_thread_name(SmallVectorIm
     break;
   }
 
-  for (size_t i = 0; i < len / sizeof(*kp); i++) {
-    if (kp[i].ki_tid == (lwpid_t)tid) {
-      Name.append(kp[i].ki_tdname, kp[i].ki_tdname + strlen(kp[i].ki_tdname));
+  const size_t count = len / sizeof(*kp);
+  for (size_t i = 0; i < count; ++i) {
+    if (kp[i].ki_tid == static_cast<lwpid_t>(tid)) {
+      const size_t nameLen = std::strlen(kp[i].ki_tdname);
+      Name.append(kp[i].ki_tdname, kp[i].ki_tdname + nameLen);
       break;
     }
   }
-  free(kp);
-  return;
+  ::free(kp);
+
 #elif (defined(__linux__) || defined(__CYGWIN__)) && HAVE_PTHREAD_GETNAME_NP
-  constexpr uint32_t len = get_max_thread_name_length_impl();
-  char Buffer[len] = {'\0'}; // FIXME: working around MSan false positive.
-  if (0 == ::pthread_getname_np(::pthread_self(), Buffer, len))
-    Name.append(Buffer, Buffer + strlen(Buffer));
-#elif defined(HAVE_PTHREAD_GET_NAME_NP) && HAVE_PTHREAD_GET_NAME_NP
-  constexpr uint32_t len = get_max_thread_name_length_impl();
-  char buf[len];
-  ::pthread_get_name_np(::pthread_self(), buf, len);
+  constexpr uint32_t Len = get_max_thread_name_length_impl();
+  char Buffer[Len] = {};
+  if (::pthread_getname_np(::pthread_self(), Buffer, Len) == 0) {
+    const size_t ActualLen = std::strlen(Buffer);
+    Name.append(Buffer, Buffer + ActualLen);
+  }
 
-  Name.append(buf, buf + strlen(buf));
+#elif defined(HAVE_PTHREAD_GET_NAME_NP) && HAVE_PTHREAD_GET_NAME_NP
+  constexpr uint32_t Len = get_max_thread_name_length_impl();
+  char Buffer[Len] = {};
+  ::pthread_get_name_np(::pthread_self(), Buffer, Len);
+  const size_t ActualLen = std::strlen(Buffer);
+  Name.append(Buffer, Buffer + ActualLen);
 
 #elif defined(HAVE_PTHREAD_GETNAME_NP) && HAVE_PTHREAD_GETNAME_NP
-  constexpr uint32_t len = get_max_thread_name_length_impl();
-  char buf[len];
-  ::pthread_getname_np(::pthread_self(), buf, len);
-
-  Name.append(buf, buf + strlen(buf));
+  constexpr uint32_t Len = get_max_thread_name_length_impl();
+  char Buffer[Len] = {};
+  ::pthread_getname_np(::pthread_self(), Buffer, Len);
+  const size_t ActualLen = std::strlen(Buffer);
+  Name.append(Buffer, Buffer + ActualLen);
 #endif
 }
 
 SetThreadPriorityResult llvm::set_thread_priority(ThreadPriority Priority) {
 #if (defined(__linux__) || defined(__CYGWIN__)) && defined(SCHED_IDLE)
-  // Some *really* old glibcs are missing SCHED_IDLE.
-  // http://man7.org/linux/man-pages/man3/pthread_setschedparam.3.html
-  // http://man7.org/linux/man-pages/man2/sched_setscheduler.2.html
-  sched_param priority;
-  // For each of the above policies, param->sched_priority must be 0.
-  priority.sched_priority = 0;
-  // SCHED_IDLE    for running very low priority background jobs.
-  // SCHED_OTHER   the standard round-robin time-sharing policy;
-  return !pthread_setschedparam(
-             pthread_self(),
-             // FIXME: consider SCHED_BATCH for Low
-             Priority == ThreadPriority::Default ? SCHED_OTHER : SCHED_IDLE,
-             &priority)
+  sched_param Param = {};
+
+  int Policy;
+  switch (Priority) {
+  case ThreadPriority::Background:
+    Policy = SCHED_IDLE;
+    break;
+  case ThreadPriority::Low:
+#if defined(SCHED_BATCH)
+    Policy = SCHED_BATCH;
+#else
+    Policy = SCHED_OTHER;
+#endif
+    break;
+  case ThreadPriority::Default:
+    Policy = SCHED_OTHER;
+    break;
+  }
+
+  return pthread_setschedparam(pthread_self(), Policy, &Param) == 0
              ? SetThreadPriorityResult::SUCCESS
              : SetThreadPriorityResult::FAILURE;
+
 #elif defined(__APPLE__)
-  // https://developer.apple.com/documentation/apple-silicon/tuning-your-code-s-performance-for-apple-silicon
-  //
-  // Background - Applies to work that isnâ€™t visible to the user and may take
-  // significant time to complete. Examples include indexing, backing up, or
-  // synchronizing data. This class emphasizes energy efficiency.
-  //
-  // Utility - Applies to work that takes anywhere from a few seconds to a few
-  // minutes to complete. Examples include downloading a document or importing
-  // data. This class offers a balance between responsiveness, performance, and
-  // energy efficiency.
-  const auto qosClass = [&]() {
-    switch (Priority) {
-    case ThreadPriority::Background:
-      return QOS_CLASS_BACKGROUND;
-    case ThreadPriority::Low:
-      return QOS_CLASS_UTILITY;
-    case ThreadPriority::Default:
-      return QOS_CLASS_DEFAULT;
-    }
-  }();
-  return !pthread_set_qos_class_self_np(qosClass, 0)
+  qos_class_t QosClass;
+  switch (Priority) {
+  case ThreadPriority::Background:
+    QosClass = QOS_CLASS_BACKGROUND;
+    break;
+  case ThreadPriority::Low:
+    QosClass = QOS_CLASS_UTILITY;
+    break;
+  case ThreadPriority::Default:
+    QosClass = QOS_CLASS_DEFAULT;
+    break;
+  }
+  return pthread_set_qos_class_self_np(QosClass, 0) == 0
              ? SetThreadPriorityResult::SUCCESS
              : SetThreadPriorityResult::FAILURE;
-#endif
+#else
+  (void)Priority;
   return SetThreadPriorityResult::FAILURE;
+#endif
 }
 
-#include <thread>
-
 static int computeHostNumHardwareThreads() {
 #if defined(__FreeBSD__)
-  cpuset_t mask;
-  CPU_ZERO(&mask);
-  if (cpuset_getaffinity(CPU_LEVEL_WHICH, CPU_WHICH_TID, -1, sizeof(mask),
-                         &mask) == 0)
-    return CPU_COUNT(&mask);
-#elif (defined(__linux__) || defined(__CYGWIN__))
+  cpuset_t Mask;
+  CPU_ZERO(&Mask);
+  if (cpuset_getaffinity(CPU_LEVEL_WHICH, CPU_WHICH_TID, -1, sizeof(Mask),
+                         &Mask) == 0)
+    return CPU_COUNT(&Mask);
+
+#elif defined(__linux__) || defined(__CYGWIN__)
   cpu_set_t Set;
   CPU_ZERO(&Set);
   if (sched_getaffinity(0, sizeof(Set), &Set) == 0)
     return CPU_COUNT(&Set);
+
+  const long NumConf = sysconf(_SC_NPROCESSORS_CONF);
+  if (NumConf > 0) {
+    const auto Count = static_cast<size_t>(NumConf);
+    const size_t Bytes = CPU_ALLOC_SIZE(Count);
+    cpu_set_t *DynSet = CPU_ALLOC(Count);
+    if (DynSet != nullptr) {
+      CPU_ZERO_S(Bytes, DynSet);
+      if (sched_getaffinity(0, Bytes, DynSet) == 0) {
+        const int Num = CPU_COUNT_S(Bytes, DynSet);
+        CPU_FREE(DynSet);
+        return Num;
+      }
+      CPU_FREE(DynSet);
+    }
+  }
 #endif
-  // Guard against std::thread::hardware_concurrency() returning 0.
-  if (unsigned Val = std::thread::hardware_concurrency())
-    return Val;
-  return 1;
+
+  const unsigned Val = std::thread::hardware_concurrency();
+  return Val > 0 ? static_cast<int>(Val) : 1;
 }
 
 void llvm::ThreadPoolStrategy::apply_thread_strategy(
-    unsigned ThreadPoolNum) const {}
+    unsigned ThreadPoolNum) const {
+  (void)ThreadPoolNum;
+}
 
 llvm::BitVector llvm::get_thread_affinity_mask() {
-  // FIXME: Implement
-  llvm_unreachable("Not implemented!");
+#if defined(__linux__) || defined(__CYGWIN__)
+  cpu_set_t Set;
+  CPU_ZERO(&Set);
+  if (sched_getaffinity(0, sizeof(Set), &Set) == 0) {
+    llvm::BitVector BV(CPU_SETSIZE, false);
+    for (int i = 0; i < CPU_SETSIZE; ++i) {
+      if (CPU_ISSET(i, &Set))
+        BV.set(static_cast<unsigned>(i));
+    }
+    const int Last = BV.find_last();
+    if (Last >= 0)
+      BV.resize(static_cast<unsigned>(Last + 1));
+    else
+      BV.clear();
+    return BV;
+  }
+
+  const long NumConf = sysconf(_SC_NPROCESSORS_CONF);
+  if (NumConf > 0) {
+    const auto Count = static_cast<size_t>(NumConf);
+    const size_t Bytes = CPU_ALLOC_SIZE(Count);
+    cpu_set_t *DynSet = CPU_ALLOC(Count);
+    if (DynSet != nullptr) {
+      CPU_ZERO_S(Bytes, DynSet);
+      if (sched_getaffinity(0, Bytes, DynSet) == 0) {
+        llvm::BitVector BV(static_cast<unsigned>(Count), false);
+        for (size_t i = 0; i < Count; ++i) {
+          if (CPU_ISSET_S(i, Bytes, DynSet))
+            BV.set(static_cast<unsigned>(i));
+        }
+        CPU_FREE(DynSet);
+        const int Last = BV.find_last();
+        if (Last >= 0)
+          BV.resize(static_cast<unsigned>(Last + 1));
+        else
+          BV.clear();
+        return BV;
+      }
+      CPU_FREE(DynSet);
+    }
+  }
+#endif
+  return llvm::BitVector();
 }
 
-unsigned llvm::get_cpus() { return 1; }
+unsigned llvm::get_cpus() {
+  const int HW = computeHostNumHardwareThreads();
+  return HW > 0 ? static_cast<unsigned>(HW) : 1;
+}
 
-#if (defined(__linux__) || defined(__CYGWIN__)) &&                             \
+#if (defined(__linux__) || defined(__CYGWIN__)) && \
     (defined(__i386__) || defined(__x86_64__))
-// On Linux, the number of physical cores can be computed from /proc/cpuinfo,
-// using the number of unique physical/core id pairs. The following
-// implementation reads the /proc/cpuinfo format on an x86_64 system.
+
 static int computeHostNumPhysicalCores() {
-  // Enabled represents the number of physical id/core id pairs with at least
-  // one processor id enabled by the CPU affinity mask.
-  cpu_set_t Affinity, Enabled;
+  cpu_set_t Affinity;
+  CPU_ZERO(&Affinity);
   if (sched_getaffinity(0, sizeof(Affinity), &Affinity) != 0)
     return -1;
-  CPU_ZERO(&Enabled);
 
-  // Read /proc/cpuinfo as a stream (until EOF reached). It cannot be
-  // mmapped because it appears to have 0 size.
   llvm::ErrorOr<std::unique_ptr<llvm::MemoryBuffer>> Text =
       llvm::MemoryBuffer::getFileAsStream("/proc/cpuinfo");
-  if (std::error_code EC = Text.getError()) {
-    llvm::errs() << "Can't read "
-                 << "/proc/cpuinfo: " << EC.message() << "\n";
+  if (!Text) {
+    cpu_set_t Set;
+    CPU_ZERO(&Set);
+    if (sched_getaffinity(0, sizeof(Set), &Set) == 0)
+      return CPU_COUNT(&Set);
     return -1;
   }
-  SmallVector<StringRef, 8> strs;
-  (*Text)->getBuffer().split(strs, "\n", /*MaxSplit=*/-1,
-                             /*KeepEmpty=*/false);
+
+  SmallVector<StringRef, 8> Lines;
+  (*Text)->getBuffer().split(Lines, "\n", -1, false);
+
   int CurProcessor = -1;
   int CurPhysicalId = -1;
   int CurSiblings = -1;
   int CurCoreId = -1;
-  for (StringRef Line : strs) {
-    std::pair<StringRef, StringRef> Data = Line.split(':');
-    auto Name = Data.first.trim();
-    auto Val = Data.second.trim();
-    // These fields are available if the kernel is configured with CONFIG_SMP.
-    if (Name == "processor")
-      Val.getAsInteger(10, CurProcessor);
-    else if (Name == "physical id")
-      Val.getAsInteger(10, CurPhysicalId);
-    else if (Name == "siblings")
-      Val.getAsInteger(10, CurSiblings);
-    else if (Name == "core id") {
-      Val.getAsInteger(10, CurCoreId);
-      // The processor id corresponds to an index into cpu_set_t.
-      if (CPU_ISSET(CurProcessor, &Affinity))
-        CPU_SET(CurPhysicalId * CurSiblings + CurCoreId, &Enabled);
+
+  cpu_set_t Enabled;
+  CPU_ZERO(&Enabled);
+
+  for (const StringRef &Line : Lines) {
+    const std::pair<StringRef, StringRef> KV = Line.split(':');
+    const StringRef FieldName = KV.first.trim();
+    const StringRef FieldVal = KV.second.trim();
+
+    if (FieldName.empty())
+      continue;
+
+    const char FirstChar = FieldName.front();
+
+    if (FirstChar == 'p') {
+      if (FieldName == "processor") {
+        FieldVal.getAsInteger(10, CurProcessor);
+        CurPhysicalId = -1;
+        CurSiblings = -1;
+        CurCoreId = -1;
+      } else if (FieldName == "physical id") {
+        FieldVal.getAsInteger(10, CurPhysicalId);
+      }
+    } else if (FirstChar == 's') {
+      if (FieldName == "siblings") {
+        FieldVal.getAsInteger(10, CurSiblings);
+      }
+    } else if (FirstChar == 'c') {
+      if (FieldName == "core id") {
+        FieldVal.getAsInteger(10, CurCoreId);
+
+        if (CurProcessor >= 0 && CurProcessor < CPU_SETSIZE &&
+            CurPhysicalId >= 0 && CurCoreId >= 0 && CurSiblings > 0 &&
+            CPU_ISSET(CurProcessor, &Affinity)) {
+          const int Index = CurPhysicalId * CurSiblings + CurCoreId;
+          if (Index >= 0 && Index < CPU_SETSIZE)
+            CPU_SET(Index, &Enabled);
+        }
+      }
     }
   }
-  return CPU_COUNT(&Enabled);
+
+  const int Count = CPU_COUNT(&Enabled);
+  if (Count > 0)
+    return Count;
+
+  return CPU_COUNT(&Affinity);
 }
+
 #elif (defined(__linux__) && defined(__s390x__)) || defined(_AIX)
+
 static int computeHostNumPhysicalCores() {
-  return sysconf(_SC_NPROCESSORS_ONLN);
+  const long Cores = sysconf(_SC_NPROCESSORS_ONLN);
+  return Cores > 0 ? static_cast<int>(Cores) : -1;
 }
+
 #elif defined(__linux__)
+
 static int computeHostNumPhysicalCores() {
   cpu_set_t Affinity;
+  CPU_ZERO(&Affinity);
   if (sched_getaffinity(0, sizeof(Affinity), &Affinity) == 0)
     return CPU_COUNT(&Affinity);
 
-  // The call to sched_getaffinity() may have failed because the Affinity
-  // mask is too small for the number of CPU's on the system (i.e. the
-  // system has more than 1024 CPUs). Allocate a mask large enough for
-  // twice as many CPUs.
-  cpu_set_t *DynAffinity;
-  DynAffinity = CPU_ALLOC(2048);
-  if (sched_getaffinity(0, CPU_ALLOC_SIZE(2048), DynAffinity) == 0) {
-    int NumCPUs = CPU_COUNT(DynAffinity);
+  cpu_set_t *DynAffinity = CPU_ALLOC(2048);
+  if (DynAffinity == nullptr)
+    return -1;
+
+  const size_t Bytes = CPU_ALLOC_SIZE(2048);
+  CPU_ZERO_S(Bytes, DynAffinity);
+
+  if (sched_getaffinity(0, Bytes, DynAffinity) == 0) {
+    const int NumCPUs = CPU_COUNT_S(Bytes, DynAffinity);
     CPU_FREE(DynAffinity);
     return NumCPUs;
   }
+
+  CPU_FREE(DynAffinity);
   return -1;
 }
+
 #elif defined(__APPLE__)
-// Gets the number of *physical cores* on the machine.
+
 static int computeHostNumPhysicalCores() {
-  uint32_t count;
-  size_t len = sizeof(count);
-  sysctlbyname("hw.physicalcpu", &count, &len, NULL, 0);
-  if (count < 1) {
-    int nm[2];
-    nm[0] = CTL_HW;
-    nm[1] = HW_AVAILCPU;
-    sysctl(nm, 2, &count, &len, NULL, 0);
-    if (count < 1)
-      return -1;
-  }
-  return count;
+  uint32_t Count = 0;
+  size_t Len = sizeof(Count);
+
+  if (sysctlbyname("hw.physicalcpu", &Count, &Len, nullptr, 0) == 0 &&
+      Count > 0)
+    return static_cast<int>(Count);
+
+  int Mib[2] = {CTL_HW, HW_AVAILCPU};
+  if (sysctl(Mib, 2, &Count, &Len, nullptr, 0) == 0 && Count > 0)
+    return static_cast<int>(Count);
+
+  return -1;
 }
+
 #elif defined(__MVS__)
+
 static int computeHostNumPhysicalCores() {
-  enum {
-    // Byte offset of the pointer to the Communications Vector Table (CVT) in
-    // the Prefixed Save Area (PSA). The table entry is a 31-bit pointer and
-    // will be zero-extended to uintptr_t.
+  enum : int {
     FLCCVT = 16,
-    // Byte offset of the pointer to the Common System Data Area (CSD) in the
-    // CVT. The table entry is a 31-bit pointer and will be zero-extended to
-    // uintptr_t.
     CVTCSD = 660,
-    // Byte offset to the number of live CPs in the LPAR, stored as a signed
-    // 32-bit value in the table.
     CSD_NUMBER_ONLINE_STANDARD_CPS = 264,
   };
-  char *PSA = 0;
-  char *CVT = reinterpret_cast<char *>(
-      static_cast<uintptr_t>(reinterpret_cast<unsigned int &>(PSA[FLCCVT])));
-  char *CSD = reinterpret_cast<char *>(
-      static_cast<uintptr_t>(reinterpret_cast<unsigned int &>(CVT[CVTCSD])));
-  return reinterpret_cast<int &>(CSD[CSD_NUMBER_ONLINE_STANDARD_CPS]);
+
+  const char *PSA = nullptr;
+  const char *CVT = reinterpret_cast<const char *>(static_cast<uintptr_t>(
+      reinterpret_cast<const unsigned int &>(PSA[FLCCVT])));
+  const char *CSD = reinterpret_cast<const char *>(static_cast<uintptr_t>(
+      reinterpret_cast<const unsigned int &>(CVT[CVTCSD])));
+  return reinterpret_cast<const int &>(CSD[CSD_NUMBER_ONLINE_STANDARD_CPS]);
 }
+
 #else
-// On other systems, return -1 to indicate unknown.
-static int computeHostNumPhysicalCores() { return -1; }
+
+static int computeHostNumPhysicalCores() {
+  return -1;
+}
+
 #endif
 
 int llvm::get_physical_cores() {
-  static int NumCores = computeHostNumPhysicalCores();
+  static const int NumCores = computeHostNumPhysicalCores();
   return NumCores;
 }
